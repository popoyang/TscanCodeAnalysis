<?xml version="1.0" encoding="UTF-8"?>
<results>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/extra/TSimpleJSONProtocol.h" line="264" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LookaheadReader::data_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LookaheadReader::data_,&quot;}" func_info="apache::thrift::protocol::TSimpleJSONProtocol::LookaheadReader" content="254:     uint32_t readDouble(double&amp; dub);
255: 
256:     uint32_t readString(std::string&amp; str);
257: 
258:     uint32_t readBinary(std::string&amp; str);
259: 
260:     class LookaheadReader {
261: 
262:       public:
263: 
264:         LookaheadReader(TTransport &amp;trans) :
265:             trans_(&amp;trans),
266:             hasData_(false) {
267:         }
268: 
269:         uint8_t read() {
270:             if (hasData_) {
271:                 hasData_ = false;
272:             } else {
273:                 trans_-&gt;readAll(&amp;data_, 1);
274:             }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/fastText/src/fasttext.cc" line="26" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FastText::start,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FastText::start,&quot;}" func_info="fasttext" content="16: #include &lt;iomanip&gt;
17: #include &lt;thread&gt;
18: #include &lt;string&gt;
19: #include &lt;vector&gt;
20: #include &lt;queue&gt;
21: #include &lt;algorithm&gt;
22: 
23: 
24: namespace fasttext {
25: 
26: FastText::FastText() : quant_(false) {}
27: 
28: void FastText::getVector(Vector&amp; vec, const std::string&amp; word) const {
29:   const std::vector&lt;int32_t&gt;&amp; ngrams = dict_-&gt;getSubwords(word);
30:   vec.zero();
31:   for (auto it = ngrams.begin(); it != ngrams.end(); ++it) {
32:     if (quant_) {
33:       vec.addRow(*qinput_, *it);
34:     } else {
35:       vec.addRow(*input_, *it);
36:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/fastText/src/qmatrix.cc" line="17" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;QMatrix::codes_,norm_codes_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;QMatrix::codes_,norm_codes_,&quot;}" func_info="fasttext" content="7:  * of patent rights can be found in the PATENTS file in the same directory.
8:  */
9: 
10: #include &quot;qmatrix.h&quot;
11: 
12: #include &lt;assert.h&gt;
13: #include &lt;iostream&gt;
14: 
15: namespace fasttext {
16: 
17: QMatrix::QMatrix() : qnorm_(false),
18:   m_(0), n_(0), codesize_(0) {}
19: 
20: QMatrix::QMatrix(const Matrix&amp; mat, int32_t dsub, bool qnorm)
21:       : qnorm_(qnorm), m_(mat.m_), n_(mat.n_),
22:         codesize_(m_ * ((n_ + dsub - 1) / dsub)) {
23:   if (codesize_ &gt; 0) {
24:     codes_ = new uint8_t[codesize_];
25:   }
26:   pq_ = std::unique_ptr&lt;ProductQuantizer&gt;( new ProductQuantizer(n_, dsub));
27:   if (qnorm_) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/MixSegment.hpp" line="60" id="logic" subid="redundantCondition" severity="Information" msg="Redundant condition: words[i].left==words[i].right. &apos;A || (!A &amp;&amp; B)&apos; is equivalent to &apos;A || B&apos;" web_identify="{&quot;identify&quot;:&quot;words[i].left==words[i].right. &apos;A || (!A &amp;&amp; B)&apos; is equivalent to &apos;A || B&apos;&quot;}" func_info="void MixSegment::Cut ( limonp :: LocalVector &lt; struct RuneStr &gt; :: const_iterator begin , limonp :: LocalVector &lt; struct RuneStr &gt; :: const_iterator end , std :: vector &lt; WordRange &gt; &amp; res , bool hmm ) const" content="50:     }
51:     vector&lt;WordRange&gt; words;
52:     assert(end &gt;= begin);
53:     words.reserve(end - begin);
54:     mpSeg_.Cut(begin, end, words);
55: 
56:     vector&lt;WordRange&gt; hmmRes;
57:     hmmRes.reserve(end - begin);
58:     for (size_t i = 0; i &lt; words.size(); i++) {
59:       //if mp Get a word, it&apos;s ok, put it into result
60:       if (words[i].left != words[i].right || (words[i].left == words[i].right &amp;&amp; mpSeg_.IsUserDictSingleChineseWord(words[i].left-&gt;rune))) {
61:         res.push_back(words[i]);
62:         continue;
63:       }
64: 
65:       // if mp Get a single one and it is not in userdict, collect it in sequence
66:       size_t j = i;
67:       while (j &lt; words.size() &amp;&amp; words[j].left == words[j].right &amp;&amp; !mpSeg_.IsUserDictSingleChineseWord(words[j].left-&gt;rune)) {
68:         j++;
69:       }
70: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/Unicode.hpp" line="23" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Word::unicode_offset,unicode_length,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Word::unicode_offset,unicode_length,&quot;}" func_info="cppjieba::Word" content="13: using std::string;
14: using std::vector;
15: 
16: typedef uint32_t Rune;
17: 
18: struct Word {
19:   string word;
20:   uint32_t offset;
21:   uint32_t unicode_offset;
22:   uint32_t unicode_length;
23:   Word(const string&amp; w, uint32_t o)
24:    : word(w), offset(o) {
25:   }
26:   Word(const string&amp; w, uint32_t o, uint32_t unicode_offset, uint32_t unicode_length)
27:           : word(w), offset(o), unicode_offset(unicode_offset), unicode_length(unicode_length) {
28:   }
29: }; // struct Word
30: 
31: inline std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, const Word&amp; w) {
32:   return os &lt;&lt; &quot;{\&quot;word\&quot;: \&quot;&quot; &lt;&lt; w.word &lt;&lt; &quot;\&quot;, \&quot;offset\&quot;: &quot; &lt;&lt; w.offset &lt;&lt; &quot;}&quot;;
33: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/Unicode.hpp" line="41" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RuneStr::unicode_offset,unicode_length,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RuneStr::unicode_offset,unicode_length,&quot;}" func_info="cppjieba::RuneStr" content="31: inline std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, const Word&amp; w) {
32:   return os &lt;&lt; &quot;{\&quot;word\&quot;: \&quot;&quot; &lt;&lt; w.word &lt;&lt; &quot;\&quot;, \&quot;offset\&quot;: &quot; &lt;&lt; w.offset &lt;&lt; &quot;}&quot;;
33: }
34: 
35: struct RuneStr {
36:   Rune rune;
37:   uint32_t offset;
38:   uint32_t len;
39:   uint32_t unicode_offset;
40:   uint32_t unicode_length;
41:   RuneStr(): rune(0), offset(0), len(0) {
42:   }
43:   RuneStr(Rune r, uint32_t o, uint32_t l)
44:     : rune(r), offset(o), len(l) {
45:   }
46:   RuneStr(Rune r, uint32_t o, uint32_t l, uint32_t unicode_offset, uint32_t unicode_length)
47:           : rune(r), offset(o), len(l), unicode_offset(unicode_offset), unicode_length(unicode_length) {
48:   }
49: }; // struct RuneStr
50: 
51: inline std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, const RuneStr&amp; r) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/Unicode.hpp" line="43" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RuneStr::unicode_offset,unicode_length,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RuneStr::unicode_offset,unicode_length,&quot;}" func_info="cppjieba::RuneStr" content="33: }
34: 
35: struct RuneStr {
36:   Rune rune;
37:   uint32_t offset;
38:   uint32_t len;
39:   uint32_t unicode_offset;
40:   uint32_t unicode_length;
41:   RuneStr(): rune(0), offset(0), len(0) {
42:   }
43:   RuneStr(Rune r, uint32_t o, uint32_t l)
44:     : rune(r), offset(o), len(l) {
45:   }
46:   RuneStr(Rune r, uint32_t o, uint32_t l, uint32_t unicode_offset, uint32_t unicode_length)
47:           : rune(r), offset(o), len(l), unicode_offset(unicode_offset), unicode_length(unicode_length) {
48:   }
49: }; // struct RuneStr
50: 
51: inline std::ostream&amp; operator &lt;&lt; (std::ostream&amp; os, const RuneStr&amp; r) {
52:   return os &lt;&lt; &quot;{\&quot;rune\&quot;: \&quot;&quot; &lt;&lt; r.rune &lt;&lt; &quot;\&quot;, \&quot;offset\&quot;: &quot; &lt;&lt; r.offset &lt;&lt; &quot;, \&quot;len\&quot;: &quot; &lt;&lt; r.len &lt;&lt; &quot;}&quot;;
53: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/limonp/Md5.hpp" line="232" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MD5::digestRaw,digestChars,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MD5::digestRaw,digestChars,&quot;}" func_info="limonp::MD5" content="222: 
223:     for (i = 0, j = 0; j &lt; len; i++, j += 4)
224:       output[i] = ((UINT4)input[j]) | (((UINT4)input[j+1]) &lt;&lt; 8) |
225:                   (((UINT4)input[j+2]) &lt;&lt; 16) | (((UINT4)input[j+3]) &lt;&lt; 24);
226:   }
227:   //#pragma endregion
228: 
229: 
230:  public:
231:   // MAIN FUNCTIONS
232:   MD5() {
233:     Init() ;
234:   }
235: 
236:   // MD5 initialization. Begins an MD5 operation, writing a new context.
237:   void Init() {
238:     context.count[0] = context.count[1] = 0;
239: 
240:     // Load magic initialization constants.
241:     context.state[0] = 0x67452301;
242:     context.state[1] = 0xefcdab89;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/jieba/limonp/Thread.hpp" line="11" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;IThread::thread_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;IThread::thread_,&quot;}" func_info="limonp::IThread" content="1: #ifndef LIMONP_THREAD_HPP
2: #define LIMONP_THREAD_HPP
3: 
4: #include &quot;Logging.hpp&quot;
5: #include &quot;NonCopyable.hpp&quot;
6: 
7: namespace limonp {
8: 
9: class IThread: NonCopyable {
10:  public:
11:   IThread(): isStarted(false), isJoined(false) {
12:   }
13:   virtual ~IThread() {
14:     if(isStarted &amp;&amp; !isJoined) {
15:       XCHECK(!pthread_detach(thread_));
16:     }
17:   };
18: 
19:   virtual void Run() = 0;
20:   void Start() {
21:     XCHECK(!isStarted);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/call.h" line="215" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpSendInitialMetadata::flags_,initial_metadata_count_,initial_metadata_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpSendInitialMetadata::flags_,initial_metadata_count_,initial_metadata_,&quot;}" func_info="grpc::internal::CallOpSendInitialMetadata" content="205: /// used for generating multiple names for the same thing.
206: template &lt;int I&gt;
207: class CallNoOp {
208:  protected:
209:   void AddOp(grpc_op* ops, size_t* nops) {}
210:   void FinishOp(bool* status) {}
211: };
212: 
213: class CallOpSendInitialMetadata {
214:  public:
215:   CallOpSendInitialMetadata() : send_(false) {
216:     maybe_compression_level_.is_set = false;
217:   }
218: 
219:   void SendInitialMetadata(
220:       const std::multimap&lt;grpc::string, grpc::string&gt;&amp; metadata,
221:       uint32_t flags) {
222:     maybe_compression_level_.is_set = false;
223:     send_ = true;
224:     flags_ = flags;
225:     initial_metadata_ =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/call.h" line="466" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpServerSendStatus::trailing_metadata_count_,trailing_metadata_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpServerSendStatus::trailing_metadata_count_,trailing_metadata_,&quot;}" func_info="grpc::internal::CallOpServerSendStatus" content="456:     op-&gt;reserved = NULL;
457:   }
458:   void FinishOp(bool* status) { send_ = false; }
459: 
460:  private:
461:   bool send_;
462: };
463: 
464: class CallOpServerSendStatus {
465:  public:
466:   CallOpServerSendStatus() : send_status_available_(false) {}
467: 
468:   void ServerSendStatus(
469:       const std::multimap&lt;grpc::string, grpc::string&gt;&amp; trailing_metadata,
470:       const Status&amp; status) {
471:     send_error_details_ = status.error_details();
472:     trailing_metadata_ = FillMetadataArray(
473:         trailing_metadata, &amp;trailing_metadata_count_, send_error_details_);
474:     send_status_available_ = true;
475:     send_status_code_ = static_cast&lt;grpc_status_code&gt;(status.error_code());
476:     send_error_message_ = status.error_message();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/call.h" line="541" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpClientRecvStatus::client_context_,metadata_map_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpClientRecvStatus::client_context_,metadata_map_,&quot;}" func_info="grpc::internal::CallOpClientRecvStatus" content="531:     if (metadata_map_ == nullptr) return;
532:     metadata_map_ = nullptr;
533:   }
534: 
535:  private:
536:   MetadataMap* metadata_map_;
537: };
538: 
539: class CallOpClientRecvStatus {
540:  public:
541:   CallOpClientRecvStatus()
542:       : recv_status_(nullptr), debug_error_string_(nullptr) {}
543: 
544:   void ClientRecvStatus(ClientContext* context, Status* status) {
545:     client_context_ = context;
546:     metadata_map_ = &amp;client_context_-&gt;trailing_metadata_;
547:     recv_status_ = status;
548:     error_message_ = g_core_codegen_interface-&gt;grpc_empty_slice();
549:   }
550: 
551:  protected:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/grpc_library.h" line="45" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [g_glip] to null at line 44 implies that [g_glip ] might be null.Dereferencing null pointer [g_glip]." web_identify="{&quot;identify&quot;:&quot;g_glip&quot;}" func_info="GrpcLibraryCodegen::GrpcLibraryCodegen ( bool call_grpc_init = true ) : grpc_init_called_ ( false )" content="35: extern GrpcLibraryInterface* g_glip;
36: 
37: /// Classes that require gRPC to be initialized should inherit from this class.
38: class GrpcLibraryCodegen {
39:  public:
40:   GrpcLibraryCodegen(bool call_grpc_init = true) : grpc_init_called_(false) {
41:     if (call_grpc_init) {
42:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
43:                          &quot;gRPC library not initialized. See &quot;
44:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
45:       g_glip-&gt;init();
46:       grpc_init_called_ = true;
47:     }
48:   }
49:   virtual ~GrpcLibraryCodegen() {
50:     if (grpc_init_called_) {
51:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
52:                          &quot;gRPC library not initialized. See &quot;
53:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
54:       g_glip-&gt;shutdown();
55:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/grpc_library.h" line="54" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [g_glip] to null at line 53 implies that [g_glip ] might be null.Dereferencing null pointer [g_glip]." web_identify="{&quot;identify&quot;:&quot;g_glip&quot;}" func_info="virtual ~ GrpcLibraryCodegen::GrpcLibraryCodegen ( )" content="44:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
45:       g_glip-&gt;init();
46:       grpc_init_called_ = true;
47:     }
48:   }
49:   virtual ~GrpcLibraryCodegen() {
50:     if (grpc_init_called_) {
51:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
52:                          &quot;gRPC library not initialized. See &quot;
53:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
54:       g_glip-&gt;shutdown();
55:     }
56:   }
57: 
58:  private:
59:   bool grpc_init_called_;
60: };
61: 
62: }  // namespace grpc
63: 
64: #endif  // GRPCPP_IMPL_CODEGEN_GRPC_LIBRARY_H
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/server_interface.h" line="275" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [method] to null at line 274 implies that [method ] might be null.Dereferencing null pointer [method]." web_identify="{&quot;identify&quot;:&quot;method&quot;}" func_info="&gt; void ServerInterface::RequestAsyncCall ( internal :: RpcServiceMethod * method , ServerContext * context , internal :: ServerAsyncStreamingInterface * stream , CompletionQueue * call_cq , ServerCompletionQueue * notification_cq , void * tag , Message * message )" content="265:   };
266: 
267:   template &lt;class Message&gt;
268:   void RequestAsyncCall(internal::RpcServiceMethod* method,
269:                         ServerContext* context,
270:                         internal::ServerAsyncStreamingInterface* stream,
271:                         CompletionQueue* call_cq,
272:                         ServerCompletionQueue* notification_cq, void* tag,
273:                         Message* message) {
274:     GPR_CODEGEN_ASSERT(method);
275:     new PayloadAsyncRequest&lt;Message&gt;(method-&gt;server_tag(), this, context,
276:                                      stream, call_cq, notification_cq, tag,
277:                                      message);
278:   }
279: 
280:   void RequestAsyncCall(internal::RpcServiceMethod* method,
281:                         ServerContext* context,
282:                         internal::ServerAsyncStreamingInterface* stream,
283:                         CompletionQueue* call_cq,
284:                         ServerCompletionQueue* notification_cq, void* tag) {
285:     GPR_CODEGEN_ASSERT(method);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/include/grpcpp/impl/codegen/server_interface.h" line="286" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [method] to null at line 285 implies that [method ] might be null.Dereferencing null pointer [method]." web_identify="{&quot;identify&quot;:&quot;method&quot;}" func_info="void ServerInterface::RequestAsyncCall ( internal :: RpcServiceMethod * method , ServerContext * context , internal :: ServerAsyncStreamingInterface * stream , CompletionQueue * call_cq , ServerCompletionQueue * notification_cq , void * tag )" content="276:                                      stream, call_cq, notification_cq, tag,
277:                                      message);
278:   }
279: 
280:   void RequestAsyncCall(internal::RpcServiceMethod* method,
281:                         ServerContext* context,
282:                         internal::ServerAsyncStreamingInterface* stream,
283:                         CompletionQueue* call_cq,
284:                         ServerCompletionQueue* notification_cq, void* tag) {
285:     GPR_CODEGEN_ASSERT(method);
286:     new NoPayloadAsyncRequest(method-&gt;server_tag(), this, context, stream,
287:                               call_cq, notification_cq, tag);
288:   }
289: 
290:   void RequestAsyncGenericCall(GenericServerContext* context,
291:                                internal::ServerAsyncStreamingInterface* stream,
292:                                CompletionQueue* call_cq,
293:                                ServerCompletionQueue* notification_cq,
294:                                void* tag) {
295:     new GenericAsyncRequest(this, context, stream, call_cq, notification_cq,
296:                             tag, true);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/filters/client_channel/subchannel.cc" line="600" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [c.connected_subchannel] to null at line 573 implies that [c.connected_subchannel ] might be null.Dereferencing null pointer [c.connected_subchannel]." web_identify="{&quot;identify&quot;:&quot;c.connected_subchannel&quot;}" func_info="static void on_connected_subchannel_connectivity_changed ( void * p , struct grpc_error * error )" content="590:         connected_subchannel_watcher-&gt;connectivity_state =
591:             GRPC_CHANNEL_SHUTDOWN;
592:       }
593:       break;
594:     }
595:     default: {
596:       grpc_connectivity_state_set(
597:           &amp;c-&gt;state_tracker, connected_subchannel_watcher-&gt;connectivity_state,
598:           GRPC_ERROR_REF(error), &quot;reflect_child&quot;);
599:       GRPC_SUBCHANNEL_WEAK_REF(c, &quot;state_watcher&quot;);
600:       c-&gt;connected_subchannel-&gt;NotifyOnStateChange(
601:           nullptr, &amp;connected_subchannel_watcher-&gt;connectivity_state,
602:           &amp;connected_subchannel_watcher-&gt;closure);
603:       connected_subchannel_watcher = nullptr;
604:     }
605:   }
606:   gpr_mu_unlock(mu);
607:   GRPC_SUBCHANNEL_WEAK_UNREF(c, &quot;state_watcher&quot;);
608:   gpr_free(connected_subchannel_watcher);
609: }
610: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/transport/chttp2/server/chttp2_server.cc" line="346" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [errors] suggests that it may be null, but it has already been dereferenced at line 294." web_identify="{&quot;identify&quot;:&quot;errors&quot;}" func_info="struct grpc_error * grpc_chttp2_server_add_port ( struct grpc_server * server , const char * addr , grpc_channel_args * args , int * port_num )" content="336:   }
337:   if (tcp_server) {
338:     grpc_tcp_server_unref(tcp_server);
339:   } else {
340:     grpc_channel_args_destroy(args);
341:     gpr_free(state);
342:   }
343:   *port_num = 0;
344: 
345: done:
346:   if (errors != nullptr) {
347:     for (i = 0; i &lt; naddrs; i++) {
348:       GRPC_ERROR_UNREF(errors[i]);
349:     }
350:     gpr_free(errors);
351:   }
352:   return err;
353: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/transport/chttp2/transport/chttp2_transport.cc" line="2832" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Chttp2IncomingByteStream::next_action_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Chttp2IncomingByteStream::next_action_,&quot;}" func_info="grpc_core" content="2822:     s-&gt;on_next = nullptr;
2823:     GRPC_ERROR_UNREF(s-&gt;byte_stream_error);
2824:     s-&gt;byte_stream_error = GRPC_ERROR_NONE;
2825:     grpc_chttp2_cancel_stream(s-&gt;t, s, GRPC_ERROR_REF(error));
2826:     s-&gt;byte_stream_error = GRPC_ERROR_REF(error);
2827:   }
2828: }
2829: 
2830: namespace grpc_core {
2831: 
2832: Chttp2IncomingByteStream::Chttp2IncomingByteStream(
2833:     grpc_chttp2_transport* transport, grpc_chttp2_stream* stream,
2834:     uint32_t frame_size, uint32_t flags)
2835:     : ByteStream(frame_size, flags),
2836:       transport_(transport),
2837:       stream_(stream),
2838:       remaining_bytes_(frame_size) {
2839:   gpr_ref_init(&amp;refs_, 2);
2840:   GRPC_ERROR_UNREF(stream-&gt;byte_stream_error);
2841:   stream-&gt;byte_stream_error = GRPC_ERROR_NONE;
2842: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/transport/chttp2/transport/frame_data.cc" line="222" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [p.parsing_frame] suggests that it may be null, but it has already been dereferenced at line 207." web_identify="{&quot;identify&quot;:&quot;p.parsing_frame&quot;}" func_info="struct grpc_error * grpc_deframe_unprocessed_incoming_frames ( struct grpc_chttp2_data_parser * p , struct grpc_chttp2_stream * s , grpc_slice_buffer * slices , struct grpc_slice * slice_out , grpc_core::OrphanablePtr &lt; grpc_core::ByteStream &gt; * stream_out )" content="212:         s-&gt;pending_byte_stream = true;
213: 
214:         if (cur != end) {
215:           grpc_slice_buffer_undo_take_first(
216:               slices, grpc_slice_sub(slice, static_cast&lt;size_t&gt;(cur - beg),
217:                                      static_cast&lt;size_t&gt;(end - beg)));
218:         }
219:         grpc_slice_unref_internal(slice);
220:         return GRPC_ERROR_NONE;
221:       case GRPC_CHTTP2_DATA_FRAME: {
222:         GPR_ASSERT(p-&gt;parsing_frame != nullptr);
223:         GPR_ASSERT(slice_out != nullptr);
224:         if (cur == end) {
225:           grpc_slice_unref_internal(slice);
226:           continue;
227:         }
228:         uint32_t remaining = static_cast&lt;uint32_t&gt;(end - cur);
229:         if (remaining == p-&gt;frame_size) {
230:           s-&gt;stats.incoming.data_bytes += remaining;
231:           if (GRPC_ERROR_NONE !=
232:               (error = p-&gt;parsing_frame-&gt;Push(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/transport/chttp2/transport/parsing.cc" line="386" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [s] to null at line 380 implies that [s ] might be null.Dereferencing null pointer [s]." web_identify="{&quot;identify&quot;:&quot;s&quot;}" func_info="static grpc_error * init_data_frame_parser ( struct grpc_chttp2_transport * t )" content="376:     t-&gt;ping_state.last_ping_sent_time = GRPC_MILLIS_INF_PAST;
377:     return GRPC_ERROR_NONE;
378:   } else if (grpc_error_get_int(err, GRPC_ERROR_INT_STREAM_ID, nullptr)) {
379:     /* handle stream errors by closing the stream */
380:     if (s != nullptr) {
381:       grpc_chttp2_mark_stream_closed(t, s, true, false, err);
382:     }
383:     grpc_slice_buffer_add(
384:         &amp;t-&gt;qbuf, grpc_chttp2_rst_stream_create(t-&gt;incoming_stream_id,
385:                                                 GRPC_HTTP2_PROTOCOL_ERROR,
386:                                                 &amp;s-&gt;stats.outgoing));
387:     return init_skip_frame_parser(t, 0);
388:   } else {
389:     return err;
390:   }
391: }
392: 
393: static void free_timeout(void* p) { gpr_free(p); }
394: 
395: static void on_initial_header(void* tp, grpc_mdelem md) {
396:   GPR_TIMER_SCOPE(&quot;on_initial_header&quot;, 0);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/ext/transport/chttp2/transport/writing.cc" line="406" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;StreamWriteContext::extra_headers_for_trailing_metadata_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;StreamWriteContext::extra_headers_for_trailing_metadata_,&quot;}" func_info="StreamWriteContext" content="396:  private:
397:   WriteContext* write_context_;
398:   grpc_chttp2_transport* t_;
399:   grpc_chttp2_stream* s_;
400:   const size_t sending_bytes_before_;
401:   bool is_last_frame_ = false;
402: };
403: 
404: class StreamWriteContext {
405:  public:
406:   StreamWriteContext(WriteContext* write_context, grpc_chttp2_stream* s)
407:       : write_context_(write_context), t_(write_context-&gt;transport()), s_(s) {
408:     GRPC_CHTTP2_IF_TRACING(
409:         gpr_log(GPR_INFO, &quot;W:%p %s[%d] im-(sent,send)=(%d,%d) announce=%d&quot;, t_,
410:                 t_-&gt;is_client ? &quot;CLIENT&quot; : &quot;SERVER&quot;, s-&gt;id,
411:                 s-&gt;sent_initial_metadata, s-&gt;send_initial_metadata != nullptr,
412:                 (int)(s-&gt;flow_control-&gt;local_window_delta() -
413:                       s-&gt;flow_control-&gt;announced_window_delta())));
414:   }
415: 
416:   void FlushInitialMetadata() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/error.cc" line="430" id="compute" subid="SizeofForPointerSize" severity="Warning" msg="Use sizeof data of &apos;&amp;out.atomics&apos; instead of sizeof the pointer." web_identify="{&quot;identify&quot;:&quot;&amp;out.atomics&quot;}" func_info="static struct grpc_error * copy_error_and_unref ( struct grpc_error * in )" content="420:       new_arena_capacity = static_cast&lt;uint8_t&gt;(3 * new_arena_capacity / 2);
421:     }
422:     out = static_cast&lt;grpc_error*&gt;(
423:         gpr_malloc(sizeof(*in) + new_arena_capacity * sizeof(intptr_t)));
424: #ifndef NDEBUG
425:     if (grpc_trace_error_refcount.enabled()) {
426:       gpr_log(GPR_DEBUG, &quot;%p create copying %p&quot;, out, in);
427:     }
428: #endif
429:     // bulk memcpy of the rest of the struct.
430:     size_t skip = sizeof(&amp;out-&gt;atomics);
431:     memcpy((void*)((uintptr_t)out + skip), (void*)((uintptr_t)in + skip),
432:            sizeof(*in) + (in-&gt;arena_size * sizeof(intptr_t)) - skip);
433:     // manually set the atomics and the new capacity
434:     gpr_atm_no_barrier_store(&amp;out-&gt;atomics.error_string, 0);
435:     gpr_ref_init(&amp;out-&gt;atomics.refs, 1);
436:     out-&gt;arena_capacity = new_arena_capacity;
437:     ref_strs(out);
438:     ref_errs(out);
439:     GRPC_ERROR_UNREF(in);
440:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/ev_epollex_linux.cc" line="744" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [specific_worker] suggests that it may be null, but it has already been dereferenced at line 742. The error is in macros." web_identify="{&quot;identify&quot;:&quot;specific_worker&quot;}" func_info="static struct grpc_error * kick_one_worker ( struct grpc_pollset_worker * specific_worker )" content="734:   }
735: }
736: 
737: /* pollset-&gt;mu must be held before calling this function,
738:  * pollset-&gt;active_pollable-&gt;mu &amp; specific_worker-&gt;pollable_obj-&gt;mu must not be
739:  * held */
740: static grpc_error* kick_one_worker(grpc_pollset_worker* specific_worker) {
741:   GPR_TIMER_SCOPE(&quot;kick_one_worker&quot;, 0);
742:   pollable* p = specific_worker-&gt;pollable_obj;
743:   grpc_core::MutexLock lock(&amp;p-&gt;mu);
744:   GPR_ASSERT(specific_worker != nullptr);
745:   if (specific_worker-&gt;kicked) {
746:     if (grpc_polling_trace.enabled()) {
747:       gpr_log(GPR_INFO, &quot;PS:%p kicked_specific_but_already_kicked&quot;, p);
748:     }
749:     GRPC_STATS_INC_POLLSET_KICKED_AGAIN();
750:     return GRPC_ERROR_NONE;
751:   }
752:   if (gpr_tls_get(&amp;g_current_thread_worker) == (intptr_t)specific_worker) {
753:     if (grpc_polling_trace.enabled()) {
754:       gpr_log(GPR_INFO, &quot;PS:%p kicked_specific_but_awake&quot;, p);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/ev_poll_posix.cc" line="1717" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [result] suggests that it may be null, but it has already been dereferenced at line 1709." web_identify="{&quot;identify&quot;:&quot;result&quot;}" func_info="static int cvfd_poll ( struct pollfd * fds , nfds_t nfds , int timeout )" content="1707:         if (res &gt;= 0) res++;
1708:       }
1709:     } else if (!skip_poll &amp;&amp; fds[i].fd &gt;= 0 &amp;&amp; result-&gt;completed) {
1710:       fds[i].revents = result-&gt;fds[idx].revents;
1711:       idx++;
1712:     }
1713:   }
1714: 
1715:   gpr_free(fd_cvs);
1716:   gpr_free(pollcv);
1717:   if (result) {
1718:     decref_poll_result(result);
1719:   }
1720: 
1721:   gpr_mu_unlock(&amp;g_cvfds.mu);
1722: 
1723:   return res;
1724: }
1725: 
1726: static void global_cv_fd_table_init() {
1727:   gpr_mu_init(&amp;g_cvfds.mu);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/ev_poll_posix.cc" line="956" id="suspicious" subid="autovar" severity="Warning" msg="Address of local auto-variable assigned to a function parameter." web_identify="{&quot;identify&quot;:&quot;*&quot;}" func_info="static struct grpc_error * pollset_work ( struct grpc_pollset * pollset , struct grpc_pollset_worker * * worker_hdl , long deadline )" content="946:     *composite = GRPC_ERROR_CREATE_FROM_STATIC_STRING(&quot;pollset_work&quot;);
947:   }
948:   *composite = grpc_error_add_child(*composite, error);
949: }
950: 
951: static grpc_error* pollset_work(grpc_pollset* pollset,
952:                                 grpc_pollset_worker** worker_hdl,
953:                                 grpc_millis deadline) {
954:   GPR_TIMER_SCOPE(&quot;pollset_work&quot;, 0);
955:   grpc_pollset_worker worker;
956:   if (worker_hdl) *worker_hdl = &amp;worker;
957:   grpc_error* error = GRPC_ERROR_NONE;
958: 
959:   /* Avoid malloc for small number of elements. */
960:   enum { inline_elements = 96 };
961:   struct pollfd pollfd_space[inline_elements];
962:   struct grpc_fd_watcher watcher_space[inline_elements];
963: 
964:   /* pollset-&gt;mu already held */
965:   int added_worker = 0;
966:   int locked = 1;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/executor.cc" line="52" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GrpcExecutor::thd_state_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GrpcExecutor::thd_state_,&quot;}" func_info="global" content="42: 
43: #define EXECUTOR_TRACE0(str)            \
44:   if (executor_trace.enabled()) {       \
45:     gpr_log(GPR_INFO, &quot;EXECUTOR &quot; str); \
46:   }
47: 
48: grpc_core::TraceFlag executor_trace(false, &quot;executor&quot;);
49: 
50: GPR_TLS_DECL(g_this_thread_state);
51: 
52: GrpcExecutor::GrpcExecutor(const char* name) : name_(name) {
53:   adding_thread_lock_ = GPR_SPINLOCK_STATIC_INITIALIZER;
54:   gpr_atm_rel_store(&amp;num_threads_, 0);
55:   max_threads_ = GPR_MAX(1, 2 * gpr_cpu_num_cores());
56: }
57: 
58: void GrpcExecutor::Init() { SetThreading(true); }
59: 
60: size_t GrpcExecutor::RunClosures(const char* executor_name,
61:                                  grpc_closure_list list) {
62:   size_t n = 0;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/pollset_windows.cc" line="113" id="suspicious" subid="autovar" severity="Warning" msg="Address of local auto-variable assigned to a function parameter." web_identify="{&quot;identify&quot;:&quot;*&quot;}" func_info="static struct grpc_error * pollset_work ( struct grpc_pollset * pollset , struct grpc_pollset_worker * * worker_hdl , long deadline )" content="103:     pollset-&gt;on_shutdown = closure;
104:   }
105: }
106: 
107: static void pollset_destroy(grpc_pollset* pollset) {}
108: 
109: static grpc_error* pollset_work(grpc_pollset* pollset,
110:                                 grpc_pollset_worker** worker_hdl,
111:                                 grpc_millis deadline) {
112:   grpc_pollset_worker worker;
113:   if (worker_hdl) *worker_hdl = &amp;worker;
114: 
115:   int added_worker = 0;
116:   worker.links[GRPC_POLLSET_WORKER_LINK_POLLSET].next =
117:       worker.links[GRPC_POLLSET_WORKER_LINK_POLLSET].prev =
118:           worker.links[GRPC_POLLSET_WORKER_LINK_GLOBAL].next =
119:               worker.links[GRPC_POLLSET_WORKER_LINK_GLOBAL].prev = NULL;
120:   worker.kicked = 0;
121:   worker.pollset = pollset;
122:   gpr_cv_init(&amp;worker.cv);
123:   if (!pollset-&gt;kicked_without_pollers &amp;&amp; !pollset-&gt;shutting_down) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/pollset_windows.cc" line="128" id="suspicious" subid="autovar" severity="Warning" msg="Returning the address of a stack variable [worker]." web_identify="{&quot;identify&quot;:&quot;worker&quot;}" func_info="static struct grpc_error * pollset_work ( struct grpc_pollset * pollset , struct grpc_pollset_worker * * worker_hdl , long deadline )" content="118:           worker.links[GRPC_POLLSET_WORKER_LINK_GLOBAL].next =
119:               worker.links[GRPC_POLLSET_WORKER_LINK_GLOBAL].prev = NULL;
120:   worker.kicked = 0;
121:   worker.pollset = pollset;
122:   gpr_cv_init(&amp;worker.cv);
123:   if (!pollset-&gt;kicked_without_pollers &amp;&amp; !pollset-&gt;shutting_down) {
124:     if (g_active_poller == NULL) {
125:       grpc_pollset_worker* next_worker;
126:       /* become poller */
127:       pollset-&gt;is_iocp_worker = 1;
128:       g_active_poller = &amp;worker;
129:       gpr_mu_unlock(&amp;grpc_polling_mu);
130:       grpc_iocp_work(deadline);
131:       grpc_core::ExecCtx::Get()-&gt;Flush();
132:       gpr_mu_lock(&amp;grpc_polling_mu);
133:       pollset-&gt;is_iocp_worker = 0;
134:       g_active_poller = NULL;
135:       /* try to get a worker from this pollsets worker list */
136:       next_worker = pop_front_worker(&amp;pollset-&gt;root_worker,
137:                                      GRPC_POLLSET_WORKER_LINK_POLLSET);
138:       if (next_worker == NULL) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/tcp_client_windows.cc" line="221" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [socket] suggests that it may be null, but it has already been dereferenced at line 184." web_identify="{&quot;identify&quot;:&quot;socket&quot;}" func_info="static void tcp_connect ( struct grpc_closure * on_done , struct grpc_endpoint * * endpoint , struct grpc_pollset_set * interested_parties , const grpc_channel_args * channel_args , const struct grpc_resolved_address * addr , long deadline )" content="211:   return;
212: 
213: failure:
214:   GPR_ASSERT(error != GRPC_ERROR_NONE);
215:   char* target_uri = grpc_sockaddr_to_uri(addr);
216:   grpc_error* final_error = grpc_error_set_str(
217:       GRPC_ERROR_CREATE_REFERENCING_FROM_STATIC_STRING(&quot;Failed to connect&quot;,
218:                                                        &amp;error, 1),
219:       GRPC_ERROR_STR_TARGET_ADDRESS, grpc_slice_from_copied_string(target_uri));
220:   GRPC_ERROR_UNREF(error);
221:   if (socket != NULL) {
222:     grpc_winsocket_destroy(socket);
223:   } else if (sock != INVALID_SOCKET) {
224:     closesocket(sock);
225:   }
226:   GRPC_CLOSURE_SCHED(on_done, final_error);
227: }
228: 
229: grpc_tcp_client_vtable grpc_windows_tcp_client_vtable = {tcp_connect};
230: 
231: #endif /* GRPC_WINSOCK_SOCKET */
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/iomgr/udp_server.cc" line="144" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GrpcUdpListener::read_closure_,write_closure_,orphan_fd_closure_,destroyed_closure_,do_read_closure_,do_write_closure_,notify_on_write_closure_,notify_on_write_armed_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GrpcUdpListener::read_closure_,write_closure_,orphan_fd_closure_,destroyed_closure_,do_read_closure_,do_write_closure_,notify_on_write_closure_,notify_on_write_armed_,&quot;}" func_info="global" content="134:   // True if fd has been shutdown.
135:   bool already_shutdown_;
136:   // Object actually handles I/O events. Assigned in StartListening().
137:   GrpcUdpHandler* udp_handler_ = nullptr;
138:   // To be notified on destruction.
139:   GrpcUdpHandlerFactory* handler_factory_ = nullptr;
140:   // Required to access above fields.
141:   gpr_mu mutex_;
142: };
143: 
144: GrpcUdpListener::GrpcUdpListener(grpc_udp_server* server, int fd,
145:                                  const grpc_resolved_address* addr)
146:     : fd_(fd),
147:       server_(server),
148:       orphan_notified_(false),
149:       already_shutdown_(false) {
150:   char* addr_str;
151:   char* name;
152:   grpc_sockaddr_to_string(&amp;addr_str, addr, 1);
153:   gpr_asprintf(&amp;name, &quot;udp-server-listener:%s&quot;, addr_str);
154:   gpr_free(addr_str);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/security/credentials/oauth2/oauth2_credentials.cc" line="200" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [null_terminated_body] suggests that it may be null, but it has already been dereferenced at line 136 in function[memcpy]." web_identify="{&quot;identify&quot;:&quot;null_terminated_body&quot;}" func_info="grpc_credentials_status grpc_oauth2_token_fetcher_credentials_parse_server_response ( const grpc_http_response * response , struct grpc_mdelem * token_md , int64_t * token_lifetime )" content="190:         grpc_slice_from_static_string(GRPC_AUTHORIZATION_METADATA_KEY),
191:         grpc_slice_from_copied_string(new_access_token));
192:     status = GRPC_CREDENTIALS_OK;
193:   }
194: 
195: end:
196:   if (status != GRPC_CREDENTIALS_OK &amp;&amp; !GRPC_MDISNULL(*token_md)) {
197:     GRPC_MDELEM_UNREF(*token_md);
198:     *token_md = GRPC_MDNULL;
199:   }
200:   if (null_terminated_body != nullptr) gpr_free(null_terminated_body);
201:   if (new_access_token != nullptr) gpr_free(new_access_token);
202:   if (json != nullptr) grpc_json_destroy(json);
203:   return status;
204: }
205: 
206: static void on_oauth2_token_fetcher_http_response(void* user_data,
207:                                                   grpc_error* error) {
208:   GRPC_LOG_IF_ERROR(&quot;oauth_fetch&quot;, GRPC_ERROR_REF(error));
209:   grpc_credentials_metadata_request* r =
210:       static_cast&lt;grpc_credentials_metadata_request*&gt;(user_data);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/security/security_connector/security_connector.cc" line="1169" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [c] suggests that it may be null, but it has already been dereferenced at line 1167." web_identify="{&quot;identify&quot;:&quot;c&quot;}" func_info="int grpc_ssl_server_security_connector_create ( struct grpc_server_credentials * gsc , struct grpc_server_security_connector * * sc )" content="1159:     if (result != TSI_OK) {
1160:       gpr_log(GPR_ERROR, &quot;Handshaker factory creation failed with %s.&quot;,
1161:               tsi_result_to_string(result));
1162:       retval = GRPC_SECURITY_ERROR;
1163:     }
1164:   }
1165: 
1166:   if (retval == GRPC_SECURITY_OK) {
1167:     *sc = &amp;c-&gt;base;
1168:   } else {
1169:     if (c != nullptr) ssl_server_destroy(&amp;c-&gt;base.base);
1170:     if (sc != nullptr) *sc = nullptr;
1171:   }
1172:   return retval;
1173: }
1174: 
1175: namespace grpc_core {
1176: 
1177: tsi_ssl_root_certs_store* DefaultSslRootStore::default_root_store_;
1178: grpc_slice DefaultSslRootStore::default_pem_root_certs_;
1179: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/security/security_connector/security_connector.cc" line="1170" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [sc] suggests that it may be null, but it has already been dereferenced at line 1167." web_identify="{&quot;identify&quot;:&quot;sc&quot;}" func_info="int grpc_ssl_server_security_connector_create ( struct grpc_server_credentials * gsc , struct grpc_server_security_connector * * sc )" content="1160:       gpr_log(GPR_ERROR, &quot;Handshaker factory creation failed with %s.&quot;,
1161:               tsi_result_to_string(result));
1162:       retval = GRPC_SECURITY_ERROR;
1163:     }
1164:   }
1165: 
1166:   if (retval == GRPC_SECURITY_OK) {
1167:     *sc = &amp;c-&gt;base;
1168:   } else {
1169:     if (c != nullptr) ssl_server_destroy(&amp;c-&gt;base.base);
1170:     if (sc != nullptr) *sc = nullptr;
1171:   }
1172:   return retval;
1173: }
1174: 
1175: namespace grpc_core {
1176: 
1177: tsi_ssl_root_certs_store* DefaultSslRootStore::default_root_store_;
1178: grpc_slice DefaultSslRootStore::default_pem_root_certs_;
1179: 
1180: const tsi_ssl_root_certs_store* DefaultSslRootStore::GetRootStore() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/security/transport/client_auth_filter.cc" line="204" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ctx] to null at line 181 implies that [ctx ] might be null.Dereferencing null pointer [ctx]." web_identify="{&quot;identify&quot;:&quot;ctx&quot;}" func_info="static void send_security_metadata ( struct grpc_call_element * elem , grpc_transport_stream_op_batch * batch )" content="194:           batch,
195:           grpc_error_set_int(
196:               GRPC_ERROR_CREATE_FROM_STATIC_STRING(
197:                   &quot;Incompatible credentials set on channel and call.&quot;),
198:               GRPC_ERROR_INT_GRPC_STATUS, GRPC_STATUS_UNAUTHENTICATED),
199:           calld-&gt;call_combiner);
200:       return;
201:     }
202:   } else {
203:     calld-&gt;creds = grpc_call_credentials_ref(
204:         call_creds_has_md ? ctx-&gt;creds : channel_call_creds);
205:   }
206: 
207:   grpc_auth_metadata_context_build(
208:       chand-&gt;security_connector-&gt;base.url_scheme, calld-&gt;host, calld-&gt;method,
209:       chand-&gt;auth_context, &amp;calld-&gt;auth_md_context);
210: 
211:   GPR_ASSERT(calld-&gt;pollent != nullptr);
212:   GRPC_CALL_STACK_REF(calld-&gt;owning_call, &quot;get_request_metadata&quot;);
213:   GRPC_CLOSURE_INIT(&amp;calld-&gt;async_result_closure, on_credentials_metadata,
214:                     batch, grpc_schedule_on_exec_ctx);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/surface/completion_queue.cc" line="108" id="suspicious" subid="autovar" severity="Warning" msg="Address of local auto-variable assigned to a function parameter." web_identify="{&quot;identify&quot;:&quot;*&quot;}" func_info="static grpc_error * non_polling_poller_work ( struct grpc_pollset * pollset , struct grpc_pollset_worker * * worker , int64_t deadline )" content="98:   gpr_mu_destroy(&amp;npp-&gt;mu);
99: }
100: 
101: static grpc_error* non_polling_poller_work(grpc_pollset* pollset,
102:                                            grpc_pollset_worker** worker,
103:                                            grpc_millis deadline) {
104:   non_polling_poller* npp = reinterpret_cast&lt;non_polling_poller*&gt;(pollset);
105:   if (npp-&gt;shutdown) return GRPC_ERROR_NONE;
106:   non_polling_worker w;
107:   gpr_cv_init(&amp;w.cv);
108:   if (worker != nullptr) *worker = reinterpret_cast&lt;grpc_pollset_worker*&gt;(&amp;w);
109:   if (npp-&gt;root == nullptr) {
110:     npp-&gt;root = w.next = w.prev = &amp;w;
111:   } else {
112:     w.next = npp-&gt;root;
113:     w.prev = w.next-&gt;prev;
114:     w.next-&gt;prev = w.prev-&gt;next = &amp;w;
115:   }
116:   w.kicked = false;
117:   gpr_timespec deadline_ts =
118:       grpc_millis_to_timespec(deadline, GPR_CLOCK_MONOTONIC);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/lib/transport/service_config.h" line="216" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [entries] suggests that it may be null, but it has already been dereferenced at line 205." web_identify="{&quot;identify&quot;:&quot;entries&quot;}" func_info="&gt; ServiceConfig::CreateMethodConfigTable ( CreateValue &lt; T &gt; create_value )" content="206:           }
207:           gpr_free(entries);
208:           return nullptr;
209:         }
210:       }
211:       GPR_ASSERT(idx == num_entries);
212:     }
213:   }
214:   // Instantiate method config table.
215:   RefCountedPtr&lt;SliceHashTable&lt;RefCountedPtr&lt;T&gt;&gt;&gt; method_config_table;
216:   if (entries != nullptr) {
217:     method_config_table =
218:         SliceHashTable&lt;RefCountedPtr&lt;T&gt;&gt;::Create(num_entries, entries, nullptr);
219:     gpr_free(entries);
220:   }
221:   return method_config_table;
222: }
223: 
224: template &lt;typename T&gt;
225: RefCountedPtr&lt;T&gt; ServiceConfig::MethodConfigTableLookup(
226:     const SliceHashTable&lt;RefCountedPtr&lt;T&gt;&gt;&amp; table, grpc_slice path) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/tsi/ssl_transport_security.cc" line="1041" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [peer.properties] suggests that it may be null, but it has already been dereferenced at line 1039." web_identify="{&quot;identify&quot;:&quot;peer.properties&quot;}" func_info="static int ssl_handshaker_result_extract_peer ( const struct tsi_handshaker_result * self , struct tsi_peer * peer )" content="1031:   }
1032: 
1033:   // 1 is for session reused property.
1034:   size_t new_property_count = peer-&gt;property_count + 1;
1035:   if (alpn_selected != nullptr) new_property_count++;
1036:   tsi_peer_property* new_properties = static_cast&lt;tsi_peer_property*&gt;(
1037:       gpr_zalloc(sizeof(*new_properties) * new_property_count));
1038:   for (size_t i = 0; i &lt; peer-&gt;property_count; i++) {
1039:     new_properties[i] = peer-&gt;properties[i];
1040:   }
1041:   if (peer-&gt;properties != nullptr) gpr_free(peer-&gt;properties);
1042:   peer-&gt;properties = new_properties;
1043: 
1044:   if (alpn_selected != nullptr) {
1045:     result = tsi_construct_string_peer_property(
1046:         TSI_SSL_ALPN_SELECTED_PROTOCOL,
1047:         reinterpret_cast&lt;const char*&gt;(alpn_selected), alpn_selected_len,
1048:         &amp;peer-&gt;properties[peer-&gt;property_count]);
1049:     if (result != TSI_OK) return result;
1050:     peer-&gt;property_count++;
1051:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/tsi/ssl_transport_security.cc" line="1493" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [self.ssl_contexts] suggests that it may be null, but it has already been dereferenced at line 1488." web_identify="{&quot;identify&quot;:&quot;self.ssl_contexts&quot;}" func_info="static void tsi_ssl_server_handshaker_factory_destroy ( struct tsi_ssl_handshaker_factory * factory )" content="1483:   if (factory == nullptr) return;
1484:   tsi_ssl_server_handshaker_factory* self =
1485:       reinterpret_cast&lt;tsi_ssl_server_handshaker_factory*&gt;(factory);
1486:   size_t i;
1487:   for (i = 0; i &lt; self-&gt;ssl_context_count; i++) {
1488:     if (self-&gt;ssl_contexts[i] != nullptr) {
1489:       SSL_CTX_free(self-&gt;ssl_contexts[i]);
1490:       tsi_peer_destruct(&amp;self-&gt;ssl_context_x509_subject_names[i]);
1491:     }
1492:   }
1493:   if (self-&gt;ssl_contexts != nullptr) gpr_free(self-&gt;ssl_contexts);
1494:   if (self-&gt;ssl_context_x509_subject_names != nullptr) {
1495:     gpr_free(self-&gt;ssl_context_x509_subject_names);
1496:   }
1497:   if (self-&gt;alpn_protocol_list != nullptr) gpr_free(self-&gt;alpn_protocol_list);
1498:   gpr_free(self);
1499: }
1500: 
1501: static int does_entry_match_name(const char* entry, size_t entry_length,
1502:                                  const char* name) {
1503:   const char* dot;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/tsi/ssl_transport_security.cc" line="1494" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [self.ssl_context_x509_subject_names] suggests that it may be null, but it has already been dereferenced at line 1490." web_identify="{&quot;identify&quot;:&quot;self.ssl_context_x509_subject_names&quot;}" func_info="static void tsi_ssl_server_handshaker_factory_destroy ( struct tsi_ssl_handshaker_factory * factory )" content="1484:   tsi_ssl_server_handshaker_factory* self =
1485:       reinterpret_cast&lt;tsi_ssl_server_handshaker_factory*&gt;(factory);
1486:   size_t i;
1487:   for (i = 0; i &lt; self-&gt;ssl_context_count; i++) {
1488:     if (self-&gt;ssl_contexts[i] != nullptr) {
1489:       SSL_CTX_free(self-&gt;ssl_contexts[i]);
1490:       tsi_peer_destruct(&amp;self-&gt;ssl_context_x509_subject_names[i]);
1491:     }
1492:   }
1493:   if (self-&gt;ssl_contexts != nullptr) gpr_free(self-&gt;ssl_contexts);
1494:   if (self-&gt;ssl_context_x509_subject_names != nullptr) {
1495:     gpr_free(self-&gt;ssl_context_x509_subject_names);
1496:   }
1497:   if (self-&gt;alpn_protocol_list != nullptr) gpr_free(self-&gt;alpn_protocol_list);
1498:   gpr_free(self);
1499: }
1500: 
1501: static int does_entry_match_name(const char* entry, size_t entry_length,
1502:                                  const char* name) {
1503:   const char* dot;
1504:   const char* name_subdomain = nullptr;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/core/tsi/ssl_transport_security.cc" line="1688" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options.pem_root_certs] to null at line 1648 implies that [options.pem_root_certs ] might be null.Dereferencing null pointer [options.pem_root_certs]." web_identify="{&quot;identify&quot;:&quot;options.pem_root_certs&quot;}" func_info="int tsi_create_ssl_client_handshaker_factory_with_options ( const struct tsi_ssl_client_handshaker_options * options , struct tsi_ssl_client_handshaker_factory * * factory )" content="1678: 
1679: #if OPENSSL_VERSION_NUMBER &gt;= 0x10100000
1680:     // X509_STORE_up_ref is only available since OpenSSL 1.1.
1681:     if (options-&gt;root_store != nullptr) {
1682:       X509_STORE_up_ref(options-&gt;root_store-&gt;store);
1683:       SSL_CTX_set_cert_store(ssl_context, options-&gt;root_store-&gt;store);
1684:     }
1685: #endif
1686:     if (OPENSSL_VERSION_NUMBER &lt; 0x10100000 || options-&gt;root_store == nullptr) {
1687:       result = ssl_ctx_load_verification_certs(
1688:           ssl_context, options-&gt;pem_root_certs, strlen(options-&gt;pem_root_certs),
1689:           nullptr);
1690:       if (result != TSI_OK) {
1691:         gpr_log(GPR_ERROR, &quot;Cannot load server root certificates.&quot;);
1692:         break;
1693:       }
1694:     }
1695: 
1696:     if (options-&gt;num_alpn_protocols != 0) {
1697:       result = build_alpn_protocol_name_list(
1698:           options-&gt;alpn_protocols, options-&gt;num_alpn_protocols,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/client/channel_cc.cc" line="85" id="suspicious" subid="autovar" severity="Warning" msg="Address of local auto-variable assigned to a function parameter." web_identify="{&quot;identify&quot;:&quot;*&quot;}" func_info="grpc::string GetChannelInfoField ( struct grpc_channel * channel , grpc_channel_info * channel_info , char * * * channel_info_field )" content="75: 
76: inline grpc_slice SliceFromArray(const char* arr, size_t len) {
77:   return g_core_codegen_interface-&gt;grpc_slice_from_copied_buffer(arr, len);
78: }
79: 
80: grpc::string GetChannelInfoField(grpc_channel* channel,
81:                                  grpc_channel_info* channel_info,
82:                                  char*** channel_info_field) {
83:   char* value = nullptr;
84:   memset(channel_info, 0, sizeof(*channel_info));
85:   *channel_info_field = &amp;value;
86:   grpc_channel_get_info(channel, channel_info);
87:   if (value == nullptr) return &quot;&quot;;
88:   grpc::string result = value;
89:   gpr_free(value);
90:   return result;
91: }
92: 
93: }  // namespace
94: 
95: grpc::string Channel::GetLoadBalancingPolicyName() const {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/ext/filters/census/client_filter.h" line="42" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CensusClientCallData::tracing_buf_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CensusClientCallData::tracing_buf_,&quot;}" func_info="grpc::CensusClientCallData" content="32: // used to store data and methods specific to that call. CensusClientCallData is
33: // thread-compatible, however typically only 1 thread should be interacting with
34: // a call at a time.
35: class CensusClientCallData : public CallData {
36:  public:
37:   // Maximum size of trace context is sent on the wire.
38:   static constexpr uint32_t kMaxTraceContextLen = 64;
39:   // Maximum size of tags that are sent on the wire.
40:   static constexpr uint32_t kMaxTagsLen = 2048;
41: 
42:   CensusClientCallData()
43:       : recv_trailing_metadata_(nullptr),
44:         initial_on_done_recv_trailing_metadata_(nullptr),
45:         initial_on_done_recv_message_(nullptr),
46:         elapsed_time_(0),
47:         recv_message_(nullptr),
48:         recv_message_count_(0),
49:         sent_message_count_(0) {
50:     memset(&amp;stats_bin_, 0, sizeof(grpc_linked_mdelem));
51:     memset(&amp;tracing_bin_, 0, sizeof(grpc_linked_mdelem));
52:     memset(&amp;path_, 0, sizeof(grpc_slice));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/ext/filters/census/server_filter.h" line="42" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CensusServerCallData::stats_buf_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CensusServerCallData::stats_buf_,&quot;}" func_info="grpc::CensusServerCallData" content="32: 
33: // A CallData class will be created for every grpc call within a channel. It is
34: // used to store data and methods specific to that call. CensusServerCallData is
35: // thread-compatible, however typically only 1 thread should be interacting with
36: // a call at a time.
37: class CensusServerCallData : public CallData {
38:  public:
39:   // Maximum size of server stats that are sent on the wire.
40:   static constexpr uint32_t kMaxServerStatsLen = 16;
41: 
42:   CensusServerCallData()
43:       : gc_(nullptr),
44:         auth_context_(nullptr),
45:         recv_initial_metadata_(nullptr),
46:         initial_on_done_recv_initial_metadata_(nullptr),
47:         initial_on_done_recv_message_(nullptr),
48:         recv_message_(nullptr),
49:         recv_message_count_(0),
50:         sent_message_count_(0) {
51:     memset(&amp;census_bin_, 0, sizeof(grpc_linked_mdelem));
52:     memset(&amp;path_, 0, sizeof(grpc_slice));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/ext/proto_server_reflection.cc" line="39" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ProtoServerReflection::services_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ProtoServerReflection::services_,&quot;}" func_info="grpc" content="29: using grpc::reflection::v1alpha::ExtensionNumberResponse;
30: using grpc::reflection::v1alpha::ExtensionRequest;
31: using grpc::reflection::v1alpha::FileDescriptorResponse;
32: using grpc::reflection::v1alpha::ListServiceResponse;
33: using grpc::reflection::v1alpha::ServerReflectionRequest;
34: using grpc::reflection::v1alpha::ServerReflectionResponse;
35: using grpc::reflection::v1alpha::ServiceResponse;
36: 
37: namespace grpc {
38: 
39: ProtoServerReflection::ProtoServerReflection()
40:     : descriptor_pool_(protobuf::DescriptorPool::generated_pool()) {}
41: 
42: void ProtoServerReflection::SetServiceList(
43:     const std::vector&lt;grpc::string&gt;* services) {
44:   services_ = services;
45: }
46: 
47: Status ProtoServerReflection::ServerReflectionInfo(
48:     ServerContext* context,
49:     ServerReaderWriter&lt;ServerReflectionResponse, ServerReflectionRequest&gt;*
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/server/load_reporter/load_reporter_async_service_impl.cc" line="138" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ReportLoadHandler::load_report_interval_ms_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ReportLoadHandler::load_report_interval_ms_,&quot;}" func_info="grpc::load_reporter" content="128:     p-&gt;next_inbound_ =
129:         CallableTag(std::bind(&amp;ReportLoadHandler::OnRequestDelivered, p,
130:                               std::placeholders::_1, std::placeholders::_2),
131:                     std::move(handler));
132:     p-&gt;ctx_.AsyncNotifyWhenDone(&amp;p-&gt;on_done_notified_);
133:     service-&gt;RequestReportLoad(&amp;p-&gt;ctx_, &amp;p-&gt;stream_, cq, cq,
134:                                &amp;p-&gt;next_inbound_);
135:   }
136: }
137: 
138: LoadReporterAsyncServiceImpl::ReportLoadHandler::ReportLoadHandler(
139:     ServerCompletionQueue* cq, LoadReporterAsyncServiceImpl* service,
140:     LoadReporter* load_reporter)
141:     : cq_(cq),
142:       service_(service),
143:       load_reporter_(load_reporter),
144:       stream_(&amp;ctx_),
145:       call_status_(WAITING_FOR_DELIVERY) {}
146: 
147: void LoadReporterAsyncServiceImpl::ReportLoadHandler::OnRequestDelivered(
148:     std::shared_ptr&lt;ReportLoadHandler&gt; self, bool ok) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/cpp/server/server_cc.cc" line="143" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SyncRequest::call_,request_payload_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SyncRequest::call_,request_payload_,&quot;}" func_info="grpc::SyncRequest" content="133:     delete this;
134:     return false;
135:   }
136: 
137:  private:
138:   UnimplementedAsyncRequest* const request_;
139: };
140: 
141: class Server::SyncRequest final : public internal::CompletionQueueTag {
142:  public:
143:   SyncRequest(internal::RpcServiceMethod* method, void* tag)
144:       : method_(method),
145:         tag_(tag),
146:         in_flight_(false),
147:         has_request_payload_(
148:             method-&gt;method_type() == internal::RpcMethod::NORMAL_RPC ||
149:             method-&gt;method_type() == internal::RpcMethod::SERVER_STREAMING),
150:         call_details_(nullptr),
151:         cq_(nullptr) {
152:     grpc_metadata_array_init(&amp;request_metadata_);
153:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/src/php/ext/grpc/call.c" line="221" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [channel.wrapper] suggests that it may be null, but it has already been dereferenced at line 220." web_identify="{&quot;identify&quot;:&quot;channel.wrapper&quot;}" func_info="PHP_METHOD ( Call , __construct )" content="211:                             &amp;deadline_obj, grpc_ce_timeval, &amp;host_override,
212:                             &amp;host_override_len) == FAILURE) {
213:     zend_throw_exception(spl_ce_InvalidArgumentException,
214:                          &quot;Call expects a Channel, a String, a Timeval and &quot;
215:                          &quot;an optional String&quot;, 1 TSRMLS_CC);
216:     return;
217:   }
218:   wrapped_grpc_channel *channel =
219:     PHP_GRPC_GET_WRAPPED_OBJECT(wrapped_grpc_channel, channel_obj);
220:   gpr_mu_lock(&amp;channel-&gt;wrapper-&gt;mu);
221:   if (channel-&gt;wrapper == NULL || channel-&gt;wrapper-&gt;wrapped == NULL) {
222:     zend_throw_exception(spl_ce_InvalidArgumentException,
223:                          &quot;Call cannot be constructed from a closed Channel&quot;,
224:                          1 TSRMLS_CC);
225:     gpr_mu_unlock(&amp;channel-&gt;wrapper-&gt;mu);
226:     return;
227:   }
228:   add_property_zval(getThis(), &quot;channel&quot;, channel_obj);
229:   wrapped_grpc_timeval *deadline =
230:     PHP_GRPC_GET_WRAPPED_OBJECT(wrapped_grpc_timeval, deadline_obj);
231:   grpc_slice method_slice = grpc_slice_from_copied_string(method);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/bad_client/bad_client.cc" line="132" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [sfd.client] suggests that it may be null, but it has already been dereferenced at line 118 in function[grpc_endpoint_write]." web_identify="{&quot;identify&quot;:&quot;sfd.client&quot;}" func_info="void grpc_run_client_side_validator ( grpc_bad_client_arg * arg , int flags , grpc_endpoint_pair * sfd , struct grpc_completion_queue * client_cq )" content="122:    * before the peer shuts down. */
123:   if (!(flags &amp; GRPC_BAD_CLIENT_LARGE_REQUEST)) {
124:     GPR_ASSERT(
125:         gpr_event_wait(&amp;done_write, grpc_timeout_seconds_to_deadline(5)));
126:   }
127: 
128:   if (flags &amp; GRPC_BAD_CLIENT_DISCONNECT) {
129:     shutdown_client(&amp;sfd-&gt;client);
130:   }
131: 
132:   if (sfd-&gt;client != nullptr) {
133:     /* Validate client stream, if requested. */
134:     if (arg-&gt;client_validator != nullptr) {
135:       gpr_timespec deadline = grpc_timeout_seconds_to_deadline(5);
136:       grpc_slice_buffer incoming;
137:       grpc_slice_buffer_init(&amp;incoming);
138:       /* We may need to do multiple reads to read the complete server
139:        * response. */
140:       while (true) {
141:         gpr_event read_done_event;
142:         gpr_event_init(&amp;read_done_event);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/gprpp/fork_test.cc" line="76" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;i6000*&quot;}" func_info="static void test_thd_count ( )" content="66:   grpc_core::Fork::Enable(true);
67:   grpc_core::Fork::GlobalInit();
68:   grpc_core::Thread thds[CONCURRENT_TEST_THREADS];
69:   gpr_timespec est_end_time =
70:       gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),
71:                    gpr_time_from_millis(THREAD_DELAY_MS, GPR_TIMESPAN));
72:   gpr_timespec tolerance =
73:       gpr_time_from_millis(THREAD_DELAY_EPSILON, GPR_TIMESPAN);
74:   for (int i = 0; i &lt; CONCURRENT_TEST_THREADS; i++) {
75:     intptr_t sleep_time_ms =
76:         (i * THREAD_DELAY_MS) / (CONCURRENT_TEST_THREADS - 1);
77:     thds[i] =
78:         grpc_core::Thread(&quot;grpc_fork_test&quot;, sleeping_thd, (void*)sleep_time_ms);
79:     thds[i].Start();
80:   }
81:   grpc_core::Fork::AwaitThreads();
82:   gpr_timespec end_time = gpr_now(GPR_CLOCK_REALTIME);
83:   for (auto&amp; thd : thds) {
84:     thd.Join();
85:   }
86:   GPR_ASSERT(gpr_time_similar(end_time, est_end_time, tolerance));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/transport/chttp2/hpack_parser_test.cc" line="61" id="suspicious" subid="autovar" severity="Warning" msg="Address of local auto-variable assigned to a function parameter." web_identify="" func_info="static void test_vector ( struct grpc_chttp2_hpack_parser * parser , grpc_slice_split_mode mode , const char * hexstring , . . . )" content="51:                         ... /* char *key, char *value */) {
52:   grpc_slice input = parse_hexstring(hexstring);
53:   grpc_slice* slices;
54:   size_t nslices;
55:   size_t i;
56:   test_checker chk;
57: 
58:   va_start(chk.args, hexstring);
59: 
60:   parser-&gt;on_header = onhdr;
61:   parser-&gt;on_header_user_data = &amp;chk;
62: 
63:   grpc_split_slices(mode, &amp;input, 1, &amp;slices, &amp;nslices);
64:   grpc_slice_unref(input);
65: 
66:   for (i = 0; i &lt; nslices; i++) {
67:     grpc_core::ExecCtx exec_ctx;
68:     GPR_ASSERT(grpc_chttp2_hpack_parser_parse(parser, slices[i]) ==
69:                GRPC_ERROR_NONE);
70:   }
71: 
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/transport/chttp2/settings_timeout_test.cc" line="97" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Client::endpoint_,mu_,pollset_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Client::endpoint_,mu_,pollset_,&quot;}" func_info="Client" content="87:   const char* address_;  // Do not own.
88:   grpc_server* server_ = nullptr;
89:   grpc_completion_queue* cq_ = nullptr;
90:   std::unique_ptr&lt;std::thread&gt; thread_;
91: };
92: 
93: // A TCP client that connects to the server, reads data until the server
94: // closes, and then terminates.
95: class Client {
96:  public:
97:   explicit Client(const char* server_address)
98:       : server_address_(server_address) {}
99: 
100:   void Connect() {
101:     grpc_core::ExecCtx exec_ctx;
102:     grpc_resolved_addresses* server_addresses = nullptr;
103:     grpc_error* error =
104:         grpc_blocking_resolve_address(server_address_, &quot;80&quot;, &amp;server_addresses);
105:     ASSERT_EQ(GRPC_ERROR_NONE, error) &lt;&lt; grpc_error_string(error);
106:     ASSERT_GE(server_addresses-&gt;naddrs, 1UL);
107:     pollset_ = static_cast&lt;grpc_pollset*&gt;(gpr_zalloc(grpc_pollset_size()));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/util/cmdline_test.cc" line="104" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [x] to null at line 102 implies that [x ] might be null.Dereferencing null pointer [x]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;x&quot;}" func_info="static void test_simple_string ( )" content="94:   gpr_cmdline* cl;
95:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;-foo&quot;),
96:                   const_cast&lt;char*&gt;(&quot;3&quot;)};
97: 
98:   LOG_TEST();
99: 
100:   cl = gpr_cmdline_create(nullptr);
101:   gpr_cmdline_add_string(cl, &quot;foo&quot;, nullptr, &amp;x);
102:   GPR_ASSERT(x == nullptr);
103:   gpr_cmdline_parse(cl, GPR_ARRAY_SIZE(args), args);
104:   GPR_ASSERT(0 == strcmp(x, &quot;3&quot;));
105:   gpr_cmdline_destroy(cl);
106: }
107: 
108: static void test_eq_string(void) {
109:   const char* x = nullptr;
110:   gpr_cmdline* cl;
111:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;-foo=3&quot;)};
112: 
113:   LOG_TEST();
114: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/util/cmdline_test.cc" line="119" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [x] to null at line 117 implies that [x ] might be null.Dereferencing null pointer [x]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;x&quot;}" func_info="static void test_eq_string ( )" content="109:   const char* x = nullptr;
110:   gpr_cmdline* cl;
111:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;-foo=3&quot;)};
112: 
113:   LOG_TEST();
114: 
115:   cl = gpr_cmdline_create(nullptr);
116:   gpr_cmdline_add_string(cl, &quot;foo&quot;, nullptr, &amp;x);
117:   GPR_ASSERT(x == nullptr);
118:   gpr_cmdline_parse(cl, GPR_ARRAY_SIZE(args), args);
119:   GPR_ASSERT(0 == strcmp(x, &quot;3&quot;));
120:   gpr_cmdline_destroy(cl);
121: }
122: 
123: static void test_2dash_string(void) {
124:   const char* x = nullptr;
125:   gpr_cmdline* cl;
126:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;--foo&quot;),
127:                   const_cast&lt;char*&gt;(&quot;3&quot;)};
128: 
129:   LOG_TEST();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/util/cmdline_test.cc" line="135" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [x] to null at line 133 implies that [x ] might be null.Dereferencing null pointer [x]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;x&quot;}" func_info="static void test_2dash_string ( )" content="125:   gpr_cmdline* cl;
126:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;--foo&quot;),
127:                   const_cast&lt;char*&gt;(&quot;3&quot;)};
128: 
129:   LOG_TEST();
130: 
131:   cl = gpr_cmdline_create(nullptr);
132:   gpr_cmdline_add_string(cl, &quot;foo&quot;, nullptr, &amp;x);
133:   GPR_ASSERT(x == nullptr);
134:   gpr_cmdline_parse(cl, GPR_ARRAY_SIZE(args), args);
135:   GPR_ASSERT(0 == strcmp(x, &quot;3&quot;));
136:   gpr_cmdline_destroy(cl);
137: }
138: 
139: static void test_2dash_eq_string(void) {
140:   const char* x = nullptr;
141:   gpr_cmdline* cl;
142:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;--foo=3&quot;)};
143: 
144:   LOG_TEST();
145: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/core/util/cmdline_test.cc" line="150" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [x] to null at line 148 implies that [x ] might be null.Dereferencing null pointer [x]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;x&quot;}" func_info="static void test_2dash_eq_string ( )" content="140:   const char* x = nullptr;
141:   gpr_cmdline* cl;
142:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;--foo=3&quot;)};
143: 
144:   LOG_TEST();
145: 
146:   cl = gpr_cmdline_create(nullptr);
147:   gpr_cmdline_add_string(cl, &quot;foo&quot;, nullptr, &amp;x);
148:   GPR_ASSERT(x == nullptr);
149:   gpr_cmdline_parse(cl, GPR_ARRAY_SIZE(args), args);
150:   GPR_ASSERT(0 == strcmp(x, &quot;3&quot;));
151:   gpr_cmdline_destroy(cl);
152: }
153: 
154: static void test_flag_on(void) {
155:   int x = 2;
156:   gpr_cmdline* cl;
157:   char* args[] = {(char*)__FILE__, const_cast&lt;char*&gt;(&quot;--foo&quot;)};
158: 
159:   LOG_TEST();
160: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/end2end/shutdown_test.cc" line="63" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ShutdownTest::port_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ShutdownTest::port_,&quot;}" func_info="grpc::testing::ShutdownTest" content="53:     }
54:     return Status::OK;
55:   }
56: 
57:  private:
58:   gpr_event* ev_;
59: };
60: 
61: class ShutdownTest : public ::testing::TestWithParam&lt;string&gt; {
62:  public:
63:   ShutdownTest() : shutdown_(false), service_(&amp;ev_) { gpr_event_init(&amp;ev_); }
64: 
65:   void SetUp() override {
66:     port_ = grpc_pick_unused_port_or_die();
67:     server_ = SetUpServer(port_);
68:   }
69: 
70:   std::unique_ptr&lt;Server&gt; SetUpServer(const int port) {
71:     grpc::string server_address = &quot;localhost:&quot; + to_string(port);
72: 
73:     ServerBuilder builder;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/qps/client.h" line="109" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HistogramEntry::value_,status_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HistogramEntry::value_,status_,&quot;}" func_info="grpc::testing::HistogramEntry" content="99:       Slice slice(buf.get(), payload_config.bytebuf_params().req_size());
100:       *req = ByteBuffer(&amp;slice, 1);
101:     } else {
102:       GPR_ASSERT(false);  // not appropriate for this specialization
103:     }
104:   }
105: };
106: 
107: class HistogramEntry final {
108:  public:
109:   HistogramEntry() : value_used_(false), status_used_(false) {}
110:   bool value_used() const { return value_used_; }
111:   double value() const { return value_; }
112:   void set_value(double v) {
113:     value_used_ = true;
114:     value_ = v;
115:   }
116:   bool status_used() const { return status_used_; }
117:   int status() const { return status_; }
118:   void set_status(int status) {
119:     status_used_ = true;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/qps/client.h" line="142" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Client::closed_loop_,thread_pool_done_,median_latency_collection_interval_seconds_,threads_remaining_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Client::closed_loop_,thread_pool_done_,median_latency_collection_interval_seconds_,threads_remaining_,&quot;}" func_info="grpc::testing::Client" content="132: inline void MergeStatusHistogram(const StatusHistogram&amp; from,
133:                                  StatusHistogram* to) {
134:   for (StatusHistogram::const_iterator it = from.begin(); it != from.end();
135:        ++it) {
136:     (*to)[it-&gt;first] += it-&gt;second;
137:   }
138: }
139: 
140: class Client {
141:  public:
142:   Client()
143:       : timer_(new UsageTimer),
144:         interarrival_timer_(),
145:         started_requests_(false),
146:         last_reset_poll_count_(0) {
147:     gpr_event_init(&amp;start_requests_);
148:   }
149:   virtual ~Client() {}
150: 
151:   ClientStats Mark(bool reset) {
152:     Histogram latencies;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/qps/client.h" line="305" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Thread::interval_start_time_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Thread::interval_start_time_,&quot;}" func_info="grpc::testing::Client::Thread" content="295:                                          GPR_TIMESPAN));
296:     return result;
297:   }
298:   std::function&lt;gpr_timespec()&gt; NextIssuer(int thread_idx) {
299:     return closed_loop_ ? std::function&lt;gpr_timespec()&gt;()
300:                         : std::bind(&amp;Client::NextIssueTime, this, thread_idx);
301:   }
302: 
303:   class Thread {
304:    public:
305:     Thread(Client* client, size_t idx)
306:         : client_(client), idx_(idx), impl_(&amp;Thread::ThreadFunc, this) {}
307: 
308:     ~Thread() { impl_.join(); }
309: 
310:     void BeginSwap(Histogram* n, StatusHistogram* s) {
311:       std::lock_guard&lt;std::mutex&gt; g(mu_);
312:       n-&gt;Swap(&amp;histogram_);
313:       s-&gt;swap(statuses_);
314:     }
315: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/qps/client_async.cc" line="768" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ClientRpcContextGenericStreamingImpl::start_,messages_per_stream_,messages_issued_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ClientRpcContextGenericStreamingImpl::start_,messages_per_stream_,messages_issued_,&quot;}" func_info="grpc::testing::ClientRpcContextGenericStreamingImpl" content="758:     return new ClientRpcContextStreamingFromServerImpl&lt;SimpleRequest,
759:                                                        SimpleResponse&gt;(
760:         stub, req, std::move(next_issue),
761:         AsyncStreamingFromServerClient::PrepareReq,
762:         AsyncStreamingFromServerClient::CheckDone);
763:   }
764: };
765: 
766: class ClientRpcContextGenericStreamingImpl : public ClientRpcContext {
767:  public:
768:   ClientRpcContextGenericStreamingImpl(
769:       grpc::GenericStub* stub, const ByteBuffer&amp; req,
770:       std::function&lt;gpr_timespec()&gt; next_issue,
771:       std::function&lt;std::unique_ptr&lt;grpc::GenericClientAsyncReaderWriter&gt;(
772:           grpc::GenericStub*, grpc::ClientContext*,
773:           const grpc::string&amp; method_name, CompletionQueue*)&gt;
774:           prepare_req,
775:       std::function&lt;void(grpc::Status, ByteBuffer*)&gt; on_done)
776:       : context_(),
777:         stub_(stub),
778:         cq_(nullptr),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/util/cli_call.cc" line="52" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CliCall::write_done_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CliCall::write_done_,&quot;}" func_info="grpc::testing" content="42:                      IncomingMetadataContainer* server_trailing_metadata) {
43:   CliCall call(std::move(channel), method, metadata);
44:   call.Write(request);
45:   call.WritesDone();
46:   if (!call.Read(response, server_initial_metadata)) {
47:     fprintf(stderr, &quot;Failed to read response.\n&quot;);
48:   }
49:   return call.Finish(server_trailing_metadata);
50: }
51: 
52: CliCall::CliCall(const std::shared_ptr&lt;grpc::Channel&gt;&amp; channel,
53:                  const grpc::string&amp; method,
54:                  const OutgoingMetadataContainer&amp; metadata)
55:     : stub_(new grpc::GenericStub(channel)) {
56:   gpr_mu_init(&amp;write_mu_);
57:   gpr_cv_init(&amp;write_cv_);
58:   if (!metadata.empty()) {
59:     for (OutgoingMetadataContainer::const_iterator iter = metadata.begin();
60:          iter != metadata.end(); ++iter) {
61:       ctx_.AddMetadata(iter-&gt;first, iter-&gt;second);
62:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/test/cpp/util/proto_file_parser.cc" line="162" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [method_descriptor] to null at line 155 implies that [method_descriptor ] might be null.Dereferencing null pointer [method_descriptor]." web_identify="{&quot;identify&quot;:&quot;method_descriptor&quot;}" func_info="grpc::string ProtoFileParser::GetFullMethodName ( const grpc::string &amp; method )" content="152:       }
153:     }
154:   }
155:   if (!method_descriptor) {
156:     LogError(&quot;Method name not found&quot;);
157:   }
158:   if (has_error_) {
159:     return &quot;&quot;;
160:   }
161: 
162:   known_methods_[method] = method_descriptor-&gt;full_name();
163: 
164:   return method_descriptor-&gt;full_name();
165: }
166: 
167: grpc::string ProtoFileParser::GetFormattedMethodName(
168:     const grpc::string&amp; method) {
169:   has_error_ = false;
170:   grpc::string formatted_method_name = GetFullMethodName(method);
171:   if (has_error_) {
172:     return &quot;&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/third_party/nanopb/pb_decode.c" line="454" id="memleak" subid="memleakOnRealloc" severity="Warning" msg="Common realloc mistake: &apos;ptr&apos; nulled but not freed upon failure" web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="" content="444:             if (size_max / array_size &lt; data_size)
445:             {
446:                 PB_RETURN_ERROR(stream, &quot;size too large&quot;);
447:             }
448:         }
449:     }
450:     
451:     /* Allocate new or expand previous allocation */
452:     /* Note: on failure the old pointer will remain in the structure,
453:      * the message must be freed by caller also on error return. */
454:     ptr = pb_realloc(ptr, array_size * data_size);
455:     if (ptr == NULL)
456:         PB_RETURN_ERROR(stream, &quot;realloc failed&quot;);
457:     
458:     *(void**)pData = ptr;
459:     return true;
460: }
461: 
462: /* Clear a newly allocated item in case it contains a pointer, or is a submessage. */
463: static void initialize_pointer_field(void *pItem, pb_field_iter_t *iter)
464: {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/third_party/nanopb/tests/alltypes_pointer/decode_alltypes_pointer.c" line="133" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [alltypes.oneof.oneof_msg1] to null at line 132 implies that [alltypes.oneof.oneof_msg1 ] might be null.Dereferencing null pointer [alltypes.oneof.oneof_msg1]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;alltypes.oneof.oneof_msg1&quot;}" func_info="bool check_alltypes ( pb_istream_t * stream , int mode )" content="123:         TEST(alltypes.opt_string &amp;&amp; strcmp(alltypes.opt_string, &quot;3054&quot;) == 0);
124:         TEST(alltypes.opt_bytes &amp;&amp; alltypes.opt_bytes-&gt;size == 4);
125:         TEST(alltypes.opt_bytes &amp;&amp; memcmp(&amp;alltypes.opt_bytes-&gt;bytes, &quot;3055&quot;, 4) == 0);
126:         TEST(alltypes.opt_submsg &amp;&amp; strcmp(alltypes.opt_submsg-&gt;substuff1, &quot;3056&quot;) == 0);
127:         TEST(alltypes.opt_submsg &amp;&amp; *alltypes.opt_submsg-&gt;substuff2 == 3056);
128:         TEST(alltypes.opt_enum &amp;&amp; *alltypes.opt_enum == MyEnum_Truth);
129:         TEST(alltypes.opt_emptymsg);
130: 
131:         TEST(alltypes.which_oneof == AllTypes_oneof_msg1_tag);
132:         TEST(alltypes.oneof.oneof_msg1 &amp;&amp; strcmp(alltypes.oneof.oneof_msg1-&gt;substuff1, &quot;4059&quot;) == 0);
133:         TEST(alltypes.oneof.oneof_msg1-&gt;substuff2 &amp;&amp; *alltypes.oneof.oneof_msg1-&gt;substuff2 == 4059);
134:     }
135:     
136:     TEST(alltypes.req_limits-&gt;int32_min &amp;&amp; *alltypes.req_limits-&gt;int32_min   == INT32_MIN);
137:     TEST(alltypes.req_limits-&gt;int32_max &amp;&amp; *alltypes.req_limits-&gt;int32_max   == INT32_MAX);
138:     TEST(alltypes.req_limits-&gt;uint32_min &amp;&amp; *alltypes.req_limits-&gt;uint32_min == 0);
139:     TEST(alltypes.req_limits-&gt;uint32_max &amp;&amp; *alltypes.req_limits-&gt;uint32_max == UINT32_MAX);
140:     TEST(alltypes.req_limits-&gt;int64_min &amp;&amp; *alltypes.req_limits-&gt;int64_min   == INT64_MIN);
141:     TEST(alltypes.req_limits-&gt;int64_max &amp;&amp; *alltypes.req_limits-&gt;int64_max   == INT64_MAX);
142:     TEST(alltypes.req_limits-&gt;uint64_min &amp;&amp; *alltypes.req_limits-&gt;uint64_min == 0);
143:     TEST(alltypes.req_limits-&gt;uint64_max &amp;&amp; *alltypes.req_limits-&gt;uint64_max == UINT64_MAX);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc-1.16.0/third_party/nanopb/tests/mem_release/mem_release.c" line="79" id="suspicious" subid="autovar" severity="Warning" msg="Returning the address of a stack variable [ext2_dest]." web_identify="{&quot;identify&quot;:&quot;ext2_dest&quot;}" func_info="static bool test_TestMessage ( )" content="69:     {
70:         TestMessage msg = TestMessage_init_zero;
71:         pb_istream_t stream;
72:         SubMessage ext2_dest;
73: 
74:         msg.extensions = &amp;ext1;
75:         ext1.type = &amp;dynamic_ext;
76:         ext1.dest = NULL;
77:         ext1.next = &amp;ext2;
78:         ext2.type = &amp;static_ext;
79:         ext2.dest = &amp;ext2_dest;
80:         ext2.next = NULL;
81:         
82:         stream = pb_istream_from_buffer(buffer, msgsize);
83:         if (!pb_decode(&amp;stream, TestMessage_fields, &amp;msg))
84:         {
85:             fprintf(stderr, &quot;Decode failed: %s\n&quot;, PB_GET_ERROR(&amp;stream));
86:             return false;
87:         }
88:         
89:         /* Make sure it encodes back to same data */
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/call.h" line="215" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpSendInitialMetadata::flags_,initial_metadata_count_,initial_metadata_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpSendInitialMetadata::flags_,initial_metadata_count_,initial_metadata_,&quot;}" func_info="grpc::internal::CallOpSendInitialMetadata" content="205: /// used for generating multiple names for the same thing.
206: template &lt;int I&gt;
207: class CallNoOp {
208:  protected:
209:   void AddOp(grpc_op* ops, size_t* nops) {}
210:   void FinishOp(bool* status) {}
211: };
212: 
213: class CallOpSendInitialMetadata {
214:  public:
215:   CallOpSendInitialMetadata() : send_(false) {
216:     maybe_compression_level_.is_set = false;
217:   }
218: 
219:   void SendInitialMetadata(
220:       const std::multimap&lt;grpc::string, grpc::string&gt;&amp; metadata,
221:       uint32_t flags) {
222:     maybe_compression_level_.is_set = false;
223:     send_ = true;
224:     flags_ = flags;
225:     initial_metadata_ =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/call.h" line="466" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpServerSendStatus::trailing_metadata_count_,trailing_metadata_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpServerSendStatus::trailing_metadata_count_,trailing_metadata_,&quot;}" func_info="grpc::internal::CallOpServerSendStatus" content="456:     op-&gt;reserved = NULL;
457:   }
458:   void FinishOp(bool* status) { send_ = false; }
459: 
460:  private:
461:   bool send_;
462: };
463: 
464: class CallOpServerSendStatus {
465:  public:
466:   CallOpServerSendStatus() : send_status_available_(false) {}
467: 
468:   void ServerSendStatus(
469:       const std::multimap&lt;grpc::string, grpc::string&gt;&amp; trailing_metadata,
470:       const Status&amp; status) {
471:     send_error_details_ = status.error_details();
472:     trailing_metadata_ = FillMetadataArray(
473:         trailing_metadata, &amp;trailing_metadata_count_, send_error_details_);
474:     send_status_available_ = true;
475:     send_status_code_ = static_cast&lt;grpc_status_code&gt;(status.error_code());
476:     send_error_message_ = status.error_message();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/call.h" line="541" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CallOpClientRecvStatus::client_context_,metadata_map_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CallOpClientRecvStatus::client_context_,metadata_map_,&quot;}" func_info="grpc::internal::CallOpClientRecvStatus" content="531:     if (metadata_map_ == nullptr) return;
532:     metadata_map_ = nullptr;
533:   }
534: 
535:  private:
536:   MetadataMap* metadata_map_;
537: };
538: 
539: class CallOpClientRecvStatus {
540:  public:
541:   CallOpClientRecvStatus()
542:       : recv_status_(nullptr), debug_error_string_(nullptr) {}
543: 
544:   void ClientRecvStatus(ClientContext* context, Status* status) {
545:     client_context_ = context;
546:     metadata_map_ = &amp;client_context_-&gt;trailing_metadata_;
547:     recv_status_ = status;
548:     error_message_ = g_core_codegen_interface-&gt;grpc_empty_slice();
549:   }
550: 
551:  protected:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/grpc_library.h" line="45" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [g_glip] to null at line 44 implies that [g_glip ] might be null.Dereferencing null pointer [g_glip]." web_identify="{&quot;identify&quot;:&quot;g_glip&quot;}" func_info="GrpcLibraryCodegen::GrpcLibraryCodegen ( bool call_grpc_init = true ) : grpc_init_called_ ( false )" content="35: extern GrpcLibraryInterface* g_glip;
36: 
37: /// Classes that require gRPC to be initialized should inherit from this class.
38: class GrpcLibraryCodegen {
39:  public:
40:   GrpcLibraryCodegen(bool call_grpc_init = true) : grpc_init_called_(false) {
41:     if (call_grpc_init) {
42:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
43:                          &quot;gRPC library not initialized. See &quot;
44:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
45:       g_glip-&gt;init();
46:       grpc_init_called_ = true;
47:     }
48:   }
49:   virtual ~GrpcLibraryCodegen() {
50:     if (grpc_init_called_) {
51:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
52:                          &quot;gRPC library not initialized. See &quot;
53:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
54:       g_glip-&gt;shutdown();
55:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/grpc_library.h" line="54" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [g_glip] to null at line 53 implies that [g_glip ] might be null.Dereferencing null pointer [g_glip]." web_identify="{&quot;identify&quot;:&quot;g_glip&quot;}" func_info="virtual ~ GrpcLibraryCodegen::GrpcLibraryCodegen ( )" content="44:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
45:       g_glip-&gt;init();
46:       grpc_init_called_ = true;
47:     }
48:   }
49:   virtual ~GrpcLibraryCodegen() {
50:     if (grpc_init_called_) {
51:       GPR_CODEGEN_ASSERT(g_glip &amp;&amp;
52:                          &quot;gRPC library not initialized. See &quot;
53:                          &quot;grpc::internal::GrpcLibraryInitializer.&quot;);
54:       g_glip-&gt;shutdown();
55:     }
56:   }
57: 
58:  private:
59:   bool grpc_init_called_;
60: };
61: 
62: }  // namespace grpc
63: 
64: #endif  // GRPCPP_IMPL_CODEGEN_GRPC_LIBRARY_H
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/server_interface.h" line="275" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [method] to null at line 274 implies that [method ] might be null.Dereferencing null pointer [method]." web_identify="{&quot;identify&quot;:&quot;method&quot;}" func_info="&gt; void ServerInterface::RequestAsyncCall ( internal :: RpcServiceMethod * method , ServerContext * context , internal :: ServerAsyncStreamingInterface * stream , CompletionQueue * call_cq , ServerCompletionQueue * notification_cq , void * tag , Message * message )" content="265:   };
266: 
267:   template &lt;class Message&gt;
268:   void RequestAsyncCall(internal::RpcServiceMethod* method,
269:                         ServerContext* context,
270:                         internal::ServerAsyncStreamingInterface* stream,
271:                         CompletionQueue* call_cq,
272:                         ServerCompletionQueue* notification_cq, void* tag,
273:                         Message* message) {
274:     GPR_CODEGEN_ASSERT(method);
275:     new PayloadAsyncRequest&lt;Message&gt;(method-&gt;server_tag(), this, context,
276:                                      stream, call_cq, notification_cq, tag,
277:                                      message);
278:   }
279: 
280:   void RequestAsyncCall(internal::RpcServiceMethod* method,
281:                         ServerContext* context,
282:                         internal::ServerAsyncStreamingInterface* stream,
283:                         CompletionQueue* call_cq,
284:                         ServerCompletionQueue* notification_cq, void* tag) {
285:     GPR_CODEGEN_ASSERT(method);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/grpc/include/grpcpp/impl/codegen/server_interface.h" line="286" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [method] to null at line 285 implies that [method ] might be null.Dereferencing null pointer [method]." web_identify="{&quot;identify&quot;:&quot;method&quot;}" func_info="void ServerInterface::RequestAsyncCall ( internal :: RpcServiceMethod * method , ServerContext * context , internal :: ServerAsyncStreamingInterface * stream , CompletionQueue * call_cq , ServerCompletionQueue * notification_cq , void * tag )" content="276:                                      stream, call_cq, notification_cq, tag,
277:                                      message);
278:   }
279: 
280:   void RequestAsyncCall(internal::RpcServiceMethod* method,
281:                         ServerContext* context,
282:                         internal::ServerAsyncStreamingInterface* stream,
283:                         CompletionQueue* call_cq,
284:                         ServerCompletionQueue* notification_cq, void* tag) {
285:     GPR_CODEGEN_ASSERT(method);
286:     new NoPayloadAsyncRequest(method-&gt;server_tag(), this, context, stream,
287:                               call_cq, notification_cq, tag);
288:   }
289: 
290:   void RequestAsyncGenericCall(GenericServerContext* context,
291:                                internal::ServerAsyncStreamingInterface* stream,
292:                                CompletionQueue* call_cq,
293:                                ServerCompletionQueue* notification_cq,
294:                                void* tag) {
295:     new GenericAsyncRequest(this, context, stream, call_cq, notification_cq,
296:                             tag, true);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/serving-1.10.1/tensorflow_serving/batching/streaming_batch_scheduler.h" line="365" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [open_batch_] to null at line 348 implies that [open_batch_ ] might be null.Dereferencing null pointer [open_batch_]." web_identify="{&quot;identify&quot;:&quot;open_batch_&quot;}" func_info="&gt; Status StreamingBatchScheduler &lt; TaskType &gt;::Schedule ( std::unique_ptr &lt; TaskType &gt; * task )" content="355:     if (num_batches_in_progress_ &gt; options_.num_batch_threads) {
356:       DCHECK(open_batch_-&gt;empty());
357:       return errors::Unavailable(
358:           &quot;This task would start a fresh batch, but all batch threads are &quot;
359:           &quot;busy, so at present there is no processing capacity available for &quot;
360:           &quot;this task&quot;);
361:     }
362: 
363:     // If we are about to add the first task to a batch, schedule the batch to
364:     // be closed after the timeout.
365:     if (options_.batch_timeout_micros &gt; 0 &amp;&amp; open_batch_-&gt;empty()) {
366:       const uint64 batch_deadline =
367:           options_.env-&gt;NowMicros() + options_.batch_timeout_micros;
368:       ScheduleCloseOfCurrentOpenBatch(batch_deadline);
369:     }
370: 
371:     open_batch_-&gt;AddTask(std::move(*task));
372: 
373:     // If we&apos;ve exactly reached the target size, we can close this batch now.
374:     if (open_batch_-&gt;size() == options_.max_batch_size) {
375:       StartNewBatch();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/serving-1.10.1/tensorflow_serving/util/net_http/client/testing/evhttp_echo_client.cc" line="38" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [connection] to null at line 31 implies that [connection ] might be null.Dereferencing null pointer [connection]." web_identify="{&quot;identify&quot;:&quot;connection&quot;}" func_info="bool SendRequest ( const char * url )" content="28: 
29: bool SendRequest(const char* url) {
30:   auto connection = EvHTTPConnection::Connect(url);
31:   if (connection == nullptr) {
32:     std::cerr &lt;&lt; &quot;Fail to connect to %s&quot; &lt;&lt; url;
33:   }
34: 
35:   ClientRequest request = {url, &quot;GET&quot;, {}, nullptr};
36:   ClientResponse response = {};
37: 
38:   if (!connection-&gt;BlockingSendRequest(request, &amp;response)) {
39:     std::cerr &lt;&lt; &quot;Request failed.&quot;;
40:     return false;
41:   }
42: 
43:   std::cout &lt;&lt; &quot;Response received: &quot; &lt;&lt; std::endl
44:             &lt;&lt; &quot;Status: &quot; &lt;&lt; response.status &lt;&lt; std::endl;
45: 
46:   for (auto keyval : response.headers) {
47:     std::cout &lt;&lt; keyval.first &lt;&lt; &quot; : &quot; &lt;&lt; keyval.second &lt;&lt; std::endl;
48:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/serving-1.10.1/tensorflow_serving/util/net_http/server/internal/evhttp_request.cc" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ParsedEvRequest::method,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ParsedEvRequest::method,&quot;}" func_info="tensorflow::serving::net_http" content="36: ParsedEvRequest::~ParsedEvRequest() {
37:   if (decoded_uri) {
38:     evhttp_uri_free(decoded_uri);
39:   }
40: 
41:   if (request &amp;&amp; evhttp_request_is_owned(request)) {
42:     evhttp_request_free(request);
43:   }
44: }
45: 
46: ParsedEvRequest::ParsedEvRequest(evhttp_request* request_in)
47:     : request(request_in) {}
48: 
49: bool ParsedEvRequest::decode() {
50:   switch (evhttp_request_get_command(request)) {
51:     case EVHTTP_REQ_GET:
52:       method = &quot;GET&quot;;
53:       break;
54:     case EVHTTP_REQ_POST:
55:       method = &quot;POST&quot;;
56:       break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/serving-1.10.1/tensorflow_serving/util/net_http/server/internal/evhttp_server.cc" line="55" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;EvHTTPServer::immediate_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;EvHTTPServer::immediate_,&quot;}" func_info="tensorflow::serving::net_http" content="45:     ABSL_RAW_LOG(FATAL, &quot;Server requires pthread support.&quot;);
46:   }
47: 
48:   // TODO(wenboz): windows support needed?
49: }
50: 
51: void GlobalInitialize() { absl::call_once(libevent_init_once, &amp;InitLibEvent); }
52: 
53: }  // namespace
54: 
55: EvHTTPServer::EvHTTPServer(std::unique_ptr&lt;ServerOptions&gt; options)
56:     : server_options_(std::move(options)), accepting_requests_() {}
57: 
58: // May crash the server if called before WaitForTermination() returns
59: EvHTTPServer::~EvHTTPServer() {
60:   if (!is_terminating()) {
61:     ABSL_RAW_LOG(ERROR,
62:                  &quot;Serer has not been terminated. Force termination now.&quot;);
63:     Terminate();
64:   }
65: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/c_api_test.cc" line="1175" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CApiColocationTest::feed1_,feed2_,constant_,desc_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CApiColocationTest::feed1_,feed2_,constant_,desc_,&quot;}" func_info="CApiColocationTest" content="1165:   ptrs-&gt;reset(new const void*[v.size()]);
1166:   lens-&gt;reset(new size_t[v.size()]);
1167:   for (size_t i = 0; i &lt; v.size(); ++i) {
1168:     (*ptrs)[i] = v[i].data();
1169:     (*lens)[i] = v[i].size();
1170:   }
1171: }
1172: 
1173: class CApiColocationTest : public ::testing::Test {
1174:  protected:
1175:   CApiColocationTest() : s_(TF_NewStatus()), graph_(TF_NewGraph()) {}
1176: 
1177:   void SetUp() override {
1178:     feed1_ = Placeholder(graph_, s_, &quot;feed1&quot;);
1179:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
1180: 
1181:     feed2_ = Placeholder(graph_, s_, &quot;feed2&quot;);
1182:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
1183: 
1184:     constant_ = ScalarConst(10, graph_, s_);
1185:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/checkpoint_reader.cc" line="114" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v2_reader_] to null at line 113 implies that [v2_reader_ ] might be null.Dereferencing null pointer [v2_reader_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;v2_reader_&quot;}" func_info="&gt; CheckpointReader::BuildV2VarMaps ( )" content="104:   }
105:   if (!status.ok()) {
106:     Set_TF_Status_from_Status(out_status, status);
107:   }
108: }
109: 
110: std::pair&lt;std::unique_ptr&lt;TensorSliceReader::VarToShapeMap&gt;,
111:           std::unique_ptr&lt;TensorSliceReader::VarToDataTypeMap&gt;&gt;
112: CheckpointReader::BuildV2VarMaps() {
113:   CHECK(v2_reader_ != nullptr);
114:   CHECK(v2_reader_-&gt;status().ok());
115: 
116:   // First pass: filters out the entries of the slices.
117:   std::unordered_set&lt;string&gt; filtered_keys;
118:   BundleEntryProto entry;
119:   v2_reader_-&gt;Seek(kHeaderEntryKey);
120:   for (v2_reader_-&gt;Next(); v2_reader_-&gt;Valid(); v2_reader_-&gt;Next()) {
121:     CHECK(entry.ParseFromArray(v2_reader_-&gt;value().data(),
122:                                v2_reader_-&gt;value().size()))
123:         &lt;&lt; entry.InitializationErrorString();
124:     for (int i = 0; i &lt; entry.slices_size(); ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/checkpoint_reader.cc" line="75" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [var_to_shape_map_] to null at line 74 implies that [var_to_shape_map_ ] might be null.Dereferencing null pointer [var_to_shape_map_]." web_identify="{&quot;identify&quot;:&quot;var_to_shape_map_&quot;}" func_info="&amp; CheckpointReader::GetVariableToShapeMap ( ) const" content="65: bool CheckpointReader::HasTensor(const string&amp; name) const {
66:   if (reader_ != nullptr) {
67:     return reader_-&gt;HasTensor(name, nullptr, nullptr);
68:   }
69:   return v2_reader_-&gt;Contains(name);
70: }
71: 
72: const TensorSliceReader::VarToShapeMap&amp;
73: CheckpointReader::GetVariableToShapeMap() const {
74:   CHECK(var_to_shape_map_);
75:   return *var_to_shape_map_;
76: }
77: 
78: const TensorSliceReader::VarToDataTypeMap&amp;
79: CheckpointReader::GetVariableToDataTypeMap() const {
80:   CHECK(var_to_data_type_map_);
81:   return *var_to_data_type_map_;
82: }
83: 
84: const string CheckpointReader::DebugString() const {
85:   if (reader_ != nullptr) return reader_-&gt;DebugString();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/checkpoint_reader.cc" line="81" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [var_to_data_type_map_] to null at line 80 implies that [var_to_data_type_map_ ] might be null.Dereferencing null pointer [var_to_data_type_map_]." web_identify="{&quot;identify&quot;:&quot;var_to_data_type_map_&quot;}" func_info="&amp; CheckpointReader::GetVariableToDataTypeMap ( ) const" content="71: 
72: const TensorSliceReader::VarToShapeMap&amp;
73: CheckpointReader::GetVariableToShapeMap() const {
74:   CHECK(var_to_shape_map_);
75:   return *var_to_shape_map_;
76: }
77: 
78: const TensorSliceReader::VarToDataTypeMap&amp;
79: CheckpointReader::GetVariableToDataTypeMap() const {
80:   CHECK(var_to_data_type_map_);
81:   return *var_to_data_type_map_;
82: }
83: 
84: const string CheckpointReader::DebugString() const {
85:   if (reader_ != nullptr) return reader_-&gt;DebugString();
86:   return v2_reader_-&gt;DebugString();
87: }
88: 
89: void CheckpointReader::GetTensor(
90:     const string&amp; name, std::unique_ptr&lt;tensorflow::Tensor&gt;* out_tensor,
91:     TF_Status* out_status) const {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/eager/c_api.cc" line="182" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [grpc_server] to null at line 177 implies that [grpc_server ] might be null.Dereferencing null pointer [grpc_server]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;grpc_server&quot;}" func_info="tensorflow::Status NewRemoteAwareTFE_Context ( const struct TFE_ContextOptions * opts , struct TFE_Context * * ctx )" content="172:   std::unique_ptr&lt;tensorflow::ServerInterface&gt; server;
173:   LOG_AND_RETURN_IF_ERROR(tensorflow::NewServer(opts-&gt;server_def, &amp;server));
174: 
175:   tensorflow::GrpcServer* grpc_server =
176:       dynamic_cast&lt;tensorflow::GrpcServer*&gt;(server.get());
177:   if (grpc_server == nullptr) {
178:     LOG_AND_RETURN_IF_ERROR(tensorflow::errors::Internal(
179:         &quot;Currently, TFE_NewContext only supports tensorflow::GrpcServer.&quot;));
180:   }
181: 
182:   LOG_AND_RETURN_IF_ERROR(grpc_server-&gt;Start());
183: 
184:   int64 rendezvous_id = tensorflow::random::New64();
185: 
186:   std::vector&lt;string&gt; remote_workers;
187:   grpc_server-&gt;master_env()-&gt;worker_cache-&gt;ListWorkers(&amp;remote_workers);
188:   remote_workers.erase(
189:       std::remove(remote_workers.begin(), remote_workers.end(), worker_name),
190:       remote_workers.end());
191: 
192:   std::unique_ptr&lt;tensorflow::DeviceMgr&gt; remote_device_mgr;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/eager/c_api.cc" line="458" id="memleak" subid="memleak" severity="Warning" msg="Memory leak: op" web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="" content="448:   return ret;
449: }
450: 
451: TF_AttrType TFE_OpNameGetAttrType(TFE_Context* ctx,
452:                                   const char* op_or_function_name,
453:                                   const char* attr_name, unsigned char* is_list,
454:                                   TF_Status* status) {
455:   TF_AttrType ret;
456:   TFE_Op* op = TFE_NewOp(ctx, op_or_function_name, status);
457:   if (!status-&gt;status.ok()) {
458:     return TF_ATTR_INT;  // Same dummy return as TFE_OpGetAttrType.
459:   }
460:   ret = TFE_OpGetAttrType(op, attr_name, is_list, status);
461:   TFE_DeleteOp(op);
462:   return ret;
463: }
464: 
465: void TFE_OpSetAttrString(TFE_Op* op, const char* attr_name, const void* value,
466:                          size_t length) {
467:   op-&gt;operation.MutableAttrs()-&gt;Set(
468:       attr_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/eager/tape.h" line="263" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [op_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;op_it&quot;}" func_info="&gt; void GradientTape &lt; Gradient , BackwardFunction &gt;::DeleteTrace ( long tensor_id )" content="253:     return;
254:   }
255:   const int64 op_id = tensor_op_it-&gt;second;
256:   if (op_id == -1) {
257:     // Do not delete watched tensors.
258:     return;
259:   }
260:   tensor_tape_.erase(tensor_op_it);
261:   auto op_it = op_tape_.find(op_id);
262:   CHECK(op_it != op_tape_.end());
263:   for (const auto&amp; output : op_it-&gt;second.output_tensor_info) {
264:     if (tensor_usage_.find(output.id) != tensor_usage_.end()) {
265:       // Found a usage for an output, so cannot delete the op.
266:       return;
267:     }
268:   }
269:   for (int64 id : op_it-&gt;second.input_tensor_id) {
270:     DeleteTrace(id);
271:   }
272:   op_it-&gt;second.backward_function_deleter(op_it-&gt;second.backward_function);
273:   op_tape_.erase(op_it);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/c/python_api.cc" line="122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ic] to null at line 121 implies that [ic ] might be null.Dereferencing null pointer [ic]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;ic&quot;}" func_info="std::string tensorflow::GetResourceHandleShapeAndType ( struct TF_Graph * graph , struct TF_Output output )" content="112: 
113: std::string GetResourceHandleShapeAndType(TF_Graph* graph, TF_Output output) {
114:   Node* node = &amp;output.oper-&gt;node;
115:   CppShapeInferenceResult::HandleData handle_data;
116:   handle_data.set_is_set(true);
117:   {
118:     mutex_lock l(graph-&gt;mu);
119:     tensorflow::shape_inference::InferenceContext* ic =
120:         graph-&gt;refiner.GetContext(node);
121:     CHECK(ic != nullptr);
122:     CHECK_LT(output.index, ic-&gt;num_outputs());
123:     const auto* shapes_and_types =
124:         ic-&gt;output_handle_shapes_and_types(output.index);
125:     if (shapes_and_types == nullptr) return &quot;&quot;;
126: 
127:     for (const auto&amp; p : *shapes_and_types) {
128:       auto* out_shape_and_type = handle_data.add_shape_and_type();
129:       ic-&gt;ShapeHandleToProto(p.shape, out_shape_and_type-&gt;mutable_shape());
130:       out_shape_and_type-&gt;set_dtype(p.dtype);
131:     }
132:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/cc/framework/cc_op_gen_test.cc" line="76" id="logic" subid="STLFindError" severity="Warning" msg="Using int as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void ExpectSubstrOrder ( const string &amp; s , const string &amp; before , const string &amp; after )" content="66:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; does not contain &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
67: }
68: 
69: void ExpectDoesNotHaveSubstr(StringPiece s, StringPiece expected) {
70:   EXPECT_FALSE(str_util::StrContains(s, expected))
71:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; contains &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
72: }
73: 
74: void ExpectSubstrOrder(const string&amp; s, const string&amp; before,
75:                        const string&amp; after) {
76:   int before_pos = s.find(before);
77:   int after_pos = s.find(after);
78:   ASSERT_NE(std::string::npos, before_pos);
79:   ASSERT_NE(std::string::npos, after_pos);
80:   EXPECT_LT(before_pos, after_pos)
81:       &lt;&lt; before &lt;&lt; &quot; is not before &quot; &lt;&lt; after &lt;&lt; &quot; in &quot; &lt;&lt; s;
82: }
83: 
84: // Runs WriteCCOps and stores output in (internal_)cc_file_path and
85: // (internal_)h_file_path.
86: void GenerateCcOpFiles(Env* env, const OpList&amp; ops,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/cc/framework/cc_op_gen_test.cc" line="77" id="logic" subid="STLFindError" severity="Warning" msg="Using int as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void ExpectSubstrOrder ( const string &amp; s , const string &amp; before , const string &amp; after )" content="67: }
68: 
69: void ExpectDoesNotHaveSubstr(StringPiece s, StringPiece expected) {
70:   EXPECT_FALSE(str_util::StrContains(s, expected))
71:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; contains &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
72: }
73: 
74: void ExpectSubstrOrder(const string&amp; s, const string&amp; before,
75:                        const string&amp; after) {
76:   int before_pos = s.find(before);
77:   int after_pos = s.find(after);
78:   ASSERT_NE(std::string::npos, before_pos);
79:   ASSERT_NE(std::string::npos, after_pos);
80:   EXPECT_LT(before_pos, after_pos)
81:       &lt;&lt; before &lt;&lt; &quot; is not before &quot; &lt;&lt; after &lt;&lt; &quot; in &quot; &lt;&lt; s;
82: }
83: 
84: // Runs WriteCCOps and stores output in (internal_)cc_file_path and
85: // (internal_)h_file_path.
86: void GenerateCcOpFiles(Env* env, const OpList&amp; ops,
87:                        const ApiDefMap&amp; api_def_map, string* h_file_text,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/create_xla_launch_op.cc" line="125" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [*fbody] to null at line 124 implies that [*fbody ] might be null.Dereferencing null pointer [*fbody]." web_identify="{&quot;identify&quot;:&quot;*fbody&quot;}" func_info="Status GetBodyAndConstantsAndResources ( FunctionLibraryRuntime * flr , const NodeDef &amp; node_def , const FunctionBody * * fbody , std::vector &lt; int &gt; * constant_arg_indices , std::vector &lt; int &gt; * resource_arg_indices )" content="115:                                        const FunctionBody** fbody,
116:                                        std::vector&lt;int&gt;* constant_arg_indices,
117:                                        std::vector&lt;int&gt;* resource_arg_indices) {
118:   FunctionLibraryRuntime::Handle handle;
119:   // If node_def is not instantiable, e.g., the function does not exist,
120:   // simply bail out.
121:   TF_RETURN_IF_ERROR(
122:       flr-&gt;Instantiate(node_def.op(), AttrSlice(&amp;node_def.attr()), &amp;handle));
123:   *fbody = flr-&gt;GetFunctionBody(handle);
124:   CHECK(*fbody);  // Can&apos;t be nullptr since we just instantiated it.
125:   const DataTypeVector&amp; arg_types = (*fbody)-&gt;arg_types;
126:   std::vector&lt;bool&gt; const_args(arg_types.size());
127:   // If we can&apos;t analyze the const args. Bail out.
128:   TF_RETURN_IF_ERROR(BackwardsConstAnalysis(*((*fbody)-&gt;graph), &amp;const_args));
129: 
130:   for (int i = 0; i &lt; const_args.size(); ++i) {
131:     if (const_args[i]) {
132:       constant_arg_indices-&gt;push_back(i);
133:     }
134:   }
135: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc" line="1237" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [host_compute_key_placeholder_] to null at line 1209 implies that [host_compute_key_placeholder_ ] might be null.Dereferencing null pointer [host_compute_key_placeholder_]." web_identify="{&quot;identify&quot;:&quot;host_compute_key_placeholder_&quot;}" func_info="Status Encapsulator::Subgraph::AddRecvAtHostNode ( const string &amp; group_attribute , const string &amp; subgraph_name , const string &amp; outside_compilation_attribute , const string &amp; oc_subgraph_name , OutsideCompilationSubgraph * oc_subgraph , Graph * graph_out )" content="1227:                          kRecvAtHostOp);
1228:   builder.Device(device_);
1229:   builder.Attr(&quot;Toutputs&quot;, dtypes);
1230:   // The correct device_ordinal will be inserted during replication in a
1231:   // subsequent rewrite.
1232:   builder.Attr(&quot;device_ordinal&quot;, 0);
1233:   builder.Attr(&quot;key&quot;, strings::StrCat(&quot;host_compute_channel_&quot;, subgraph_name,
1234:                                       &quot;_&quot;, oc_subgraph_name));
1235:   builder.Attr(group_attribute, subgraph_name);
1236:   builder.Attr(outside_compilation_attribute, oc_subgraph_name);
1237:   builder.Input(host_compute_key_placeholder_-&gt;name(), 0, DT_STRING);
1238:   Status s = builder.Finalize(&amp;recv_def);
1239:   if (!s.ok()) return s;
1240: 
1241:   oc_subgraph-&gt;recv_at_host = graph_out-&gt;AddNode(recv_def, &amp;s);
1242:   if (!s.ok()) return s;
1243:   graph_out-&gt;AddEdge(host_compute_key_placeholder_, 0,
1244:                      oc_subgraph-&gt;recv_at_host, 0);
1245: 
1246:   // Add a control dependency forcing the RecvAtHost to run before the subgraph
1247:   // completes. This has no effect on execution order but prevents the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc" line="1293" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [host_compute_key_placeholder_] to null at line 1260 implies that [host_compute_key_placeholder_ ] might be null.Dereferencing null pointer [host_compute_key_placeholder_]." web_identify="{&quot;identify&quot;:&quot;host_compute_key_placeholder_&quot;}" func_info="Status Encapsulator::Subgraph::AddSendFromHostNode ( const std::unordered_map &lt; const Node * , Node * &gt; &amp; node_images , const string &amp; group_attribute , const string &amp; subgraph_name , const string &amp; outside_compilation_attribute , const string &amp; oc_subgraph_name , OutsideCompilationSubgraph * oc_subgraph , Graph * graph_out )" content="1283:   builder.Device(device_);
1284:   builder.Attr(&quot;Tinputs&quot;, dtypes);
1285:   builder.Attr(&quot;key&quot;, strings::StrCat(&quot;host_compute_channel_&quot;, subgraph_name,
1286:                                       &quot;_&quot;, oc_subgraph_name));
1287:   // The correct device_ordinal will be inserted during replication in a
1288:   // subsequent rewrite.
1289:   builder.Attr(&quot;device_ordinal&quot;, 0);
1290:   builder.Attr(group_attribute, subgraph_name);
1291:   builder.Attr(outside_compilation_attribute, oc_subgraph_name);
1292:   builder.Input(inputs);
1293:   builder.Input(host_compute_key_placeholder_-&gt;name(), 0, DT_STRING);
1294:   Status s = builder.Finalize(&amp;send_def);
1295:   if (!s.ok()) return s;
1296: 
1297:   oc_subgraph-&gt;send_from_host = graph_out-&gt;AddNode(send_def, &amp;s);
1298:   if (!s.ok()) return s;
1299:   graph_out-&gt;AddEdge(host_compute_key_placeholder_, 0,
1300:                      oc_subgraph-&gt;send_from_host, inputs.size());
1301: 
1302:   // Add a control dependency forcing the SendFromHost to run before the
1303:   // subgraph completes. This has no effect on execution order but prevents the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/graphcycles/graphcycles.cc" line="53" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Node::rank,visited,data,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Node::rank,visited,data,&quot;}" func_info="Node" content="43: 
44: typedef std::unordered_set&lt;int32&gt; NodeSet;
45: template &lt;typename T&gt;
46: struct VecStruct {
47:   typedef gtl::InlinedVector&lt;T, 4&gt; type;
48: };
49: template &lt;typename T&gt;
50: using Vec = typename VecStruct&lt;T&gt;::type;
51: 
52: struct Node {
53:   Node() : in(4), out(4) {}  // Small hashtables for in/out edges
54: 
55:   int32 rank;    // rank number assigned by Pearce-Kelly algorithm
56:   bool visited;  // Temporary marker used by depth-first-search
57:   void* data;    // User-supplied data
58:   NodeSet in;    // List of immediate predecessor nodes in graph
59:   NodeSet out;   // List of immediate successor nodes in graph
60: };
61: 
62: }  // namespace
63: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/mark_for_compilation_pass.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fbody] to null at line 141 implies that [fbody ] might be null.Dereferencing null pointer [fbody]." web_identify="{&quot;identify&quot;:&quot;fbody&quot;}" func_info="bool IsCompilableCall ( const NodeDef &amp; call_def , const DeviceType &amp; jit_device_type , int depth , FunctionLibraryRuntime * lib_runtime )" content="132: 
133:   FunctionLibraryRuntime::Handle handle;
134:   Status status =
135:       lib_runtime-&gt;Instantiate(call_def.op(), AttrSlice(call_def), &amp;handle);
136:   if (!status.ok()) {
137:     VLOG(2) &lt;&lt; &quot;Could not instantiate &quot; &lt;&lt; call_def.op() &lt;&lt; &quot;: &quot; &lt;&lt; status;
138:     return false;
139:   }
140:   const FunctionBody* fbody = lib_runtime-&gt;GetFunctionBody(handle);
141:   CHECK(fbody);
142:   const FunctionDef&amp; fdef = fbody-&gt;fdef;
143:   bool noinline = false;
144:   if (GetNodeAttr(AttrSlice(&amp;fdef.attr()), &quot;_noinline&quot;, &amp;noinline).ok() &amp;&amp;
145:       noinline) {
146:     // The underlying mechanism that calls non-inlined functions uses
147:     // LocalExecutor, which interacts poorly with the LocalExecutor used by
148:     // tf2xla to translate the TF graph into XLA.  So we avoid this for now.
149:     //
150:     // TODO(b/36139787): Create a mechanism to set inlining hints.
151:     VLOG(2) &lt;&lt; &quot;Can&apos;t compile noinline function: &quot; &lt;&lt; fdef.DebugString();
152:     return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_compile_on_demand_op.cc" line="153" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rm] to null at line 144 implies that [rm ] might be null.Dereferencing null pointer [rm]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;rm&quot;}" func_info="Status XlaCompileOnDemandOp::Compile ( OpKernelContext * ctx , const XlaDevice::Metadata &amp; metadata , const XlaCompiler::CompilationResult * * result , xla::LocalExecutable * * executable )" content="143:   ResourceMgr* rm = ctx-&gt;resource_manager();
144:   CHECK(rm);
145: 
146:   XlaCompilationCache* cache;
147:   TF_RETURN_IF_ERROR(rm-&gt;LookupOrCreate&lt;XlaCompilationCache&gt;(
148:       rm-&gt;default_container(), &quot;xla_cache&quot;, &amp;cache,
149:       [&amp;](XlaCompilationCache** cache) {
150:         *cache = new XlaCompilationCache(metadata.client(),
151:                                          metadata.jit_device_type());
152:         return Status::OK();
153:       }));
154:   // Hold the reference to the JIT during evaluation. (We could probably
155:   // free it sooner because the ResourceMgr will retain a reference, but
156:   // this is more obviously correct.)
157:   core::ScopedUnref cache_ref(cache);
158: 
159:   XlaCompiler::Options options;
160:   options.device_type = metadata.jit_device_type();
161:   options.client = metadata.client();
162:   options.flib_def =
163:       new FunctionLibraryDefinition(OpRegistry::Global(), FunctionDefLibrary{});
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_compile_on_demand_op.cc" line="91" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [constant_inputs] to null at line 89 implies that [constant_inputs ] might be null.Dereferencing null pointer [constant_inputs]." web_identify="{&quot;identify&quot;:&quot;constant_inputs&quot;}" func_info="bool XlaCompileOnDemandOp::MustArgumentBeConstant ( const OpKernel * op_kernel , long argument_idx )" content="81:   return Status::OK();
82: }
83: 
84: bool XlaCompileOnDemandOp::MustArgumentBeConstant(const OpKernel* op_kernel,
85:                                                   int64 argument_idx) {
86:   // TODO(jmolloy): This could be expensive, so memoize.
87:   auto* constant_inputs = tensorflow::XlaOpRegistry::CompileTimeConstantInputs(
88:       op_kernel-&gt;def().op());
89:   CHECK(constant_inputs);
90:   std::set&lt;int64&gt; constant_input_indices;
91:   for (const auto&amp; name : *constant_inputs) {
92:     int start, stop;
93:     TF_CHECK_OK(op_kernel-&gt;InputRange(name, &amp;start, &amp;stop));
94:     for (int i = start; i &lt; stop; ++i) {
95:       constant_input_indices.insert(i);
96:     }
97:   }
98:   return constant_input_indices.count(argument_idx) &gt; 0;
99: }
100: 
101: bool XlaCompileOnDemandOp::ShouldArgumentBeConstant(const OpKernel* op_kernel,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_device_context.cc" line="147" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 138 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaTransferManager::CopyCPUTensorToDevice ( const Tensor * cpu_tensor , Device * device , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * device_tensor , StatusCallback done ) const" content="137:   XlaTensor* xla_tensor = XlaTensor::FromTensor(device_tensor);
138:   CHECK(xla_tensor);
139: 
140:   xla::StatusOr&lt;TensorShape&gt; shape_or_status =
141:       shape_representation_fn_(device_tensor-&gt;shape(), device_tensor-&gt;dtype());
142:   if (!shape_or_status.ok()) {
143:     done(shape_or_status.status());
144:     return;
145:   }
146:   TensorShape shape = shape_or_status.ValueOrDie();
147:   if (!xla_tensor-&gt;has_shaped_buffer()) {
148:     Status s =
149:         xla_tensor-&gt;AllocateShapedBuffer(device_tensor-&gt;dtype(), shape, client_,
150:                                          stream_-&gt;parent()-&gt;device_ordinal());
151:     if (!s.ok()) {
152:       done(s);
153:       return;
154:     }
155:   }
156: 
157:   Status status;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_device_context.cc" line="250" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_dst] to null at line 248 implies that [xla_dst ] might be null.Dereferencing null pointer [xla_dst]." web_identify="{&quot;identify&quot;:&quot;xla_dst&quot;}" func_info="void XlaTransferManager::CopyDeviceTensorToDevice ( const Tensor &amp; src_tensor , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst_tensor , const StatusCallback &amp; done )" content="240:       return Status::OK();
241:     }
242:     // TODO(jmolloy): We co-opt the device_to_host stream for device to device
243:     // transfers; perhaps we should have a dedicated device to device stream? or
244:     // one per device?
245:     auto device_to_device_stream = device_to_host_stream_;
246:     XlaTensor* xla_src = XlaTensor::FromTensor(&amp;src_tensor);
247:     XlaTensor* xla_dst = XlaTensor::FromTensor(dst_tensor);
248:     CHECK(xla_src &amp;&amp; xla_dst)
249:         &lt;&lt; &quot;Missing destination tensor for device-to-device copy&quot;;
250:     if (!xla_dst-&gt;has_shaped_buffer()) {
251:       TF_ASSIGN_OR_RETURN(
252:           TensorShape shape,
253:           shape_representation_fn_(src_tensor.shape(), src_tensor.dtype()));
254:       TF_RETURN_IF_ERROR(
255:           xla_dst-&gt;AllocateShapedBuffer(src_tensor.dtype(), shape, client_,
256:                                         stream_-&gt;parent()-&gt;device_ordinal()));
257:     }
258: 
259:     if (se::Event* event =
260:             xla_src-&gt;GetDefinitionEvent(device_to_device_stream)) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_device_context.cc" line="260" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_src] to null at line 248 implies that [xla_src ] might be null.Dereferencing null pointer [xla_src]." web_identify="{&quot;identify&quot;:&quot;xla_src&quot;}" func_info="void XlaTransferManager::CopyDeviceTensorToDevice ( const Tensor &amp; src_tensor , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst_tensor , const StatusCallback &amp; done )" content="250:     if (!xla_dst-&gt;has_shaped_buffer()) {
251:       TF_ASSIGN_OR_RETURN(
252:           TensorShape shape,
253:           shape_representation_fn_(src_tensor.shape(), src_tensor.dtype()));
254:       TF_RETURN_IF_ERROR(
255:           xla_dst-&gt;AllocateShapedBuffer(src_tensor.dtype(), shape, client_,
256:                                         stream_-&gt;parent()-&gt;device_ordinal()));
257:     }
258: 
259:     if (se::Event* event =
260:             xla_src-&gt;GetDefinitionEvent(device_to_device_stream)) {
261:       device_to_device_stream-&gt;ThenWaitFor(event);
262:       xla_src-&gt;SetDefinedOn(device_to_device_stream);
263:       TF_RETURN_IF_ERROR(device_to_device_stream-&gt;BlockHostUntilDone());
264:     }
265:     TF_RETURN_IF_ERROR(
266:         xla_dst-&gt;shaped_buffer().buffers().ForEachMutableElementWithStatus(
267:             [&amp;](const xla::ShapeIndex&amp; index, se::DeviceMemoryBase* buffer) {
268:               const se::DeviceMemoryBase&amp; from_buffer =
269:                   xla_src-&gt;shaped_buffer().buffers().element(index);
270:               CHECK_EQ(buffer-&gt;size(), from_buffer.size());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_device_context.cc" line="66" id="nullpointer" subid="dereferenceIfNull" severity="Critical" msg="[shape_representation_fn_] is null dereferenced here, as codes at line 65 make it a null pointer." web_identify="{&quot;identify&quot;:&quot;shape_representation_fn_&quot;}" func_info="XlaTransferManager::XlaTransferManager ( se::Stream * compute_stream , se::Stream * host_to_device_stream , se::Stream * device_to_host_stream , xla::LocalClient * client , bool transfer_as_literal , XlaCompiler::ShapeRepresentationFn shape_representation_fn ) : stream_ ( compute_stream ) , host_to_device_stream_ ( host_to_device_stream ) , device_to_host_stream_ ( device_to_host_stream ) , client_ ( client ) , transfer_manager_ ( client . backend ( ) . transfer_manager ( ) ) , transfer_as_literal_ ( transfer_as_literal ) , shape_representation_fn_ ( std::move ( shape_representation_fn ) )" content="56:       host_to_device_stream_(host_to_device_stream),
57:       device_to_host_stream_(device_to_host_stream),
58:       client_(client),
59:       transfer_manager_(client-&gt;backend().transfer_manager()),
60:       transfer_as_literal_(transfer_as_literal),
61:       shape_representation_fn_(std::move(shape_representation_fn)) {
62:   CHECK(host_to_device_stream_ != nullptr);
63:   CHECK(device_to_host_stream_ != nullptr);
64:   CHECK(stream_ != nullptr);
65:   if (!shape_representation_fn_) {
66:     shape_representation_fn_ =
67:         [](const TensorShape&amp; shape,
68:            DataType dtype) -&gt; xla::StatusOr&lt;TensorShape&gt; { return shape; };
69:   }
70: }
71: 
72: Status XlaTransferManager::TransferLiteralToDevice(
73:     const Tensor&amp; host_tensor, Tensor* device_tensor) const {
74:   xla::Shape xla_shape;
75:   TF_RETURN_IF_ERROR(TensorShapeToXLAShape(host_tensor.dtype(),
76:                                            host_tensor.shape(), &amp;xla_shape));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_device_context.cc" line="81" id="nullpointer" subid="funcRetNullStatistic" severity="Serious" msg="return value of function [FromTensor] [xla_tensor] isn&apos;t checked-null, however [10] times checked-null elsewhere." web_identify="FromTensor|xla_tensor" func_info="XlaTensor* FromTensor(Tensor*)" content="71: 
72: Status XlaTransferManager::TransferLiteralToDevice(
73:     const Tensor&amp; host_tensor, Tensor* device_tensor) const {
74:   xla::Shape xla_shape;
75:   TF_RETURN_IF_ERROR(TensorShapeToXLAShape(host_tensor.dtype(),
76:                                            host_tensor.shape(), &amp;xla_shape));
77:   xla::BorrowingLiteral literal(
78:       static_cast&lt;const char*&gt;(DMAHelper::base(&amp;host_tensor)), xla_shape);
79: 
80:   XlaTensor* xla_tensor = XlaTensor::FromTensor(device_tensor);
81:   const xla::ShapedBuffer&amp; shaped_buffer = xla_tensor-&gt;shaped_buffer();
82:   VLOG(1) &lt;&lt; &quot;Transfer to device as literal: &quot; &lt;&lt; literal.ToString() &lt;&lt; &quot; &quot;
83:           &lt;&lt; shaped_buffer.ToString();
84:   TF_RETURN_IF_ERROR(transfer_manager_-&gt;TransferLiteralToDevice(
85:       host_to_device_stream_, literal, shaped_buffer));
86:   if (UseMultipleStreams()) {
87:     se::Event event(stream_-&gt;parent());
88:     TF_RET_CHECK(event.Init()) &lt;&lt; &quot;Event failed to initialize!&quot;;
89:     host_to_device_stream_-&gt;ThenRecordEvent(&amp;event);
90:     xla_tensor-&gt;SetDefinedOn(host_to_device_stream_, std::move(event));
91:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_launch_util.cc" line="155" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 154 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="145:       t = &amp;(variables.at(arg_num).value);
146:       CHECK(t);
147:     } else {
148:       t = &amp;(ctx-&gt;input(arg_num));
149:     }
150: 
151:     if (use_multiple_streams_) {
152:       CHECK(stream) &lt;&lt; &quot;Must have a stream available when using XLA tensors!&quot;;
153:       XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
154:       CHECK(xla_tensor);
155:       if (se::Event* event = xla_tensor-&gt;GetDefinitionEvent(stream)) {
156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_launch_util.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [stream] to null at line 152 implies that [stream ] might be null.Dereferencing null pointer [stream]." web_identify="{&quot;identify&quot;:&quot;stream&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="146:       CHECK(t);
147:     } else {
148:       t = &amp;(ctx-&gt;input(arg_num));
149:     }
150: 
151:     if (use_multiple_streams_) {
152:       CHECK(stream) &lt;&lt; &quot;Must have a stream available when using XLA tensors!&quot;;
153:       XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
154:       CHECK(xla_tensor);
155:       if (se::Event* event = xla_tensor-&gt;GetDefinitionEvent(stream)) {
156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
166:       arg_ptrs_[i] = const_cast&lt;ShapedBuffer*&gt;(&amp;xla_tensor-&gt;shaped_buffer());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_launch_util.cc" line="166" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 165 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
166:       arg_ptrs_[i] = const_cast&lt;ShapedBuffer*&gt;(&amp;xla_tensor-&gt;shaped_buffer());
167:     } else {
168:       CHECK(xla::ShapeUtil::Equal(shape, on_device_shape))
169:           &lt;&lt; &quot;On-device shape &quot;
170:           &lt;&lt; xla::ShapeUtil::HumanStringWithLayout(on_device_shape)
171:           &lt;&lt; &quot; not the same as on-host shape &quot;
172:           &lt;&lt; xla::ShapeUtil::HumanStringWithLayout(shape);
173:       se::DeviceMemoryBase dmem = XlaTensor::DeviceMemoryFromTensor(*t);
174:       arg_buffers_[i] = xla::MakeUnique&lt;ShapedBuffer&gt;(
175:           /*on_host_shape=*/shape, /*on_device_shape=*/shape,
176:           client_-&gt;platform(), client_-&gt;default_device_ordinal());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/jit/xla_launch_util.cc" line="327" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 326 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateOutputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , ScopedShapedBuffer output )" content="317:     mutex_lock ml(*variable-&gt;mu());
318:     OP_REQUIRES(ctx, variable-&gt;tensor()-&gt;dtype() == write.type,
319:                 errors::Internal(&quot;Mismatched type in variable write&quot;));
320: 
321:     if (allocate_xla_tensors_) {
322:       Tensor output_tensor;
323:       OP_REQUIRES_OK(
324:           ctx, ctx-&gt;allocate_temp(write.type, write.shape, &amp;output_tensor));
325:       XlaTensor* xla_tensor = XlaTensor::FromTensor(&amp;output_tensor);
326:       CHECK(xla_tensor);
327:       xla_tensor-&gt;set_shaped_buffer(
328:           ExtractSubShapedBuffer(&amp;output, output_num, xla_allocator_));
329:       if (use_multiple_streams_) {
330:         se::Event event(stream-&gt;parent());
331:         CHECK(event.Init());
332:         stream-&gt;ThenRecordEvent(&amp;event);
333:         xla_tensor-&gt;SetDefinedOn(stream, std::move(event));
334:       }
335:       *variable-&gt;tensor() = output_tensor;
336:     } else {
337:       Tensor output_tensor = XlaTensorBuffer::MakeTensor(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/tf2xla/functionalize_control_flow.cc" line="924" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="&gt; FunctionalizeCond::DeterminePredicateSwitchOrder ( )" content="914:   auto find_output_cluster = [&amp;](Node* n) {
915:     UnionFind&lt;Cluster&gt;* cluster = &amp;clusters[n-&gt;id()];
916:     if (!IsMerge(n)) return cluster;
917:     auto it = entry_cluster.find(clusters[n-&gt;id()].Get().representative);
918:     // If the cluster is not found in the entry_cluster map then an
919:     // instruction not dominated by a switch node has been merged into the
920:     // cluster of the merge. This indicates a failure of the clustering.
921:     CHECK(it != entry_cluster.end())
922:         &lt;&lt; &quot;Unable to find entry for n=&quot; &lt;&lt; n-&gt;id() &lt;&lt; &quot; (&quot;
923:         &lt;&lt; cluster-&gt;Get().representative &lt;&lt; &quot;)&quot;;
924:     return it-&gt;second;
925:   };
926: 
927:   // TODO(jpienaar): This could be combined with DetermineBranchMapAndFrontier.
928:   std::vector&lt;int&gt; switch_depth(graph_-&gt;num_node_ids());
929:   for (auto it = rev_topo_sorted_nodes.rbegin();
930:        it != rev_topo_sorted_nodes.rend(); ++it) {
931:     Node* n = *it;
932: 
933:     // Compute switch depth.
934:     int new_switch_depth = 0;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/tf2xla/kernels/sequence_ops.cc" line="83" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;delta&gt;0&apos; is redundant or there is division by zero at line 83." web_identify="" func_info="&gt; Status CreateRangeTensor ( const xla::LiteralSlice &amp; start_literal , const xla::LiteralSlice &amp; limit_literal , const xla::LiteralSlice &amp; delta_literal , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * output )" content="73:     }
74:   } else {
75:     if (start &lt; limit) {
76:       return errors::InvalidArgument(
77:           &quot;Requires start &gt;= limit when delta &lt; 0: &quot;, start, &quot;/&quot;, limit);
78:     }
79:   }
80:   int64 size =
81:       (std::is_integral&lt;T&gt;::value
82:            ? ((std::abs(limit - start) + std::abs(delta) - 1) / std::abs(delta))
83:            : std::ceil(std::abs((limit - start) / delta)));
84: 
85:   *output = Tensor(DataTypeToEnum&lt;T&gt;::v(), TensorShape({size}));
86:   auto flat = output-&gt;flat&lt;T&gt;();
87:   T val = start;
88:   for (int64 i = 0; i &lt; size; ++i) {
89:     flat(i) = val;
90:     val += delta;
91:   }
92:   return Status::OK();
93: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/tf2xla/xla_op_registry.cc" line="314" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="std::vector &lt; const KernelDef * &gt; XlaOpRegistry::DeviceKernels ( const string &amp; compilation_device_name , bool include_compilation_only_kernels )" content="304:     const string&amp; compilation_device_name,
305:     bool include_compilation_only_kernels) {
306:   // Ensure compilation kernels registered.
307:   RegisterCompilationKernels();
308:   std::vector&lt;const KernelDef*&gt; kernels;
309:   XlaOpRegistry&amp; registry = Instance();
310:   mutex_lock lock(registry.mutex_);
311:   auto it = registry.backends_.find(compilation_device_name);
312:   CHECK(it != registry.backends_.end())
313:       &lt;&lt; &quot;Unknown backend &quot; &lt;&lt; compilation_device_name;
314:   for (const std::unique_ptr&lt;KernelDef&gt;&amp; k : it-&gt;second.kernel_defs) {
315:     auto op_iter = registry.ops_.find(k-&gt;op());
316:     CHECK(op_iter != registry.ops_.end() &amp;&amp; !op_iter-&gt;second.empty());
317:     // The test in IsCompatible ensures that if there are multiple matching
318:     // registrations for this op name, they all have the same value of
319:     // compilation_only, so only the first match needs to be tested.
320:     if (include_compilation_only_kernels ||
321:         !op_iter-&gt;second.front()-&gt;compilation_only) {
322:       kernels.push_back(k.get());
323:     }
324:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/tf2xla/xla_op_registry.cc" line="321" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [op_iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;op_iter&quot;}" func_info="std::vector &lt; const KernelDef * &gt; XlaOpRegistry::DeviceKernels ( const string &amp; compilation_device_name , bool include_compilation_only_kernels )" content="311:   auto it = registry.backends_.find(compilation_device_name);
312:   CHECK(it != registry.backends_.end())
313:       &lt;&lt; &quot;Unknown backend &quot; &lt;&lt; compilation_device_name;
314:   for (const std::unique_ptr&lt;KernelDef&gt;&amp; k : it-&gt;second.kernel_defs) {
315:     auto op_iter = registry.ops_.find(k-&gt;op());
316:     CHECK(op_iter != registry.ops_.end() &amp;&amp; !op_iter-&gt;second.empty());
317:     // The test in IsCompatible ensures that if there are multiple matching
318:     // registrations for this op name, they all have the same value of
319:     // compilation_only, so only the first match needs to be tested.
320:     if (include_compilation_only_kernels ||
321:         !op_iter-&gt;second.front()-&gt;compilation_only) {
322:       kernels.push_back(k.get());
323:     }
324:   }
325:   return kernels;
326: }
327: 
328: /* static */ const std::unordered_set&lt;string&gt;*
329: XlaOpRegistry::CompileTimeConstantInputs(const string&amp; op) {
330:   XlaOpRegistry&amp; registry = Instance();
331:   mutex_lock lock(registry.mutex_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/client/client.cc" line="228" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [argument] to null at line 227 implies that [argument ] might be null.Dereferencing null pointer [argument]." web_identify="{&quot;identify&quot;:&quot;argument&quot;}" func_info="StatusOr &lt; std::unique_ptr &lt; GlobalData &gt; &gt; Client::Execute ( const XlaComputation &amp; computation , tensorflow::gtl::ArraySlice &lt; GlobalData * &gt; arguments , const ExecutionOptions * execution_options , ExecutionProfile * execution_profile )" content="218:   ExecuteGraphRequest request;
219:   *request.mutable_computation() = computation.proto();
220: 
221:   if (execution_options == nullptr) {
222:     *request.mutable_execution_options() = CreateDefaultExecutionOptions();
223:   } else {
224:     *request.mutable_execution_options() = *execution_options;
225:   }
226:   for (GlobalData* argument : arguments) {
227:     CHECK(argument != nullptr) &lt;&lt; &quot;Argument pointers must not be null.&quot;;
228:     *request.add_arguments() = argument-&gt;handle();
229:   }
230: 
231:   ExecuteResponse response;
232:   VLOG(1) &lt;&lt; &quot;making execute request: &quot; &lt;&lt; request.ShortDebugString();
233:   Status s = stub_-&gt;ExecuteGraph(&amp;request, &amp;response);
234:   VLOG(1) &lt;&lt; &quot;done with request&quot;;
235: 
236:   if (!s.ok()) {
237:     return s;
238:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/client/client_library.cc" line="120" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="LocalService * ClientLibrary::GetXlaService ( se::Platform * platform )" content="110:   TF_CHECK_OK(client_status.status());
111:   return client_status.ValueOrDie();
112: }
113: 
114: /* static */ LocalService* ClientLibrary::GetXlaService(
115:     se::Platform* platform) {
116:   ClientLibrary&amp; client_library = Singleton();
117:   tensorflow::mutex_lock lock(client_library.service_mutex_);
118:   auto it = client_library.local_instances_.find(platform-&gt;id());
119:   CHECK(it != client_library.local_instances_.end());
120:   return it-&gt;second-&gt;service.get();
121: }
122: 
123: /* static */ StatusOr&lt;CompileOnlyClient*&gt;
124: ClientLibrary::GetOrCreateCompileOnlyClient(se::Platform* platform) {
125:   ClientLibrary&amp; client_library = Singleton();
126:   tensorflow::mutex_lock lock(client_library.service_mutex_);
127: 
128:   if (platform == nullptr) {
129:     TF_ASSIGN_OR_RETURN(platform, PlatformUtil::GetDefaultPlatform());
130:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/metric_table_report.cc" line="83" id="logic" subid="STLFindError" severity="Warning" msg="Using long as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void MetricTableReport::WriteReportToInfoLog ( double expected_metric_sum )" content="73:   return std::move(report_);
74: }
75: 
76: void MetricTableReport::WriteReportToInfoLog(double expected_metric_sum) {
77:   // Write something to the log normally to get the date-time and file prefix.
78:   LOG(INFO) &lt;&lt; &quot;Writing report to log.&quot;;
79: 
80:   int64 pos = 0;
81:   const string report = MakeReport(expected_metric_sum);
82:   while (pos &lt; report.size()) {
83:     int64 end_of_line = report.find(&apos;\n&apos;, pos);
84:     if (end_of_line == string::npos) {
85:       end_of_line = report.size();
86:     }
87:     tensorflow::StringPiece line(report.data() + pos, end_of_line - pos);
88: 
89:     // TODO(b/34779244): Figure out how to do this without the verbose log-line
90:     // prefix. The usual way didn&apos;t compile on open source.
91:     LOG(INFO) &lt;&lt; line;
92: 
93:     pos = end_of_line + 1;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1027" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [buffers_to_assign_sequentially] to null at line 846 implies that [buffers_to_assign_sequentially ] might be null.Dereferencing null pointer [buffers_to_assign_sequentially]." web_identify="{&quot;identify&quot;:&quot;buffers_to_assign_sequentially&quot;}" func_info="Status BufferAssigner::AssignBuffersForComputation ( const HloComputation * computation , const DebugOptions &amp; debug_options , bool is_thread_local , const FlatSet &lt; const LogicalBuffer * &gt; &amp; colocated_buffers , const FlatSet &lt; BufferAllocation::Index &gt; &amp; colocated_allocations , FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; * buffers_to_assign_sequentially , BufferAssignment * assignment )" content="1017:       // There is a sequential instruction ordering, so we delay assignment of
1018:       // temp buffers until after the loop. We do this right before we decide to
1019:       // create a new allocation, to ensure we&apos;ve exhausted all the buffer
1020:       // re-use cases above.
1021:       //
1022:       // Entry parameters and thread local buffers were already handled earlier
1023:       // in this loop iteration.  See BufferAllocation::IsPreallocatedTempBuffer
1024:       // for the definition of temp buffers.
1025:       CHECK(!is_entry_parameter) &lt;&lt; *buffer;
1026:       CHECK(!is_thread_local) &lt;&lt; *buffer;
1027:       (*buffers_to_assign_sequentially)[computation].insert(buffer);
1028:       VLOG(3) &lt;&lt; &quot;Delaying assignment of temp buffer: &quot; &lt;&lt; *buffer;
1029:       continue;
1030:     }
1031: 
1032:     if (!assignment-&gt;HasAllocation(*buffer)) {
1033:       BufferAllocation* allocation = assignment-&gt;NewAllocation(
1034:           *buffer, buffer_size, is_thread_local, /*is_reusable=*/true);
1035:       allocation_indices.push_back(allocation-&gt;index());
1036:       VLOG(3) &lt;&lt; &quot;New allocation #&quot; &lt;&lt; allocation-&gt;index()
1037:               &lt;&lt; &quot; for: &quot; &lt;&lt; *buffer;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1078" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [instruction_sequence] to null at line 1077 implies that [instruction_sequence ] might be null.Dereferencing null pointer [instruction_sequence]." web_identify="{&quot;identify&quot;:&quot;instruction_sequence&quot;}" func_info="Status BufferAssigner::AssignBuffersWithSequentialOrdering ( const FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; &amp; buffers_to_assign_sequentially , bool run_whole_module_heap_simulation , BufferAssignment * assignment )" content="1068:     // only live for the duration of their calling instructions.
1069:     VLOG(1) &lt;&lt; &quot;Running whole-module heap simulation&quot;;
1070:     SequentialHloOrdering::HloModuleSequence module_sequence;
1071:     FlatSet&lt;const LogicalBuffer*&gt; all_buffers_to_assign;
1072:     for (const auto&amp; pair : buffers_to_assign_sequentially) {
1073:       const HloComputation* computation = pair.first;
1074:       const FlatSet&lt;const LogicalBuffer*&gt;&amp; buffers_to_assign = pair.second;
1075:       const std::vector&lt;const HloInstruction*&gt;* instruction_sequence =
1076:           hlo_ordering.SequentialOrder(*computation);
1077:       CHECK(instruction_sequence != nullptr) &lt;&lt; computation-&gt;name();
1078:       module_sequence[computation] = *instruction_sequence;
1079:       all_buffers_to_assign.insert(buffers_to_assign.begin(),
1080:                                    buffers_to_assign.end());
1081:     }
1082:     auto color_map = SplitBuffersByColor(all_buffers_to_assign);
1083:     for (auto&amp; single_colored_set : color_map) {
1084:       auto color = single_colored_set.first;
1085:       VLOG(2) &lt;&lt; &quot;Simulating heap for color &quot; &lt;&lt; color;
1086:       int64 alignment = assignment-&gt;color_alignment_(color);
1087:       HeapSimulator::Options options;
1088:       BufferValueFlatSet buffer_value_set =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1127" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [instruction_sequence] to null at line 1111 implies that [instruction_sequence ] might be null.Dereferencing null pointer [instruction_sequence]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;instruction_sequence&quot;}" func_info="Status BufferAssigner::AssignBuffersWithSequentialOrdering ( const FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; &amp; buffers_to_assign_sequentially , bool run_whole_module_heap_simulation , BufferAssignment * assignment )" content="1117:         HeapSimulator::Options options;
1118:         BufferValueFlatSet buffer_value_set =
1119:             ToBufferValueFlatSet(single_colored_set.second);
1120:         options.buffers_to_assign = &amp;buffer_value_set;
1121:         TF_ASSIGN_OR_RETURN(
1122:             const HeapSimulator::Result result,
1123:             HeapSimulator::Run(MakeUnique&lt;DecreasingSizeRunsHeap&gt;(
1124:                                    MakeUnique&lt;LazyBestFitHeap&gt;(alignment)),
1125:                                *computation, *instruction_sequence,
1126:                                assignment-&gt;points_to_analysis(),
1127:                                assignment-&gt;buffer_size_, options));
1128:         AssignBuffersFromHeapSimulator(result, assignment,
1129:                                        single_colored_set.first);
1130:       }
1131:     }
1132:   }
1133:   return Status::OK();
1134: }
1135: 
1136: namespace {
1137: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/call_graph.cc" line="129" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const CallGraphNode &amp; CallGraph::GetNode ( const HloComputation * computation ) const" content="119:     }
120:   }
121: }
122: 
123: CallGraph::CallGraph(const HloModule* module) : module_(module) {}
124: 
125: const CallGraphNode&amp; CallGraph::GetNode(
126:     const HloComputation* computation) const {
127:   auto it = node_indices_.find(computation);
128:   CHECK(it != node_indices_.end());
129:   return nodes_[it-&gt;second];
130: }
131: 
132: CallGraphNode&amp; CallGraph::GetNode(const HloComputation* computation) {
133:   auto it = node_indices_.find(computation);
134:   CHECK(it != node_indices_.end());
135:   return nodes_[it-&gt;second];
136: }
137: 
138: bool CallGraph::DominatesHelper(
139:     const HloComputation* a, const HloComputation* b,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/call_graph.cc" line="135" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="CallGraphNode &amp; CallGraph::GetNode ( const HloComputation * computation )" content="125: const CallGraphNode&amp; CallGraph::GetNode(
126:     const HloComputation* computation) const {
127:   auto it = node_indices_.find(computation);
128:   CHECK(it != node_indices_.end());
129:   return nodes_[it-&gt;second];
130: }
131: 
132: CallGraphNode&amp; CallGraph::GetNode(const HloComputation* computation) {
133:   auto it = node_indices_.find(computation);
134:   CHECK(it != node_indices_.end());
135:   return nodes_[it-&gt;second];
136: }
137: 
138: bool CallGraph::DominatesHelper(
139:     const HloComputation* a, const HloComputation* b,
140:     tensorflow::gtl::FlatSet&lt;const HloComputation*&gt;* visited) const {
141:   if (a == b || ContainsKey(*visited, b)) {
142:     // The call graph is guaranteed to be acyclic so any previously visited node
143:     // we encounter was already determined to be dominated.
144:     return true;
145:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/cpu/ir_emitter.cc" line="2699" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * IrEmitter::GetEmittedValueFor ( const HloInstruction * hlo )" content="2689:       std::back_inserter(arrays),
2690:       [&amp;](const HloInstruction* operand) { return GetIrArrayFor(operand); });
2691:   return arrays;
2692: }
2693: 
2694: llvm::Value* IrEmitter::GetEmittedValueFor(const HloInstruction* hlo) {
2695:   auto it = emitted_value_.find(hlo);
2696:   if (it == emitted_value_.end()) {
2697:     LOG(FATAL) &lt;&lt; &quot;could not find emitted value for: &quot; &lt;&lt; hlo-&gt;ToString();
2698:   }
2699:   return it-&gt;second;
2700: }
2701: 
2702: llvm::Type* IrEmitter::IrShapeType(const Shape&amp; shape) {
2703:   return llvm_ir::ShapeToIrType(shape, module_);
2704: }
2705: 
2706: llvm::Value* IrEmitter::GetProfileCountersArgument() {
2707:   return compute_function_-&gt;profile_counters_arg();
2708: }
2709: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/cpu/xfeed_manager.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [current_buffer_] to null at line 76 implies that [current_buffer_ ] might be null.Dereferencing null pointer [current_buffer_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;current_buffer_&quot;}" func_info="void XfeedQueueManager::ReleaseCurrentBuffer ( int length , void * data , StatusOr &lt; Shape &gt; shape )" content="67:   return current_buffer_;
68: }
69: 
70: void XfeedQueueManager::ReleaseCurrentBuffer(int32 length, void* data,
71:                                              StatusOr&lt;Shape&gt; shape) {
72:   VLOG(3) &lt;&lt; &quot;Releasing buffer with shape: &quot;
73:           &lt;&lt; (shape.ok() ? ShapeUtil::HumanString(shape.ValueOrDie())
74:                          : &quot;&lt;error status&gt;&quot;);
75:   tensorflow::mutex_lock l(mu_);
76:   CHECK(current_buffer_ != nullptr);
77:   CHECK_EQ(length, current_buffer_-&gt;length());
78:   CHECK_EQ(data, current_buffer_-&gt;data());
79:   current_buffer_-&gt;Done(std::move(shape));
80:   current_buffer_ = nullptr;
81: }
82: 
83: }  // namespace runtime
84: }  // namespace cpu
85: }  // namespace xla
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/fusion_merger.cc" line="68" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;instruction&quot;}" func_info="double CalculateBytesReadByFusionParameter ( HloInstruction * param )" content="58:   std::vector&lt;HloInstruction*&gt; instructions;
59:   MaybeResolveTupleElements(param, &amp;instructions);
60: 
61:   // Iterate through &apos;instructions&apos; accumulating byte sizes of each instruction
62:   // shape. For each &apos;instruction&apos; in &apos;instructions&apos;, if all users of
63:   // &apos;instruction&apos; are Slice instructions, accumuates the byte sizes of each
64:   // Slice for a more accurate estimate of bytes read.
65:   double bytes = 0.0;
66:   for (auto&amp; instruction : instructions) {
67:     if (c_all_of(instruction-&gt;users(), [](const HloInstruction* instruction) {
68:           return instruction-&gt;opcode() == HloOpcode::kSlice ||
69:                  instruction-&gt;opcode() == HloOpcode::kDynamicSlice;
70:         })) {
71:       // All users are slice: accumulate bytes of all user slice instructions.
72:       for (auto&amp; user : instruction-&gt;users()) {
73:         bytes += ShapeUtil::ByteSizeOf(user-&gt;shape());
74:       }
75:     } else {
76:       // Some users are not slice: accumulate full size of &apos;instruction&apos;.
77:       bytes += ShapeUtil::ByteSizeOf(instruction-&gt;shape());
78:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/hlo_to_ir_bindings.h" line="77" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * HloToIrBindings::GetBasePointer ( const HloInstruction &amp; hlo , ShapeIndexView shape_index = { } ) const" content="67: 
68:   llvm::Value* GetTempBufferBase() const { return temp_buffer_base_; }
69:   void SetTempBufferBase(llvm::Value* v) { temp_buffer_base_ = v; }
70: 
71:   // A helper method that returns the base pointer of the IrArray containing the
72:   // output of &quot;inst&quot;.at the given ShapeIndex.
73:   llvm::Value* GetBasePointer(const HloInstruction&amp; hlo,
74:                               ShapeIndexView shape_index = {}) const {
75:     auto it = base_ptrs_.find(&amp;hlo);
76:     CHECK(it != base_ptrs_.end()) &lt;&lt; hlo.ToString();
77:     return it-&gt;second.element(shape_index);
78:   }
79: 
80:   // Returns the IrArray which contains the output of hlo.
81:   //
82:   // consumer is the HLO in which this IrArray is used -- we use this to (try
83:   // to) add metadata indicating that the array is invariant within consumer.
84:   //
85:   // To get the buffer into which hlo should write its own output, call
86:   // GetIrArray(hlo, hlo).
87:   llvm_ir::IrArray GetIrArray(const HloInstruction&amp; hlo,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc" line="628" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [first_reduce] to null at line 593 implies that [first_reduce ] might be null.Dereferencing null pointer [first_reduce]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;first_reduce&quot;}" func_info="Status IrEmitterUnnested::HandleFusion ( HloInstruction * fusion )" content="618:           const HloInstruction* inst = output_instructions[i];
619:           ShapeIndex output_shape_index;
620:           if (root-&gt;opcode() == HloOpcode::kTuple) {
621:             output_shape_index = {i};
622:           }
623:           if (inst-&gt;opcode() == HloOpcode::kReduce) {
624:             CHECK(IsReductionToVector(*inst))
625:                 &lt;&lt; &quot;Only reductions to vector are supported&quot;;
626:             // Shapes, layouts and dimensions must be the same for all reduces
627:             // inside of this fusion.
628:             CHECK(ShapeUtil::Equal(first_reduce-&gt;shape(), inst-&gt;shape()));
629:             CHECK(ShapeUtil::Equal(first_reduce-&gt;operand(0)-&gt;shape(),
630:                                    inst-&gt;operand(0)-&gt;shape()));
631:             CHECK(ShapeUtil::Equal(first_reduce-&gt;operand(1)-&gt;shape(),
632:                                    inst-&gt;operand(1)-&gt;shape()));
633:             CHECK(first_reduce-&gt;dimensions() == inst-&gt;dimensions());
634:             input_gens.push_back(fused_emitter.GetGenerator(inst-&gt;operand(0)));
635:             init_value_gens.push_back(
636:                 fused_emitter.GetGenerator(inst-&gt;operand(1)));
637:             reducers.push_back(inst-&gt;to_apply());
638:             reduce_output_shapes.push_back(std::move(output_shape_index));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/kernel_thunk.cc" line="92" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Status KernelThunk::ExecuteOnStream ( const BufferAllocations &amp; buffer_allocations , se::Stream * stream , HloExecutionProfiler * profiler )" content="82:   se::StreamExecutor* executor = stream-&gt;parent();
83:   LaunchDimensions launch_dimensions;
84:   const se::KernelBase* kernel = nullptr;
85: 
86:   {
87:     tensorflow::mutex_lock lock(mutex_);
88:     auto it = kernel_cache_.find(executor);
89:     CHECK(it != kernel_cache_.end())
90:         &lt;&lt; &quot;Initialize() not called for StreamExecutor &quot; &lt;&lt; executor;
91:     launch_dimensions = launch_dimensions_;
92:     kernel = &amp;it-&gt;second;
93:   }
94: 
95:   VLOG(3) &lt;&lt; &quot;Launching &quot; &lt;&lt; kernel-&gt;name();
96:   // Launch the kernel with potentially multiple blocks and threads.
97:   static constexpr int kKernelArgsLimit = 1024;
98:   auto kernel_args = MakeUnique&lt;se::KernelArgsArray&lt;kKernelArgsLimit&gt;&gt;();
99:   for (const BufferAllocation* arg : args_) {
100:     const auto&amp; buf = buffer_allocations.GetDeviceAddress(arg-&gt;index());
101:     kernel_args-&gt;add_device_memory_argument(buf);
102:     VLOG(3) &lt;&lt; &quot;  Arg: alloc #&quot; &lt;&lt; arg-&gt;index() &lt;&lt; &quot;: &quot; &lt;&lt; buf.opaque() &lt;&lt; &quot; (&quot;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/multi_output_fusion.cc" line="223" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;producer&quot;}" func_info="bool GpuMultiOutputFusion::DoProducerConsumerMultiOutputFusion ( )" content="213:       break;
214:     }
215:   }
216: 
217:   // Filter out pairs that will be no longer fusable because of reachability
218:   // change.
219:   for (auto&amp; fusion_pair : potential_fusion_list) {
220:     HloInstruction* producer = fusion_pair.first;
221:     HloInstruction* consumer = fusion_pair.second;
222:     if (!c_any_of(consumer-&gt;operands(), [&amp;](HloInstruction* operand) {
223:           return producer != operand &amp;&amp;
224:                  reachability()-&gt;IsReachable(producer, operand);
225:         })) {
226:       UpdateReachability(producer, consumer, instrs_to_update_reachability);
227:       fusion_list.push_back(fusion_pair);
228:     }
229:   }
230: 
231:   for (auto fusions_to_create : fusion_list) {
232:     HloInstruction* producer = fusions_to_create.first;
233:     HloInstruction* consumer = fusions_to_create.second;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/gpu/while_transformer.cc" line="139" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fused_root_tree_] to null at line 136 implies that [fused_root_tree_ ] might be null.Dereferencing null pointer [fused_root_tree_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;fused_root_tree_&quot;}" func_info="Status ExprTree::Match ( const HloInstruction * instruction , std :: unordered_map &lt; string , const HloInstruction * &gt; * tagged_instructions ) const" content="129: 
130:     VLOG(2) &lt;&lt; &quot;Matched &quot; &lt;&lt; HloOpcodeString(opcode_) &lt;&lt; &quot;: &quot; &lt;&lt; tag_;
131:     if (!tag_.empty()) {
132:       tagged_instructions-&gt;insert({tag_, instruction});
133:     }
134: 
135:     if (instruction-&gt;opcode() == HloOpcode::kFusion) {
136:       CHECK(fused_root_tree_ != nullptr);
137:       // Match fused instructions for this node starting a &apos;fused_root_tree&apos;.
138:       TF_RETURN_IF_ERROR(fused_root_tree_-&gt;Match(
139:           instruction-&gt;fused_expression_root(), tagged_instructions));
140:     }
141: 
142:     // Match each operand in &apos;operands_&apos;.
143:     for (auto&amp; pair : operands_) {
144:       TF_RETURN_IF_ERROR(pair.second-&gt;Match(instruction-&gt;operand(pair.first),
145:                                             tagged_instructions));
146:     }
147:     return Status::OK();
148:   }
149: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/heap_simulator.cc" line="508" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [share_with_canonical] to null at line 507 implies that [share_with_canonical ] might be null.Dereferencing null pointer [share_with_canonical]." web_identify="{&quot;identify&quot;:&quot;share_with_canonical&quot;}" func_info="void HeapSimulator::FillDebugTrace ( HeapSimulatorTrace::Event::Kind kind , const BufferValue * buffer , const HloInstruction * instruction , const BufferValue * share_with_canonical )" content="498:                                    const BufferValue* buffer,
499:                                    const HloInstruction* instruction,
500:                                    const BufferValue* share_with_canonical) {
501:   HeapSimulatorTrace::Event* event = debug_trace_.add_events();
502:   event-&gt;set_kind(kind);
503:   event-&gt;set_buffer_id(buffer-&gt;id());
504:   event-&gt;set_computation_name(instruction-&gt;parent()-&gt;name());
505:   event-&gt;set_instruction_name(instruction-&gt;name());
506:   if (kind == HeapSimulatorTrace::Event::SHARE_WITH) {
507:     CHECK(share_with_canonical != nullptr);
508:     event-&gt;set_share_with_canonical_id(share_with_canonical-&gt;id());
509:   } else {
510:     CHECK(share_with_canonical == nullptr);
511:   }
512: }
513: 
514: void NoFragmentationStatsHeap::Alloc(const BufferValue* buffer, int64 size) {
515:   current_heap_size_ += size;
516:   if (current_heap_size_ &gt; max_heap_size_) {
517:     max_heap_size_ = current_heap_size_;
518:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/heap_simulator.cc" line="671" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [alloc_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;alloc_it&quot;}" func_info="void LazyBestFitHeap::Free ( const BufferValue * buffer , long size )" content="661:   }
662: 
663:   // Otherwise lazily allocate the buffer in Free.
664:   result_.chunk_map.emplace(buffer, Chunk{kLazyAllocOffset, size});
665: }
666: 
667: void LazyBestFitHeap::Free(const BufferValue* buffer, int64 size) {
668:   auto alloc_it = result_.chunk_map.find(buffer);
669:   CHECK(alloc_it != result_.chunk_map.end())
670:       &lt;&lt; &quot;Free called on non-allocated buffer: &quot; &lt;&lt; *buffer;
671:   Chunk* alloc = &amp;alloc_it-&gt;second;
672:   CHECK_EQ(alloc-&gt;size, size) &lt;&lt; &quot;Free with mismatched sizes: &quot; &lt;&lt; *buffer;
673:   if (alloc-&gt;offset != kLazyAllocOffset) {
674:     // The buffer was already allocated in Alloc, do a normal free.
675:     AddFreeChunk(alloc-&gt;offset, alloc-&gt;size);
676:   } else {
677:     // This buffer is lazily allocated, so we *can not* allocate out of existing
678:     // free chunks, since that might cause interference between buffers.  The
679:     // buffer is allocated by growing the heap, accounting for alignment.
680:     alloc-&gt;offset = RoundUpToNearest(result_.heap_size, alignment_);
681:     const int64 new_end = alloc-&gt;chunk_end();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_cost_analysis.cc" line="35" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloCostAnalysis::current_should_compute_bottleneck_time_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloCostAnalysis::current_should_compute_bottleneck_time_,&quot;}" func_info="xla" content="25: #include &quot;tensorflow/core/lib/core/errors.h&quot;
26: #include &quot;tensorflow/core/lib/gtl/map_util.h&quot;
27: 
28: namespace xla {
29: 
30: constexpr char HloCostAnalysis::kFlopsKey[];
31: constexpr char HloCostAnalysis::kTranscendentalsKey[];
32: constexpr char HloCostAnalysis::kBytesAccessedKey[];
33: constexpr char HloCostAnalysis::kOptimalSecondsKey[];
34: 
35: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size)
36:     : HloCostAnalysis(shape_size, {}) {}
37: 
38: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size,
39:                                  const Properties&amp; per_second_rates)
40:     : shape_size_(shape_size), per_second_rates_(per_second_rates) {}
41: 
42: Status HloCostAnalysis::Preprocess(const HloInstruction* hlo) {
43:   // Set current instruction cost values to reasonable default values. Each
44:   // handler can overwrite these values. In Postprocess, these values are
45:   // accumulated and written to the per-instruction maps.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_cost_analysis.cc" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloCostAnalysis::current_should_compute_bottleneck_time_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloCostAnalysis::current_should_compute_bottleneck_time_,&quot;}" func_info="xla" content="28: namespace xla {
29: 
30: constexpr char HloCostAnalysis::kFlopsKey[];
31: constexpr char HloCostAnalysis::kTranscendentalsKey[];
32: constexpr char HloCostAnalysis::kBytesAccessedKey[];
33: constexpr char HloCostAnalysis::kOptimalSecondsKey[];
34: 
35: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size)
36:     : HloCostAnalysis(shape_size, {}) {}
37: 
38: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size,
39:                                  const Properties&amp; per_second_rates)
40:     : shape_size_(shape_size), per_second_rates_(per_second_rates) {}
41: 
42: Status HloCostAnalysis::Preprocess(const HloInstruction* hlo) {
43:   // Set current instruction cost values to reasonable default values. Each
44:   // handler can overwrite these values. In Postprocess, these values are
45:   // accumulated and written to the per-instruction maps.
46:   current_properties_.clear();
47:   current_should_compute_bottleneck_time_ = true;
48: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_dataflow_analysis_test.cc" line="64" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [analysis_] to null at line 61 implies that [analysis_ ] might be null.Dereferencing null pointer [analysis_]." web_identify="{&quot;identify&quot;:&quot;analysis_&quot;}" func_info="std::vector &lt; HloValue &gt; HloDataflowAnalysisTest::HloValuesAt ( const HloInstruction * instruction , const ShapeIndex &amp; index = { } )" content="54:             .ConsumeValueOrDie();
55:     return *analysis_;
56:   }
57: 
58:   // Return a vector of the HloValues at the given program position.
59:   std::vector&lt;HloValue&gt; HloValuesAt(const HloInstruction* instruction,
60:                                     const ShapeIndex&amp; index = {}) {
61:     CHECK(analysis_ != nullptr);
62:     std::vector&lt;HloValue&gt; values;
63:     for (const HloValue* value :
64:          analysis_-&gt;GetValueSet(instruction, index).values()) {
65:       values.push_back(*value);
66:     }
67:     return values;
68:   }
69: 
70:   // Returns true if the top-level values for instructions &apos;a&apos; and &apos;b&apos; may
71:   // interfere. Precondition: &apos;a&apos; and &apos;b&apos; define array-shaped values.
72:   bool InstructionsMayInterfere(const HloOrdering&amp; ordering,
73:                                 const HloInstruction* a,
74:                                 const HloInstruction* b) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_evaluator.h" line="199" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const Literal &amp; HloEvaluator::GetEvaluatedLiteralFor ( const HloInstruction * hlo )" content="189:   // A Constant instruction is considered evaluated and its literal will be
190:   // returned directly without looking up the cache.
191:   // Crash with log if the given instruction has not been evaluated previously.
192:   const Literal&amp; GetEvaluatedLiteralFor(const HloInstruction* hlo) {
193:     if (hlo-&gt;IsConstant()) {
194:       return hlo-&gt;literal();
195:     }
196:     auto it = evaluated_.find(hlo);
197:     CHECK(it != evaluated_.end())
198:         &lt;&lt; &quot;could not find evaluated value for: &quot; &lt;&lt; hlo-&gt;ToString();
199:     return *(it-&gt;second);
200:   }
201: 
202:   // Tracks the HLO instruction and its evaluated literal result.
203:   // TODO(b/35950897): have better memory management here to free instructions
204:   // that are no longer a parent for any other subsequent instruction in
205:   // post-orderring.
206:   // Must be cleared for each evaluation.
207:   tensorflow::gtl::FlatMap&lt;const HloInstruction*, std::unique_ptr&lt;Literal&gt;&gt;
208:       evaluated_;
209: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_graph_dumper.cc" line="1461" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph_renderer] to null at line 1458 implies that [graph_renderer ] might be null.Dereferencing null pointer [graph_renderer]." web_identify="{&quot;identify&quot;:&quot;graph_renderer&quot;}" func_info="string ExportGraph ( const string &amp; graph , int graph_kind , const DebugOptions &amp; debug_options )" content="1451:                    const DebugOptions&amp; debug_options) {
1452:   string path = debug_options.xla_hlo_graph_path();
1453:   if (!path.empty()) {
1454:     return SaveGraph(graph, graph_kind, path);
1455:   } else {
1456:     auto graph_renderer =
1457:         GraphRendererRegistry::Default()-&gt;GetDefaultRenderer();
1458:     CHECK(graph_renderer != nullptr)
1459:         &lt;&lt; &quot;No registered renderer for the HLO graph. &quot;
1460:            &quot;Use --xla_hlo_graph_path=PATH to export to local file system&quot;;
1461:     return graph_renderer-&gt;RenderGraph(graph, graph_kind, debug_options);
1462:   }
1463: }
1464: 
1465: }  // namespace
1466: 
1467: string DumpGraph(const HloComputation&amp; computation, const string&amp; label,
1468:                  const DebugOptions&amp; debug_options,
1469:                  const HloExecutionProfile* hlo_execution_profile,
1470:                  bool show_backend_config) {
1471:   GraphRendererInterface::GraphKind graph_kind;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_graph_dumper.cc" line="325" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloDotDumper::root_node_id_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloDotDumper::root_node_id_,&quot;}" func_info="HloDotDumper" content="315:     case HloOpcode::kNe:
316:       return &quot;not-equal-to&quot;;
317:     default:
318:       return nullopt;
319:   }
320: }
321: 
322: // Encapsulates logic for dumping an HLO module to DOT (i.e. graphviz syntax).
323: class HloDotDumper {
324:  public:
325:   HloDotDumper(const HloComputation* computation, tensorflow::StringPiece label,
326:                const DebugOptions&amp; debug_options, bool show_backend_config,
327:                const HloExecutionProfile* profile, NodeFilter filter)
328:       : computation_(computation),
329:         label_(std::string(label)),
330:         debug_options_(debug_options),
331:         show_backend_config_(show_backend_config),
332:         profile_(profile),
333:         filter_(std::move(filter)) {}
334: 
335:   string Dump();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instruction.cc" line="2316" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [child] to null at line 2315 implies that [child ] might be null.Dereferencing null pointer [child]." web_identify="{&quot;identify&quot;:&quot;child&quot;}" func_info="&gt; bool xla::PushDFSChild ( Visitor * visitor , DFSStack * dfs_stack , HloInstruction * child )" content="2306: 
2307: using DFSStack =
2308:     tensorflow::gtl::InlinedVector&lt;std::pair&lt;int, HloInstruction*&gt;, 16&gt;;
2309: 
2310: // Push &quot;child&quot; onto the dfs_stack if not already visited.  Returns false if a
2311: // cycle was detected, and true otherwise.
2312: template &lt;typename Visitor&gt;
2313: inline bool PushDFSChild(Visitor* visitor, DFSStack* dfs_stack,
2314:                          HloInstruction* child) {
2315:   CHECK(child != nullptr);
2316:   const int id = child-&gt;unique_id();
2317:   CHECK_GE(id, 0) &lt;&lt; &quot;instruction may not have a parent computation&quot;;
2318:   switch (visitor-&gt;GetVisitState(id)) {
2319:     case Visitor::kVisiting:
2320:       return false;
2321: 
2322:     case Visitor::kVisited:
2323:       // Nothing to do
2324:       return true;
2325: 
2326:     case Visitor::kNotVisited:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instruction.h" line="1071" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dot_dimension_numbers_] to null at line 1070 implies that [dot_dimension_numbers_ ] might be null.Dereferencing null pointer [dot_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;dot_dimension_numbers_&quot;}" func_info="const DotDimensionNumbers &amp; HloInstruction::dot_dimension_numbers ( ) const" content="1061:   }
1062: 
1063:   void SetCopyElisionAllowed(bool value) {
1064:     CHECK_EQ(HloOpcode::kCopy, opcode_);
1065:     copy_elision_allowed_ = value;
1066:   }
1067: 
1068:   // Returns data on the dimension numbers used for a dot operation.
1069:   const DotDimensionNumbers&amp; dot_dimension_numbers() const {
1070:     CHECK(dot_dimension_numbers_ != nullptr);
1071:     return *dot_dimension_numbers_;
1072:   }
1073: 
1074:   // Returns the dump string of the dot dimension numbers.
1075:   string DotDimensionNumbersToString() const;
1076: 
1077:   // Clones the HLO instruction. The clone will have the same opcode, shape, and
1078:   // operands. After creation the clone has no uses. &quot;this&quot; (the instruction
1079:   // cloned from) is not changed. Suffix is the string to append to the name of
1080:   // the instruction to form the name of the cloned instruction.
1081:   // Ignores the control predecessors and successors of this HLO instruction.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instructions.cc" line="1934" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gather_dimension_numbers_] to null at line 1931 implies that [gather_dimension_numbers_ ] might be null.Dereferencing null pointer [gather_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;gather_dimension_numbers_&quot;}" func_info="string HloGatherInstruction::GatherDimensionNumbersToString ( ) const" content="1924:   AppendOperand(gather_indices);
1925:   gather_dimension_numbers_ =
1926:       MakeUnique&lt;GatherDimensionNumbers&gt;(gather_dim_numbers);
1927:   c_copy(window_bounds, std::back_inserter(gather_window_bounds_));
1928: }
1929: 
1930: string HloGatherInstruction::GatherDimensionNumbersToString() const {
1931:   CHECK(gather_dimension_numbers_ != nullptr);
1932:   string output_window_dims =
1933:       StrCat(&quot;output_window_dims={&quot;,
1934:              Join(gather_dimension_numbers_-&gt;output_window_dims(), &quot;,&quot;), &quot;}&quot;);
1935:   string elided_window_dims =
1936:       StrCat(&quot;elided_window_dims={&quot;,
1937:              Join(gather_dimension_numbers_-&gt;elided_window_dims(), &quot;,&quot;), &quot;}&quot;);
1938:   string gather_dims_to_operand_dims = StrCat(
1939:       &quot;gather_dims_to_operand_dims={&quot;,
1940:       Join(gather_dimension_numbers_-&gt;gather_dims_to_operand_dims(), &quot;,&quot;), &quot;}&quot;);
1941:   string index_vector_dim = StrCat(
1942:       &quot;index_vector_dim=&quot;, gather_dimension_numbers_-&gt;index_vector_dim());
1943: 
1944:   return Join&lt;std::initializer_list&lt;string&gt;&gt;(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instructions.cc" line="841" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fused_root] to null at line 839 implies that [fused_root ] might be null.Dereferencing null pointer [fused_root]." web_identify="{&quot;identify&quot;:&quot;fused_root&quot;}" func_info="HloFusionInstruction::HloFusionInstruction ( const Shape &amp; shape , int fusion_kind , HloInstruction * fused_root ) : HloInstruction ( HloOpcode::kFusion , shape ) , fusion_kind_ ( fusion_kind )" content="831:     HloCloneContext* context) const {
832:   LOG(FATAL) &lt;&lt; &quot;Not yet implemented, clone: &quot; &lt;&lt; HloOpcodeString(opcode());
833: }
834: 
835: HloFusionInstruction::HloFusionInstruction(const Shape&amp; shape,
836:                                            FusionKind fusion_kind,
837:                                            HloInstruction* fused_root)
838:     : HloInstruction(HloOpcode::kFusion, shape), fusion_kind_(fusion_kind) {
839:   CHECK(fused_root != nullptr);
840:   SetAndSanitizeName(&quot;fusion&quot;);
841:   set_parent(fused_root-&gt;parent());
842:   set_metadata(fused_root-&gt;metadata());
843:   CloneAndFuseInternal(fused_root);
844: }
845: 
846: HloFusionInstruction::HloFusionInstruction(
847:     const Shape&amp; shape, FusionKind fusion_kind,
848:     tensorflow::gtl::ArraySlice&lt;HloInstruction*&gt; operands,
849:     HloComputation* fusion_computation)
850:     : HloInstruction(HloOpcode::kFusion, shape), fusion_kind_(fusion_kind) {
851:   for (auto operand : operands) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instructions.h" line="1020" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [window_] to null at line 1019 implies that [window_ ] might be null.Dereferencing null pointer [window_]." web_identify="{&quot;identify&quot;:&quot;window_&quot;}" func_info="const Window &amp; HloCustomCallInstruction::window ( ) const" content="1010:   Window window_;
1011: };
1012: 
1013: class HloCustomCallInstruction : public HloInstruction {
1014:  public:
1015:   explicit HloCustomCallInstruction(
1016:       const Shape&amp; shape, tensorflow::gtl::ArraySlice&lt;HloInstruction*&gt; operands,
1017:       tensorflow::StringPiece custom_call_target);
1018:   const Window&amp; window() const override {
1019:     CHECK(window_ != nullptr);
1020:     return *window_;
1021:   }
1022: 
1023:   void set_window(const Window&amp; window) override {
1024:     window_ = MakeUnique&lt;Window&gt;(window);
1025:   }
1026: 
1027:   const ConvolutionDimensionNumbers&amp; convolution_dimension_numbers() const {
1028:     CHECK(convolution_dimension_numbers_ != nullptr);
1029:     return *convolution_dimension_numbers_;
1030:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instructions.h" line="1029" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [convolution_dimension_numbers_] to null at line 1028 implies that [convolution_dimension_numbers_ ] might be null.Dereferencing null pointer [convolution_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;convolution_dimension_numbers_&quot;}" func_info="const ConvolutionDimensionNumbers &amp; HloCustomCallInstruction::convolution_dimension_numbers ( ) const" content="1019:     CHECK(window_ != nullptr);
1020:     return *window_;
1021:   }
1022: 
1023:   void set_window(const Window&amp; window) override {
1024:     window_ = MakeUnique&lt;Window&gt;(window);
1025:   }
1026: 
1027:   const ConvolutionDimensionNumbers&amp; convolution_dimension_numbers() const {
1028:     CHECK(convolution_dimension_numbers_ != nullptr);
1029:     return *convolution_dimension_numbers_;
1030:   }
1031: 
1032:   void set_convolution_dimension_numbers(
1033:       const ConvolutionDimensionNumbers&amp; dnums) {
1034:     convolution_dimension_numbers_ =
1035:         MakeUnique&lt;ConvolutionDimensionNumbers&gt;(dnums);
1036:   }
1037:   const string&amp; custom_call_target() const { return custom_call_target_; }
1038:   // Returns a serialized representation of this instruction.
1039:   HloInstructionProto ToProto() const override;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_instructions.h" line="1161" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gather_dimension_numbers_] to null at line 1160 implies that [gather_dimension_numbers_ ] might be null.Dereferencing null pointer [gather_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;gather_dimension_numbers_&quot;}" func_info="const GatherDimensionNumbers &amp; HloGatherInstruction::gather_dimension_numbers ( ) const" content="1151: 
1152: class HloGatherInstruction : public HloInstruction {
1153:  public:
1154:   explicit HloGatherInstruction(
1155:       const Shape&amp; shape, HloInstruction* operand,
1156:       HloInstruction* gather_indices,
1157:       const GatherDimensionNumbers&amp; gather_dim_numbers,
1158:       tensorflow::gtl::ArraySlice&lt;int64&gt; window_bounds);
1159:   const GatherDimensionNumbers&amp; gather_dimension_numbers() const {
1160:     CHECK(gather_dimension_numbers_ != nullptr);
1161:     return *gather_dimension_numbers_;
1162:   }
1163:   tensorflow::gtl::ArraySlice&lt;int64&gt; gather_window_bounds() const {
1164:     return gather_window_bounds_;
1165:   }
1166:   // Returns the dump string of the gather dimension numbers.
1167:   string GatherDimensionNumbersToString() const;
1168:   // Returns a serialized representation of this instruction.
1169:   HloInstructionProto ToProto() const override;
1170: 
1171:   // Creates an instance of GatherDimensionNumbers.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_lexer.h" line="37" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloLexer::token_start_,current_kind_,decimal_val_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloLexer::token_start_,current_kind_,decimal_val_,&quot;}" func_info="xla::HloLexer" content="27: #include &quot;map/base/mlp/tf/tensorflow/core/platform/types.h&quot;
28: 
29: namespace xla {
30: 
31: // Lexer for the HloModule::ToString() format text.
32: //
33: // This class is meant to be used by hlo_parser.cc.  You shouldn&apos;t need to use
34: // it directly.
35: class HloLexer {
36:  public:
37:   explicit HloLexer(tensorflow::StringPiece buf) : buf_(buf) {
38:     current_ptr_ = buf_.begin();
39:   }
40: 
41:   TokKind Lex() { return current_kind_ = LexToken(); }
42: 
43:   TokKind GetKind() const { return current_kind_; }
44:   string GetStrVal() const {
45:     switch (GetKind()) {
46:       case TokKind::kName:
47:       case TokKind::kAttributeName:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_rematerialization.cc" line="189" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="Item * InstructionList::GetItem ( const HloInstruction * inst ) const" content="179:     Item* item = new Item;
180:     item-&gt;instruction = inst;
181:     CHECK(item_map_.insert({inst, item}).second) &lt;&lt; &quot;inserting inst twice&quot;;
182:     return item;
183:   }
184: 
185:   // Return the Item corresponding to inst.
186:   Item* GetItem(const HloInstruction* inst) const {
187:     auto iter = item_map_.find(inst);
188:     CHECK(iter != item_map_.end()) &lt;&lt; &quot;Did not find &quot; &lt;&lt; inst-&gt;name();
189:     return iter-&gt;second;
190:   }
191: 
192:   // Insert instruction &apos;to_insert&apos; immediately before the earliest instruction
193:   // in &apos;before_instructions&apos;.
194:   //
195:   // Each instruction gets a non-decreasing ordinal number. We use this to let
196:   // InsertBeforeInstructions quickly insert an instruction before the earliest
197:   // instruction in a set of instructions.  If position_number_[a] &lt;
198:   // position_number_[b] then &apos;a&apos; comes before &apos;b&apos; in the list. If the position
199:   // numbers are the same then nothing can be said about their order without
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_runner.cc" line="114" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [literal] to null at line 112 implies that [literal ] might be null.Dereferencing null pointer [literal]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;literal&quot;}" func_info="StatusOr &lt; std::vector &lt; ScopedShapedBuffer &gt; &gt; HloRunner::TransferLiteralsToDevice ( const tensorflow::gtl::ArraySlice &lt; const Literal * &gt; literals )" content="104:       stream.get(), literal, buffer));
105:   return std::move(buffer);
106: }
107: 
108: StatusOr&lt;std::vector&lt;ScopedShapedBuffer&gt;&gt; HloRunner::TransferLiteralsToDevice(
109:     const tensorflow::gtl::ArraySlice&lt;const Literal*&gt; literals) {
110:   std::vector&lt;ScopedShapedBuffer&gt; buffers;
111:   for (const Literal* literal : literals) {
112:     CHECK(literal != nullptr);
113:     TF_ASSIGN_OR_RETURN(ScopedShapedBuffer buffer,
114:                         TransferLiteralToDevice(*literal));
115:     buffers.push_back(std::move(buffer));
116:   }
117:   return std::move(buffers);
118: }
119: 
120: StatusOr&lt;std::vector&lt;ScopedShapedBuffer&gt;&gt; HloRunner::TransferLiteralsToDevice(
121:     const tensorflow::gtl::ArraySlice&lt;std::unique_ptr&lt;Literal&gt;&gt; literals) {
122:   std::vector&lt;const Literal*&gt; literal_pointers;
123:   literal_pointers.reserve(literals.size());
124:   for (const auto&amp; literal : literals) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_scheduling.cc" line="192" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [unscheduled_use_count_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;unscheduled_use_count_it&quot;}" func_info="ReadyListEntry ListScheduler::MakeReadyListEntry ( const HloInstruction * instruction )" content="182:       }
183:     }
184: 
185:     for (auto* buffer : buffer_uses_.at(instruction)) {
186:       if (IgnoreBuffer(*buffer)) {
187:         continue;
188:       }
189:       auto unscheduled_use_count_it = unscheduled_use_count_.find(buffer);
190:       CHECK(unscheduled_use_count_it != unscheduled_use_count_.end());
191:       entry.used_buffer_unscheduled_use_counts.push_back(
192:           &amp;*unscheduled_use_count_it);
193:     }
194:     return entry;
195:   }
196: 
197:   // Returns the number of bytes freed if the HLO instruction is scheduled.
198:   // If the instruction calls subcomputations, we count the memory used by the
199:   // subcomputations as memory &quot;defined&quot; by the instruction. This is not
200:   // entirely accurate, because subcomputation memory will be freed after the
201:   // instruction finishes. But it is more accurate than not taking
202:   // subcomputations into account at all. In the future, we may improve
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_sharding_metadata.cc" line="208" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [operand_sharding] to null at line 206 implies that [operand_sharding ] might be null.Dereferencing null pointer [operand_sharding]." web_identify="{&quot;identify&quot;:&quot;operand_sharding&quot;}" func_info="StatusOr &lt; long &gt; ApplyDomainShardingPass ( const DomainMetadata::Domain &amp; domain , const HloSharding &amp; sharding )" content="198:         ++assigned;
199:       }
200:     } else if (instruction-&gt;opcode() == HloOpcode::kTuple) {
201:       int64 tuple_assigned = 0;
202:       ShapeTree&lt;HloSharding&gt; shape_tree = GetTupleSharding(instruction);
203:       for (int64 i = 0; i &lt; instruction-&gt;operand_count(); ++i) {
204:         const HloSharding* operand_sharding =
205:             GetOperandSharding(instruction-&gt;operand(i), domain, sharding);
206:         if (operand_sharding != nullptr &amp;&amp;
207:             shape_tree.element({i}) != *operand_sharding) {
208:           *shape_tree.mutable_element({i}) = *operand_sharding;
209:           ++tuple_assigned;
210:         }
211:       }
212:       if (tuple_assigned &gt; 0) {
213:         HloSharding tuple_sharding = HloSharding::Tuple(shape_tree);
214:         VLOG(4) &lt;&lt; &quot;  &quot; &lt;&lt; instruction-&gt;name() &lt;&lt; &quot; to sharding &quot;
215:                 &lt;&lt; tuple_sharding;
216:         instruction-&gt;set_sharding(tuple_sharding);
217:         ++assigned;
218:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/hlo_tfgraph_builder_test.cc" line="59" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [attr] may be invalid here." web_identify="{&quot;identify&quot;:&quot;attr&quot;}" func_info="static const tensorflow::AttrValue &amp; GetNodeAttr ( const tensorflow::NodeDef &amp; node , const string &amp; attr_name )" content="49:         HloInstruction::CreateMap(r0f32_, {param}, map_computation));
50:     return builder.Build();
51:   }
52:   Shape r0f32_ = ShapeUtil::MakeShape(PrimitiveType::F32, {});
53: };
54: 
55: static const tensorflow::AttrValue &amp;GetNodeAttr(const tensorflow::NodeDef &amp;node,
56:                                                 const string &amp;attr_name) {
57:   auto attr = node.attr().find(attr_name);
58:   CHECK(attr != node.attr().end());
59:   return attr-&gt;second;
60: }
61: 
62: TEST_F(HloTfGraphBuilderTest, CheckConcatenateDimsAndShapes) {
63:   auto builder = HloComputation::Builder(&quot;Concatenate&quot;);
64:   Shape shape = ShapeUtil::MakeShape(PrimitiveType::F32, {2, 2});
65:   auto param_1 = builder.AddInstruction(
66:       HloInstruction::CreateParameter(0, shape, &quot;param0&quot;));
67:   auto param_2 = builder.AddInstruction(
68:       HloInstruction::CreateParameter(1, shape, &quot;param1&quot;));
69:   builder.AddInstruction(HloInstruction::CreateConcatenate(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/indexed_array_analysis.cc" line="438" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="long MapPassthroughOperandDimToResultDim ( ArraySlice &lt; ReshapePassthroughDimPair &gt; passthrough_dims , long operand_dim )" content="428: 
429: // Maps `operand_dim` which must be an passthrough operand dimension to its
430: // corresponding passthrough result dimension based on `passthrough_dims`.
431: int64 MapPassthroughOperandDimToResultDim(
432:     ArraySlice&lt;ReshapePassthroughDimPair&gt; passthrough_dims, int64 operand_dim) {
433:   auto it = c_find_if(passthrough_dims,
434:                       [&amp;](ReshapePassthroughDimPair passthrough_dim_pair) {
435:                         return passthrough_dim_pair.operand_dim == operand_dim;
436:                       });
437:   CHECK(it != passthrough_dims.end());
438:   return it-&gt;result_dim;
439: }
440: 
441: int64 FindSourcePositionForPassthroughResultDim(ArraySlice&lt;int64&gt; operand_shape,
442:                                                 ArraySlice&lt;int64&gt; result_shape,
443:                                                 int64 source_passthrough_dim) {
444:   VLOG(3) &lt;&lt; &quot;FindSourcePositionForPassthroughResultDim([&quot;
445:           &lt;&lt; Join(operand_shape, &quot;,&quot;) &lt;&lt; &quot;], [&quot; &lt;&lt; Join(result_shape, &quot;,&quot;)
446:           &lt;&lt; &quot;], &quot; &lt;&lt; source_passthrough_dim &lt;&lt; &quot;)&quot;;
447: 
448:   int64 indexed_source_subarray_size =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/instruction_fusion.h" line="34" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;InstructionFusion::computation_,module_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;InstructionFusion::computation_,module_,&quot;}" func_info="xla::InstructionFusion" content="24: 
25: namespace xla {
26: 
27: // HLO pass which performs instruction fusion. Instructions are fused
28: // &quot;vertically&quot;, meaning producing instructions are fused into their consumers
29: // with the intent that the loops which compute their values will be fused in
30: // code generation. Derived classes define ShouldFuse method to select which
31: // instructions to fuse.
32: class InstructionFusion : public HloPassInterface {
33:  public:
34:   explicit InstructionFusion(
35:       std::function&lt;bool(const HloInstruction&amp; instruction)&gt; is_expensive,
36:       bool may_duplicate = true)
37:       : is_expensive_(is_expensive), may_duplicate_(may_duplicate) {}
38:   ~InstructionFusion() override = default;
39:   tensorflow::StringPiece name() const override { return &quot;fusion&quot;; }
40: 
41:   // Run instruction fusion on the given computation. Returns whether the
42:   // computation was changed (instructions were fused).
43:   StatusOr&lt;bool&gt; Run(HloModule* module) override;
44: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/layout_assignment.cc" line="444" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [channel_constraints] to null at line 441 implies that [channel_constraints ] might be null.Dereferencing null pointer [channel_constraints]." web_identify="{&quot;identify&quot;:&quot;channel_constraints&quot;}" func_info="Status LayoutAssignment::AddMandatoryConstraints ( const ComputationLayout * computation_layout , ChannelLayoutConstraints * channel_constraints , HloComputation * computation , LayoutConstraints * constraints )" content="434:     if (shape_with_layout != nullptr) {
435:       TF_RETURN_IF_ERROR(
436:           constraints-&gt;SetInstructionLayout(*shape_with_layout, instruction));
437:     }
438: 
439:     if (instruction-&gt;opcode() == HloOpcode::kSend ||
440:         instruction-&gt;opcode() == HloOpcode::kRecv) {
441:       CHECK(channel_constraints)
442:           &lt;&lt; &quot;Multi-module layout assignment requires ChannelLayoutConstraints&quot;;
443:       int64 channel_id = instruction-&gt;channel_id();
444:       if (!channel_constraints-&gt;IsChannelConstrained(channel_id)) {
445:         continue;
446:       }
447:       if (instruction-&gt;opcode() == HloOpcode::kSend) {
448:         // TODO(b/68493863): Change to use SetOperandLayout().
449:         const Shape send_buffer_shape = instruction-&gt;operand(0)-&gt;shape();
450:         TF_RET_CHECK(ShapeUtil::IsArray(send_buffer_shape));
451:         Shape new_buffer_shape = channel_constraints-&gt;LayoutShapeForChannel(
452:             send_buffer_shape, instruction-&gt;channel_id());
453:         TF_RETURN_IF_ERROR(constraints-&gt;SetInstructionLayout(
454:             new_buffer_shape, instruction-&gt;operand(0)));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/layout_assignment.h" line="254" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Shape ChannelLayoutConstraints::LayoutShapeForChannel ( Shape shape , long channel_id ) const" content="244:   // Returns true if channel_id has a layout constraint.
245:   bool IsChannelConstrained(int64 channel_id) const {
246:     return constraints_.count(channel_id) &gt; 0;
247:   }
248: 
249:   // Given `shape`, apply the layout for `channel_id`. `channel_id` must already
250:   // be constrained.
251:   Shape LayoutShapeForChannel(Shape shape, int64 channel_id) const {
252:     auto it = constraints_.find(channel_id);
253:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
254:     *shape.mutable_layout() = it-&gt;second;
255:     return shape;
256:   }
257: 
258:   // Returns the layout constraint for `channel_id`, which must already be
259:   // constrained.
260:   const Layout&amp; LayoutForChannel(int64 channel_id) const {
261:     auto it = constraints_.find(channel_id);
262:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
263:     return it-&gt;second;
264:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/layout_assignment.h" line="263" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const Layout &amp; ChannelLayoutConstraints::LayoutForChannel ( long channel_id ) const" content="253:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
254:     *shape.mutable_layout() = it-&gt;second;
255:     return shape;
256:   }
257: 
258:   // Returns the layout constraint for `channel_id`, which must already be
259:   // constrained.
260:   const Layout&amp; LayoutForChannel(int64 channel_id) const {
261:     auto it = constraints_.find(channel_id);
262:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
263:     return it-&gt;second;
264:   }
265: 
266:   // Adds a new layout constraint for `channel_id`. If a constraint for
267:   // `channel_id` has been added, this API returns nullptr, otherwise returns
268:   // the layout which has already been set for the channel.
269:   const Layout* ConstrainChannel(int64 channel_id, const Layout&amp; layout) {
270:     auto it = constraints_.emplace(std::make_pair(channel_id, layout));
271:     if (it.second) {
272:       return nullptr;
273:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/fused_ir_emitter.h" line="88" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * FusedIrEmitter::GetIrValueForGTE ( const HloInstruction * hlo ) const" content="78:   // Returns the generator function for the root of the fused computation.
79:   Generator GetRootGenerator() const;
80: 
81:   // Returns the generator function for the given instruction.
82:   Generator GetGenerator(const HloInstruction* instruction) const;
83: 
84:   // Returns the ir value for instruction &apos;hlo&apos;.
85:   llvm::Value* GetIrValueForGTE(const HloInstruction* hlo) const {
86:     auto it = gte_values_.find(hlo);
87:     CHECK(it != gte_values_.end());
88:     return it-&gt;second;
89:   }
90: 
91:   void SetTiledParameterInfo(const llvm_ir::TiledParameterInfo* info) {
92:     tiled_parameter_info_ = info;
93:   }
94: 
95:  private:
96:   // Arrays of parameters of fusion instruction
97:   tensorflow::gtl::ArraySlice&lt;llvm_ir::IrArray&gt; parameter_arrays_;
98:   const llvm_ir::TiledParameterInfo* tiled_parameter_info_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/ir_array.h" line="217" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;IrArray::element_type_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;IrArray::element_type_,&quot;}" func_info="xla::llvm_ir::IrArray" content="207:     // If a loop is emitted with a multidimensional index space, `linear_` would
208:     // be null and `layout_` and `dims_` would be ignored.
209:     llvm::Value* linear_ = nullptr;
210:     Layout layout_;
211:     std::vector&lt;int64&gt; dims_;
212: 
213:     llvm::Type* index_type_;
214:   };
215: 
216:   // Default constructor. Constructs an IrArray in a null status.
217:   IrArray() : base_ptr_(nullptr), shape_(nullptr) {}
218: 
219:   // Construct an IrArray with the given base pointer and shape. base_ptr is a
220:   // pointer type pointing to the first element(lowest address) of the array.
221:   IrArray(llvm::Value* base_ptr, const Shape&amp; shape);
222: 
223:   // Default implementations of copying and moving.
224:   IrArray(IrArray&amp;&amp; other) = default;
225:   IrArray(const IrArray&amp; other) = default;
226:   IrArray&amp; operator=(IrArray&amp;&amp; other) = default;
227:   IrArray&amp; operator=(const IrArray&amp; other) = default;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/ir_array.h" line="234" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [shape_] to null at line 233 implies that [shape_ ] might be null.Dereferencing null pointer [shape_]." web_identify="{&quot;identify&quot;:&quot;shape_&quot;}" func_info="const Shape &amp; IrArray::GetShape ( ) const" content="224:   IrArray(IrArray&amp;&amp; other) = default;
225:   IrArray(const IrArray&amp; other) = default;
226:   IrArray&amp; operator=(IrArray&amp;&amp; other) = default;
227:   IrArray&amp; operator=(const IrArray&amp; other) = default;
228: 
229:   llvm::Value* GetBasePointer() const { return base_ptr_; }
230:   llvm::Type* GetElementLlvmType() const { return element_type_; }
231: 
232:   const Shape&amp; GetShape() const {
233:     CHECK(shape_ != nullptr);
234:     return *shape_;
235:   }
236: 
237:   // Emit a sequence of instructions to compute the address of the element in
238:   // the given array at the given index. Returns the address of the element as
239:   // an LLVM Value.
240:   //
241:   // The optional name is useful for debugging when looking at
242:   // the emitted LLVM IR.
243:   llvm::Value* EmitArrayElementAddress(const Index&amp; index,
244:                                        llvm::IRBuilder&lt;&gt;* ir_builder,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="35" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="25: #include &quot;tensorflow/compiler/xla/xla_data.pb.h&quot;
26: #include &quot;tensorflow/core/lib/core/errors.h&quot;
27: #include &quot;tensorflow/core/lib/strings/stringprintf.h&quot;
28: #include &quot;tensorflow/core/platform/logging.h&quot;
29: #include &quot;tensorflow/core/platform/protobuf.h&quot;
30: #include &quot;tensorflow/core/platform/types.h&quot;
31: 
32: namespace xla {
33: namespace llvm_ir {
34: 
35: LoopEmitter::LoopEmitter(const BodyEmitter&amp; body_emitter, const Shape&amp; shape,
36:                          llvm::IRBuilder&lt;&gt;* ir_builder)
37:     : body_emitter_(body_emitter), shape_(shape), ir_builder_(ir_builder) {}
38: 
39: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
40:                          const IrArray&amp; target_array,
41:                          llvm::IRBuilder&lt;&gt;* ir_builder)
42:     : body_emitter_([=](const llvm_ir::IrArray::Index array_index) -&gt; Status {
43:         // Convert target_element_generator to a BodyEmitter.
44:         TF_ASSIGN_OR_RETURN(llvm::Value * target_element,
45:                             target_element_generator(array_index));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="39" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="29: #include &quot;tensorflow/core/platform/protobuf.h&quot;
30: #include &quot;tensorflow/core/platform/types.h&quot;
31: 
32: namespace xla {
33: namespace llvm_ir {
34: 
35: LoopEmitter::LoopEmitter(const BodyEmitter&amp; body_emitter, const Shape&amp; shape,
36:                          llvm::IRBuilder&lt;&gt;* ir_builder)
37:     : body_emitter_(body_emitter), shape_(shape), ir_builder_(ir_builder) {}
38: 
39: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
40:                          const IrArray&amp; target_array,
41:                          llvm::IRBuilder&lt;&gt;* ir_builder)
42:     : body_emitter_([=](const llvm_ir::IrArray::Index array_index) -&gt; Status {
43:         // Convert target_element_generator to a BodyEmitter.
44:         TF_ASSIGN_OR_RETURN(llvm::Value * target_element,
45:                             target_element_generator(array_index));
46:         target_array.EmitWriteArrayElement(array_index, target_element,
47:                                            ir_builder);
48:         return Status::OK();
49:       }),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="74" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="64: 
65:     for (int64 i = 0; i &lt; target_arrays.size(); ++i) {
66:       target_arrays[i].EmitWriteArrayElement(
67:           array_index, ir_builder-&gt;CreateExtractValue(target_element, i),
68:           ir_builder);
69:     }
70:     return Status::OK();
71:   };
72: }
73: 
74: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
75:                          tensorflow::gtl::ArraySlice&lt;IrArray&gt; target_arrays,
76:                          llvm::IRBuilder&lt;&gt;* ir_builder)
77:     : body_emitter_(MakeBodyEmitterForMultiOutputFusion(
78:           target_element_generator,
79:           std::vector&lt;IrArray&gt;(target_arrays.begin(), target_arrays.end()),
80:           ir_builder)),
81:       shape_(target_arrays[0].GetShape()),
82:       ir_builder_(ir_builder) {
83:   // Sanity check: In multi-output fusion, all shapes produced must have the
84:   // same dimensions.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/multi_output_fusion.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MultiOutputFusion::computation_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MultiOutputFusion::computation_,&quot;}" func_info="xla::MultiOutputFusion" content="39: //
40: //  Function Perform() applies the optimization. It picks up the most profitable
41: //  pair in the worklist_, check if it&apos;s legal to fuse and fuse the pair.
42: //  After fusion, it updates the associated structure such as reachability_,
43: //  candidates_ and worklist_.
44: //  Note that the reachability map is updated based on the original computation.
45: //  This works because the reachability is monotonically increasing with
46: //  instruction fusion.
47: class MultiOutputFusion : public HloPassInterface {
48:  public:
49:   MultiOutputFusion(int64 fuel) : fuel_(fuel) {}
50: 
51:   tensorflow::StringPiece name() const override {
52:     return &quot;multi_output_fusion&quot;;
53:   }
54: 
55:   // Run multi-output fusion on the given module. Returns whether the module
56:   // was changed.
57:   StatusOr&lt;bool&gt; Run(HloModule* module) override;
58: 
59:  protected:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/owning_device_memory.cc" line="26" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [allocator_] to null at line 23 implies that [allocator_ ] might be null.Dereferencing null pointer [allocator_]." web_identify="{&quot;identify&quot;:&quot;allocator_&quot;}" func_info="void OwningDeviceMemory::Free ( )" content="16: #include &quot;tensorflow/compiler/xla/service/owning_device_memory.h&quot;
17: 
18: #include &quot;tensorflow/compiler/xla/service/device_memory_allocator.h&quot;
19: 
20: namespace xla {
21: 
22: void OwningDeviceMemory::Free() {
23:   CHECK(allocator_ != nullptr)
24:       &lt;&lt; &quot;Can&apos;t call Free() on an inactive (i.e. moved from, Forget()&apos;ten, &quot;
25:          &quot;or Free()&apos;ed) instance.&quot;;
26:   auto status = allocator_-&gt;Deallocate(device_ordinal_, mem_);
27:   if (!status.ok()) {
28:     LOG(WARNING) &lt;&lt; &quot;Deallocating buffer &quot; &lt;&lt; mem_.opaque() &lt;&lt; &quot; failed.&quot;;
29:   }
30: 
31:   allocator_ = nullptr;
32:   mem_ = se::DeviceMemoryBase();
33: }
34: 
35: }  // namespace xla
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/reshape_mover.cc" line="378" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;!&quot;}" func_info="StatusOr &lt; bool &gt; TryReshapeMoveOnCandidates ( HloInstructionSet * reshape_candidates )" content="368:       for (const auto* operand : instruction-&gt;operands()) {
369:         if (IsNontrivialReshape(operand)) {
370:           nontrivial_operands.insert(operand);
371:         }
372:       }
373:     }
374: 
375:     removed = false;
376:     for (auto operand : nontrivial_operands) {
377:       if (c_any_of(operand-&gt;users(), [&amp;](HloInstruction* user) {
378:             return !reshape_candidates-&gt;count(user);
379:           })) {
380:         for (auto* user : operand-&gt;users()) {
381:           removed |= reshape_candidates-&gt;erase(user) &gt; 0;
382:         }
383:       }
384:     }
385:   }
386: 
387:   if (reshape_candidates-&gt;empty()) {
388:     return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/tuple_points_to_analysis.cc" line="631" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="bool TuplePointsToAnalysis::DoesNotUseOperandBuffer ( const HloInstruction * operand , const ShapeIndex &amp; index , const HloInstruction * user ) const" content="621:     // Find fusion parameter associated with &apos;operand&apos;.
622:     auto it = std::find_if(
623:         user-&gt;fused_parameters().begin(), user-&gt;fused_parameters().end(),
624:         [=](HloInstruction* fused_param) {
625:           return user-&gt;operand(fused_param-&gt;parameter_number()) == operand;
626:         });
627:     CHECK(it != user-&gt;fused_parameters().end());
628:     // Iterate through all users of all buffer aliases of the buffer in the
629:     // points-to set of fusion parameter at &apos;index&apos;.
630:     // Return false if any uses are detected at &apos;index&apos;, returns true otherwise.
631:     const LogicalBuffer* buffer = GetBufferDefinedAt(*it, index).ValueOrDie();
632:     for (const BufferAlias&amp; alias : GetBufferAliases(*buffer)) {
633:       for (HloInstruction* alias_user : alias.instruction()-&gt;users()) {
634:         if (DoesNotUseOperandBuffer(alias.instruction(), alias.index(),
635:                                     alias_user)) {
636:           continue;
637:         }
638:         // Return false: use detected at &apos;buffer&apos; -&gt; &apos;alias&apos; -&gt; &apos;alias_user&apos;.
639:         return false;
640:       }
641:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/service/tuple_points_to_analysis_test.cc" line="717" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="HloInstruction * FusionPointsToAnalysisTest::GetFusionParameterForOperand ( HloInstruction * fusion , HloInstruction * operand )" content="707:   // to fusion &apos;operand&apos;.
708:   HloInstruction* GetFusionParameterForOperand(HloInstruction* fusion,
709:                                                HloInstruction* operand) {
710:     auto it = std::find_if(
711:         fusion-&gt;fused_instructions().begin(),
712:         fusion-&gt;fused_instructions().end(), [=](const HloInstruction* fused) {
713:           return fused-&gt;opcode() == HloOpcode::kParameter &amp;&amp;
714:                  fusion-&gt;operand(fused-&gt;parameter_number()) == operand;
715:         });
716:     CHECK(it != fusion-&gt;fused_instructions().end());
717:     return *it;
718:   }
719: 
720:   // Returns all users of &apos;fusion_paran&apos; at &apos;tuple_index&apos;.
721:   std::vector&lt;HloInstruction*&gt; GetFusionParameterUsersAt(
722:       HloInstruction* fusion_param, int64 tuple_index) {
723:     CHECK(ShapeUtil::IsTuple(fusion_param-&gt;shape()));
724:     std::vector&lt;HloInstruction*&gt; users_at_tuple_index;
725:     for (auto user : fusion_param-&gt;users()) {
726:       CHECK_EQ(HloOpcode::kGetTupleElement, user-&gt;opcode());
727:       if (user-&gt;tuple_index() == tuple_index) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/tests/test_utils.cc" line="100" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 92 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="&gt; void PopulateWithRandomIntegralData ( Literal * literal , std::minstd_rand0 * engine )" content="90: void PopulateWithRandomIntegralData(Literal* literal,
91:                                     std::minstd_rand0* engine) {
92:   CHECK(engine != nullptr);
93:   CHECK_EQ(literal-&gt;shape().element_type(),
94:            primitive_util::NativeToPrimitiveType&lt;IntT&gt;());
95:   std::uniform_int_distribution&lt;IntT&gt; generator(
96:       std::numeric_limits&lt;IntT&gt;::lowest(), std::numeric_limits&lt;IntT&gt;::max());
97:   TF_CHECK_OK(literal-&gt;Populate&lt;IntT&gt;(
98:       [&amp;](tensorflow::gtl::ArraySlice&lt;int64&gt; /*indices*/) {
99:         return generator(*engine);
100:       }));
101: }
102: 
103: // Similar to MakeFakeLiteral but takes a random number generator engine to
104: // enable reusing the engine across randomly generated literals.
105: StatusOr&lt;std::unique_ptr&lt;Literal&gt;&gt; MakeFakeLiteralInternal(
106:     const Shape&amp; shape, std::minstd_rand0* engine) {
107:   if (ShapeUtil::IsTuple(shape)) {
108:     std::vector&lt;std::unique_ptr&lt;Literal&gt;&gt; elements;
109:     for (const Shape&amp; element_shape : shape.tuple_shapes()) {
110:       TF_ASSIGN_OR_RETURN(std::unique_ptr&lt;Literal&gt; element,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/tests/test_utils.cc" line="58" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 30 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="&gt; void PopulateWithRandomFloatingPointDataImpl ( Literal * literal , std::minstd_rand0 * engine )" content="48:         // indices are zero.
49:         int64 index_product = 1;
50:         for (int64 i : indices) {
51:           index_product *= (1 + i);
52:         }
53:         const int64 negative_bias = should_index_bias ? 47 : 0;
54:         FloatT index_bias =
55:             static_cast&lt;FloatT&gt;(index_product % 113 - negative_bias) /
56:             static_cast&lt;FloatT&gt;(256.0f);
57:         return static_cast&lt;FloatT&gt;(generator(*engine) - 1.0625f) + index_bias;
58:       }));
59: }
60: 
61: template &lt;typename FloatT&gt;
62: void PopulateWithRandomFloatingPointData(Literal* literal,
63:                                          std::minstd_rand0* engine) {
64:   CHECK(engine != nullptr);
65:   PopulateWithRandomFloatingPointDataImpl&lt;FloatT, FloatT&gt;(literal, engine);
66: }
67: 
68: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/compiler/xla/tests/test_utils.cc" line="86" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 80 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="void PopulateWithRandomFloatingPointData&lt;bfloat16&gt; ( Literal * literal , std::minstd_rand0 * engine )" content="76: // handle that one specially.
77: template &lt;&gt;
78: void PopulateWithRandomFloatingPointData&lt;bfloat16&gt;(Literal* literal,
79:                                                    std::minstd_rand0* engine) {
80:   CHECK(engine != nullptr);
81:   CHECK_EQ(literal-&gt;shape().element_type(), BF16);
82:   std::uniform_real_distribution&lt;float&gt; generator(-0.9f, 1.0f);
83:   TF_CHECK_OK(literal-&gt;Populate&lt;bfloat16&gt;(
84:       [&amp;](tensorflow::gtl::ArraySlice&lt;int64&gt; /*indices*/) {
85:         return static_cast&lt;bfloat16&gt;(generator(*engine));
86:       }));
87: }
88: 
89: template &lt;typename IntT&gt;
90: void PopulateWithRandomIntegralData(Literal* literal,
91:                                     std::minstd_rand0* engine) {
92:   CHECK(engine != nullptr);
93:   CHECK_EQ(literal-&gt;shape().element_type(),
94:            primitive_util::NativeToPrimitiveType&lt;IntT&gt;());
95:   std::uniform_int_distribution&lt;IntT&gt; generator(
96:       std::numeric_limits&lt;IntT&gt;::lowest(), std::numeric_limits&lt;IntT&gt;::max());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/boosted_trees/kernels/training_ops.cc" line="677" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [mapped_node_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;mapped_node_it&quot;}" func_info="void GrowTreeEnsembleOp::PruneTree ( boosted_trees :: trees :: DecisionTreeConfig * tree_config )" content="667:     for (size_t node_idx = 0; node_idx &lt; tree_nodes.size(); ++node_idx) {
668:       // Skip pruned nodes.
669:       auto&amp; original_node = tree_nodes[node_idx];
670:       if (original_node.node_case() == TreeNode::NODE_NOT_SET) {
671:         continue;
672:       }
673: 
674:       // Find node mapped in tree ensemble.
675:       auto mapped_node_it = nodes_map.find(node_idx);
676:       CHECK(mapped_node_it != nodes_map.end());
677:       auto&amp; mapped_node = (*tree_config-&gt;mutable_nodes(mapped_node_it-&gt;second));
678: 
679:       // Get node children
680:       auto children =
681:           boosted_trees::trees::DecisionTree::GetChildren(original_node);
682:       for (int32&amp; child_idx : children) {
683:         auto new_idx = tree_config-&gt;nodes_size();
684:         (*tree_config-&gt;add_nodes()) = tree_nodes[child_idx];
685:         nodes_map[child_idx] = new_idx;
686:         child_idx = new_idx;
687:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/data/kernels/csv_dataset_op.cc" line="158" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Iterator::pos_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Iterator::pos_,&quot;}" func_info="CSVDatasetOp::Dataset::Iterator" content="148:                               Node** output) const override {
149:       // TODO(rachelim): Implement this
150:       std::vector&lt;Node*&gt; input_tensors;
151:       TF_RETURN_IF_ERROR(b-&gt;AddDataset(this, input_tensors, output));
152:       return errors::Unimplemented(&quot;CSVDataset: AsGraphDefInternal&quot;);
153:     }
154: 
155:    private:
156:     class Iterator : public DatasetIterator&lt;Dataset&gt; {
157:      public:
158:       explicit Iterator(const Params&amp; params)
159:           : DatasetIterator&lt;Dataset&gt;(params) {}
160: 
161:       Status GetNextInternal(IteratorContext* ctx,
162:                              std::vector&lt;Tensor&gt;* out_tensors,
163:                              bool* end_of_sequence) override {
164:         mutex_lock l(mu_);
165:         bool select_all = dataset()-&gt;select_cols_.empty();
166:         do {
167:           // We are currently processing a file, so try to read the next record
168:           if (input_stream_) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/ffmpeg/decode_audio_op.cc" line="221" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DecodeAudioOp::samples_per_second_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DecodeAudioOp::samples_per_second_,&quot;}" func_info="tensorflow::ffmpeg::DecodeAudioOp" content="211: sampled_audio: A rank-2 tensor containing all tracks of the audio.
212:     Dimension 0 is time and dimension 1 is the channel. If ffmpeg fails
213:     to decode the audio then an empty tensor will be returned.
214: )doc&quot;);
215: 
216: /*
217:  * Deprecated in favor of DecodeAudioOpV2.
218:  */
219: class DecodeAudioOp : public OpKernel {
220:  public:
221:   explicit DecodeAudioOp(OpKernelConstruction* context) : OpKernel(context) {
222:     OP_REQUIRES_OK(context, context-&gt;GetAttr(&quot;file_format&quot;, &amp;file_format_));
223:     file_format_ = str_util::Lowercase(file_format_);
224:     const std::set&lt;string&gt; valid_file_formats(
225:         kValidFileFormats, kValidFileFormats + TF_ARRAYSIZE(kValidFileFormats));
226:     OP_REQUIRES(
227:         context, valid_file_formats.count(file_format_) == 1,
228:         errors::InvalidArgument(&quot;file_format must be one of {&quot;,
229:                                 str_util::Join(valid_file_formats, &quot;, &quot;),
230:                                 &quot;}, but was: \&quot;&quot;, file_format_, &quot;\&quot;&quot;));
231: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/gdr/gdr_memory_manager.cc" line="208" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GdrMemoryManager::epfd_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GdrMemoryManager::epfd_,&quot;}" func_info="tensorflow::" content="198: // cpu_allocator() returns visitable allocator
199: class BFCRdmaAllocator : public BFCAllocator {
200:  public:
201:   BFCRdmaAllocator()
202:       : BFCAllocator(new BasicCPUAllocator(), 1LL &lt;&lt; 36, true, &quot;cpu_rdma_bfc&quot;) {
203:   }
204: };
205: 
206: REGISTER_MEM_ALLOCATOR(&quot;BFCRdmaAllocator&quot;, 101, BFCRdmaAllocator);
207: 
208: GdrMemoryManager::GdrMemoryManager(const string&amp; host, const string&amp; port)
209:     : host_(host),
210:       port_(port),
211:       listening_(nullptr, EndpointDeleter),
212:       stopped_(true),
213:       next_key_(0) {}
214: 
215: GdrMemoryManager::~GdrMemoryManager() { close(epfd_); }
216: 
217: Status GdrMemoryManager::Init() {
218:   epfd_ = epoll_create1(0);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/gdr/gdr_memory_manager.cc" line="299" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [visitable_allocator] to null at line 295 implies that [visitable_allocator ] might be null.Dereferencing null pointer [visitable_allocator]." web_identify="{&quot;identify&quot;:&quot;visitable_allocator&quot;}" func_info="Status GdrMemoryManager::Init ( )" content="289: 
290:   std::set&lt;Allocator*&gt; instrumented_;
291: 
292:   // Host memory allocators
293:   for (Allocator* allocator : allocators) {
294:     auto* visitable_allocator = dynamic_cast&lt;VisitableAllocator*&gt;(allocator);
295:     CHECK(visitable_allocator)
296:         &lt;&lt; &quot;is not visitable for instrumentation&quot; &lt;&lt; allocator-&gt;Name();
297:     // Make sure we don&apos;t instrument the same allocator twice
298:     if (instrumented_.find(allocator) == std::end(instrumented_)) {
299:       visitable_allocator-&gt;AddAllocVisitor(alloc_visitor);
300:       visitable_allocator-&gt;AddFreeVisitor(free_visitor);
301:       instrumented_.insert(allocator);
302:       LOG(INFO) &lt;&lt; &quot;Instrumenting CPU allocator &quot; &lt;&lt; allocator-&gt;Name();
303:     }
304:   }
305: 
306: #if GOOGLE_CUDA
307:   VisitableAllocator::Visitor cuda_alloc_visitor =
308:       std::bind(&amp;GdrMemoryManager::InsertMemoryRegion, this, _1, _2);
309:   if (IsGDRAvailable()) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/delegates/nnapi/nnapi_delegate_test.cc" line="589" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SqueezeOpModel::new_shape_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SqueezeOpModel::new_shape_,&quot;}" func_info="SqueezeOpModel" content="579: TEST(NNAPIDelegate, ReshapeSimpleTest) {
580:   ReshapeOpModel m({1, 2, 4, 1}, {2, 2, 2});
581:   m.SetInput({1, 2, 3, 4, 5, 6, 7, 8});
582:   m.Invoke();
583:   EXPECT_THAT(m.GetOutput(), ElementsAreArray({1, 2, 3, 4, 5, 6, 7, 8}));
584:   EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 2, 2}));
585: }
586: 
587: class SqueezeOpModel : public SingleOpModelWithNNAPI {
588:  public:
589:   SqueezeOpModel(const TensorData&amp; input, const TensorData&amp; output,
590:                  std::initializer_list&lt;int&gt; axis) {
591:     input_ = AddInput(input);
592:     output_ = AddOutput(output);
593:     SetBuiltinOp(
594:         BuiltinOperator_SQUEEZE, BuiltinOptions_SqueezeOptions,
595:         CreateSqueezeOptions(builder_, builder_.CreateVector&lt;int&gt;(axis))
596:             .Union());
597:     BuildInterpreter({GetShape(input_)});
598:   }
599: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/fully_connected.cc" line="124" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias] to null at line 114 implies that [bias ] might be null.Dereferencing null pointer [bias]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias&quot;}" func_info="TfLiteStatus fully_connected::Prepare ( TfLiteContext * context , TfLiteNode * node )" content="114:   if (bias) {
115:     TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));
116:   }
117: 
118:   // Note that quantized inference requires that all tensors have their
119:   // parameters set. This is usually done during quantized training.
120:   TfLiteType data_type = input-&gt;type;
121:   if (data_type != kTfLiteFloat32) {
122:     double real_multiplier = 0.0;
123:     TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(
124:         context, input, filter, bias, output, &amp;real_multiplier));
125:     TF_LITE_ENSURE(context, real_multiplier &lt; 1.0);
126:     QuantizeMultiplierSmallerThanOneExp(
127:         real_multiplier, &amp;data-&gt;output_multiplier, &amp;data-&gt;output_shift);
128:     data-&gt;output_shift *= -1;
129:     TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized(
130:         context, params-&gt;activation, output, &amp;data-&gt;output_activation_min,
131:         &amp;data-&gt;output_activation_max));
132:   }
133: 
134:   // If we have to perform on-the-fly quantization (with quantized weights and
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/fully_connected.cc" line="220" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [bias] suggests that it may be null, but it has already been dereferenced at line 207." web_identify="{&quot;identify&quot;:&quot;bias&quot;}" func_info="TfLiteStatus fully_connected::EvalPieQuantized ( TfLiteContext * context , TfLiteNode * node , TfLiteFullyConnectedParams * params , OpData * data , const TfLiteTensor * input , const TfLiteTensor * filter , const TfLiteTensor * bias , TfLiteTensor * input_quantized , TfLiteTensor * output )" content="210:   int total_input_size = 1;
211:   for (int i = 0; i &lt; input-&gt;dims-&gt;size; i++) {
212:     total_input_size *= input-&gt;dims-&gt;data[i];
213:   }
214: 
215:   const int input_size = filter-&gt;dims-&gt;data[1];
216:   const int batch_size = total_input_size / filter-&gt;dims-&gt;data[1];
217:   const int num_units = filter-&gt;dims-&gt;data[0];
218: 
219:   // Output = bias if bias tensor exists.
220:   if (bias) {
221:     tensor_utils::VectorBatchVectorAssign(bias-&gt;data.f, num_units, batch_size,
222:                                           output-&gt;data.f);
223:   } else {
224:     tensor_utils::ZeroVector(output-&gt;data.f, batch_size * num_units);
225:   }
226: 
227:   // Save matrix multiplication computation for all zero input.
228:   if (tensor_utils::IsZeroVector(input-&gt;data.f, total_input_size)) {
229:     tensor_utils::ApplyActivationToVector(output-&gt;data.f,
230:                                           batch_size * num_units,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/internal/mfcc_dct.cc" line="23" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccDct::coefficient_count_,input_length_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccDct::coefficient_count_,input_length_,&quot;}" func_info="tflite::internal" content="13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/contrib/lite/kernels/internal/mfcc_dct.h&quot;
17: 
18: #include &lt;math.h&gt;
19: 
20: namespace tflite {
21: namespace internal {
22: 
23: MfccDct::MfccDct() : initialized_(false) {}
24: 
25: bool MfccDct::Initialize(int input_length, int coefficient_count) {
26:   coefficient_count_ = coefficient_count;
27:   input_length_ = input_length;
28: 
29:   if (coefficient_count_ &lt; 1) {
30:     return false;
31:   }
32: 
33:   if (input_length &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.cc" line="102" id="bufoverrun" subid="arrayIndexThenCheck" severity="Critical" msg="Array index &apos;channel&apos; is used before limits check." web_identify="{&quot;identify&quot;:&quot;channel&quot;}" func_info="bool MfccMelFilterbank::Initialize ( int input_length , double input_sample_rate , int output_channel_count , double lower_frequency_limit , double upper_frequency_limit )" content="92:   // each FFT bin, band_mapper tells us which channel this bin contributes to
93:   // on the right side of the triangle.  Thus this bin also contributes to the
94:   // left side of the next channel&apos;s triangle response.
95:   band_mapper_.resize(input_length_);
96:   int channel = 0;
97:   for (int i = 0; i &lt; input_length_; ++i) {
98:     double melf = FreqToMel(i * hz_per_sbin);
99:     if ((i &lt; start_index_) || (i &gt; end_index_)) {
100:       band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.
101:     } else {
102:       while ((center_frequencies_[channel] &lt; melf) &amp;&amp;
103:              (channel &lt; num_channels_)) {
104:         ++channel;
105:       }
106:       band_mapper_[i] = channel - 1;  // Can be == -1
107:     }
108:   }
109: 
110:   // Create the weighting functions to taper the band edges.  The contribution
111:   // of any one FFT bin is based on its distance along the continuum between two
112:   // mel-channel center frequencies.  This bin contributes weights_[i] to the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.cc" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&quot;}" func_info="tflite::internal" content="28: // channels may end up with no contributing FFT bins.  The resulting mel
29: // spectrum output will have some channels that are always zero.
30: 
31: #include &quot;tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.h&quot;
32: 
33: #include &lt;math.h&gt;
34: 
35: namespace tflite {
36: namespace internal {
37: 
38: MfccMelFilterbank::MfccMelFilterbank() : initialized_(false) {}
39: 
40: bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,
41:                                    int output_channel_count,
42:                                    double lower_frequency_limit,
43:                                    double upper_frequency_limit) {
44:   num_channels_ = output_channel_count;
45:   sample_rate_ = input_sample_rate;
46:   input_length_ = input_length;
47: 
48:   if (num_channels_ &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/internal/spectrogram.h" line="45" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&quot;}" func_info="tflite::internal::Spectrogram" content="35: #include &lt;deque&gt;
36: #include &lt;vector&gt;
37: 
38: #include &quot;third_party/fft2d/fft.h&quot;
39: 
40: namespace tflite {
41: namespace internal {
42: 
43: class Spectrogram {
44:  public:
45:   Spectrogram() : initialized_(false) {}
46:   ~Spectrogram() {}
47: 
48:   // Initializes the class with a given window length and step length
49:   // (both in samples). Internally a Hann window is used as the window
50:   // function. Returns true on success, after which calls to Process()
51:   // are possible. window_length must be greater than 1 and step
52:   // length must be greater than 0.
53:   bool Initialize(int window_length, int step_length);
54: 
55:   // Initialize with an explicit window instead of a length.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/test_util.cc" line="110" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [interpreter_] to null at line 106 implies that [interpreter_ ] might be null.Dereferencing null pointer [interpreter_]." web_identify="{&quot;identify&quot;:&quot;interpreter_&quot;}" func_info="void SingleOpModel::BuildInterpreter ( std::vector &lt; std::vector &lt; int &gt; &gt; input_shapes )" content="100:       resolver-&gt;AddCustom(reg.first.data(), reg.second());
101:     }
102:     resolver_ = std::unique_ptr&lt;OpResolver&gt;(resolver);
103:   }
104:   CHECK(InterpreterBuilder(model, *resolver_)(&amp;interpreter_) == kTfLiteOk);
105: 
106:   CHECK(interpreter_ != nullptr);
107: 
108:   int i = 0;
109:   for (const auto&amp; shape : input_shapes) {
110:     int input_idx = interpreter_-&gt;inputs()[i++];
111:     if (input_idx == kOptionalTensor) continue;
112:     if (shape.empty()) continue;
113:     CHECK(interpreter_-&gt;ResizeInputTensor(input_idx, shape) == kTfLiteOk);
114:   }
115: 
116:   // Modify delegate with function.
117:   if (apply_delegate_fn_) {
118:     apply_delegate_fn_(interpreter_.get());
119:   }
120: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/test_util.cc" line="132" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [t] to null at line 130 implies that [t ] might be null.Dereferencing null pointer [t]." web_identify="{&quot;identify&quot;:&quot;t&quot;}" func_info="int SingleOpModel::GetTensorSize ( int index ) const" content="122:       &lt;&lt; &quot;Cannot allocate tensors&quot;;
123:   interpreter_-&gt;ResetVariableTensorsToZero();
124: }
125: 
126: void SingleOpModel::Invoke() { CHECK(interpreter_-&gt;Invoke() == kTfLiteOk); }
127: 
128: int32_t SingleOpModel::GetTensorSize(int index) const {
129:   TfLiteTensor* t = interpreter_-&gt;tensor(index);
130:   CHECK(t);
131:   int total_size = 1;
132:   for (int i = 0; i &lt; t-&gt;dims-&gt;size; ++i) {
133:     total_size *= t-&gt;dims-&gt;data[i];
134:   }
135:   return total_size;
136: }
137: 
138: template &lt;&gt;
139: std::vector&lt;string&gt; SingleOpModel::ExtractVector(int index) {
140:   TfLiteTensor* tensor_ptr = interpreter_-&gt;tensor(index);
141:   CHECK(tensor_ptr != nullptr);
142:   const int num_strings = GetStringCount(tensor_ptr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/test_util.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor_ptr] to null at line 141 implies that [tensor_ptr ] might be null.Dereferencing null pointer [tensor_ptr]." web_identify="{&quot;identify&quot;:&quot;tensor_ptr&quot;}" func_info="&gt; std::vector &lt; string &gt; SingleOpModel::ExtractVector ( int index )" content="132:   for (int i = 0; i &lt; t-&gt;dims-&gt;size; ++i) {
133:     total_size *= t-&gt;dims-&gt;data[i];
134:   }
135:   return total_size;
136: }
137: 
138: template &lt;&gt;
139: std::vector&lt;string&gt; SingleOpModel::ExtractVector(int index) {
140:   TfLiteTensor* tensor_ptr = interpreter_-&gt;tensor(index);
141:   CHECK(tensor_ptr != nullptr);
142:   const int num_strings = GetStringCount(tensor_ptr);
143:   std::vector&lt;string&gt; result;
144:   result.reserve(num_strings);
145:   for (int i = 0; i &lt; num_strings; ++i) {
146:     const auto str = GetString(tensor_ptr, i);
147:     result.emplace_back(str.str, str.len);
148:   }
149:   return result;
150: }
151: }  // namespace tflite
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/test_util.h" line="205" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v] to null at line 203 implies that [v ] might be null.Dereferencing null pointer [v]." web_identify="{&quot;identify&quot;:&quot;v&quot;}" func_info="&gt; void SingleOpModel::PopulateTensor ( int index , const std :: initializer_list &lt; T &gt; &amp; data )" content="195:     buf.WriteToTensor(tensor);
196:   }
197: 
198:   // Populate the tensor given its index.
199:   // TODO(b/110696148) clean up and merge with vector-taking variant below.
200:   template &lt;typename T&gt;
201:   void PopulateTensor(int index, const std::initializer_list&lt;T&gt;&amp; data) {
202:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
203:     CHECK(v) &lt;&lt; &quot;No tensor with index &apos;&quot; &lt;&lt; index &lt;&lt; &quot;&apos;.&quot;;
204:     for (T f : data) {
205:       *v = f;
206:       ++v;
207:     }
208:   }
209: 
210:   // Populate the tensor given its index.
211:   // TODO(b/110696148) clean up and merge with initializer_list-taking variant
212:   // above.
213:   template &lt;typename T&gt;
214:   void PopulateTensor(int index, const std::vector&lt;T&gt;&amp; data) {
215:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/kernels/test_util.h" line="218" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v] to null at line 216 implies that [v ] might be null.Dereferencing null pointer [v]." web_identify="{&quot;identify&quot;:&quot;v&quot;}" func_info="&gt; void SingleOpModel::PopulateTensor ( int index , const std :: vector &lt; T &gt; &amp; data )" content="208:   }
209: 
210:   // Populate the tensor given its index.
211:   // TODO(b/110696148) clean up and merge with initializer_list-taking variant
212:   // above.
213:   template &lt;typename T&gt;
214:   void PopulateTensor(int index, const std::vector&lt;T&gt;&amp; data) {
215:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
216:     CHECK(v) &lt;&lt; &quot;No tensor with index &apos;&quot; &lt;&lt; index &lt;&lt; &quot;&apos;.&quot;;
217:     for (T f : data) {
218:       *v = f;
219:       ++v;
220:     }
221:   }
222: 
223:   // Partially populate the tensor, starting at the given offset.
224:   template &lt;typename T&gt;
225:   void PopulateTensor(int index, int offset, T* begin, T* end) {
226:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
227:     memcpy(v + offset, begin, (end - begin) * sizeof(T));
228:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/simple_memory_arena.h" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SimpleMemoryArena::underlying_buffer_aligned_ptr_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SimpleMemoryArena::underlying_buffer_aligned_ptr_,&quot;}" func_info="tflite::SimpleMemoryArena" content="36:   }
37: };
38: 
39: // This small class is responsible for allocating, deallocating and reusing
40: // dynamic memory from a common underlying buffer. The arena can be used in
41: // scenarios when the pattern of memory allocations and deallocations is
42: // repetitive, e.g. running NN inference in multiple iterations. Note that
43: // zero-sized allocations are explicitly allowed, and will resolve to null.
44: class SimpleMemoryArena {
45:  public:
46:   explicit SimpleMemoryArena(size_t arena_alignment)
47:       : committed_(false),
48:         arena_alignment_(arena_alignment),
49:         high_water_mark_(0),
50:         underlying_buffer_size_(0),
51:         allocs_() {}
52: 
53:   TfLiteStatus Allocate(TfLiteContext* context, size_t alignment, size_t size,
54:                         ArenaAlloc* new_alloc);
55: 
56:   TfLiteStatus Deallocate(TfLiteContext* context, const ArenaAlloc&amp; alloc);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/allocate_transient_arrays.cc" line="133" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here. The error is in macros." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="void Allocator::Deallocate ( const Alloc &amp; a )" content="123:     // We may then have to grow total_size_.
124:     total_size_ = std::max(total_size_, pos + size);
125:     result-&gt;start = pos;
126:     result-&gt;end = pos + size;
127:     live_allocs_.insert(*result);
128:   }
129: 
130:   void Deallocate(const Alloc&amp; a) {
131:     auto iter = std::lower_bound(live_allocs_.begin(), live_allocs_.end(), a);
132:     CHECK(iter != live_allocs_.end());
133:     CHECK(*iter == a);
134:     live_allocs_.erase(iter);
135:   }
136: 
137:   std::size_t total_size() const { return total_size_; }
138: 
139:  private:
140:   std::size_t total_size_;
141:   std::set&lt;Alloc&gt; live_allocs_;
142: };
143: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/allocate_transient_arrays.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [array.alloc] to null at line 199 implies that [array.alloc ] might be null.Dereferencing null pointer [array.alloc]." web_identify="{&quot;identify&quot;:&quot;array.alloc&quot;}" func_info="void DeallocateTransientArray ( const Model &amp; model , const string &amp; array_name , Allocator * allocator )" content="190: 
191: // Deallocates an array: call this for every array just after the last
192: // op where it is used.
193: void DeallocateTransientArray(const Model&amp; model, const string&amp; array_name,
194:                               Allocator* allocator) {
195:   if (!IsAllocatableTransientArray(model, array_name)) {
196:     return;
197:   }
198:   const auto&amp; array = &amp;model.GetArray(array_name);
199:   CHECK(!!array-&gt;alloc);
200:   allocator-&gt;Deallocate(*array-&gt;alloc);
201: }
202: 
203: void PushBackIfNotFound(const string&amp; s, std::vector&lt;string&gt;* v) {
204:   if (std::find(v-&gt;begin(), v-&gt;end(), s) == v-&gt;end()) {
205:     v-&gt;push_back(s);
206:   }
207: }
208: 
209: }  // namespace
210: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1337" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [weights_array.buffer] to null at line 1336 implies that [weights_array.buffer ] might be null.Dereferencing null pointer [weights_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;weights_array.buffer&quot;}" func_info="void ConvertLstmCellOperator ( const Model &amp; model , const LstmCellOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1327:   // Write weights
1328:   const string weights_output = base + &quot;weights&quot;;
1329:   CHECK(model.HasArray(src_op.inputs[LstmCellOperator::WEIGHTS_INPUT]));
1330:   const string weights_name = WalkUpToConstantArray(
1331:       model, src_op.inputs[LstmCellOperator::WEIGHTS_INPUT]);
1332:   const auto&amp; weights_array = model.GetArray(weights_name);
1333:   // Convert 4D FullyConnected weights into 2D matrix
1334:   const auto&amp; weights_shape = weights_array.shape();
1335:   CHECK_EQ(weights_shape.dimensions_count(), 2);
1336:   CHECK(weights_array.buffer);
1337:   CHECK(weights_array.buffer-&gt;type == ArrayDataType::kFloat);
1338:   const float* weights_data =
1339:       weights_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
1340:   ConvertFloatTensorConst(weights_output, weights_shape, weights_data,
1341:                           AxesOrder::kCR, AxesOrder::kRC, tensorflow_graph);
1342: 
1343:   // Fully connected matrix multiply
1344:   const string matmul_output = base + &quot;MatMul&quot;;
1345:   tensorflow::NodeDef* matmul_op = tensorflow_graph-&gt;add_node();
1346:   matmul_op-&gt;set_op(&quot;MatMul&quot;);
1347:   matmul_op-&gt;set_name(matmul_output);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1364" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_array.buffer] to null at line 1363 implies that [bias_array.buffer ] might be null.Dereferencing null pointer [bias_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias_array.buffer&quot;}" func_info="void ConvertLstmCellOperator ( const Model &amp; model , const LstmCellOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1354:   // Write biases
1355:   const string biases_output = base + &quot;biases&quot;;
1356:   CHECK(model.HasArray(src_op.inputs[LstmCellOperator::BIASES_INPUT]));
1357:   const string bias_name = WalkUpToConstantArray(
1358:       model, src_op.inputs[LstmCellOperator::BIASES_INPUT]);
1359:   const auto&amp; bias_array = model.GetArray(bias_name);
1360:   // TODO(b/62904716) Bias arrays should be 1-D, and used directly.
1361:   Shape bias_shape_1d = bias_array.shape();
1362:   UnextendShape(&amp;bias_shape_1d, 1);
1363:   CHECK(bias_array.buffer);
1364:   CHECK(bias_array.buffer-&gt;type == ArrayDataType::kFloat);
1365:   const float* bias_data =
1366:       bias_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
1367:   ConvertFloatTensorConst(biases_output, bias_shape_1d, bias_data,
1368:                           AxesOrder::kOneAxis, AxesOrder::kOneAxis,
1369:                           tensorflow_graph,
1370:                           LegacyScalarPolicy::kDoCreateLegacyScalars);
1371: 
1372:   // Add biases
1373:   string biasadd_output = base + &quot;BiasAdd&quot;;
1374:   tensorflow::NodeDef* biasadd_op = tensorflow_graph-&gt;add_node();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1765" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensorflow_graph] to null at line 1764 implies that [tensorflow_graph ] might be null.Dereferencing null pointer [tensorflow_graph]." web_identify="{&quot;identify&quot;:&quot;tensorflow_graph&quot;}" func_info="void ConvertRandomUniformOperator ( const Model &amp; model , const RandomUniformOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1755:   CHECK_EQ(src_op.inputs.size(), 2);
1756:   *topk_op-&gt;add_input() = src_op.inputs[0];
1757:   *topk_op-&gt;add_input() = src_op.inputs[1];
1758:   (*topk_op-&gt;mutable_attr())[&quot;sorted&quot;].set_b(true);
1759: }
1760: 
1761: void ConvertRandomUniformOperator(const Model&amp; model,
1762:                                   const RandomUniformOperator&amp; src_op,
1763:                                   GraphDef* tensorflow_graph) {
1764:   CHECK(tensorflow_graph != nullptr);
1765:   tensorflow::NodeDef* new_op = tensorflow_graph-&gt;add_node();
1766:   new_op-&gt;set_op(&quot;RandomUniform&quot;);
1767:   CHECK_EQ(src_op.inputs.size(), 1);
1768:   new_op-&gt;set_name(src_op.outputs[0]);
1769:   *new_op-&gt;add_input() = src_op.inputs[0];
1770:   const tensorflow::DataType shape_type =
1771:       GetTensorFlowDataType(model, src_op.inputs[0]);
1772:   (*new_op-&gt;mutable_attr())[&quot;T&quot;].set_type(shape_type);
1773:   (*new_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(
1774:       GetTensorFlowDataType(src_op.dtype));
1775:   (*new_op-&gt;mutable_attr())[&quot;seed&quot;].set_i(src_op.seed);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="190" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 189 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="void ConvertFloatTensorConst ( const Model &amp; model , const string &amp; name , int input_axes_order , int output_axes_order , GraphDef * tensorflow_graph )" content="180:   }
181:   tensorflow::NodeDef* const_op = tensorflow_graph-&gt;add_node();
182:   const_op-&gt;set_op(&quot;Const&quot;);
183:   const_op-&gt;set_name(name);
184:   (*const_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(DT_FLOAT);
185:   auto* tensor = (*const_op-&gt;mutable_attr())[&quot;value&quot;].mutable_tensor();
186:   CHECK(model.HasArray(name));
187:   const auto&amp; input_array = model.GetArray(name);
188:   const auto&amp; input_shape = input_array.shape();
189:   CHECK(input_array.buffer);
190:   CHECK(input_array.buffer-&gt;type == ArrayDataType::kFloat);
191:   const float* input_data =
192:       input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
193:   ExportFloatArray(input_axes_order, input_shape, input_data, output_axes_order,
194:                    tensor, LegacyScalarPolicy::kAvoidLegacyScalars);
195: }
196: 
197: void ConvertFloatTensorConst(const Model&amp; model, const string&amp; name,
198:                              GraphDef* tensorflow_graph) {
199:   if (HasAlreadyExportedConst(name, *tensorflow_graph)) {
200:     return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="211" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 210 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="void ConvertFloatTensorConst ( const Model &amp; model , const string &amp; name , GraphDef * tensorflow_graph )" content="201:   }
202:   tensorflow::NodeDef* const_op = tensorflow_graph-&gt;add_node();
203:   const_op-&gt;set_op(&quot;Const&quot;);
204:   const_op-&gt;set_name(name);
205:   (*const_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(DT_FLOAT);
206:   auto* tensor = (*const_op-&gt;mutable_attr())[&quot;value&quot;].mutable_tensor();
207:   CHECK(model.HasArray(name));
208:   const auto&amp; input_array = model.GetArray(name);
209:   const auto&amp; input_shape = input_array.shape();
210:   CHECK(input_array.buffer);
211:   CHECK(input_array.buffer-&gt;type == ArrayDataType::kFloat);
212:   const float* input_data =
213:       input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
214:   ExportFloatArray(input_shape, input_data, tensor,
215:                    LegacyScalarPolicy::kAvoidLegacyScalars);
216: }
217: 
218: void ConvertIntTensorConst(const Model&amp; model, const string&amp; name,
219:                            GraphDef* tensorflow_graph) {
220:   if (HasAlreadyExportedConst(name, *tensorflow_graph)) {
221:     return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="329" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 328 implies that [op ] might be null.Dereferencing null pointer [op]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="string WalkUpToConstantArray ( const Model &amp; model , const string &amp; name )" content="319:   }
320: }
321: 
322: string WalkUpToConstantArray(const Model&amp; model, const string&amp; name) {
323:   const Array&amp; original_array = model.GetArray(name);
324:   if (original_array.buffer) {
325:     return name;
326:   }
327:   const auto* op = GetOpWithOutput(model, name);
328:   CHECK(op);
329:   CHECK(op-&gt;type == OperatorType::kFakeQuant);
330:   const string&amp; input_of_fakequant_name = op-&gt;inputs[0];
331:   const Array&amp; input_of_fakequant = model.GetArray(input_of_fakequant_name);
332:   CHECK(input_of_fakequant.buffer);
333:   return input_of_fakequant_name;
334: }
335: 
336: void ConvertConvOperator(const Model&amp; model, const ConvOperator&amp; src_op,
337:                          GraphDef* tensorflow_graph) {
338:   const bool has_bias = src_op.inputs.size() &gt;= 3;
339:   string conv_output = src_op.outputs[0];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="606" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_array.buffer] to null at line 605 implies that [bias_array.buffer ] might be null.Dereferencing null pointer [bias_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias_array.buffer&quot;}" func_info="void ConvertFullyConnectedOperator ( const Model &amp; model , const FullyConnectedOperator &amp; src_op , GraphDef * tensorflow_graph )" content="596:     biasadd_op-&gt;add_input(matmul_output);
597:     biasadd_op-&gt;add_input(src_op.inputs[2]);
598:     (*biasadd_op-&gt;mutable_attr())[&quot;T&quot;].set_type(
599:         GetTensorFlowDataType(model, src_op.inputs[0]));
600:     CHECK(model.HasArray(src_op.inputs[2]));
601:     const auto&amp; bias_array = model.GetArray(src_op.inputs[2]);
602:     // TODO(b/62904716) Bias arrays should be 1-D, and used directly.
603:     Shape bias_shape_1d = bias_array.shape();
604:     UnextendShape(&amp;bias_shape_1d, 1);
605:     CHECK(bias_array.buffer);
606:     CHECK(bias_array.buffer-&gt;type == ArrayDataType::kFloat);
607:     const float* bias_data =
608:         bias_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
609:     ConvertFloatTensorConst(WalkUpToConstantArray(model, src_op.inputs[2]),
610:                             bias_shape_1d, bias_data, AxesOrder::kOneAxis,
611:                             AxesOrder::kOneAxis, tensorflow_graph,
612:                             LegacyScalarPolicy::kDoCreateLegacyScalars);
613:   }
614: }
615: 
616: void ConvertAddOperator(const Model&amp; model, const AddOperator&amp; src_op,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="882" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [src_op.minmax] to null at line 881 implies that [src_op.minmax ] might be null.Dereferencing null pointer [src_op.minmax]." web_identify="{&quot;identify&quot;:&quot;src_op.minmax&quot;}" func_info="void ConvertFakeQuantOperator ( const FakeQuantOperator &amp; src_op , GraphDef * tensorflow_graph )" content="872: }
873: 
874: void ConvertFakeQuantOperator(const FakeQuantOperator&amp; src_op,
875:                               GraphDef* tensorflow_graph) {
876:   tensorflow::NodeDef* fakequant_op = tensorflow_graph-&gt;add_node();
877:   fakequant_op-&gt;set_op(&quot;FakeQuantWithMinMaxArgs&quot;);
878:   fakequant_op-&gt;set_name(src_op.outputs[0]);
879:   CHECK_EQ(src_op.inputs.size(), 1);
880:   *fakequant_op-&gt;add_input() = src_op.inputs[0];
881:   CHECK(src_op.minmax);
882:   (*fakequant_op-&gt;mutable_attr())[&quot;min&quot;].set_f(src_op.minmax-&gt;min);
883:   (*fakequant_op-&gt;mutable_attr())[&quot;max&quot;].set_f(src_op.minmax-&gt;max);
884:   if (src_op.num_bits) {
885:     (*fakequant_op-&gt;mutable_attr())[&quot;num_bits&quot;].set_i(src_op.num_bits);
886:   }
887:   if (src_op.narrow_range) {
888:     (*fakequant_op-&gt;mutable_attr())[&quot;narrow_range&quot;].set_b(src_op.narrow_range);
889:   }
890: }
891: 
892: void ConvertMaxPoolOperator(const MaxPoolOperator&amp; src_op,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc" line="60" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [array.quantization_params] to null at line 57 implies that [array.quantization_params ] might be null.Dereferencing null pointer [array.quantization_params]." web_identify="{&quot;identify&quot;:&quot;array.quantization_params&quot;}" func_info="void ClearArrayQuantizationParams ( const string &amp; array_name , Model * model )" content="50:     }
51:   }
52:   return model-&gt;operators.end();
53: }
54: 
55: void ClearArrayQuantizationParams(const string&amp; array_name, Model* model) {
56:   auto* array = &amp;model-&gt;GetArray(array_name);
57:   CHECK(array-&gt;quantization_params);
58:   for (auto&amp; input_array : *model-&gt;flags.mutable_input_arrays()) {
59:     if (input_array.name() == array_name) {
60:       auto&amp; qparams = *array-&gt;quantization_params;
61:       const double new_std_value = 1. / qparams.scale;
62:       const double new_mean_value = qparams.zero_point;
63:       if (input_array.has_std_value()) {
64:         CHECK_LE(std::abs(new_std_value - input_array.std_value()), 0.001);
65:       } else {
66:         input_array.set_std_value(new_std_value);
67:       }
68:       if (input_array.has_mean_value()) {
69:         CHECK_LE(std::abs(new_mean_value - input_array.mean_value()), 0.001);
70:       } else {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc" line="148" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: output_depth" web_identify="{&quot;identify&quot;:&quot;output_depth&quot;}" func_info="void FuseMulOrDivParamsIntoPrecedingAffine ( Model * model , Operator * preceding_op , const Operator * mul_or_div_op , int index_of_constant_input )" content="138:   if (preceding_op-&gt;type == OperatorType::kConv ||
139:       preceding_op-&gt;type == OperatorType::kFullyConnected) {
140:     output_depth = weights_shape.dims(0);
141:   } else if (preceding_op-&gt;type == OperatorType::kDepthwiseConv) {
142:     output_depth = weights_shape.dims(weights_shape.dimensions_count() - 1);
143:   } else {
144:     LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
145:   }
146: 
147:   const int weights_size = RequiredBufferSizeForShape(weights_shape);
148:   const int weights_per_depth = weights_size / output_depth;
149:   CHECK_EQ(weights_size, weights_per_depth * output_depth);
150: 
151:   int operand_channel = 0;
152:   for (int c = 0; c &lt; output_depth; c++) {
153:     if (mul_or_div_op-&gt;type == OperatorType::kMul) {
154:       bias_data[c] *= operand_data[operand_channel];
155:     } else if (mul_or_div_op-&gt;type == OperatorType::kDiv) {
156:       bias_data[c] /= operand_data[operand_channel];
157:     } else {
158:       LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc" line="152" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: output_depth" web_identify="{&quot;identify&quot;:&quot;output_depth&quot;}" func_info="void FuseMulOrDivParamsIntoPrecedingAffine ( Model * model , Operator * preceding_op , const Operator * mul_or_div_op , int index_of_constant_input )" content="142:     output_depth = weights_shape.dims(weights_shape.dimensions_count() - 1);
143:   } else {
144:     LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
145:   }
146: 
147:   const int weights_size = RequiredBufferSizeForShape(weights_shape);
148:   const int weights_per_depth = weights_size / output_depth;
149:   CHECK_EQ(weights_size, weights_per_depth * output_depth);
150: 
151:   int operand_channel = 0;
152:   for (int c = 0; c &lt; output_depth; c++) {
153:     if (mul_or_div_op-&gt;type == OperatorType::kMul) {
154:       bias_data[c] *= operand_data[operand_channel];
155:     } else if (mul_or_div_op-&gt;type == OperatorType::kDiv) {
156:       bias_data[c] /= operand_data[operand_channel];
157:     } else {
158:       LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
159:     }
160:     if (preceding_op-&gt;type == OperatorType::kConv ||
161:         preceding_op-&gt;type == OperatorType::kFullyConnected) {
162:       for (int i = 0; i &lt; weights_per_depth; i++) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc" line="44" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [source_op] to null at line 43 implies that [source_op ] might be null.Dereferencing null pointer [source_op]." web_identify="{&quot;identify&quot;:&quot;source_op&quot;}" func_info="bool ValidateSourceOp ( const Model &amp; model , const string &amp; array_name , OperatorType op_type , Operator * * source_op )" content="34:   }
35:   return it;
36: }
37: 
38: bool ValidateSourceOp(const Model&amp; model, const string&amp; array_name,
39:                       OperatorType op_type, Operator** source_op) {
40:   if (op_type == OperatorType::kNone) {
41:     CHECK(!source_op);
42:   } else {
43:     CHECK(source_op);
44:     *source_op = GetOpWithOutput(model, array_name);
45:     if (*source_op == nullptr) {
46:       return false;
47:     }
48: 
49:     // Check that first operator, if connected, is of correct type
50:     if ((*source_op)-&gt;type != op_type) {
51:       return false;
52:     }
53:   }
54: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc" line="124" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 113 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="bool ResolveConstantUnaryOperator::Run ( Model * model , long op_index )" content="114:   std::vector&lt;DataType&lt;ArrayDataType::kFloat&gt;&gt; const* input_float_data;
115:   if (unary_op-&gt;type == OperatorType::kCast) {
116:     CastOperator const* cast_op = static_cast&lt;CastOperator const*&gt;(unary_op);
117:     if (cast_op-&gt;dst_data_type != ArrayDataType::kFloat) {
118:       AddMessageF(
119:           &quot;Not resolving constant %s because we currently only support casting &quot;
120:           &quot;to float&quot;,
121:           LogName(*unary_op));
122:       return false;
123:     }
124:     if (cast_op-&gt;src_data_type != input_array.buffer-&gt;type) {
125:       AddMessageF(
126:           &quot;Not resolving constant %s because cast op source type does not &quot;
127:           &quot;match input type&quot;,
128:           LogName(*unary_op));
129:     }
130:   } else {
131:     if (input_array.buffer-&gt;type != ArrayDataType::kFloat) {
132:       return false;
133:     }
134:     input_float_data = &amp;(input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="115" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 114 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="105:       indices_data_array.GetBuffer&lt;ArrayDataType::kInt32&gt;().data;
106:   for (size_t i = 0; i &lt; indices_data_buffer.size(); ++i) {
107:     CHECK_EQ(indices_data_buffer[i], i) &lt;&lt; &quot;Indices range must be identity&quot;;
108:   }
109: 
110:   // Find all of the gathers used for the data inputs.
111:   std::vector&lt;GatherOperator*&gt; gather_ops;
112:   for (const string&amp; gather_output_name : stitch_data_inputs) {
113:     auto* op = GetOpWithOutput(*model, gather_output_name);
114:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; gather_output_name &lt;&lt; &quot; not found&quot;;
115:     if (op-&gt;type != OperatorType::kGather) {
116:       AddMessageF(
117:           &quot;Skipping because data input %s into %s &quot;
118:           &quot;is unexpected&quot;,
119:           LogName(*op), LogName(*stitch_op));
120:       return false;
121:     }
122:     gather_ops.push_back(static_cast&lt;GatherOperator*&gt;(op));
123:   }
124: 
125:   // Validate all gathers come from the same DynamicPartition.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="130" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 129 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="120:       return false;
121:     }
122:     gather_ops.push_back(static_cast&lt;GatherOperator*&gt;(op));
123:   }
124: 
125:   // Validate all gathers come from the same DynamicPartition.
126:   DynamicPartitionOperator* data_partition_op = nullptr;
127:   for (auto* gather_op : gather_ops) {
128:     auto* op = GetOpWithOutput(*model, gather_op-&gt;inputs[1]);
129:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; gather_op-&gt;inputs[1] &lt;&lt; &quot; not found&quot;;
130:     if (op-&gt;type != OperatorType::kDynamicPartition) {
131:       AddMessageF(
132:           &quot;Skipping because data input %s into &quot;
133:           &quot;%s is unexpected&quot;,
134:           LogName(*op), LogName(*gather_op));
135:       return false;
136:     }
137:     if (!data_partition_op) {
138:       data_partition_op = static_cast&lt;DynamicPartitionOperator*&gt;(op);
139:     } else {
140:       // Ensure this is the same op as previous ones.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="154" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [data_partition_op] to null at line 150 implies that [data_partition_op ] might be null.Dereferencing null pointer [data_partition_op]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;data_partition_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="144:             &quot;%s is from a different source op than others&quot;,
145:             LogName(*op), LogName(*gather_op));
146:         return false;
147:       }
148:     }
149:   }
150:   CHECK(data_partition_op) &lt;&lt; &quot;No data inputs&quot;;
151: 
152:   // Validate the partition ops have the same sizes.
153:   CHECK_EQ(indices_partition_op-&gt;num_partitions,
154:            data_partition_op-&gt;num_partitions)
155:       &lt;&lt; &quot;Indices and data partition ops have differing dimensions&quot;;
156:   int num_partitions = indices_partition_op-&gt;num_partitions;
157: 
158:   // Partition strategy of &apos;mod&apos; gives us a FloorMod and FloorDiv.
159:   // The gather partition uses the FloorDiv as the data and FloorMod as the
160:   // partitions and the indices use the FloorMod as their partitions.
161:   Operator* div_op = GetOpWithOutput(*model, data_partition_op-&gt;inputs[0]);
162:   Operator* mod_op = GetOpWithOutput(*model, data_partition_op-&gt;inputs[1]);
163:   CHECK(div_op &amp;&amp; div_op-&gt;type == OperatorType::kFloorDiv)
164:       &lt;&lt; &quot;Unsupported partition strategy&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="212" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [mod_op] to null at line 165 implies that [mod_op ] might be null.Dereferencing null pointer [mod_op]." web_identify="{&quot;identify&quot;:&quot;mod_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="202:   perm_data.resize(RequiredBufferSizeForShape(perm_array.shape()));
203:   // NOTE: this is what relies on the partition_strategy.
204:   for (int i = 0; i &lt; num_partitions * partition_array_dims[0]; ++i) {
205:     int p = i % num_partitions;
206:     perm_data[i] = p * partition_array_dims[0] + i / num_partitions;
207:   }
208: 
209:   // Insert the new unpartitioned gather op.
210:   auto* merged_gather_op = new GatherOperator;
211:   merged_gather_op-&gt;inputs = {gather_params_permute_op-&gt;outputs[0],
212:                               mod_op-&gt;inputs[0]};
213:   merged_gather_op-&gt;outputs = {stitch_op-&gt;outputs[0]};
214:   merged_gather_op-&gt;input_rank = partition_array.shape().dimensions_count();
215:   model-&gt;operators.emplace(op_it, merged_gather_op);
216: 
217:   AddMessageF(
218:       &quot;Replacing suspected partitioned tf.nn.embedding_lookup (starting at %s &quot;
219:       &quot;+ %s and ending at %s) with a single unpartitioned gather %s&quot;,
220:       LogName(*div_op), LogName(*mod_op), LogName(*stitch_op),
221:       LogName(*merged_gather_op));
222: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="220" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [div_op] to null at line 163 implies that [div_op ] might be null.Dereferencing null pointer [div_op]." web_identify="{&quot;identify&quot;:&quot;div_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="210:   auto* merged_gather_op = new GatherOperator;
211:   merged_gather_op-&gt;inputs = {gather_params_permute_op-&gt;outputs[0],
212:                               mod_op-&gt;inputs[0]};
213:   merged_gather_op-&gt;outputs = {stitch_op-&gt;outputs[0]};
214:   merged_gather_op-&gt;input_rank = partition_array.shape().dimensions_count();
215:   model-&gt;operators.emplace(op_it, merged_gather_op);
216: 
217:   AddMessageF(
218:       &quot;Replacing suspected partitioned tf.nn.embedding_lookup (starting at %s &quot;
219:       &quot;+ %s and ending at %s) with a single unpartitioned gather %s&quot;,
220:       LogName(*div_op), LogName(*mod_op), LogName(*stitch_op),
221:       LogName(*merged_gather_op));
222: 
223:   // Ensure the stitch output array is dead, as we don&apos;t want whatever was in it
224:   // previously now that we&apos;ve redefined it. It&apos;ll be recreated when needed.
225:   model-&gt;EraseArray(stitch_op-&gt;outputs[0]);
226:   model-&gt;GetOrCreateArray(merged_gather_op-&gt;outputs[0]);
227: 
228:   // Erase all the original ops.
229:   DeleteOpAndArraysIfUnused(model, div_op);
230:   DeleteOpAndArraysIfUnused(model, mod_op);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="70" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 69 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="60:   for (size_t i = stitch_op-&gt;num_partitions; i &lt; stitch_op-&gt;num_partitions * 2;
61:        ++i) {
62:     stitch_data_inputs.push_back(stitch_op-&gt;inputs[i]);
63:   }
64: 
65:   // Validate all indices come from the same DynamicPartition.
66:   DynamicPartitionOperator* indices_partition_op = nullptr;
67:   for (const string&amp; indices_partition_output_name : stitch_indices_inputs) {
68:     auto* op = GetOpWithOutput(*model, indices_partition_output_name);
69:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; indices_partition_output_name &lt;&lt; &quot; not found&quot;;
70:     if (op-&gt;type != OperatorType::kDynamicPartition) {
71:       AddMessageF(
72:           &quot;Skipping because indices input %s into &quot;
73:           &quot;%s is unexpected&quot;,
74:           LogName(*op), LogName(*stitch_op));
75:       return false;
76:     }
77:     if (!indices_partition_op) {
78:       indices_partition_op = static_cast&lt;DynamicPartitionOperator*&gt;(op);
79:     } else {
80:       // Ensure this is the same op as previous ones.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="93" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [indices_partition_op] to null at line 90 implies that [indices_partition_op ] might be null.Dereferencing null pointer [indices_partition_op]." web_identify="{&quot;identify&quot;:&quot;indices_partition_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="83:             &quot;Skipping because indices input %s into &quot;
84:             &quot;%s is from a different source op than others&quot;,
85:             LogName(*op), LogName(*stitch_op));
86:         return false;
87:       }
88:     }
89:   }
90:   CHECK(indices_partition_op) &lt;&lt; &quot;No indices inputs&quot;;
91: 
92:   // The data for the indices must be a constant range of the array shape.
93:   if (!IsConstantParameterArray(*model, indices_partition_op-&gt;inputs[0])) {
94:     AddMessageF(&quot;Skipping because indices partition data is non-constant&quot;);
95:     return false;
96:   }
97:   auto&amp; indices_data_array = model-&gt;GetArray(indices_partition_op-&gt;inputs[0]);
98:   if (indices_data_array.data_type == ArrayDataType::kNone) {
99:     // Yield until data types are propagated.
100:     return false;
101:   }
102:   CHECK(indices_data_array.data_type == ArrayDataType::kInt32)
103:       &lt;&lt; &quot;Indices partition inputs must be int32&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/import_tensorflow.cc" line="718" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [model] to null at line 717 implies that [model ] might be null.Dereferencing null pointer [model]." web_identify="{&quot;identify&quot;:&quot;model&quot;}" func_info="tensorflow::Status ConvertRandomUniform ( const NodeDef &amp; node , const TensorFlowImportFlags &amp; tf_import_flags , Model * model )" content="708:   TF_QCHECK_OK(CheckInputsCount(node, tf_import_flags, 1));
709: 
710:   CHECK_EQ(GetDataTypeAttr(node, &quot;T&quot;), DT_INT32);
711:   auto op = absl::make_unique&lt;RandomUniformOperator&gt;();
712:   op-&gt;inputs.push_back(node.input(0));
713:   op-&gt;outputs.push_back(node.name());
714:   op-&gt;dtype = ConvertDataType(GetDataTypeAttr(node, &quot;dtype&quot;));
715:   op-&gt;seed = GetIntAttr(node, &quot;seed&quot;);
716:   op-&gt;seed2 = GetIntAttr(node, &quot;seed2&quot;);
717:   CHECK(model != nullptr);
718:   model-&gt;operators.emplace_back(std::move(op));
719:   return tensorflow::Status::OK();
720: }
721: 
722: tensorflow::Status ConvertIdentityOperator(
723:     const NodeDef&amp; node, const TensorFlowImportFlags&amp; tf_import_flags,
724:     Model* model) {
725:   CHECK(node.op() == &quot;Identity&quot; || node.op() == &quot;CheckNumerics&quot; ||
726:         node.op() == &quot;PlaceholderWithDefault&quot; || node.op() == &quot;StopGradient&quot;);
727:   auto* op = new TensorFlowIdentityOperator;
728:   // Amazingly, some TensorFlow graphs (at least rajeev_lstm.pb) have
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/model.h" line="1081" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RandomUniformOperator::seed,seed2,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RandomUniformOperator::seed,seed2,&quot;}" func_info="toco::RandomUniformOperator" content="1071: // Inputs:
1072: //   inputs[0]: required: the left-hand side array
1073: //   inputs[1]: required: the right-hand side array
1074: //
1075: // TensorFlow equivalent: FloorMod
1076: struct FloorModOperator : Operator {
1077:   FloorModOperator() : Operator(OperatorType::kFloorMod) {}
1078: };
1079: 
1080: struct RandomUniformOperator : Operator {
1081:   RandomUniformOperator() : Operator(OperatorType::kRandomUniform) {}
1082:   ArrayDataType dtype = ArrayDataType::kNone;
1083:   int64 seed;
1084:   int64 seed2;
1085: };
1086: 
1087: // Creates a sequence of numbers that begins at start and extends by increments
1088: // of delta up to but not including limit.
1089: //
1090: // The dtype of the resulting tensor is inferred from the inputs unless it is
1091: // provided explicitly.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc" line="128" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_input] to null at line 126 implies that [bias_input ] might be null.Dereferencing null pointer [bias_input]." web_identify="{&quot;identify&quot;:&quot;bias_input&quot;}" func_info="void SvdfCluster::CreateNodes ( )" content="118:   }
119:   for (const std::unique_ptr&lt;tensorflow::NodeDef&gt;&amp; node : new_nodes_) {
120:     const string node_name = node-&gt;name();
121:     if (StrContains(node_name, &quot;SVDF_weights_feature&quot;)) {
122:       *weights_feature_input = node_name;
123:     } else if (StrContains(node_name, &quot;SVDF_weights_time&quot;)) {
124:       *weights_time_input = node_name;
125:     } else if (StrContains(node_name, &quot;SVDF_bias&quot;)) {
126:       CHECK(bias_input) &lt;&lt; &quot;Bias input cannot be provided when there are only &quot;
127:                            &quot;two Const input nodes!&quot;;
128:       *bias_input = node_name;
129:     } else {
130:       // Unexpected input for Svdf op.
131:       LOG(FATAL) &lt;&lt; &quot;Unexpected input node for SVDF op! Accepted inputs are: &quot;
132:                     &quot;weights_feature, weights_time and bias.&quot;;
133:     }
134:   }
135:   const int rank = InferFilterRank();
136:   CHECK_GT(rank, 0);
137: 
138:   // Add Svdf activation and rank.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/toco/tooling_util.cc" line="1011" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 1010 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="void toco::FixOperatorOrdering ( Model * model )" content="1001:   for (std::size_t i = 0; i &lt; old_operators.size(); i++) {
1002:     remaining.insert(i);
1003:   }
1004:   std::unordered_map&lt;string, string&gt; reason_why_leftover;
1005:   while (true) {
1006:     bool inserted_something = false;
1007:     for (auto i : remaining) {
1008:       bool can_insert = true;
1009:       auto&amp; op = old_operators[i];
1010:       CHECK(op);
1011:       for (const auto&amp; input : op-&gt;inputs) {
1012:         if (!IsConstantParameterArray(*model, input) &amp;&amp;
1013:             !arrays_behind_us.count(input)) {
1014:           for (const string&amp; output : op-&gt;outputs) {
1015:             reason_why_leftover[output] = input;
1016:           }
1017:           can_insert = false;
1018:           break;
1019:         }
1020:       }
1021:       if (can_insert) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/tools/benchmark/benchmark_tflite_model.cc" line="239" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [model] to null at line 235 implies that [model ] might be null.Dereferencing null pointer [model]." web_identify="{&quot;identify&quot;:&quot;model&quot;}" func_info="void BenchmarkTfLiteModel::Init ( )" content="229:   return total_input_bytes;
230: }
231: 
232: void BenchmarkTfLiteModel::Init() {
233:   std::string graph = params_.Get&lt;std::string&gt;(&quot;graph&quot;);
234:   model = tflite::FlatBufferModel::BuildFromFile(graph.c_str());
235:   if (!model) {
236:     TFLITE_LOG(FATAL) &lt;&lt; &quot;Failed to mmap model &quot; &lt;&lt; graph;
237:   }
238:   TFLITE_LOG(INFO) &lt;&lt; &quot;Loaded model &quot; &lt;&lt; graph;
239:   model-&gt;error_reporter();
240:   TFLITE_LOG(INFO) &lt;&lt; &quot;resolved reporter&quot;;
241: 
242: #ifdef TFLITE_CUSTOM_OPS_HEADER
243:   tflite::MutableOpResolver resolver;
244:   RegisterSelectedOps(&amp;resolver);
245: #else
246:   tflite::ops::builtin::BuiltinOpResolver resolver;
247: #endif
248: 
249:   tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/lite/tools/benchmark/benchmark_tflite_model.cc" line="258" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [interpreter] to null at line 250 implies that [interpreter ] might be null.Dereferencing null pointer [interpreter]." web_identify="{&quot;identify&quot;:&quot;interpreter&quot;}" func_info="void BenchmarkTfLiteModel::Init ( )" content="248: 
249:   tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);
250:   if (!interpreter) {
251:     TFLITE_LOG(FATAL) &lt;&lt; &quot;Failed to construct interpreter&quot;;
252:   }
253:   profiling_listener_.SetInterpreter(interpreter.get());
254: 
255:   const int32_t num_threads = params_.Get&lt;int32_t&gt;(&quot;num_threads&quot;);
256: 
257:   if (num_threads != -1) {
258:     interpreter-&gt;SetNumThreads(num_threads);
259:   }
260: 
261:   bool use_nnapi = params_.Get&lt;bool&gt;(&quot;use_nnapi&quot;);
262: 
263:   interpreter-&gt;UseNNAPI(use_nnapi);
264:   auto interpreter_inputs = interpreter-&gt;inputs();
265: 
266:   if (!inputs.empty()) {
267:     TFLITE_BENCHMARK_CHECK_EQ(inputs.size(), interpreter_inputs.size())
268:         &lt;&lt; &quot;Inputs mismatch: Model inputs #:&quot; &lt;&lt; interpreter_inputs.size()
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/nccl/kernels/nccl_manager.cc" line="416" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [nccl_stream] to null at line 410 implies that [nccl_stream ] might be null.Dereferencing null pointer [nccl_stream]." web_identify="{&quot;identify&quot;:&quot;nccl_stream&quot;}" func_info="void NcclManager::RunCollective ( const string &amp; key , Collective * collective )" content="406: 
407:   for (int rank = 0; rank &lt; size; ++rank) {
408:     Participant* p = collective-&gt;participants[rank].get();
409:     NcclStream* nccl_stream = communicator-&gt;members[rank].nccl_stream;
410:     CHECK(nccl_stream != nullptr);
411: 
412:     if (p-&gt;in_t != nullptr) {
413:       // Wait to ensure that the kernel that produces the data in the input
414:       // tensor has finished running before the nccl kernel runs on the
415:       // communication stream.
416:       nccl_stream-&gt;stream-&gt;ThenWaitFor(p-&gt;tensor_stream);
417:     }
418:     if (p-&gt;root) {
419:       CHECK_EQ(collective-&gt;root_rank, -1);
420:       collective-&gt;root_rank = rank;
421:     }
422:   }
423: 
424:   if (collective-&gt;type == kBroadcast) {
425:     CHECK_NE(collective-&gt;root_rank, -1);
426:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/pi_examples/camera/camera.cc" line="352" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;image_widthimage_channels*&quot;}" func_info="Status TensorFromFrame ( char * image_data , int image_width , int image_height , int image_channels , const int wanted_height , const int wanted_width , const float input_mean , const float input_std , std::vector &lt; Tensor &gt; * out_tensors )" content="342:   // In these loops, we convert the eight-bit data in the image into float,
343:   // resize it using bilinear filtering, and scale it numerically to the float
344:   // range that the model expects (given by input_mean and input_std).
345:   tensorflow::Tensor image_tensor(
346:       tensorflow::DT_FLOAT,
347:       tensorflow::TensorShape(
348:           {1, wanted_height, wanted_width, wanted_channels}));
349:   auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;();
350:   tensorflow::uint8* in = image_data;
351:   float* out = image_tensor_mapped.data();
352:   const size_t image_rowlen = image_width * image_channels;
353:   const float width_scale = static_cast&lt;float&gt;(image_width) / wanted_width;
354:   const float height_scale = static_cast&lt;float&gt;(image_height) / wanted_height;
355:   for (int y = 0; y &lt; wanted_height; ++y) {
356:     const float in_y = y * height_scale;
357:     const int top_y_index = static_cast&lt;int&gt;(floorf(in_y));
358:     const int bottom_y_index =
359:         std::min(static_cast&lt;int&gt;(ceilf(in_y)), (image_height - 1));
360:     const float y_lerp = in_y - top_y_index;
361:     tensorflow::uint8* in_top_row = in + (top_y_index * image_rowlen);
362:     tensorflow::uint8* in_bottom_row = in + (bottom_y_index * image_rowlen);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/pi_examples/label_image/label_image.cc" line="163" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;image_widthimage_channels*&quot;}" func_info="Status ReadTensorFromImageFile ( string file_name , const int wanted_height , const int wanted_width , const float input_mean , const float input_std , std::vector &lt; Tensor &gt; * out_tensors )" content="153:   // In these loops, we convert the eight-bit data in the image into float,
154:   // resize it using bilinear filtering, and scale it numerically to the float
155:   // range that the model expects (given by input_mean and input_std).
156:   tensorflow::Tensor image_tensor(
157:       tensorflow::DT_FLOAT,
158:       tensorflow::TensorShape(
159:           {1, wanted_height, wanted_width, wanted_channels}));
160:   auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;();
161:   tensorflow::uint8* in = image_data.data();
162:   float* out = image_tensor_mapped.data();
163:   const size_t image_rowlen = image_width * image_channels;
164:   const float width_scale = static_cast&lt;float&gt;(image_width) / wanted_width;
165:   const float height_scale = static_cast&lt;float&gt;(image_height) / wanted_height;
166:   for (int y = 0; y &lt; wanted_height; ++y) {
167:     const float in_y = y * height_scale;
168:     const int top_y_index = static_cast&lt;int&gt;(floorf(in_y));
169:     const int bottom_y_index =
170:         std::min(static_cast&lt;int&gt;(ceilf(in_y)), (image_height - 1));
171:     const float y_lerp = in_y - top_y_index;
172:     tensorflow::uint8* in_top_row = in + (top_y_index * image_rowlen);
173:     tensorflow::uint8* in_bottom_row = in + (bottom_y_index * image_rowlen);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc" line="64" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ &lt;&lt; ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;tree_num16&lt;&lt;&quot;}" func_info="void tensorforest::GetFeatureSet ( int tree_num , int node_num , int random_seed , int num_features , int num_features_to_pick , std :: vector &lt; int &gt; * features )" content="54: 
55:   // TODO(thomaswc): At some point we should consider
56:   // //learning/logistic/logodds-to-prob.h
57:   return 1.0 / (1.0 + exp(-dot_product + bias));
58: }
59: 
60: void GetFeatureSet(int32 tree_num, int32 node_num, int32 random_seed,
61:                    int32 num_features, int32 num_features_to_pick,
62:                    std::vector&lt;int32&gt;* features) {
63:   features-&gt;clear();
64:   uint64 seed = node_num ^ (tree_num &lt;&lt; 16) ^ random_seed;
65:   random::PhiloxRandom rng(seed);
66:   for (int i = 0; i &lt; num_features_to_pick; ++i) {
67:     // PhiloxRandom returns an array of int32&apos;s
68:     const random::PhiloxRandom::ResultType rand = rng();
69:     const int32 feature = (rand[0] + rand[1]) % num_features;
70:     features-&gt;push_back(feature);
71:   }
72: }
73: 
74: }  // namespace tensorforest
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc" line="613" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;parent_sum&gt;=0&apos; is redundant or there is division by zero at line 613." web_identify="" func_info="void tensorforest::GetParentWeightedMean ( float leaf_sum , const float * leaf_data , float parent_sum , const float * parent_data , float valid_leaf_threshold , int num_outputs , std :: vector &lt; float &gt; * mean )" content="603:                            float valid_leaf_threshold, int num_outputs,
604:                            std::vector&lt;float&gt;* mean) {
605:   float parent_weight = 0.0;
606:   if (leaf_sum &lt; valid_leaf_threshold &amp;&amp; parent_sum &gt;= 0) {
607:     VLOG(1) &lt;&lt; &quot;not enough samples at leaf, including parent counts.&quot;
608:             &lt;&lt; &quot;child sum = &quot; &lt;&lt; leaf_sum;
609:     // Weight the parent&apos;s counts just enough so that the new sum is
610:     // valid_leaf_threshold_, but never give any counts a weight of
611:     // more than 1.
612:     parent_weight =
613:         std::min(1.0f, (valid_leaf_threshold - leaf_sum) / parent_sum);
614:     leaf_sum += parent_weight * parent_sum;
615:     VLOG(1) &lt;&lt; &quot;Sum w/ parent included = &quot; &lt;&lt; leaf_sum;
616:   }
617: 
618:   for (int c = 0; c &lt; num_outputs; c++) {
619:     float w = leaf_data[c];
620:     if (parent_weight &gt; 0.0) {
621:       w += parent_weight * parent_data[c];
622:     }
623:     (*mean)[c] = w / leaf_sum;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/kernels/v4/graph_collection_operator.cc" line="34" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;node_idnum_splits_to_consider_*&quot;}" func_info="long GraphRunnerSplitCollectionOperator::UniqueId ( int node_id , int split_id ) const" content="24: REGISTER_SPLIT_COLLECTION(GRAPH_RUNNER_COLLECTION,
25:                           GraphRunnerSplitCollectionOperator);
26: 
27: std::unique_ptr&lt;GrowStats&gt; GraphRunnerSplitCollectionOperator::CreateGrowStats(
28:     int32 node_id, int32 depth) const {
29:   return std::unique_ptr&lt;GrowStats&gt;(new SimpleStats(params_, depth));
30: }
31: 
32: int64 GraphRunnerSplitCollectionOperator::UniqueId(int32 node_id,
33:                                                    int32 split_id) const {
34:   return node_id * num_splits_to_consider_ + split_id;
35: }
36: 
37: bool GraphRunnerSplitCollectionOperator::BestSplit(int32 node_id,
38:                                                    SplitCandidate* best,
39:                                                    int32* depth) const {
40:   float min_score = FLT_MAX;
41:   int best_index = -1;
42:   auto* slot = stats_.at(node_id).get();
43:   *depth = slot-&gt;depth();
44:   for (int i = 0; i &lt; slot-&gt;num_splits(); ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/kernels/v4/graph_collection_operator.h" line="36" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GraphRunnerSplitCollectionOperator::features_per_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GraphRunnerSplitCollectionOperator::features_per_node_,&quot;}" func_info="tensorflow::tensorforest::GraphRunnerSplitCollectionOperator" content="26: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/split_collection_operators.h&quot;
27: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/proto/fertile_stats.pb.h&quot;
28: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/proto/tensor_forest_params.pb.h&quot;
29: 
30: namespace tensorflow {
31: namespace tensorforest {
32: 
33: // Holds split candidates that are trained by running any TF graph.
34: class GraphRunnerSplitCollectionOperator : public SplitCollectionOperator {
35:  public:
36:   explicit GraphRunnerSplitCollectionOperator(const TensorForestParams&amp; params)
37:       : SplitCollectionOperator(params) {
38:     if (params.num_splits_to_consider().ParamType_case() ==
39:         DepthDependentParam::PARAMTYPE_NOT_SET) {
40:       LOG(FATAL) &lt;&lt; &quot;GRAPH_RUNNER_COLLECTION must specify a constant value for &quot;
41:                  &lt;&lt; &quot; num_splits_to_consider&quot;;
42:     } else {
43:       num_splits_to_consider_ =
44:           params.num_splits_to_consider().constant_value();
45:     }
46:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc" line="141" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [sparse_indices_] to null at line 126 implies that [sparse_indices_ ] might be null.Dereferencing null pointer [sparse_indices_]." web_identify="{&quot;identify&quot;:&quot;sparse_indices_&quot;}" func_info="void TensorDataSet::RandomSample ( int example , decision_trees::FeatureId * feature_id , float * bias , int * type ) const" content="131:     }
132:   }
133:   int rand_feature = rng_-&gt;Uniform(num_total_features);
134:   if (rand_feature &lt; available_features_.size()) {  // it&apos;s dense.
135:     *feature_id = available_features_[rand_feature];
136:     *type = input_spec_.GetDenseFeatureType(rand_feature);
137:   } else {
138:     const int32 sparse_index =
139:         sparse_input_start + rand_feature - input_spec_.dense_features_size();
140:     const int32 saved_index =
141:         (*sparse_indices_)(sparse_index, 1) + input_spec_.dense_features_size();
142:     *feature_id = decision_trees::FeatureId();
143:     feature_id-&gt;mutable_id()-&gt;set_value(strings::StrCat(saved_index));
144: 
145:     // TODO(gilberth): Remove this shortcut when different sparse types are
146:     // allowed.
147:     *type = input_spec_.sparse(0).original_type();
148:   }
149: 
150:   *bias = GetExampleValue(example, *feature_id);
151: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensor_forest/kernels/v4/input_data.h" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TensorDataSet::sparse_batch_size_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TensorDataSet::sparse_batch_size_,&quot;}" func_info="tensorflow::tensorforest::TensorDataSet" content="28: 
29: namespace tensorflow {
30: namespace tensorforest {
31: 
32: typedef TTypes&lt;const float, 2&gt;::ConstTensor DenseStorageType;
33: typedef TTypes&lt;const int64, 2&gt;::ConstTensor SparseIndicesStorageType;
34: typedef TTypes&lt;const float, 1&gt;::ConstTensor SparseValuesStorageType;
35: 
36: class TensorDataSet {
37:  public:
38:   TensorDataSet(const tensorforest::TensorForestDataSpec&amp; input_spec,
39:                 int32 seed)
40:       : dense_data_(nullptr),
41:         sparse_indices_(nullptr),
42:         sparse_values_(nullptr),
43:         input_spec_(input_spec),
44:         split_sampling_random_seed_(seed) {
45:     int column_count = 0;
46:     for (int i = 0; i &lt; input_spec_.dense_size(); ++i) {
47:       for (int j = 0; j &lt; input_spec_.dense(i).size(); ++j) {
48:         ++column_count;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensorboard/db/summary_file_writer.cc" line="32" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SummaryFileWriter::last_flush_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SummaryFileWriter::last_flush_,&quot;}" func_info="SummaryFileWriter" content="22: #include &quot;tensorflow/core/framework/types.h&quot;
23: #include &quot;tensorflow/core/lib/io/path.h&quot;
24: #include &quot;tensorflow/core/util/events_writer.h&quot;
25: #include &quot;tensorflow/core/util/ptr_util.h&quot;
26: 
27: namespace tensorflow {
28: namespace {
29: 
30: class SummaryFileWriter : public SummaryWriterInterface {
31:  public:
32:   SummaryFileWriter(int max_queue, int flush_millis, Env* env)
33:       : SummaryWriterInterface(),
34:         is_initialized_(false),
35:         max_queue_(max_queue),
36:         flush_millis_(flush_millis),
37:         env_(env) {}
38: 
39:   Status Initialize(const string&amp; logdir, const string&amp; filename_suffix) {
40:     const Status is_dir = env_-&gt;IsDirectory(logdir);
41:     if (!is_dir.ok()) {
42:       if (is_dir.code() != tensorflow::error::NOT_FOUND) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensorrt/convert/convert_nodes.cc" line="2715" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [tensor] suggests that it may be null, but it has already been dereferenced at line 2714." web_identify="{&quot;identify&quot;:&quot;tensor&quot;}" func_info="tensorflow::Status convert::ConvertGraphDefToEngine ( const tensorflow :: GraphDef &amp; gdef , int precision_mode , int max_batch_size , long max_workspace_size_bytes , const std :: vector &lt; tensorflow :: PartialTensorShape &gt; &amp; input_shapes , Logger * logger , nvinfer1 :: IGpuAllocator * allocator , TRTInt8Calibrator * calibrator , TrtUniquePtrType &lt; nvinfer1 :: ICudaEngine &gt; * engine , bool * convert_successfully )" content="2705:     }
2706:   }
2707:   for (const auto&amp; output : output_tensors) {
2708:     auto tensor_or_weights = converter.get_tensor(output.first);
2709:     if (!tensor_or_weights.is_tensor()) {
2710:       return tensorflow::errors::InvalidArgument(
2711:           &quot;Output node &apos;&quot; + output.first + &quot;&apos; is weights not tensor&quot;);
2712:     }
2713:     nvinfer1::ITensor* tensor = tensor_or_weights.tensor();
2714:     tensor-&gt;setName(output.second.c_str());
2715:     if (!tensor) {
2716:       return tensorflow::errors::NotFound(&quot;Output tensor not found: &quot; +
2717:                                           output.first);
2718:     }
2719:     VLOG(1) &lt;&lt; &quot;Marking output tensor &quot; &lt;&lt; output.first &lt;&lt; &quot;, as output tensor &quot;
2720:             &lt;&lt; output.second;
2721: 
2722:     converter.network()-&gt;markOutput(*tensor);
2723:   }
2724:   if (convert_successfully) *convert_successfully = true;
2725: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc" line="179" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cluster] to null at line 93 implies that [cluster ] might be null.Dereferencing null pointer [cluster]." web_identify="{&quot;identify&quot;:&quot;cluster&quot;}" func_info="void TRTOptimizationPass::PrintDebugInfo ( tensorflow::grappler::Cluster * cluster , const tensorflow::grappler::GrapplerItem &amp; item )" content="169:   VLOG(1) &lt;&lt; &quot;save_restore_loc_tensor = &quot; &lt;&lt; item.save_restore_loc_tensor;
170:   if (item.keep_ops.size()) {
171:     VLOG(1) &lt;&lt; offset &lt;&lt; &quot;keep ops  :&quot;;
172:     for (const auto&amp; f : item.keep_ops) {
173:       VLOG(1) &lt;&lt; offset2 &lt;&lt; f;
174:     }
175:   } else {
176:     VLOG(1) &lt;&lt; offset &lt;&lt; &quot;No keep ops&quot;;
177:   }
178:   VLOG(3) &lt;&lt; item.graph.DebugString();
179:   for (const auto dev : cluster-&gt;GetDeviceSet()-&gt;devices()) {
180:     const auto&amp; pname = dev-&gt;parsed_name();
181:     VLOG(1) &lt;&lt; &quot;Device name= &quot; &lt;&lt; dev-&gt;name()
182:             &lt;&lt; &quot; parsedname job= &quot; &lt;&lt; pname.job &lt;&lt; &quot; id= &quot; &lt;&lt; pname.id
183:             &lt;&lt; &quot; has_id: &quot; &lt;&lt; pname.has_id &lt;&lt; &quot; has_job: &quot; &lt;&lt; pname.has_job
184:             &lt;&lt; &quot;has_type: &quot; &lt;&lt; pname.has_type &lt;&lt; &quot; type =&quot; &lt;&lt; pname.type;
185:   }
186: }
187: 
188: tensorflow::Status TRTOptimizationPass::Optimize(
189:     tensorflow::grappler::Cluster* cluster,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.cc" line="106" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="bool TRTInt8Calibrator::getBatch ( void * * bindings , const char * * names , int num_bindings )" content="96:   while ((!batch_is_set_ &amp;&amp; !done_)) cond_.wait(lock);
97:   if (done_) return false;
98: 
99:   // Gets the batch
100:   for (int i = 0; i &lt; num_bindings; i++) {
101:     auto it = dev_buffers_.find(names[i]);
102:     if (it == dev_buffers_.end()) {
103:       LOG(FATAL) &lt;&lt; &quot;Calibration engine asked for unknown tensor name &apos;&quot;
104:                  &lt;&lt; names[i] &lt;&lt; &quot;&apos; at position &quot; &lt;&lt; i;
105:     }
106:     bindings[i] = it-&gt;second.first;
107:   }
108:   batch_is_set_ = false;
109:   calib_running_ = true;
110:   return true;
111: }
112: 
113: void TRTInt8Calibrator::waitAndSetDone() {
114:   tensorflow::mutex_lock lock(cond_mtx_);
115:   // Wait while the queue is full or calibration is running, so we don&apos;t miss
116:   // the last batch.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.cc" line="68" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [devptr] may be invalid here." web_identify="{&quot;identify&quot;:&quot;devptr&quot;}" func_info="bool TRTInt8Calibrator::setBatch ( const std::unordered_map &lt; string , void * &gt; &amp; data , const cudaStream_t stream )" content="58:   CHECK(!calib_running_ &amp;&amp; !batch_is_set_);
59:   VLOG(1) &lt;&lt; &quot;Set Batch Waiting finished&quot;;
60: 
61:   // Sets the batch.
62:   for (const auto it : data) {
63:     auto devptr = dev_buffers_.find(it.first);
64:     if (devptr == dev_buffers_.end()) {
65:       LOG(FATAL) &lt;&lt; &quot;FATAL &quot; &lt;&lt; engine_name_ &lt;&lt; &quot; input name &apos;&quot; &lt;&lt; it.first
66:                  &lt;&lt; &quot;&apos; does not match with the buffer names&quot;;
67:     }
68:     const auto&amp; d = devptr-&gt;second;
69: 
70:     // TODO(sami,aaroey): Need to figure out a way to ensure synchronization
71:     // between stream, perhaps using a tensor?
72:     auto status = cudaMemcpyAsync(d.first, it.second, d.second,
73:                                   cudaMemcpyDeviceToDevice, stream);
74:     if (status != cudaSuccess) {
75:       LOG(FATAL) &lt;&lt; &quot;cudaMemcpy &quot; &lt;&lt; engine_name_ &lt;&lt; &quot; for &apos;&quot; &lt;&lt; it.first
76:                  &lt;&lt; &quot;&apos; failed with &quot; &lt;&lt; status;
77:     }
78:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/grpc_verbs_service.cc" line="122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rc] to null at line 115 implies that [rc ] might be null.Dereferencing null pointer [rc]." web_identify="{&quot;identify&quot;:&quot;rc&quot;}" func_info="Status GrpcVerbsService::GetRemoteAddressSync ( const GetRemoteAddressRequest * request , GetRemoteAddressResponse * response )" content="112:   // the channel setting part is redundant.
113:   const string remote_host_name = request-&gt;host_name();
114:   RdmaChannel* rc = rdma_mgr_-&gt;FindChannel(remote_host_name);
115:   CHECK(rc);
116:   RdmaAddress ra;
117:   ra.lid = request-&gt;channel().lid();
118:   ra.qpn = request-&gt;channel().qpn();
119:   ra.psn = request-&gt;channel().psn();
120:   ra.snp = request-&gt;channel().snp();
121:   ra.iid = request-&gt;channel().iid();
122:   rc-&gt;SetRemoteAddress(ra, false);
123:   rc-&gt;Connect();
124:   int i = 0;
125:   int idx[] = {1, 0};
126:   std::vector&lt;RdmaMessageBuffer*&gt; mb(rc-&gt;message_buffers());
127:   CHECK_EQ(request-&gt;mr_size(), RdmaChannel::kNumMessageBuffers);
128:   for (const auto&amp; mr : request-&gt;mr()) {
129:     // the connections are crossed, i.e.
130:     // local tx_message_buffer &lt;---&gt; remote rx_message_buffer_
131:     // local rx_message_buffer &lt;---&gt; remote tx_message_buffer_
132:     // hence idx[] = {1, 0}.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_list] to null at line 128 implies that [dev_list ] might be null.Dereferencing null pointer [dev_list]." web_identify="{&quot;identify&quot;:&quot;dev_list&quot;}" func_info="ibv_device * tensorflow::set_device ( )" content="124:   int num_devs_with_active_port = 0;
125:   string env_p_rdma_device, str_port_num;
126: 
127:   dev_list = ibv_get_device_list(&amp;dev_num);
128:   CHECK(dev_list) &lt;&lt; &quot;No InfiniBand device found&quot;;
129: 
130:   env_p_rdma_device = get_env_var(&quot;RDMA_DEVICE&quot;);
131:   if (!env_p_rdma_device.empty()) {
132:     for (device_index = 0; device_index &lt; dev_num; device_index++) {
133:       if (!env_p_rdma_device.compare(
134:               ibv_get_device_name(dev_list[device_index]))) {
135:         CHECK(get_dev_active_port_count(dev_list[device_index]) != 0)
136:             &lt;&lt; &quot;Device &quot; &lt;&lt; ibv_get_device_name(dev_list[device_index])
137:             &lt;&lt; &quot; has no active ports&quot;;
138:         return dev_list[device_index];
139:       }
140:     }
141:     // check validity of input device
142:     CHECK(false) &lt;&lt; &quot;The device &quot; &lt;&lt; env_p_rdma_device &lt;&lt; &quot; wasn&apos;t found&quot;;
143:   } else {
144:     // set default device
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="1426" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [mr] suggests that it may be null, but it has already been dereferenced at line 1423." web_identify="{&quot;identify&quot;:&quot;mr&quot;}" func_info="void RdmaMemoryMgr::InsertMemoryRegion ( void * addr , long length , const std::string &amp; allocator_name )" content="1416: }
1417: 
1418: void RdmaMemoryMgr::InsertMemoryRegion(void* addr, size_t length,
1419:                                        const std::string&amp; allocator_name) {
1420:   if (length == 0) return;
1421:   ibv_mr* mr = ibv_reg_mr(pd_, addr, length,
1422:                           IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);
1423:   RDMA_LOG(1) &lt;&lt; &quot;Insert memory region 0x&quot; &lt;&lt; std::hex &lt;&lt; mr-&gt;rkey &lt;&lt; &quot;. [&quot;
1424:               &lt;&lt; addr &lt;&lt; &quot;-&quot; &lt;&lt; (void*)((uint64_t)addr + length - 1) &lt;&lt; &quot;]&quot;
1425:               &lt;&lt; &quot; SIZE: 0x&quot; &lt;&lt; length &lt;&lt; &quot; (&quot; &lt;&lt; allocator_name &lt;&lt; &quot;).&quot;;
1426:   if (mr != nullptr) {
1427:     mutex_lock l(mrs_mu_);
1428:     auto iter = std::upper_bound(mrs_.begin(), mrs_.end(), addr, &amp;Comparator);
1429:     mrs_.insert(iter, {mr, &amp;MRDeleter});
1430:   } else {
1431:     LOG(WARNING) &lt;&lt; &quot;Cannot register memory region&quot;;
1432:   }
1433: }
1434: 
1435: void RdmaMemoryMgr::EvictMemoryRegion(void* addr, size_t length) {
1436:   if (length == 0) return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="567" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [mr_] to null at line 562 implies that [mr_ ] might be null.Dereferencing null pointer [mr_]." web_identify="{&quot;identify&quot;:&quot;mr_&quot;}" func_info="RdmaChannel::RdmaChannel ( const RdmaAdapter * adapter , const string local_name , const string remote_name ) : adapter_ ( adapter ) , local_name_ ( local_name ) , remote_name_ ( remote_name ) , request_serial_ ( 0 )" content="557:       request_serial_(0) {
558:   struct ibv_sge list;
559: 
560:   mr_ = ibv_reg_mr(adapter_-&gt;pd_, ping_buff_, kPingBuffSize,
561:                    IBV_ACCESS_LOCAL_WRITE);
562:   CHECK(mr_) &lt;&lt; &quot;Failed to register memory region&quot;;
563: 
564:   memset(&amp;list, 0, sizeof(list));
565:   list.addr = (uintptr_t)ping_buff_;
566:   list.length = kPingBuffSize;
567:   list.lkey = mr_-&gt;lkey;
568: 
569:   ping_sge_list_ = list;
570:   // Create queue pair
571:   {
572:     struct ibv_qp_init_attr attr;
573:     memset(&amp;attr, 0, sizeof(ibv_qp_init_attr));
574:     attr.send_cq = adapter_-&gt;cq_;
575:     attr.recv_cq = adapter_-&gt;cq_;
576:     attr.cap.max_send_wr = adapter_-&gt;params_.queue_depth;
577:     attr.cap.max_recv_wr = adapter_-&gt;params_.queue_depth;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="607" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [qp_] to null at line 583 implies that [qp_ ] might be null.Dereferencing null pointer [qp_]." web_identify="{&quot;identify&quot;:&quot;qp_&quot;}" func_info="RdmaChannel::RdmaChannel ( const RdmaAdapter * adapter , const string local_name , const string remote_name ) : adapter_ ( adapter ) , local_name_ ( local_name ) , remote_name_ ( remote_name ) , request_serial_ ( 0 )" content="597:     CHECK(!ibv_modify_qp(qp_, &amp;attr, mask)) &lt;&lt; &quot;Failed to set QP to INIT&quot;;
598:   }
599: 
600:   // Local address
601:   {
602:     struct ibv_port_attr attr;
603:     CHECK(
604:         !ibv_query_port(adapter_-&gt;context_, adapter_-&gt;params_.port_num, &amp;attr))
605:         &lt;&lt; &quot;Query port&quot;;
606:     self_.lid = attr.lid;
607:     self_.qpn = qp_-&gt;qp_num;
608:     self_.psn = static_cast&lt;uint32_t&gt;(random::New64()) &amp; 0xffffff;
609:     union ibv_gid gid;
610:     CHECK(!ibv_query_gid(adapter_-&gt;context_, adapter_-&gt;params_.port_num,
611:                          adapter_-&gt;params_.sgid_index, &amp;gid))
612:         &lt;&lt; &quot;Query gid&quot;;
613:     self_.snp = gid.global.subnet_prefix;
614:     self_.iid = gid.global.interface_id;
615:   }
616: 
617:   // create message and ack buffers, then initialize the tables.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="692" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="RdmaTensorRequest * RdmaChannel::GetTensorRequest ( int request_index )" content="682: 
683: void RdmaChannel::RemoveTensorRequest(uint32_t request_index) {
684:   mutex_lock lock{ct_mu_};
685:   request_table_.erase(request_index);
686: }
687: 
688: RdmaTensorRequest* RdmaChannel::GetTensorRequest(uint32_t request_index) {
689:   mutex_lock lock{ct_mu_};
690:   RequestTable::iterator iter = request_table_.find(request_index);
691:   CHECK(iter != request_table_.end());
692:   return &amp;iter-&gt;second;
693: }
694: 
695: void RdmaChannel::Connect() {
696:   {
697:     mutex_lock lock{mu_};
698:     CHECK(remote_set_) &lt;&lt; &quot;remote channel is not set&quot;;
699:   }
700:   Connect(remote_);
701: }
702: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma.cc" line="986" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="RdmaTensorResponse * RdmaChannel::UpdateTensorResponse ( const RdmaMessage &amp; rm )" content="976:       responses_table_.emplace(rm.request_index_, RdmaTensorResponse(this, rm));
977:   CHECK(it.second) &lt;&lt; &quot;Response with the ID &quot; &lt;&lt; rm.request_index_
978:                    &lt;&lt; &quot; already exists.&quot;;
979:   return &amp;it.first-&gt;second;
980: }
981: 
982: RdmaTensorResponse* RdmaChannel::UpdateTensorResponse(const RdmaMessage&amp; rm) {
983:   mutex_lock lock{mu_};
984:   auto it = responses_table_.find(rm.request_index_);
985:   CHECK(it != responses_table_.end()) &lt;&lt; &quot;No response found.&quot;;
986:   RdmaTensorResponse* response = &amp;it-&gt;second;
987:   response-&gt;Update(rm);
988:   return response;
989: }
990: 
991: void RdmaChannel::RemoveTensorResponse(uint32_t request_index) {
992:   mutex_lock lock{mu_};
993:   responses_table_.erase(request_index);
994: }
995: 
996: void RdmaTensorResponse::Start() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma_mgr.cc" line="197" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="RdmaChannel * RdmaMgr::FindChannel ( const string &amp; name )" content="187: }
188: 
189: // Find a channel via the given name.
190: // Args:
191: //   name: peer name, e.g. worker1
192: // Returns
193: //   channel object that is connected to the named peer.
194: RdmaChannel* RdmaMgr::FindChannel(const string&amp; name) {
195:   ChannelTable::iterator iter = channel_table_.find(name);
196:   CHECK(iter != channel_table_.end());
197:   return iter-&gt;second;
198: }
199: 
200: bool IsGDRAvailable() {
201: #if defined(__APPLE__)
202:   return false;
203: #elif defined(PLATFORM_WINDOWS)
204:   return false;
205: #else
206:   std::ifstream ifs(&quot;/proc/modules&quot;);
207:   string line;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/contrib/verbs/rdma_mgr.cc" line="309" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [visitable_allocator] to null at line 305 implies that [visitable_allocator ] might be null.Dereferencing null pointer [visitable_allocator]." web_identify="{&quot;identify&quot;:&quot;visitable_allocator&quot;}" func_info="void RdmaMgr::InitAllocators ( )" content="299:         std::bind(&amp;RdmaMemoryMgr::InsertMemoryRegion,
300:                   &amp;RdmaMemoryMgr::Singleton(), _1, _2, allocator-&gt;Name());
301:     VisitableAllocator::Visitor free_visitor = std::bind(
302:         &amp;RdmaMemoryMgr::EvictMemoryRegion, &amp;RdmaMemoryMgr::Singleton(), _1, _2);
303: 
304:     auto* visitable_allocator = dynamic_cast&lt;VisitableAllocator*&gt;(allocator);
305:     CHECK(visitable_allocator)
306:         &lt;&lt; &quot;is not visitable for instrumentation&quot; &lt;&lt; allocator-&gt;Name();
307:     // Make sure we don&apos;t instrument the same allocator twice
308:     if (instrumented_.find(allocator) == std::end(instrumented_)) {
309:       visitable_allocator-&gt;AddAllocVisitor(alloc_visitor);
310:       visitable_allocator-&gt;AddFreeVisitor(free_visitor);
311:       instrumented_.insert(allocator);
312:       LOG(INFO) &lt;&lt; &quot;Instrumenting CPU allocator &quot; &lt;&lt; allocator-&gt;Name();
313:     }
314:   }
315: 
316: #if GOOGLE_CUDA
317:   if (IsGDRAvailable()) {
318:     // Note we don&apos;t free allocated GPU memory so there is no free visitor
319:     int32_t bus_id = TryToReadNumaNode(rdma_adapter_-&gt;context_-&gt;device) + 1;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/broadcaster_test.cc" line="191" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BroadcasterTest::rma_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BroadcasterTest::rma_,&quot;}" func_info="BroadcasterTest" content="181:         peer_device, peer_task, key, from_device, from_device_ctx,
182:         from_alloc_attr, from_tensor, client_locality, done);
183:   }
184: 
185:   mutex mu_;
186:   int fail_after_ GUARDED_BY(mu_);
187: };
188: 
189: class BroadcasterTest : public ::testing::Test {
190:  protected:
191:   BroadcasterTest() : device_type_(DEVICE_CPU) {}
192: 
193:   ~BroadcasterTest() override {
194:     stop_ = true;
195:     for (auto i : instances_) {
196:       delete i;
197:     }
198:     if (col_exec_) col_exec_-&gt;Unref();
199:   }
200: 
201:   void SetUp() override {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/broadcaster_test.cc" line="206" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [device_factory] to null at line 204 implies that [device_factory ] might be null.Dereferencing null pointer [device_factory]." web_identify="{&quot;identify&quot;:&quot;device_factory&quot;}" func_info="void BroadcasterTest::SetUp ( )" content="196:       delete i;
197:     }
198:     if (col_exec_) col_exec_-&gt;Unref();
199:   }
200: 
201:   void SetUp() override {
202: #if GOOGLE_CUDA
203:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
204:     CHECK(device_factory);
205:     SessionOptions options;
206:     Status s = device_factory-&gt;CreateDevices(
207:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
208:     CHECK(s.ok());
209: #endif
210:   }
211: 
212:   void Init(int num_workers, int num_devices, DataType dtype,
213:             const DeviceType&amp; device_type, int fail_after) {
214:     device_type_ = device_type;
215:     std::vector&lt;Device*&gt; local_devices;
216:     SessionOptions sess_opts;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/broadcaster_test.cc" line="414" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 413 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void BroadcasterTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int tensor_len , int fail_after , bool forward_input )" content="404:     int broadcast_dev_id =
405:         cp.instance.impl_details.subdiv_permutations
406:             [0][cp.instance.impl_details.subdiv_source_rank[0]];
407:     const Tensor* t = &amp;instances_[broadcast_dev_id]-&gt;tensor_;
408:     Tensor cpu_copy(dtype, TensorShape({tensor_len}));
409:     if (device_type == DEVICE_GPU) {
410:       Notification notification;
411:       Device* dev = instances_[broadcast_dev_id]-&gt;device_;
412:       auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
413:       CHECK(dev_info);
414:       dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
415:           t, &quot;&quot; /*tensor_name*/, dev, &amp;cpu_copy,
416:           [this, &amp;notification](Status s) {
417:             TF_CHECK_OK(s);
418:             notification.Notify();
419:           });
420:       notification.WaitForNotification();
421:       t = &amp;cpu_copy;
422:     }
423:     for (size_t i = 0; i &lt; t-&gt;NumElements(); ++i) {
424:       expected[i] = t-&gt;flat&lt;T&gt;()(i);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/broadcaster_test.cc" line="448" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 447 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void BroadcasterTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int tensor_len , int fail_after , bool forward_input )" content="438:       }
439:       Tensor* inst = &amp;instances_[di]-&gt;tensor_;
440:       Tensor actual(dtype, TensorShape({tensor_len}));
441:       if (device_type_ == DEVICE_CPU) {
442:         CHECK(actual.CopyFrom(*inst, inst-&gt;shape()));
443:       } else if (device_type_ == DEVICE_GPU) {
444:         Notification notification;
445:         Device* dev = instances_[di]-&gt;device_;
446:         auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
447:         CHECK(dev_info);
448:         dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
449:             inst, &quot;&quot; /*tensor_name*/, dev, &amp;actual,
450:             [this, &amp;notification](Status s) {
451:               TF_CHECK_OK(s);
452:               notification.Notify();
453:             });
454:         notification.WaitForNotification();
455:       }
456:       for (int i = 0; i &lt; tensor_len; ++i) {
457:         switch (dtype) {
458:           case DT_FLOAT:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/broadcaster_test.cc" line="566" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 565 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void DeviceInstance::InitTensor ( DataType dtype , const TensorShape &amp; shape , const std :: function &lt; void ( Tensor * ) &gt; &amp; f )" content="556:       tensor_ =
557:           Tensor(device_-&gt;GetAllocator(AllocatorAttributes()), dtype, shape);
558:       if (device_type_ == DEVICE_CPU) {
559:         f(&amp;tensor_);
560:       } else if (device_type_ == DEVICE_GPU) {
561:         Tensor cpu_tensor(dtype, shape);
562:         f(&amp;cpu_tensor);
563:         Notification notification;
564:         auto* dev_info = device_-&gt;tensorflow_gpu_device_info();
565:         CHECK(dev_info);
566:         dev_info-&gt;default_context-&gt;CopyCPUTensorToDevice(
567:             &amp;cpu_tensor, device_, &amp;tensor_, [this, &amp;notification](Status s) {
568:               TF_CHECK_OK(s);
569:               notification.Notify();
570:             });
571:         notification.WaitForNotification();
572:       } else {
573:         LOG(FATAL) &lt;&lt; &quot;Unsupported device_type &quot; &lt;&lt; device_type_;
574:       }
575:     }
576: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/collective_executor_mgr.cc" line="26" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CollectiveExecutorMgr::remote_access_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CollectiveExecutorMgr::remote_access_,&quot;}" func_info="tensorflow" content="16: 
17: #include &quot;tensorflow/core/common_runtime/base_collective_executor.h&quot;
18: #include &quot;tensorflow/core/common_runtime/build_graph_options.h&quot;
19: #include &quot;tensorflow/core/common_runtime/collective_rma_local.h&quot;
20: #include &quot;tensorflow/core/common_runtime/device_mgr.h&quot;
21: #include &quot;tensorflow/core/framework/collective.h&quot;
22: #include &quot;tensorflow/core/protobuf/config.pb.h&quot;
23: 
24: namespace tensorflow {
25: 
26: CollectiveExecutorMgr::CollectiveExecutorMgr(
27:     const ConfigProto&amp; config, const DeviceMgr* dev_mgr,
28:     std::unique_ptr&lt;DeviceResolverInterface&gt; dev_resolver,
29:     std::unique_ptr&lt;ParamResolverInterface&gt; param_resolver)
30:     : dev_mgr_(dev_mgr),
31:       dev_resolver_(std::move(dev_resolver)),
32:       param_resolver_(std::move(param_resolver)) {}
33: 
34: CollectiveExecutorMgr::~CollectiveExecutorMgr() {
35:   for (auto iter : executor_table_) {
36:     iter.second-&gt;Unref();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/collective_param_resolver_local.cc" line="295" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [cp] suggests that it may be null, but it has already been dereferenced at line 294. The error is in macros." web_identify="{&quot;identify&quot;:&quot;cp&quot;}" func_info="void SortDevicesAndTasks ( CollectiveParams * cp )" content="285:   }
286:   cp-&gt;instance.same_num_devices_per_task = true;
287:   CHECK_EQ((cp-&gt;group.group_size % cp-&gt;group.num_tasks), 0);
288: }
289: 
290: // Sort cp-&gt;instance.device_names lexicographically, but do by first
291: // computing a reordering permutation so we can keep cp-&gt;instance.task_names
292: // in corresponding order.
293: void SortDevicesAndTasks(CollectiveParams* cp) {
294:   VLOG(1) &lt;&lt; &quot;SortDevicesAndTasks &quot; &lt;&lt; cp &lt;&lt; &quot; instance &quot; &lt;&lt; &amp;cp-&gt;instance;
295:   CHECK(cp);
296:   CHECK_EQ(cp-&gt;group.group_size, cp-&gt;instance.device_names.size());
297:   CHECK_EQ(cp-&gt;group.group_size, cp-&gt;instance.task_names.size());
298:   std::vector&lt;int&gt; perm(cp-&gt;group.group_size);
299:   // TODO(tucker): substitute std::iota when the windows build supports it.
300:   // std::iota(perm.begin(), perm.end(), 0);
301:   for (int i = 0; i &lt; perm.size(); ++i) {
302:     perm[i] = i;
303:   }
304:   std::sort(perm.begin(), perm.end(), [cp](const int&amp; a, const int&amp; b) {
305:     return cp-&gt;instance.device_names[a] &lt; cp-&gt;instance.device_names[b];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/collective_rma_local.cc" line="107" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 106 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void CollectiveRemoteAccessLocal::MemCpyAsync ( DeviceContext * src_dev_ctx , DeviceContext * dst_dev_ctx , Device * src_dev , Device * dst_dev , const AllocatorAttributes &amp; src_attr , const AllocatorAttributes &amp; dst_attr , const Tensor * src , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst , int dev_to_dev_stream_index , const StatusCallback &amp; done )" content="97:       dst_attr.on_host() ? DEVICE_CPU : dst_dev-&gt;attributes().device_type());
98:   const bool non_cpu_src = src_device_type != DeviceType(DEVICE_CPU);
99:   const bool non_cpu_dst = dst_device_type != DeviceType(DEVICE_CPU);
100:   // For GPU devices when only one compute stream is used (the default)
101:   // the OpKernelContext does not supply a DeviceContext.  It&apos;s assumed
102:   // that all nodes use the default context.
103:   if (src_dev_ctx == nullptr &amp;&amp; src_device_type == DEVICE_GPU) {
104:     const DeviceBase::GpuDeviceInfo* dev_info =
105:         src_dev-&gt;tensorflow_gpu_device_info();
106:     CHECK(dev_info);
107:     src_dev_ctx = dev_info-&gt;default_context;
108:   }
109:   if (dst_dev_ctx == nullptr &amp;&amp; dst_device_type == DEVICE_GPU) {
110:     const DeviceBase::GpuDeviceInfo* dev_info =
111:         src_dev-&gt;tensorflow_gpu_device_info();
112:     CHECK(dev_info);
113:     dst_dev_ctx = dev_info-&gt;default_context;
114:   }
115:   if (non_cpu_src) CHECK(src_dev_ctx);
116:   if (non_cpu_dst) CHECK(dst_dev_ctx);
117:   if (non_cpu_src || non_cpu_dst) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/collective_rma_local.cc" line="113" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 112 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void CollectiveRemoteAccessLocal::MemCpyAsync ( DeviceContext * src_dev_ctx , DeviceContext * dst_dev_ctx , Device * src_dev , Device * dst_dev , const AllocatorAttributes &amp; src_attr , const AllocatorAttributes &amp; dst_attr , const Tensor * src , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst , int dev_to_dev_stream_index , const StatusCallback &amp; done )" content="103:   if (src_dev_ctx == nullptr &amp;&amp; src_device_type == DEVICE_GPU) {
104:     const DeviceBase::GpuDeviceInfo* dev_info =
105:         src_dev-&gt;tensorflow_gpu_device_info();
106:     CHECK(dev_info);
107:     src_dev_ctx = dev_info-&gt;default_context;
108:   }
109:   if (dst_dev_ctx == nullptr &amp;&amp; dst_device_type == DEVICE_GPU) {
110:     const DeviceBase::GpuDeviceInfo* dev_info =
111:         src_dev-&gt;tensorflow_gpu_device_info();
112:     CHECK(dev_info);
113:     dst_dev_ctx = dev_info-&gt;default_context;
114:   }
115:   if (non_cpu_src) CHECK(src_dev_ctx);
116:   if (non_cpu_dst) CHECK(dst_dev_ctx);
117:   if (non_cpu_src || non_cpu_dst) {
118:     CopyTensor::ViaDMA(&quot;&quot;,  // edge name (non-existent)
119:                        src_dev_ctx, dst_dev_ctx, src_dev, dst_dev, src_attr,
120:                        dst_attr, src, dst, dev_to_dev_stream_index, done);
121:   } else {
122:     int64 bytes = src-&gt;TotalBytes();
123:     DCHECK_EQ(dst-&gt;TotalBytes(), bytes);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/constant_folding.cc" line="364" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="void AddNodeToConstantGraph ( Node * n , std::unordered_map &lt; Node * , std::vector &lt; Node * &gt; &gt; * node_map , Graph * constant_graph )" content="354:     Graph* constant_graph) {
355:   std::vector&lt;Node*&gt;&amp; added = (*node_map)[n];
356:   added.push_back(constant_graph-&gt;CopyNode(n));
357:   for (const Edge* in_edge : n-&gt;in_edges()) {
358:     // Don&apos;t copy control edges to the constant graph.
359:     if (!in_edge-&gt;IsControlEdge()) {
360:       Node* in = in_edge-&gt;src();
361:       auto it = node_map-&gt;find(in);
362:       CHECK(it != node_map-&gt;end())
363:           &lt;&lt; n-&gt;DebugString() &lt;&lt; &quot; &lt;-&quot; &lt;&lt; in-&gt;DebugString();
364:       if (it-&gt;second.size() == 1) {
365:         constant_graph-&gt;AddEdge(it-&gt;second[0], in_edge-&gt;src_output(), added[0],
366:                                 in_edge-&gt;dst_input());
367:       } else {
368:         // The original source node had multiple outputs and was replaced by a
369:         // vector of constants, so the edge comes from the 0th output of the kth
370:         // added constant, rather than the kth output of the added node as in
371:         // the standard case above.
372:         constant_graph-&gt;AddEdge(it-&gt;second[in_edge-&gt;src_output()], 0, added[0],
373:                                 in_edge-&gt;dst_input());
374:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/constant_folding.cc" line="65" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [shape_map] to null at line 61 implies that [shape_map ] might be null.Dereferencing null pointer [shape_map]." web_identify="{&quot;identify&quot;:&quot;shape_map&quot;}" func_info="bool ReadPartialShapesFromShapeMap ( const Node * n , const std::unordered_map &lt; string , std::vector &lt; PartialTensorShape &gt; &gt; * shape_map , std::vector &lt; PartialTensorShape &gt; * input_shapes )" content="55: // in shape_map.
56: bool ReadPartialShapesFromShapeMap(
57:     const Node* n,
58:     const std::unordered_map&lt;string, std::vector&lt;PartialTensorShape&gt;&gt;*
59:         shape_map,
60:     std::vector&lt;PartialTensorShape&gt;* input_shapes) {
61:   CHECK(shape_map != nullptr);
62:   for (const Edge* in : n-&gt;in_edges()) {
63:     // Don&apos;t need to check if incoming control edges have known shapes.
64:     if (in-&gt;IsControlEdge()) continue;
65:     const auto known_shape_iter = shape_map-&gt;find(in-&gt;src()-&gt;name());
66:     if (known_shape_iter == shape_map-&gt;end()) {
67:       // One of n&apos;s inputs doesn&apos;t have known shapes, so don&apos;t replace n.
68:       return false;
69:     }
70:     const auto&amp; known_shape = known_shape_iter-&gt;second;
71:     CHECK_GT(known_shape.size(), in-&gt;src_output()) &lt;&lt; known_shape_iter-&gt;first;
72:     input_shapes-&gt;push_back(known_shape[in-&gt;src_output()]);
73:   }
74:   return true;
75: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/direct_session.cc" line="621" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [args.stats_collector] to null at line 605 implies that [args.stats_collector ] might be null.Dereferencing null pointer [args.stats_collector]." web_identify="{&quot;identify&quot;:&quot;args.stats_collector&quot;}" func_info="Status DirectSession::RunInternal ( long step_id , const RunOptions &amp; run_options , CallFrameInterface * call_frame , ExecutorsAndKeys * executors_and_keys , RunMetadata * run_metadata )" content="611:     // Build the cost model
612:     std::unordered_map&lt;string, const Graph*&gt; device_to_graph;
613:     for (const PerPartitionExecutorsAndLib&amp; partition :
614:          executors_and_keys-&gt;items) {
615:       const Graph* graph = partition.graph;
616:       const string device = partition.flib-&gt;device()-&gt;name();
617:       device_to_graph[device] = graph;
618:     }
619: 
620:     mutex_lock l(executor_lock_);
621:     args.stats_collector-&gt;BuildCostModel(&amp;cost_model_manager_, device_to_graph);
622: 
623:     // annotate stats onto cost graph.
624:     CostGraphDef* cost_graph = run_metadata-&gt;mutable_cost_graph();
625:     for (const auto&amp; item : executors_and_keys-&gt;items) {
626:       TF_RETURN_IF_ERROR(
627:           cost_model_manager_.AddToCostGraphDef(item.graph, cost_graph));
628:     }
629:   }
630: 
631:   // If requested via RunOptions, output the partition graphs.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/eager/tensor_handle.cc" line="116" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [remote_shape_] to null at line 115 implies that [remote_shape_ ] might be null.Dereferencing null pointer [remote_shape_]." web_identify="{&quot;identify&quot;:&quot;remote_shape_&quot;}" func_info="Status TensorHandle::NumDims ( int * num_dims )" content="106:   *tensor = &amp;tensor_;
107:   *device = device_;
108:   *op_device = op_device_;
109:   return Status::OK();
110: }
111: 
112: Status TensorHandle::NumDims(int* num_dims) {
113:   if (IsRemote()) {
114:     TF_RETURN_IF_ERROR(WaitForNode(remote_shape_node_id_, false));
115:     CHECK(remote_shape_ != nullptr);
116:     *num_dims = remote_shape_-&gt;dims();
117:   } else {
118:     TF_RETURN_IF_ERROR(WaitReady());
119:     DCHECK(IsReady());
120:     DCHECK(num_dims != nullptr);
121: 
122:     *num_dims = tensor_.dims();
123:   }
124: 
125:   return Status::OK();
126: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/executor.cc" line="1058" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FrameState::frame_id,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FrameState::frame_id,&quot;}" func_info="ExecutorState::FrameState" content="1048:                                     dead_result);
1049:     }
1050: 
1051:     ~IterationState() { delete[] input_tensors; }
1052: 
1053:    private:
1054:     PendingCounts counts_;
1055:   };
1056: 
1057:   struct FrameState {
1058:     explicit FrameState(const ExecutorImpl* impl, int parallel_iters)
1059:         : executor(impl),
1060:           max_parallel_iterations(parallel_iters),
1061:           num_outstanding_iterations(1) {}
1062: 
1063:     // A new frame is created for each loop. Execution starts at iteration 0.
1064:     // When a value at iteration 0 passes through a NextIteration node,
1065:     // iteration 1 is created and starts running. Note that iteration 0 may
1066:     // still be running so multiple iterations may run in parallel. The
1067:     // frame maintains the state of iterations in several data structures
1068:     // such as pending_count and input_tensors. When iteration 0 completes,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/executor.cc" line="2124" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [output_frame] suggests that it may be null, but it has already been dereferenced at line 2062." web_identify="{&quot;identify&quot;:&quot;output_frame&quot;}" func_info="void ExecutorState::PropagateOutputs ( const TaggedNode &amp; tagged_node , const NodeItem * item , gtl::InlinedVector &lt; Entry , 4 &gt; * outputs , gtl::InlinedVector &lt; TaggedNode , 8 &gt; * ready )" content="2114:         input_frame-&gt;next_iter_roots.push_back({node, (*outputs)[0]});
2115:         output_frame = nullptr;
2116:       } else {
2117:         // If this is a new iteration, start it.
2118:         if (input_iter == input_frame-&gt;iteration_count) {
2119:           input_frame-&gt;IncrementIteration(&amp;impl_-&gt;gview_, ready);
2120:         }
2121:         output_iter = input_iter + 1;
2122:       }
2123:     }
2124:     if (output_frame != nullptr) {
2125:       // This is the case when node is not Enter, Exit, or NextIteration.
2126:       DCHECK(input_frame == output_frame);
2127:       output_frame-&gt;ActivateNodes(item, is_dead, output_iter, outputs, ready);
2128:     }
2129:     is_frame_done = input_frame-&gt;DecrementOutstandingOpsLocked(
2130:         &amp;impl_-&gt;gview_, input_iter, ready);
2131:   }
2132: 
2133:   // At this point, this node is completely done. We also know if the
2134:   // completion of this node makes its frame completed.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/executor.cc" line="701" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [item.kernel] to null at line 700 implies that [item.kernel ] might be null.Dereferencing null pointer [item.kernel]." web_identify="{&quot;identify&quot;:&quot;item.kernel&quot;}" func_info="Status ExecutorImpl::Initialize ( )" content="691:     frame_info-&gt;total_inputs += n-&gt;num_inputs();
692: 
693:     Status s = params_.create_kernel(n-&gt;def(), &amp;item-&gt;kernel);
694:     if (!s.ok()) {
695:       item-&gt;kernel = nullptr;
696:       s = AttachDef(s, *n);
697:       LOG(ERROR) &lt;&lt; &quot;Executor failed to create kernel. &quot; &lt;&lt; s;
698:       return s;
699:     }
700:     CHECK(item-&gt;kernel);
701:     item-&gt;kernel_is_expensive = item-&gt;kernel-&gt;IsExpensive();
702:     item-&gt;kernel_is_async = (item-&gt;kernel-&gt;AsAsync() != nullptr);
703:     item-&gt;is_merge = IsMerge(n);
704:     item-&gt;is_enter = IsEnter(n);
705:     item-&gt;is_exit = IsExit(n);
706:     item-&gt;is_control_trigger = IsControlTrigger(n);
707:     item-&gt;is_sink = IsSink(n);
708:     item-&gt;is_enter_exit_or_next_iter =
709:         (IsEnter(n) || IsExit(n) || IsNextIteration(n));
710: 
711:     // Compute the maximum values we&apos;ll store for this node in the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/function.cc" line="965" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [out_flr] suggests that it may be null, but it has already been dereferenced at line 964." web_identify="{&quot;identify&quot;:&quot;out_flr&quot;}" func_info="Status FunctionLibraryRuntimeImpl::Clone ( std::unique_ptr &lt; FunctionLibraryDefinition &gt; * out_lib_def , std::unique_ptr &lt; ProcessFunctionLibraryRuntime &gt; * out_pflr , FunctionLibraryRuntime * * out_flr )" content="955: }
956: 
957: Status FunctionLibraryRuntimeImpl::Clone(
958:     std::unique_ptr&lt;FunctionLibraryDefinition&gt;* out_lib_def,
959:     std::unique_ptr&lt;ProcessFunctionLibraryRuntime&gt;* out_pflr,
960:     FunctionLibraryRuntime** out_flr) {
961:   TF_RETURN_IF_ERROR(
962:       parent_-&gt;Clone(env_, graph_def_version_, optimizer_.options(),
963:                      custom_kernel_creator_, out_lib_def, out_pflr));
964:   *out_flr = (*out_pflr)-&gt;GetFLR(device_-&gt;name());
965:   if (out_flr != nullptr) {
966:     return Status::OK();
967:   } else {
968:     return errors::Internal(&quot;Cloning FunctionLibraryRuntime failed.&quot;);
969:   }
970: }
971: 
972: namespace {
973: 
974: struct CustomCreatorSingleton {
975:   mutex mu;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_device.cc" line="263" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BaseGPUDevice::executor_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BaseGPUDevice::executor_,&quot;}" func_info="tensorflow" content="253:   mutex lock_;
254:   using key_type = std::tuple&lt;int, int&gt;;
255:   std::map&lt;key_type, StreamGroup&gt; streams_;
256: 
257:   // StreamGroupFactory cannot be created directly; Call
258:   // StreamGroupFactory::Global() to get the global instance.
259:   StreamGroupFactory() = default;
260:   TF_DISALLOW_COPY_AND_ASSIGN(StreamGroupFactory);
261: };
262: 
263: BaseGPUDevice::BaseGPUDevice(const SessionOptions&amp; options, const string&amp; name,
264:                              Bytes memory_limit, const DeviceLocality&amp; locality,
265:                              TfGpuId tf_gpu_id,
266:                              const string&amp; physical_device_desc,
267:                              Allocator* gpu_allocator, Allocator* cpu_allocator,
268:                              bool sync_every_op, int32 max_streams)
269:     : LocalDevice(options, Device::BuildDeviceAttributes(name, DEVICE_GPU,
270:                                                          memory_limit, locality,
271:                                                          physical_device_desc)),
272:       gpu_allocator_(gpu_allocator),
273:       cpu_allocator_(cpu_allocator),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_device.cc" line="89" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;EigenCudaStreamDevice::step_id_,stream_,device_prop_,allocator_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;EigenCudaStreamDevice::step_id_,stream_,device_prop_,allocator_,&quot;}" func_info="tensorflow::EigenCudaStreamDevice" content="79: // memory directly through the device allocator.  As an Open Source
80: // project, Eigen assumes allocator semantics similar to those of the
81: // CUDA memory allocator, and may not work correctly due to race
82: // conditions if used with some other allocator.  For safety, we need
83: // to delay deallocation calls out of Eigen until all events on the
84: // corresponding stream have completed.  The following two classes
85: // serve this purpose in two different compilation environments.
86: 
87: class EigenCudaStreamDevice : public ::Eigen::StreamInterface {
88:  public:
89:   EigenCudaStreamDevice()
90:       : scratch_(nullptr), semaphore_(nullptr), context_(nullptr) {
91:     Eigen::initializeDeviceProp();
92:   }
93:   ~EigenCudaStreamDevice() override {}
94:   void Reinitialize(OpKernelContext* context, const cudaStream_t* cuda_stream,
95:                     TfGpuId tf_gpu_id, ::tensorflow::Allocator* alloc,
96:                     char* scratch) {
97:     if (LogMemory::IsEnabled()) {
98:       operation_ = context-&gt;op_kernel().name() + &quot;/EigenAllocator&quot;;
99:       step_id_ = context-&gt;step_id();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_process_state.cc" line="163" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [process_state_] to null at line 161 implies that [process_state_ ] might be null.Dereferencing null pointer [process_state_]." web_identify="{&quot;identify&quot;:&quot;process_state_&quot;}" func_info="Allocator * GPUProcessState::GetCUDAHostAllocator ( int numa_node )" content="153:   return gpu_allocators_[tf_gpu_id.value()];
154: #else
155:   LOG(FATAL) &lt;&lt; &quot;GPUAllocator unavailable. Not compiled with --config=cuda.&quot;;
156:   return nullptr;
157: #endif  // GOOGLE_CUDA
158: }
159: 
160: Allocator* GPUProcessState::GetCUDAHostAllocator(int numa_node) {
161:   CHECK(process_state_);
162:   if (!HasGPUDevice() ||
163:       !process_state_-&gt;ProcessState::FLAGS_brain_mem_reg_cuda_dma) {
164:     return process_state_-&gt;GetCPUAllocator(numa_node);
165:   }
166:   CHECK_GE(numa_node, 0);
167:   {
168:     // Here we optimize the most common use case where cuda_host_allocators_
169:     // and cuda_al_ have already been populated and since we&apos;re only reading
170:     // these vectors, we can get by with a shared lock. In the slower case,
171:     // we take a unique lock and populate these vectors.
172:     tf_shared_lock lock(mu_);
173: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_stream_util.cc" line="52" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph] to null at line 36 implies that [graph ] might be null.Dereferencing null pointer [graph]." web_identify="{&quot;identify&quot;:&quot;graph&quot;}" func_info="Status gpu_stream_util::AssignStreams ( const Graph * graph , const AssignStreamsOpts &amp; opts , std :: unordered_map &lt; int , int &gt; * node_to_stream_id )" content="42:   if ((opts.max_streams &lt; 1) || (opts.send_stream &gt;= opts.max_streams) ||
43:       (opts.recv_stream &gt;= opts.max_streams) ||
44:       (opts.const_stream &gt;= opts.max_streams) ||
45:       (opts.compute_stream &gt;= opts.max_streams)) {
46:     status.Update(errors::InvalidArgument(&quot;Bad graph argument supplied.&quot;));
47:   }
48:   TF_RETURN_IF_ERROR(status);
49: 
50:   // Topologically sort the nodes.
51:   std::vector&lt;Node*&gt; order;
52:   GetReversePostOrder(*graph, &amp;order);
53:   if (VLOG_IS_ON(2)) {
54:     for (Node* n : order) {
55:       const int node_id = n-&gt;id();
56:       VLOG(2) &lt;&lt; &quot;Node &quot; &lt;&lt; node_id &lt;&lt; &quot; &quot; &lt;&lt; n-&gt;type_string() &lt;&lt; &quot; &quot;
57:               &lt;&lt; n-&gt;name() &lt;&lt; &quot; &quot; &lt;&lt; n-&gt;in_edges().size() &lt;&lt; &quot; inputs&quot;;
58:       for (const Edge* e : n-&gt;in_edges()) {
59:         VLOG(2) &lt;&lt; &quot;  Edge from &quot; &lt;&lt; e-&gt;src()-&gt;id() &lt;&lt; &quot;  &quot; &lt;&lt; e-&gt;src()-&gt;name()
60:                 &lt;&lt; &quot; fanout &quot; &lt;&lt; e-&gt;src()-&gt;out_edges().size();
61:       }
62:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_stream_util.cc" line="87" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [node_to_stream_id] to null at line 38 implies that [node_to_stream_id ] might be null.Dereferencing null pointer [node_to_stream_id]." web_identify="{&quot;identify&quot;:&quot;node_to_stream_id&quot;}" func_info="Status gpu_stream_util::AssignStreams ( const Graph * graph , const AssignStreamsOpts &amp; opts , std :: unordered_map &lt; int , int &gt; * node_to_stream_id )" content="77:   for (Node* n : order) {
78:     VLOG(3) &lt;&lt; &quot;Inspecting node &quot; &lt;&lt; n-&gt;DebugString();
79:     const int node_id = n-&gt;id();
80:     const string&amp; op = n-&gt;type_string();
81: 
82:     // Determine a suitable stream to use.
83:     int stream_id = highest_stream_id + 1;
84:     for (const Edge* e : n-&gt;in_edges()) {
85:       const size_t fanout = e-&gt;src()-&gt;out_edges().size();
86:       if (fanout == 1) {
87:         stream_id = (*node_to_stream_id)[e-&gt;src()-&gt;id()];
88:         break;
89:       }
90:     }
91:     // Override stream for specific op types.
92:     if (op == &quot;_Send&quot;) {
93:       if (opts.send_stream &gt;= 0) stream_id = opts.send_stream;
94:     } else if (op == &quot;_Recv&quot;) {
95:       if (opts.recv_stream &gt;= 0) stream_id = opts.recv_stream;
96:     } else if (op == &quot;Const&quot;) {
97:       if (opts.const_stream &gt;= 0) stream_id = opts.const_stream;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/gpu/gpu_util.cc" line="371" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor] to null at line 369 implies that [tensor ] might be null.Dereferencing null pointer [tensor]." web_identify="{&quot;identify&quot;:&quot;tensor&quot;}" func_info="string GPUUtil::MemoryDebugString ( const Device * device , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * tensor )" content="361:       !dev_info-&gt;stream-&gt;ok()) {
362:     return errors::Internal(&quot;GPU sync failed&quot;);
363:   }
364:   return Status::OK();
365: }
366: 
367: string GPUUtil::MemoryDebugString(const Device* device, Tensor* tensor) {
368:   string ret;
369:   CHECK(tensor);
370:   const int64 num_bytes = std::min&lt;int64&gt;(
371:       FLAGS_brain_gpu_util_debug_string_maxlen, tensor-&gt;TotalBytes());
372:   void* ptr = (num_bytes &gt; 0) ? GetBase(tensor) : nullptr;
373:   strings::Appendf(&amp;ret, &quot;%p:&quot;, ptr);
374:   if (num_bytes &gt; 0) {
375:     auto* dev_info = device-&gt;tensorflow_gpu_device_info();
376:     if (!dev_info) {
377:       strings::StrAppend(
378:           &amp;ret, PrintMemory(reinterpret_cast&lt;const char*&gt;(ptr), num_bytes));
379:     } else {
380:       string buf;
381:       buf.resize(num_bytes);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/graph_execution_state.cc" line="713" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rewrite_metadata_] to null at line 712 implies that [rewrite_metadata_ ] might be null.Dereferencing null pointer [rewrite_metadata_]." web_identify="{&quot;identify&quot;:&quot;rewrite_metadata_&quot;}" func_info="Status GraphExecutionState::BuildGraph ( const BuildGraphOptions &amp; options , std::unique_ptr &lt; ClientGraph &gt; * out )" content="703:   subgraph::RewriteGraphMetadata rewrite_metadata;
704:   if (session_options_ == nullptr ||
705:       !session_options_-&gt;config.graph_options().place_pruned_graph()) {
706:     TF_RETURN_IF_ERROR(
707:         PruneGraph(options, optimized_graph.get(), &amp;rewrite_metadata));
708:   } else {
709:     // This GraphExecutionState represents a graph that was
710:     // pruned when this was constructed, so we copy the metadata from
711:     // a member variable.
712:     CHECK(rewrite_metadata_);
713:     rewrite_metadata = *rewrite_metadata_;
714:   }
715: 
716:   CHECK_EQ(options.callable_options.feed_size(),
717:            rewrite_metadata.feed_types.size());
718:   CHECK_EQ(options.callable_options.fetch_size(),
719:            rewrite_metadata.fetch_types.size());
720: 
721:   // TODO(andydavis): Clarify optimization pass requirements around CostModel.
722:   GraphOptimizationPassOptions optimization_options;
723:   optimization_options.session_options = session_options_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/lower_if_op.cc" line="206" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fdef] to null at line 199 implies that [fdef ] might be null.Dereferencing null pointer [fdef]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;fdef&quot;}" func_info="Status InlineCallInGraph ( Node * n , Graph * g )" content="196: Status InlineCallInGraph(Node* n, Graph* g) {
197:   const auto&amp; lib = g-&gt;flib_def();
198:   const FunctionDef* fdef = lib.Find(n-&gt;type_string());
199:   CHECK(fdef != nullptr);
200:   FunctionBody* fbody;
201:   TF_RETURN_IF_ERROR(
202:       FunctionDefToBodyHelper(*fdef, n-&gt;attrs(), &amp;lib,
203:                               [&amp;lib](const string&amp; op, const OpDef** sig) {
204:                                 return lib.LookUpOpDef(op, sig);
205:                               },
206:                               &amp;fbody));
207:   // TODO(jpienaar): Improve this interface to make the need to delete it
208:   // explicit.
209:   InlineFunctionBody(g-&gt;flib_def(), g, n, fbody, false);
210:   delete fbody;
211:   return Status::OK();
212: }
213: 
214: Status CondBuilder::BuildLoweredIfOutput() {
215:   // Build the identity node output.
216:   NodeBuilder ib(name_, &quot;IdentityN&quot;);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/lower_if_op.cc" line="98" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CondBuilder::control_predecessor_,lowered_if_output_,pivot_f_,pivot_t_,then_call_node_,else_call_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CondBuilder::control_predecessor_,lowered_if_output_,pivot_f_,pivot_t_,then_call_node_,else_call_node_,&quot;}" func_info="tensorflow::" content="88:   Node* pivot_t_;
89:   Node* then_call_node_;
90:   Node* else_call_node_;
91:   Graph* graph_;
92:   string name_;
93: 
94:   NodeBuilder then_call_builder_;
95:   NodeBuilder else_call_builder_;
96: };
97: 
98: CondBuilder::CondBuilder(Node* if_op, const string&amp; then_fn_name,
99:                          const string&amp; else_fn_name, Graph* graph)
100:     : if_op_(if_op),
101:       graph_(graph),
102:       name_(if_op-&gt;name()),
103:       then_call_builder_(NewName(&quot;then&quot;), then_fn_name, graph-&gt;op_registry()),
104:       else_call_builder_(NewName(&quot;else&quot;), else_fn_name, graph-&gt;op_registry()) {
105:   TF_CHECK_OK(if_op_-&gt;input_node(0, &amp;pred_));
106: }
107: 
108: Status CondBuilder::CreatePivotNodes() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/placer_test.cc" line="231" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [search] may be invalid here." web_identify="{&quot;identify&quot;:&quot;search&quot;}" func_info="Node * PlacerTest::GetNodeByName ( const Graph &amp; graph , const string &amp; name )" content="221:   }
222: 
223:   Status Place(Graph* graph) { return Place(graph, &amp;devices_, nullptr); }
224: 
225:   // Returns the node in &quot;graph&quot; with the given name.
226:   //
227:   // REQUIRES: &quot;graph&quot; was produced by the most recent call to BuildGraph.
228:   Node* GetNodeByName(const Graph&amp; graph, const string&amp; name) {
229:     const auto search = nodes_by_name_.find(name);
230:     CHECK(search != nodes_by_name_.end()) &lt;&lt; &quot;Unknown node name: &quot; &lt;&lt; name;
231:     return graph.FindNodeId(search-&gt;second);
232:   }
233: 
234:  protected:
235:   std::vector&lt;std::unique_ptr&lt;Device&gt;&gt; local_devices_;
236:   DeviceSet devices_;
237:   Placer::NodeNameToIdMap nodes_by_name_;
238: 
239:   Status ReferenceTestHelper(const string&amp; variable_op_type,
240:                              const string&amp; assign_op_type,
241:                              const DeviceType&amp; expected_device_type);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/ring_reducer.cc" line="139" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_mgr_] to null at line 138 implies that [dev_mgr_ ] might be null.Dereferencing null pointer [dev_mgr_]." web_identify="{&quot;identify&quot;:&quot;dev_mgr_&quot;}" func_info="void RingReducer::Run ( StatusCallback done )" content="129:       strings::StrAppend(&amp;buf, &quot;\nsubdiv &quot;, sd, &quot; perm: &quot;);
130:       for (auto x : col_params_.instance.impl_details.subdiv_permutations[sd]) {
131:         strings::StrAppend(&amp;buf, x, &quot;, &quot;);
132:       }
133:     }
134:     VLOG(1) &lt;&lt; &quot;RingReducer::Run for device &quot; &lt;&lt; device_name_
135:             &lt;&lt; &quot; default_rank &quot; &lt;&lt; col_params_.default_rank &lt;&lt; &quot;\n&quot;
136:             &lt;&lt; buf;
137:   }
138:   CHECK(dev_mgr_);
139:   Status status = dev_mgr_-&gt;LookupDevice(
140:       col_params_.instance.device_names[col_params_.default_rank], &amp;device_);
141:   if (!status.ok()) {
142:     LOG(ERROR) &lt;&lt; &quot;Failed to find device &quot;
143:                &lt;&lt; col_params_.instance.device_names[col_params_.default_rank];
144:     for (auto d : dev_mgr_-&gt;ListDevices()) {
145:       LOG(ERROR) &lt;&lt; &quot;Available device &quot; &lt;&lt; d-&gt;name();
146:     }
147:     done_(status);
148:     return;
149:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/ring_reducer_test.cc" line="136" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RingReducerTest::col_exec_,rma_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RingReducerTest::col_exec_,rma_,&quot;}" func_info="RingReducerTest" content="126:                   .Input(FakeInput(dtype))
127:                   .Input(FakeInput(dtype))
128:                   .Finalize(&amp;node_def));
129:   return GetKernel(node_def, device_type, device);
130: }
131: 
132: static int64 kStepId = 123;
133: 
134: class RingReducerTest : public ::testing::Test {
135:  protected:
136:   RingReducerTest() : device_type_(DEVICE_CPU) {}
137: 
138:   void SetUp() override {
139: #if GOOGLE_CUDA
140:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
141:     CHECK(device_factory);
142:     SessionOptions options;
143:     Status s = device_factory-&gt;CreateDevices(
144:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
145:     CHECK(s.ok());
146: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/ring_reducer_test.cc" line="143" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [device_factory] to null at line 141 implies that [device_factory ] might be null.Dereferencing null pointer [device_factory]." web_identify="{&quot;identify&quot;:&quot;device_factory&quot;}" func_info="void RingReducerTest::SetUp ( )" content="133: 
134: class RingReducerTest : public ::testing::Test {
135:  protected:
136:   RingReducerTest() : device_type_(DEVICE_CPU) {}
137: 
138:   void SetUp() override {
139: #if GOOGLE_CUDA
140:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
141:     CHECK(device_factory);
142:     SessionOptions options;
143:     Status s = device_factory-&gt;CreateDevices(
144:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
145:     CHECK(s.ok());
146: #endif
147:   }
148: 
149:   ~RingReducerTest() override {
150:     stop_ = true;
151:     for (auto i : instances_) {
152:       delete i;
153:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/ring_reducer_test.cc" line="323" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 322 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void RingReducerTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int num_subdivs , int tensor_len , int fail_after )" content="313:         CHECK(inst);
314:         Tensor actual(dtype, TensorShape({tensor_len}));
315:         if (device_type_ == DEVICE_CPU) {
316:           CHECK(actual.CopyFrom(*inst, inst-&gt;shape()));
317:           VLOG(1) &lt;&lt; &quot;actual &quot; &lt;&lt; actual.SummarizeValue(100);
318:         } else if (device_type_ == DEVICE_GPU) {
319:           Notification note;
320:           Device* dev = instances_[di]-&gt;device_;
321:           auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
322:           CHECK(dev_info);
323:           dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
324:               inst, &quot;&quot; /*tensor_name*/, dev, &amp;actual, [&amp;note](const Status&amp; s) {
325:                 CHECK(s.ok());
326:                 note.Notify();
327:               });
328:           note.WaitForNotification();
329:         }
330: 
331:         for (int i = 0; i &lt; tensor_len; ++i) {
332:           switch (dtype) {
333:             case DT_FLOAT:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/ring_reducer_test.cc" line="430" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 428 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void DeviceInstance::InitTensor ( DataType dtype , const TensorShape &amp; shape , const std :: function &lt; void ( Tensor * ) &gt; &amp; init_f )" content="420:       tensor_ =
421:           Tensor(device_-&gt;GetAllocator(AllocatorAttributes()), dtype, shape);
422:       if (device_type_ == DEVICE_CPU) {
423:         init_f(&amp;tensor_);
424:       } else if (device_type_ == DEVICE_GPU) {
425:         Tensor cpu_tensor(dtype, shape);
426:         init_f(&amp;cpu_tensor);
427:         auto* dev_info = device_-&gt;tensorflow_gpu_device_info();
428:         CHECK(dev_info);
429:         Notification note;
430:         dev_info-&gt;default_context-&gt;CopyCPUTensorToDevice(
431:             &amp;cpu_tensor, device_, &amp;tensor_, [&amp;note](const Status&amp; s) {
432:               CHECK(s.ok());
433:               note.Notify();
434:             });
435:         note.WaitForNotification();
436:       } else {
437:         LOG(FATAL) &lt;&lt; &quot;Unsupported device_type &quot; &lt;&lt; device_type_;
438:       }
439:     }
440: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/common_runtime/scoped_allocator.cc" line="53" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [tbuf_] suggests that it may be null, but it has already been dereferenced at line 43." web_identify="{&quot;identify&quot;:&quot;tbuf_&quot;}" func_info="ScopedAllocator::~ tensorflow::ScopedAllocator ( )" content="43:           &lt;&lt; static_cast&lt;void*&gt;(tbuf_-&gt;data());
44:   // In the absence of incomplete graph execution situations
45:   // (interruption by error status or control flow branch crossing
46:   // ScopedAllocation region) we expect expected_call_count_ == 0 at
47:   // exit.
48:   if (VLOG_IS_ON(1)) {
49:     if (expected_call_count_ &gt; 0)
50:       VLOG(1) &lt;&lt; &quot;expected_call_count_ = &quot; &lt;&lt; expected_call_count_
51:               &lt;&lt; &quot; at deallocation&quot;;
52:   }
53:   if (tbuf_) tbuf_-&gt;Unref();
54: }
55: 
56: void* ScopedAllocator::AllocateRaw(int32 field_index, size_t num_bytes) {
57:   VLOG(1) &lt;&lt; &quot;ScopedAllocator index &quot; &lt;&lt; id_ &lt;&lt; &quot; AllocateRaw &quot;
58:           &lt;&lt; &quot;field &quot; &lt;&lt; field_index &lt;&lt; &quot; num_bytes &quot; &lt;&lt; num_bytes;
59:   mutex_lock l(mu_);
60:   if (expected_call_count_ &lt;= 0) {
61:     LOG(ERROR) &lt;&lt; &quot;Scoped allocator &quot; &lt;&lt; name_
62:                &lt;&lt; &quot; could not satisfy request for &quot; &lt;&lt; num_bytes
63:                &lt;&lt; &quot; bytes, expected uses exhausted. &quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/debug/debug_io_utils.cc" line="444" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [callback] to null at line 443 implies that [callback ] might be null.Dereferencing null pointer [callback]." web_identify="{&quot;identify&quot;:&quot;callback&quot;}" func_info="Status DebugIO::PublishDebugTensor ( const DebugNodeKey &amp; debug_node_key , const Tensor &amp; tensor , const long wall_time_us , const gtl::ArraySlice &lt; string &gt; &amp; debug_urls , const bool gated_grpc )" content="434:         fail_statuses.push_back(s);
435:       }
436: #else
437:       GRPC_OSS_WINDOWS_UNIMPLEMENTED_ERROR;
438: #endif
439:     } else if (str_util::Lowercase(url).find(kMemoryURLScheme) == 0) {
440:       const string dump_root_dir = url.substr(strlen(kMemoryURLScheme));
441:       auto* callback_registry = DebugCallbackRegistry::singleton();
442:       auto* callback = callback_registry-&gt;GetCallback(dump_root_dir);
443:       CHECK(callback) &lt;&lt; &quot;No callback registered for: &quot; &lt;&lt; dump_root_dir;
444:       (*callback)(debug_node_key, tensor);
445:     } else {
446:       return Status(error::UNAVAILABLE,
447:                     strings::StrCat(&quot;Invalid debug target URL: &quot;, url));
448:     }
449:   }
450: 
451:   if (num_failed_urls == 0) {
452:     return Status::OK();
453:   } else {
454:     string error_message = strings::StrCat(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/collective_param_resolver_distributed_test.cc" line="235" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cp_res] to null at line 234 implies that [cp_res ] might be null.Dereferencing null pointer [cp_res]." web_identify="{&quot;identify&quot;:&quot;cp_res&quot;}" func_info="void DeviceResDistTest::IssueRequest ( int num_workers , int num_devices , int idx )" content="225:     int di = idx % num_devices;
226:     string task_name = strings::StrCat(&quot;/job:worker/replica:0/task:&quot;, wi);
227:     string device_name = strings::StrCat(task_name, &quot;/device:CPU:&quot;, di);
228:     while (idx &gt;= cp_.size()) {
229:       status_.resize(idx + 1);
230:       cp_.resize(idx + 1);
231:     }
232:     CollectiveParams* cp = &amp;cp_[idx];
233:     CollectiveParamResolverDistributed* cp_res = cp_resolvers_[task_name];
234:     CHECK(cp_res);
235:     cp_res-&gt;CompleteParamsAsync(device_name, cp, &amp;cm_,
236:                                 [this, idx, device_count](const Status&amp; s) {
237:                                   status_[idx] = s;
238:                                   {
239:                                     mutex_lock l(mu_);
240:                                     ++num_done_;
241:                                     if (num_done_ == device_count) {
242:                                       done_.notify_all();
243:                                     }
244:                                   }
245:                                 });
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/collective_rma_distributed_test.cc" line="113" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [h] suggests that it may be null, but it has already been dereferenced at line 108." web_identify="{&quot;identify&quot;:&quot;h&quot;}" func_info="void FakeWorker::RecvBufAsync ( CallOptions * opts , const RecvBufRequest * request , RecvBufResponse * response , std :: function &lt; void ( const Status &amp; ) &gt; done )" content="103:             // Since this is not really RDMA into pre-allocated memory send the
104:             // bytes in the response.
105:             RecvBufRespExtra extra;
106:             int64 num_bytes = h-&gt;prod_value-&gt;TotalBytes();
107:             extra.set_tensor_content(string(
108:                 reinterpret_cast&lt;const char*&gt;(DMAHelper::base(h-&gt;prod_value)),
109:                 num_bytes));
110:             response-&gt;mutable_transport_options()-&gt;PackFrom(extra);
111:           }
112:           done(s);
113:           if (h) BufRendezvous::DoneWithHook(h);
114:         });
115:   }
116: 
117:  private:
118:   string name_;
119:   DeviceMgr* device_mgr_;
120:   DeviceResolverDistributed* device_resolver_;
121:   BufRendezvous buf_rendezvous_;
122: };
123: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/device_resolver_distributed.cc" line="102" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [worker] to null at line 101 implies that [worker ] might be null.Dereferencing null pointer [worker]." web_identify="{&quot;identify&quot;:&quot;worker&quot;}" func_info="void DeviceResolverDistributed::RefreshRemoteAttributes ( const string &amp; device , const string &amp; task , const std::function &lt; void ( const Status &amp; ) &gt; &amp; done )" content="92:     done(Status::OK());
93:   }
94: }
95: 
96: void DeviceResolverDistributed::RefreshRemoteAttributes(
97:     const string&amp; device, const string&amp; task, const StatusCallback&amp; done) {
98:   GetStatusRequest* req = new GetStatusRequest;
99:   GetStatusResponse* resp = new GetStatusResponse;
100:   WorkerInterface* worker = worker_cache_-&gt;CreateWorker(task);
101:   CHECK(worker) &lt;&lt; &quot;Failed to get worker for &quot; &lt;&lt; task;
102:   worker-&gt;GetStatusAsync(
103:       req, resp, [this, device, task, req, resp, worker, done](Status s) {
104:         if (s.ok()) {
105:           mutex_lock l(mu_);
106:           for (const DeviceAttributes&amp; da : resp-&gt;device_attributes()) {
107:             attr_table_[da.name()] = da;
108:           }
109:         }
110:         done(s);
111:         delete req;
112:         delete resp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/master.cc" line="173" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [worker_cache] to null at line 156 implies that [worker_cache ] might be null.Dereferencing null pointer [worker_cache]." web_identify="{&quot;identify&quot;:&quot;worker_cache&quot;}" func_info="explicit DeviceFinder::DeviceFinder ( const protobuf :: RepeatedPtrField &lt; string &gt; &amp; device_filters , MasterEnv * env , WorkerCacheInterface * worker_cache ) : env_ ( env ) , worker_cache_ ( worker_cache )" content="163:       }
164:     };
165:     for (const string&amp; filter : device_filters) {
166:       process_filter(filter);
167:     }
168:     // Enumerates all known workers&apos; target. A target name is a
169:     // prefix of a device name. E.g., /job:mnist/replica:0/task:10.
170:     CHECK_GT(env_-&gt;local_devices.size(), 0) &lt;&lt; &quot;No local devices provided.&quot;;
171:     const string&amp; local_device_name = env_-&gt;local_devices[0]-&gt;name();
172:     std::vector&lt;string&gt; workers;
173:     worker_cache-&gt;ListWorkers(&amp;workers);
174:     if (filters_.empty()) {
175:       std::swap(workers, targets_);
176:     } else {
177:       for (const string&amp; name : workers) {
178:         if (MatchFilters(name) ||
179:             DeviceNameUtils::IsSameAddressSpace(name, local_device_name)) {
180:           targets_.push_back(name);
181:         }
182:       }
183:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/master_session.cc" line="1384" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [execution_state_] to null at line 1382 implies that [execution_state_ ] might be null.Dereferencing null pointer [execution_state_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;execution_state_&quot;}" func_info="Status MasterSession::Extend ( const ExtendSessionRequest * req , ExtendSessionResponse * resp )" content="1374:     }
1375: 
1376:     if (graph_version_ != req-&gt;current_graph_version()) {
1377:       return errors::Aborted(&quot;Current version is &quot;, graph_version_,
1378:                              &quot; but caller expected &quot;,
1379:                              req-&gt;current_graph_version(), &quot;.&quot;);
1380:     }
1381: 
1382:     CHECK(execution_state_);
1383:     TF_RETURN_IF_ERROR(
1384:         execution_state_-&gt;Extend(req-&gt;graph_def(), &amp;extended_execution_state));
1385: 
1386:     CHECK(extended_execution_state);
1387:     // The old execution state will be released outside the lock.
1388:     execution_state_.swap(extended_execution_state);
1389:     ++graph_version_;
1390:     resp-&gt;set_new_graph_version(graph_version_);
1391:   }
1392:   return Status::OK();
1393: }
1394: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/master_session.cc" line="2017" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RunState::collective_graph_key,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RunState::collective_graph_key,&quot;}" func_info="tensorflow" content="2007: void MasterSession::GarbageCollect() {
2008:   {
2009:     mutex_lock l(mu_);
2010:     closed_ = true;
2011:     garbage_collected_ = true;
2012:   }
2013:   cancellation_manager_.StartCancel();
2014:   Unref();
2015: }
2016: 
2017: MasterSession::RunState::RunState(const std::vector&lt;string&gt;&amp; input_names,
2018:                                   const std::vector&lt;string&gt;&amp; output_names,
2019:                                   ReffedClientGraph* rcg, const uint64 step_id,
2020:                                   const int64 count)
2021:     : rcg(rcg), step_id(step_id), count(count) {
2022:   // Initially all the feeds and fetches are pending.
2023:   for (auto&amp; name : input_names) {
2024:     pending_inputs[name] = false;
2025:   }
2026:   for (auto&amp; name : output_names) {
2027:     pending_outputs[name] = false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/master_test.cc" line="117" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here. The error is in macros." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Status MasterTest::RunStep ( const string &amp; handle , const std :: vector &lt; std :: pair &lt; string , const Tensor * &gt; &gt; &amp; feed , const std :: map &lt; string , Tensor * &gt; &amp; fetch )" content="107:     for (const auto&amp; p : fetch) {
108:       const string&amp; fetch_name = p.first;
109:       req.add_fetch(fetch_name);
110:     }
111:     RunStepResponse resp;
112:     const Status s = FromGrpcStatus(master_-&gt;RunStep(&amp;ctx, req, &amp;resp));
113:     if (s.ok()) {
114:       for (const auto&amp; fetch_resp : resp.tensor()) {
115:         auto it = fetch.find(fetch_resp.name());
116:         CHECK(it != fetch.end());
117:         CHECK(it-&gt;second-&gt;FromProto(fetch_resp.tensor()));
118:       }
119:     }
120:     return s;
121:   }
122: 
123:   Status CloseSession(const string&amp; handle) {
124:     ::grpc::ClientContext ctx;
125:     CloseSessionRequest req;
126:     req.set_session_handle(handle);
127:     CloseSessionResponse resp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/rpc/grpc_channel.cc" line="181" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cache] to null at line 179 implies that [cache ] might be null.Dereferencing null pointer [cache]." web_identify="{&quot;identify&quot;:&quot;cache&quot;}" func_info="GRPC_CUSTOM_STRING MultiGrpcChannelCache::TranslateTask ( const string &amp; target )" content="171:         string r = c-&gt;TranslateTask(target);
172:         if (!r.empty()) {
173:           target_caches_.insert({target, c});
174:           cache = c;
175:           break;
176:         }
177:       }
178:     }
179:     CHECK(cache) &lt;&lt; &quot;Could not find GrpcChannelCache holding channel for &quot;
180:                  &lt;&lt; target;
181:     return cache-&gt;TranslateTask(target);
182:   }
183: 
184:  protected:
185:   SharedGrpcChannelPtr FindChannelOnce(const string&amp; target) override {
186:     for (GrpcChannelCache* cache : caches_) {
187:       SharedGrpcChannelPtr ch(cache-&gt;FindWorkerChannel(target));
188:       if (ch) {
189:         mutex_lock l(mu_);
190:         target_caches_.insert({target, cache});
191:         return ch;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/rpc/grpc_util.h" line="36" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GrpcByteSource::space_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GrpcByteSource::space_,&quot;}" func_info="tensorflow::GrpcByteSource" content="26: #include &quot;map/base/mlp/tf/tensorflow/core/lib/strings/stringprintf.h&quot;
27: #include &quot;map/base/mlp/tf/tensorflow/core/platform/mutex.h&quot;
28: #include &quot;map/base/mlp/tf/tensorflow/core/platform/protobuf.h&quot;
29: 
30: namespace tensorflow {
31: 
32: // Thin wrapper around ::grpc::ProtoBufferReader to give TensorResponse an
33: // efficient byte reader from which to decode a RecvTensorResponse.
34: class GrpcByteSource : public TensorResponse::Source {
35:  public:
36:   explicit GrpcByteSource(::grpc::ByteBuffer* buffer) : buffer_(buffer) {}
37:   ~GrpcByteSource() override { DeleteStream(); }
38: 
39:   typedef ::grpc::ProtoBufferReader Reader;
40: 
41:   protobuf::io::ZeroCopyInputStream* contents() override {
42:     DeleteStream();
43:     stream_ = new (&amp;space_) Reader(buffer_);
44:     return stream_;
45:   }
46: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc" line="191" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [callback_tag] to null at line 190 implies that [callback_tag ] might be null.Dereferencing null pointer [callback_tag]." web_identify="{&quot;identify&quot;:&quot;callback_tag&quot;}" func_info="void GrpcWorkerServiceThread::HandleRPCsLoop ( )" content="181:         ENQUEUE_REQUEST(GetStepSequence, true);
182:       }
183: 
184:       void* tag;
185:       bool ok;
186: 
187:       while (cq_-&gt;Next(&amp;tag, &amp;ok)) {
188:         UntypedCall&lt;GrpcWorkerServiceThread&gt;::Tag* callback_tag =
189:             static_cast&lt;UntypedCall&lt;GrpcWorkerServiceThread&gt;::Tag*&gt;(tag);
190:         CHECK(callback_tag);
191:         callback_tag-&gt;OnCompleted(this, ok);
192:       }
193:     }
194: 
195:    private:
196:     void Schedule(std::function&lt;void()&gt; f) {
197:       worker_-&gt;env()-&gt;compute_pool-&gt;Schedule(std::move(f));
198:     }
199: 
200:     // The following section contains one request handler method per
201:     // RPC. The `FooHandler` method is called (indirectly) by
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc" line="494" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [send_dev_context] to null at line 481 implies that [send_dev_context ] might be null.Dereferencing null pointer [send_dev_context]." web_identify="{&quot;identify&quot;:&quot;send_dev_context&quot;}" func_info="void GrpcWorker::GrpcRecvTensorAsync ( CallOptions * opts , const RecvTensorRequest * request ,::grpc::ByteBuffer * response , StatusCallback done )" content="484:               // &quot;val&quot; is on an accelerator device. Uses the device_context to
485:               // fill the copy on host.
486:               StatusCallback copy_ready = [response, done, copy,
487:                                            is_dead](const Status&amp; s) {
488:                 // The value is now ready to be returned on the wire.
489:                 grpc::EncodeTensorToByteBuffer(is_dead, *copy, response);
490:                 done(s);
491:                 delete copy;
492:               };
493: 
494:               send_dev_context-&gt;CopyDeviceTensorToCPU(
495:                   &amp;val, request-&gt;rendezvous_key(), src_dev, copy, copy_ready);
496:             } else {
497:               grpc::EncodeTensorToByteBuffer(is_dead, val, response);
498:               done(Status::OK());
499:             }
500:           }
501:         } else {
502:           //  !s.ok()
503:           done(status);
504:         }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/tensor_coding_test.cc" line="51" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;StringSource::space_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;StringSource::space_,&quot;}" func_info="tensorflow::StringSource" content="41:   Allocator* GetAllocator(AllocatorAttributes attr) override {
42:     return cpu_allocator();
43:   }
44: 
45:  private:
46:   DeviceAttributes attr_;
47: };
48: 
49: class StringSource : public TensorResponse::Source {
50:  public:
51:   explicit StringSource(const string* s, int block_size)
52:       : s_(s), stream_(nullptr), block_size_(block_size) {}
53:   ~StringSource() override { DeleteStream(); }
54: 
55:   protobuf::io::ZeroCopyInputStream* contents() override {
56:     DeleteStream();
57:     stream_ = new (&amp;space_)
58:         protobuf::io::ArrayInputStream(s_-&gt;data(), s_-&gt;size(), block_size_);
59:     return stream_;
60:   }
61: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/distributed_runtime/worker_cache_partial.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rwi] to null at line 70 implies that [rwi ] might be null.Dereferencing null pointer [rwi]." web_identify="{&quot;identify&quot;:&quot;rwi&quot;}" func_info="Status WorkerCachePartial::RefreshDeviceStatus ( const string &amp; device_name )" content="67:   };
68:   std::unique_ptr&lt;WorkerInterface, decltype(deleter)&gt; rwi(CreateWorker(task),
69:                                                           deleter);
70:   if (s.ok() &amp;&amp; !rwi) {
71:     s = errors::Internal(&quot;RefreshDeviceStatus, unknown worker task: &quot;, task);
72:   }
73: 
74:   if (s.ok()) {
75:     GetStatusRequest req;
76:     GetStatusResponse resp;
77:     s = rwi-&gt;GetStatus(&amp;req, &amp;resp);
78:     if (s.ok()) {
79:       mutex_lock lock(mu_);
80:       for (auto&amp; dev_attr : resp.device_attributes()) {
81:         device_status_cache_[dev_attr.name()] = dev_attr;
82:       }
83:     }
84:   }
85:   return s;
86: }
87: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/graph/gradients.cc" line="277" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="NodeOut SymbolicGradientBuilder::SumGradients ( const NodeOut &amp; src )" content="267:       }
268:     }
269:   }
270:   CHECK(!ready_.empty());
271: }
272: 
273: NodeOut SymbolicGradientBuilder::SumGradients(const NodeOut&amp; src) {
274:   const DataType dtype = src.dtype();
275:   auto iter = backprops_.find(src);
276:   CHECK(iter != backprops_.end());
277:   const auto&amp; grads = iter-&gt;second;
278:   if (grads.empty()) {
279:     // Nothing propagated back. The best we can come up is zeros.
280:     Node* zero_like = AddZerosLike(graph_, src);
281:     return {zero_like, 0};
282:   }
283:   if (grads.size() == 1) {
284:     // Just one backprop edge.
285:     return grads[0];
286:   }
287:   // Otherwise, adds backprop-ed gradients.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/graph/graph_constructor.cc" line="69" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Options::uniquify_names,uniquify_prefix,skip_mapped_nodes,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Options::uniquify_names,uniquify_prefix,skip_mapped_nodes,&quot;}" func_info="GraphConstructor::Options" content="59:       .One(allow_internal_ops ? Scanner::LETTER_DIGIT_DOT_UNDERSCORE
60:                               : Scanner::LETTER_DIGIT_DOT)
61:       .Any(Scanner::LETTER_DIGIT_DASH_DOT_SLASH_UNDERSCORE)
62:       .Eos()
63:       .GetResult();
64: }
65: 
66: class GraphConstructor {
67:  public:
68:   struct Options {
69:     Options(const GraphConstructorOptions&amp; in)  // NOLINT(runtime/explicit)
70:         : allow_internal_ops(in.allow_internal_ops),
71:           expect_device_spec(in.expect_device_spec),
72:           importing(false),
73:           validate_colocation_constraints(false) {}
74:     Options(const ImportGraphDefOptions&amp; in)  // NOLINT(runtime/explicit)
75:         : allow_internal_ops(false),
76:           expect_device_spec(false),
77:           prefix(in.prefix.empty() || str_util::EndsWith(in.prefix, &quot;/&quot;)
78:                      ? in.prefix
79:                      : in.prefix + &quot;/&quot;),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/graph/mkl_layout_pass.cc" line="4471" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options.partition_graphs] to null at line 4452 implies that [options.partition_graphs ] might be null.Dereferencing null pointer [options.partition_graphs]." web_identify="{&quot;identify&quot;:&quot;options.partition_graphs&quot;}" func_info="Status MklLayoutRewritePass::Run ( const GraphOptimizationPassOptions &amp; options )" content="4461:     g-&gt;reset(ng-&gt;release());
4462:   };
4463: 
4464:   if (kMklLayoutRewritePassGroup !=
4465:       OptimizationPassRegistry::POST_PARTITIONING) {
4466:     // For any pre-partitioning phase, a graph is stored in options.graph.
4467:     process_graph(options.graph);
4468:   } else {
4469:     // For post partitioning phase, graphs are stored in
4470:     // options.partition_graphs.
4471:     for (auto&amp; pg : *options.partition_graphs) {
4472:       process_graph(&amp;pg.second);
4473:     }
4474:   }
4475: 
4476:   return Status::OK();
4477: }
4478: #endif  // INTEL_MKL_ML
4479: }  // namespace tensorflow
4480: 
4481: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/graph/mkl_tfconversion_pass.cc" line="433" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options.partition_graphs] to null at line 415 implies that [options.partition_graphs ] might be null.Dereferencing null pointer [options.partition_graphs]." web_identify="{&quot;identify&quot;:&quot;options.partition_graphs&quot;}" func_info="Status MklToTfConversionPass::Run ( const GraphOptimizationPassOptions &amp; options )" content="423:     // Return the ownership of graph back
424:     g-&gt;reset(ng-&gt;release());
425:   };
426: 
427:   if (kMklTfConvPassGroup != OptimizationPassRegistry::POST_PARTITIONING) {
428:     // For any pre-partitioning phase, graph is stored in options.graph.
429:     process_graph(options.graph);
430:   } else {
431:     // For post partitioning phase, graphs are stored in
432:     // options.partition_graphs.
433:     for (auto&amp; pg : *options.partition_graphs) {
434:       process_graph(&amp;pg.second);
435:     }
436:   }
437: 
438:   return Status::OK();
439: }
440: 
441: }  // namespace tensorflow
442: 
443: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/costs/virtual_placer.cc" line="33" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cluster] to null at line 27 implies that [cluster ] might be null.Dereferencing null pointer [cluster]." web_identify="{&quot;identify&quot;:&quot;cluster&quot;}" func_info="VirtualPlacer::VirtualPlacer ( const Cluster * cluster )" content="23: namespace tensorflow {
24: namespace grappler {
25: 
26: VirtualPlacer::VirtualPlacer(const Cluster* cluster) {
27:   CHECK(cluster);
28: 
29:   // Default job name for canonical device name. Needs to be set before the
30:   // first call to to_lfqn_or_empty()
31:   default_job_name_lowercase_ = &quot;localhost&quot;;
32: 
33:   devices_ = cluster-&gt;GetDevices();
34:   lfqn_map_.reserve(devices_.size());
35:   for (const auto&amp; kv : devices_) {
36:     const auto lfqn = to_lfqn_or_empty(kv.first);
37:     if (lfqn.empty()) {
38:       LOG(ERROR) &lt;&lt; &quot;VirtualPlacer couldn&apos;t parse device name from cluster: &quot;
39:                  &lt;&lt; kv.first;
40:     } else {
41:       lfqn_map_[lfqn] = kv.first;
42:     }
43:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="119" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FirstReadyManager::node_state_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FirstReadyManager::node_state_,&quot;}" func_info="tensorflow::grappler" content="109: void LIFOManager::RemoveCurrNode() {
110:   // Make sure we have curr_pos_ ready to be removed.
111:   GetCurrNode();
112:   // Note curr_pos_ may not be pointing the last element if some nodes are
113:   // added.
114:   nodes_.erase(curr_pos_);
115: 
116:   curr_pos_ = nodes_.end();  // Reset curr_pos_.
117: }
118: 
119: FirstReadyManager::FirstReadyManager() : ReadyNodeManager() {
120:   std::make_heap(nodes_.begin(), nodes_.end());
121: }
122: 
123: void FirstReadyManager::Init(
124:     const std::unordered_map&lt;const NodeDef*, NodeState&gt;* node_state) {
125:   // Reset the node state since different instances of the scheduler can reuse
126:   // the same node_manager.
127:   node_state_ = node_state;
128:   nodes_.clear();
129:   waiting_queue_.clear();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="176" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CompositeNodeManager::node_state_,curr_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CompositeNodeManager::node_state_,curr_node_,&quot;}" func_info="tensorflow::grappler" content="166: void FirstReadyManager::DrainWaitingQueue() {
167:   for (const auto* node : waiting_queue_) {
168:     // push_heap in AddNode() and pop_heap in RemoveCurrNode() guarantees that
169:     // the first element is the node with minimum time_ready.
170:     nodes_.push_back(node);
171:     std::push_heap(nodes_.begin(), nodes_.end(), greater_);
172:   }
173:   waiting_queue_.clear();
174: }
175: 
176: CompositeNodeManager::CompositeNodeManager()
177:     : ReadyNodeManager(), send_manager_(), recv_manager_() {}
178: 
179: void CompositeNodeManager::Init(
180:     const std::unordered_map&lt;const NodeDef*, NodeState&gt;* node_state) {
181:   node_state_ = node_state;
182:   send_manager_.Init(node_state);
183:   recv_manager_.Init(node_state);
184:   curr_node_ = nullptr;
185: }
186: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="393" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_node] to null at line 392 implies that [input_node ] might be null.Dereferencing null pointer [input_node]." web_identify="{&quot;identify&quot;:&quot;input_node&quot;}" func_info="Status VirtualScheduler::Init ( )" content="383:         inputs.push_back(input);
384:       }
385:     }
386:     for (const string&amp; input_node_name : inputs) {
387:       // Note that input_node_name may be in &lt;prefix&gt;&lt;node_name&gt;:&lt;port_num&gt;
388:       // format, where &lt;prefix&gt; (e.g., &quot;^&quot; for control dependency) and
389:       // &quot;:&lt;port_num&gt;&quot; may be omitted. NodeName() extracts only the node_name.
390:       const NodeDef* input_node = name_to_node[NodeName(input_node_name)];
391: 
392:       CHECK(input_node);
393:       const string in_device = DeviceName(input_node);
394:       const auto input_node_port_num = NodePosition(input_node_name);
395: 
396:       if (curr_node_device == in_device) {
397:         // Same device: connect input_node and curr_node directly.
398:         curr_node_state.inputs.push_back(
399:             std::make_pair(input_node, input_node_port_num));
400:         auto&amp; input_node_state = GetNodeStateOrCreateIt(input_node);
401:         input_node_state.outputs[input_node_port_num].push_back(curr_node);
402:       } else {
403:         RecvNodeDescriptor recv_node(input_node, input_node_port_num,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/grappler_item_builder.cc" line="496" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="std::unique_ptr &lt; GrapplerItem &gt; grappler::GrapplerItemFromMetaGraphDef ( const string &amp; id , const MetaGraphDef &amp; meta_graph , const ItemConfig &amp; cfg )" content="486:         if (signature_feed_nodes.count(node.name()) == 0) {
487:           new_item-&gt;feed.emplace_back(node.name(), fake_input);
488:         }
489:       } else if (cfg.feed_nodes.count(node.name()) &gt; 0) {
490:         // If specific feed nodes were given, only update their tensors.
491:         auto it = find_if(new_item-&gt;feed.begin(), new_item-&gt;feed.end(),
492:                           [&amp;node](std::pair&lt;string, Tensor&gt;&amp; f) {
493:                             return f.first == node.name();
494:                           });
495:         QCHECK(it != new_item-&gt;feed.end());
496:         it-&gt;second = fake_input;
497:       }
498: 
499:       // Set the shape of the node in the graph. This is needed for statically
500:       // inferring shapes and is a no-op when dynamically inferring shapes as
501:       // the Placeholder shape will match the shape passed from new_item-&gt;feed.
502:       *(node.mutable_attr()-&gt;at(&quot;shape&quot;).mutable_shape()) = shape_proto;
503:     } else if (IsConstant(node)) {
504:       auto it = asset_node_to_value.find(node.name());
505:       if (it != asset_node_to_value.end()) {
506:         auto iter = node.mutable_attr()-&gt;find(&quot;value&quot;);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/arithmetic_optimizer.cc" line="834" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [shapes_match] suggests that it may be null, but it has already been dereferenced at line 831." web_identify="{&quot;identify&quot;:&quot;shapes_match&quot;}" func_info="Status HoistCommonFactorOutOfAggregation::GetUniqueFactors ( const NodeDef * node , const string &amp; common_factor , const bool common_factor_is_denominator , bool * shapes_match , std :: vector &lt; string &gt; * unique_factors ) const" content="824:   // Unless the aggregation is Add, we have to make sure that all the y&apos;s
825:   // have the same shape since the other aggregation ops do not support
826:   // broadcasting.
827:   Status GetUniqueFactors(const NodeDef* node, const string&amp; common_factor,
828:                           const bool common_factor_is_denominator,
829:                           bool* shapes_match,
830:                           std::vector&lt;string&gt;* unique_factors) const {
831:     *shapes_match = true;
832:     unique_factors-&gt;reserve(node-&gt;input_size());
833: 
834:     for (int i = 0; i &lt; node-&gt;input_size() &amp;&amp; shapes_match; ++i) {
835:       const string&amp; input = node-&gt;input(i);
836:       if (IsControlInput(input)) {
837:         break;
838:       }
839:       NodeDef* inner_node;
840:       TF_RETURN_IF_ERROR(GetInputNode(input, &amp;inner_node));
841:       const int unique_factor_index =
842:           common_factor_is_denominator
843:               ? 0
844:               : (inner_node-&gt;input(0) == common_factor ? 1 : 0);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/auto_parallel.cc" line="179" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dequeue_node] to null at line 162 implies that [dequeue_node ] might be null.Dereferencing null pointer [dequeue_node]." web_identify="{&quot;identify&quot;:&quot;dequeue_node&quot;}" func_info="Status AutoParallel::Initialize ( const GrapplerItem &amp; item )" content="169:   for (const auto&amp; variable : item.MainVariables()) {
170:     dont_replicate_nodes.insert(variable-&gt;name());
171:   }
172: 
173:   for (const auto&amp; init : item.init_ops) {
174:     dont_replicate_nodes.insert(NodeName(init));
175:   }
176: 
177:   // Don&apos;t replicate all input nodes, except the dequeue node.
178:   for (const auto&amp; input_node : input_nodes) {
179:     if (input_node-&gt;name() != dequeue_node-&gt;name()) {
180:       dont_replicate_nodes.insert(input_node-&gt;name());
181:     }
182:   }
183: 
184:   for (const auto&amp; node : train_nodes) {
185:     if (dont_replicate_nodes.find(node-&gt;name()) == dont_replicate_nodes.end()) {
186:       replica_nodes_.insert(node-&gt;name());
187:     }
188:   }
189:   LOG(INFO) &lt;&lt; &quot;Number of replica nodes: &quot; &lt;&lt; replica_nodes_.size();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/auto_parallel.h" line="29" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AutoParallel::item_,num_gpus_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AutoParallel::item_,num_gpus_,&quot;}" func_info="tensorflow::grappler::AutoParallel" content="19: #include &quot;map/base/mlp/tf/tensorflow/core/framework/variable.pb.h&quot;
20: #include &quot;map/base/mlp/tf/tensorflow/core/grappler/optimizers/graph_optimizer.h&quot;
21: #include &quot;map/base/mlp/tf/tensorflow/core/lib/core/status.h&quot;
22: 
23: namespace tensorflow {
24: namespace grappler {
25: 
26: // Automatically parallelize a graph by splitting in the batch dimension.
27: class AutoParallel : public GraphOptimizer {
28:  public:
29:   AutoParallel(int num_replicas) : num_replicas_(num_replicas) {
30:     CHECK(num_replicas_ &gt;= 2);
31:   }
32:   ~AutoParallel() override {}
33: 
34:   string name() const override { return &quot;autoparallel&quot;; };
35: 
36:   Status Optimize(Cluster* cluster, const GrapplerItem&amp; item,
37:                   GraphDef* output) override;
38: 
39:   void Feedback(Cluster* cluster, const GrapplerItem&amp; item,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/constant_folding.cc" line="178" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&quot;}" func_info="tensorflow::grappler" content="168:     }
169:   }
170:   if (update_node_map) {
171:     node_map-&gt;RemoveOutput(NodeName(old_input), node-&gt;name());
172:   }
173:   return removed_input;
174: }
175: 
176: }  // namespace
177: 
178: ConstantFolding::ConstantFolding(RewriterConfig::Toggle opt_level,
179:                                  DeviceBase* cpu_device)
180:     : opt_level_(opt_level), cpu_device_(cpu_device) {
181:   resource_mgr_.reset(new ResourceMgr());
182: }
183: 
184: ConstantFolding::ConstantFolding(DeviceBase* cpu_device)
185:     : ConstantFolding(RewriterConfig::ON, cpu_device) {}
186: 
187: // static
188: string ConstantFolding::AddControlDependency(const string&amp; input_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/constant_folding.cc" line="184" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&quot;}" func_info="tensorflow::grappler" content="174: }
175: 
176: }  // namespace
177: 
178: ConstantFolding::ConstantFolding(RewriterConfig::Toggle opt_level,
179:                                  DeviceBase* cpu_device)
180:     : opt_level_(opt_level), cpu_device_(cpu_device) {
181:   resource_mgr_.reset(new ResourceMgr());
182: }
183: 
184: ConstantFolding::ConstantFolding(DeviceBase* cpu_device)
185:     : ConstantFolding(RewriterConfig::ON, cpu_device) {}
186: 
187: // static
188: string ConstantFolding::AddControlDependency(const string&amp; input_name,
189:                                              GraphDef* graph,
190:                                              NodeMap* node_map) {
191:   if (IsControlInput(input_name)) {
192:     return input_name;
193:   }
194:   const NodeDef* node = node_map-&gt;GetNode(input_name);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/constant_folding.cc" line="2495" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [denom] to null at line 2494 implies that [denom ] might be null.Dereferencing null pointer [denom]." web_identify="{&quot;identify&quot;:&quot;denom&quot;}" func_info="bool ConstantFolding::ReduceDivToReciprocalMul ( GraphDef * optimized_graph , NodeDef * node )" content="2485: 
2486: bool ConstantFolding::ReduceDivToReciprocalMul(GraphDef* optimized_graph,
2487:                                                NodeDef* node) {
2488:   // Strength reduce floating point division by a constant Div(x, const) to
2489:   // multiplication by the reciprocal Mul(x, Reciprocal(const)). This in turn
2490:   // will be constant folded to Mul(x, 1.0/const).
2491:   if (node-&gt;input_size() &gt;= 2 &amp;&amp; (IsRealDiv(*node) || IsDiv(*node))) {
2492:     const string&amp; const_input = node-&gt;input(1);
2493:     const NodeDef* denom = node_map_-&gt;GetNode(const_input);
2494:     CHECK(denom != nullptr);
2495:     if (!IsReallyConstant(*denom)) {
2496:       return false;
2497:     }
2498:     if (node-&gt;attr().count(&quot;T&quot;) == 0) {
2499:       return false;
2500:     }
2501:     DataType type = node-&gt;attr().at(&quot;T&quot;).type();
2502:     if (IsDiv(*node) &amp;&amp;
2503:         !(DataTypeIsFloating(type) || DataTypeIsComplex(type))) {
2504:       return false;
2505:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/constant_folding.cc" line="2809" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_node] to null at line 2808 implies that [input_node ] might be null.Dereferencing null pointer [input_node]." web_identify="{&quot;identify&quot;:&quot;input_node&quot;}" func_info="bool ConstantFolding::PartialAssocOpConstFolding ( GraphDef * optimized_graph , GraphProperties * properties , NodeDef * node )" content="2799:   const int num_non_control_inputs = NumNonControlInputs(*node);
2800:   if (IsAggregate(*node) &amp;&amp; IsCommutative(*node) &amp;&amp;
2801:       num_non_control_inputs &gt; 2) {
2802:     const int num_control_inputs = node-&gt;input_size() - num_non_control_inputs;
2803:     std::vector&lt;int&gt; const_inputs;
2804:     std::vector&lt;int&gt; nonconst_inputs;
2805:     for (int i = 0; i &lt; node-&gt;input_size(); ++i) {
2806:       const string&amp; input = node-&gt;input(i);
2807:       const NodeDef* input_node = node_map_-&gt;GetNode(NodeName(input));
2808:       CHECK(input_node != nullptr) &lt;&lt; input;
2809:       if (!IsControlInput(input) &amp;&amp; IsReallyConstant(*input_node)) {
2810:         const_inputs.push_back(i);
2811:       } else {
2812:         // Non-const and control inputs.
2813:         nonconst_inputs.push_back(i);
2814:       }
2815:     }
2816:     // Promote AccumulateNV2 with all constant inputs to AddN, since it is
2817:     // a fake node that cannot be constant folded by itself.
2818:     if (const_inputs.size() == num_non_control_inputs &amp;&amp;
2819:         node-&gt;op() == &quot;AccumulateNV2&quot;) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/dependency_optimizer.cc" line="85" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input] to null at line 81 implies that [input ] might be null.Dereferencing null pointer [input]." web_identify="{&quot;identify&quot;:&quot;input&quot;}" func_info="bool DependencyOptimizer::SafeToRemoveIdentity ( const NodeDef &amp; node ) const" content="75:   }
76:   if (!fetch_nodes_known_) {
77:     // The output values of this node may be needed.
78:     return false;
79:   }
80:   const NodeDef* input = node_map_-&gt;GetNode(NodeName(node.input(0)));
81:   CHECK(input != nullptr) &lt;&lt; &quot;node = &quot; &lt;&lt; node.name()
82:                           &lt;&lt; &quot; input = &quot; &lt;&lt; node.input(0);
83:   // Don&apos;t remove Identity nodes corresponding to Variable reads or following
84:   // Recv.
85:   if (IsVariable(*input) || IsRecv(*input)) {
86:     return false;
87:   } else if (IsSwitch(*input)) {
88:     // Don&apos;t turn Identity nodes following Switch into NoOp or remove them
89:     // if it requires anchoring a control dependencies the Switch node, which
90:     // is not valid.
91:     if (str_util::StartsWith(node.name(), kConstantFoldingCtrl)) {
92:       // TODO(rmlarsen): Try to remove this artificial contraint.
93:       return false;
94:     }
95:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/dependency_optimizer.h" line="33" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DependencyOptimizer::fetch_nodes_known_,optimized_graph_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DependencyOptimizer::fetch_nodes_known_,optimized_graph_,&quot;}" func_info="tensorflow::grappler::DependencyOptimizer" content="23: 
24: namespace tensorflow {
25: namespace grappler {
26: 
27: // Optimize TF computations by removing control dependencies or re-arranging
28: // them to shorten the critical path for a model step or enable other
29: // optimizations, such as removing nodes that are effectively noops.
30: class DependencyOptimizer : public GraphOptimizer {
31:  public:
32:   DependencyOptimizer() {}
33:   explicit DependencyOptimizer(RewriterConfig::Toggle opt_level)
34:       : opt_level_(opt_level) {}
35:   ~DependencyOptimizer() override {}
36: 
37:   string name() const override { return &quot;dependency_optimizer&quot;; };
38: 
39:   Status Optimize(Cluster* cluster, const GrapplerItem&amp; item,
40:                   GraphDef* optimized_graph) override;
41: 
42:   void Feedback(Cluster* cluster, const GrapplerItem&amp; item,
43:                 const GraphDef&amp; optimized_graph, double result) override;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [node_to_copy] to null at line 73 implies that [node_to_copy ] might be null.Dereferencing null pointer [node_to_copy]." web_identify="{&quot;identify&quot;:&quot;node_to_copy&quot;}" func_info="NodeDef * grappler::AddCopyNode ( const GraphOptimizerContext &amp; ctx , const string &amp; name , const NodeDef * node_to_copy )" content="67:   properties-&gt;CopyFrom(output_properties[port]);
68:   return Status::OK();
69: }
70: 
71: NodeDef* AddCopyNode(const GraphOptimizerContext&amp; ctx, const string&amp; name,
72:                      const NodeDef* node_to_copy) {
73:   CHECK(node_to_copy != nullptr);
74:   CHECK(!ctx.node_map-&gt;NodeExists(name))
75:       &lt;&lt; &quot;Node &quot; &lt;&lt; name &lt;&lt; &quot; already exists in a graph&quot;;
76:   NodeDef* new_node = ctx.optimized_graph-&gt;add_node();
77:   *new_node = *node_to_copy;
78:   new_node-&gt;set_name(name);
79:   ctx.node_map-&gt;AddNode(name, new_node);
80:   return new_node;
81: }
82: 
83: NodeDef* AddEmptyNode(const GraphOptimizerContext&amp; ctx, const string&amp; name) {
84:   CHECK(!ctx.node_map-&gt;NodeExists(name))
85:       &lt;&lt; &quot;Node &quot; &lt;&lt; name &lt;&lt; &quot; already exists in a graph&quot;;
86:   NodeDef* new_node = ctx.optimized_graph-&gt;add_node();
87:   new_node-&gt;set_name(name);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/loop_optimizer.cc" line="50" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopInvariantNodeMotionOptimizer::new_enter_id_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopInvariantNodeMotionOptimizer::new_enter_id_,&quot;}" func_info="LoopInvariantNodeMotionOptimizer" content="40: #include &quot;tensorflow/core/util/saved_tensor_slice_util.h&quot;
41: 
42: using tensorflow::strings::StrCat;
43: 
44: namespace tensorflow {
45: namespace grappler {
46: namespace {
47: 
48: class LoopInvariantNodeMotionOptimizer {
49:  public:
50:   explicit LoopInvariantNodeMotionOptimizer(GraphDef* optimized_graph)
51:       : optimized_graph_(optimized_graph) {}
52:   virtual ~LoopInvariantNodeMotionOptimizer() = default;
53:   Status Optimize();
54: 
55:  private:
56:   Status FindInvariantNodes(NodeDef* node);
57:   Status RevertInvariantNodes();
58:   Status MoveInvariantNodes(const int frame_id);
59:   Status HandleInvariantNode(NodeDef* node, const int num_outputs,
60:                              const int frame_id);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/memory_optimizer.cc" line="256" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [child_component_iterator] may be invalid here." web_identify="{&quot;identify&quot;:&quot;child_component_iterator&quot;}" func_info="std::unordered_map &lt; const NodeDef * , int &gt; grappler::GetMaxDownstreamComponents ( const std :: unordered_set &lt; const NodeDef * &gt; &amp; recomputed_source_nodes , const std :: unordered_set &lt; NodeDef * &gt; &amp; target_nodes , const NodeMap &amp; node_map , const std :: unordered_map &lt; const NodeDef * , int &gt; &amp; components )" content="246:     } else {
247:       max_component = -1;
248:     }
249:     for (NodeDef* output :
250:          node_map.GetOutputs(original_recompute_node-&gt;name())) {
251:       if (recomputed_source_nodes.count(output) == 0) {
252:         continue;
253:       }
254:       auto child_component_iterator = recomputed_node_components.find(output);
255:       CHECK(child_component_iterator != recomputed_node_components.end());
256:       int child_component = child_component_iterator-&gt;second;
257:       if (child_component &gt; max_component) {
258:         max_component = child_component;
259:       }
260:     }
261:     CHECK_GE(max_component, 0);
262:     recomputed_node_components[original_recompute_node] = max_component;
263:   }
264:   return recomputed_node_components;
265: }
266: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [inode] to null at line 141 implies that [inode ] might be null.Dereferencing null pointer [inode]." web_identify="{&quot;identify&quot;:&quot;inode&quot;}" func_info="Status GetInputs ( NodeMap * node_map , const std::vector &lt; NodeDef * &gt; &amp; ops , DataType dtype , std::vector &lt; InputDesc &gt; * inputs )" content="132:     VLOG(2) &lt;&lt; &quot;for node &quot; &lt;&lt; n-&gt;name();
133:     for (const auto&amp; input_name : n-&gt;input()) {
134:       if (!IsControlInput(input_name)) {
135:         if (inode) {
136:           return errors::Internal(&quot;Found more than one input for node &quot;,
137:                                   n-&gt;name());
138:         }
139:         ParseNodeName(input_name, &amp;position);
140:         inode = node_map-&gt;GetNode(input_name);
141:         CHECK(inode) &lt;&lt; input_name;
142:         VLOG(2) &lt;&lt; &quot;inode &quot; &lt;&lt; inode-&gt;DebugString();
143:       }
144:     }
145:     AttrSlice inode_attrs = AttrSlice(*inode);
146:     DataType inode_dtype;
147:     LOG_WARNING_AND_RETURN_IF_ERROR(
148:         GetNodeAttr(inode_attrs, &quot;T&quot;, &amp;inode_dtype));
149:     if (inode_dtype != dtype) {
150:       return errors::Internal(&quot;ScopedAllocatorOptimizer expected input type &quot;,
151:                               dtype, &quot; but found &quot;, inode_dtype);
152:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc" line="287" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph_properties_] to null at line 285 implies that [graph_properties_ ] might be null.Dereferencing null pointer [graph_properties_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;graph_properties_&quot;}" func_info="Status UnaryElementwiseRewriter::AnalyzeInputs ( ScopedAllocatorOptimizer * sa_opti , NodeMap * node_map , const std :: vector &lt; NodeDef * &gt; &amp; ops , const std :: set &lt; string &gt; &amp; op_instance_names , string * device_name , DataType * dtype , std :: vector &lt; TensorShape &gt; * input_shapes , std :: vector &lt; InputDesc &gt; * inputs , TensorShape * sa_shape )" content="277:   // and checking whether there are any considerations that prevent use
278:   // of a single ScopedAllocator for all of those inputs.
279:   Status AnalyzeInputs(ScopedAllocatorOptimizer* sa_opti, NodeMap* node_map,
280:                        const std::vector&lt;NodeDef*&gt;&amp; ops,
281:                        const std::set&lt;string&gt;&amp; op_instance_names,
282:                        string* device_name, DataType* dtype,
283:                        std::vector&lt;TensorShape&gt;* input_shapes,
284:                        std::vector&lt;InputDesc&gt;* inputs, TensorShape* sa_shape) {
285:     CHECK(graph_properties_);
286:     LOG_WARNING_AND_RETURN_IF_ERROR(
287:         CheckTypesAndGetShapes(*graph_properties_, ops, dtype, input_shapes));
288:     LOG_WARNING_AND_RETURN_IF_ERROR(
289:         GetInputs(sa_opti-&gt;node_map(), ops, *dtype, inputs));
290:     LOG_WARNING_AND_RETURN_IF_ERROR(CheckExistingScopedAllocator(*inputs));
291:     LOG_WARNING_AND_RETURN_IF_ERROR(
292:         CheckInternalDataDependency(op_instance_names, *inputs));
293:     ClearInternalControlInputs(op_instance_names, ops, node_map);
294:     *device_name = ops[0]-&gt;device();
295:     CHECK(!device_name-&gt;empty());
296:     CHECK(!input_shapes-&gt;empty());
297:     CHECK_EQ(0, Allocator::kAllocatorAlignment % DataTypeSize(*dtype))
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/grappler/utils.cc" line="57" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph] to null at line 56 implies that [graph ] might be null.Dereferencing null pointer [graph]." web_identify="{&quot;identify&quot;:&quot;graph&quot;}" func_info="NodeMap::NodeMap ( GraphDef * graph )" content="47: // TODO(ezhulenev): what about Identity passing tensor to Shape consumer?
48: bool IsShapeConsumer(const NodeDef&amp; node) {
49:   const string&amp; op = node.op();
50:   return op == &quot;Shape&quot; || op == &quot;ShapeN&quot; || op == &quot;Rank&quot; || op == &quot;Size&quot;;
51: }
52: 
53: }  // namespace
54: 
55: NodeMap::NodeMap(GraphDef* graph) {
56:   CHECK(graph != nullptr);
57:   for (int i = 0; i &lt; graph-&gt;node_size(); i++) {
58:     NodeDef* node = graph-&gt;mutable_node(i);
59:     const string&amp; node_name = node-&gt;name();
60:     auto rslt = nodes_.emplace(node_name, node);
61:     // Check that the graph doesn&apos;t contain multiple nodes with the same name.
62:     if (!rslt.second) {
63:       LOG(WARNING) &lt;&lt; &quot;Duplicated node in the graph: &quot; &lt;&lt; node_name;
64:     }
65:     for (const auto&amp; input : node-&gt;input()) {
66:       outputs_[NodeName(input)].insert(nodes_[node_name]);
67:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/candidate_sampler_ops.cc" line="56" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [sampler_] to null at line 52 implies that [sampler_ ] might be null.Dereferencing null pointer [sampler_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;sampler_&quot;}" func_info="void BaseCandidateSamplerOp::Compute ( OpKernelContext * context )" content="46:     const int32 batch_size = true_classes.dim_size(0);
47:     OP_REQUIRES(
48:         context, true_classes.dim_size(1) == num_true_,
49:         errors::InvalidArgument(&quot;true_classes must have &quot;
50:                                 &quot;num_true columns, expected: &quot;,
51:                                 true_classes.dim_size(1), &quot; was: &quot;, num_true_));
52:     CHECK(sampler_) &lt;&lt; &quot;CandidateSamplerOp did not set sampler_&quot;;
53: 
54:     if (unique_) {
55:       OP_REQUIRES(context, num_sampled_ &lt;= sampler_-&gt;range(),
56:                   errors::InvalidArgument(&quot;Sampler&apos;s range is too small.&quot;));
57:     }
58: 
59:     // Output candidates and expected_count.
60:     Tensor* out_sampled_candidates = nullptr;
61:     OP_REQUIRES_OK(context,
62:                    context-&gt;allocate_output(0, TensorShape({num_sampled_}),
63:                                             &amp;out_sampled_candidates));
64: 
65:     Tensor* out_true_expected_count = nullptr;
66:     OP_REQUIRES_OK(context, context-&gt;allocate_output(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/conv_ops_fused.cc" line="367" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;output_width1-stride_cols*&quot;}" func_info="void FusedResizeAndPadConvFunctor::operator() ( OpKernelContext * context , const Tensor &amp; input , int input_batches , int resized_height , int resized_width , int padded_height , int padded_width , int input_depth , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int stride_rows , int stride_cols , Padding padding , T3 * output_data , int output_height , int output_width , const ImageResizerState &amp; st , int top_padding , int bottom_padding , int left_padding , int right_padding , int pad_offset )" content="357:     // cache  |                    |
358:     // height |                    |
359:     //   v    +--------------------+
360:     // Each cache row contains a cache_line_width number of resized pixels,
361:     // each with input_depth channels. The cache height is typically less than
362:     // the full height the resized image would be, so it&apos;s filled up
363:     // incrementally as we progress downwards through the input creating im2col
364:     // patches.
365:     task_params.cache_start_x = -filter_left_offset;
366:     task_params.cache_end_x =
367:         (((output_width - 1) * stride_cols) - filter_left_offset) +
368:         filter_width;
369:     task_params.cache_line_width =
370:         task_params.cache_end_x - task_params.cache_start_x;
371:     task_params.cache_height =
372:         kResizeCacheSize / (task_params.cache_line_width * input_depth);
373:     const int needed_resize_cache_count =
374:         filter_height * task_params.cache_line_width * input_depth;
375:     OP_REQUIRES(context,
376:                 (needed_resize_cache_count * sizeof(T1)) &lt;= kResizeCacheSize,
377:                 errors::InvalidArgument(&quot;Input too large for resize cache&quot;));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/conv_ops_gpu_3.cu.cc" line="773" id="suspicious" subid="autovar" severity="Warning" msg="Reference to auto variable returned." web_identify="{&quot;identify&quot;:&quot;return&quot;}" func_info="&gt; const std::vector &lt; std::pair &lt; int , int &gt; &gt; &amp; functor::GetTileSizesFrontier ( )" content="763:     for (int long_side = 32; long_side &lt;= kMaxLongSideLen; long_side *= 2) {
764:       for (int short_side = 2; short_side &lt;= kMaxShortSideLen;
765:            short_side += 1) {
766:         if (TileSizeOnLongSideFrontier(long_side, short_side, SizeOfT)) {
767:           // The current combination lies on the frontier, thus we
768:           // add it to the frontier definition.
769:           frontier-&gt;push_back(std::make_pair(long_side, short_side));
770: 
771:           // The long side length is the largest one allowed iff its
772:           // corresponding short side length is 2.
773:           if (short_side == 2) return frontier;
774: 
775:           // We have exhausted all the possibilities in the frontier
776:           // with the given long side length.
777:           break;
778:         }
779:       }
780:     }
781:     LOG(FATAL)
782:         &lt;&lt; &quot;The corresponding short side length of the largest long side &quot;
783:            &quot;length has to be 2.&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/conv_ops_using_gemm.cc" line="325" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_batchesoutput_height*&quot;}" func_info="void Im2ColConvFunctor::operator() ( OpKernelContext * context , const T1 * input_data , int input_batches , int input_height , int input_width , int input_depth , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int stride_rows , int stride_cols , Padding padding , T3 * output_data , int output_height , int output_width )" content="315:                                 &quot;Conv2d&quot;, &quot;im2col_buffer&quot;,
316:                                 &amp;im2col_buffer_resource, creator));
317:     // This means that multiple ops can&apos;t be run simultaneously on different
318:     // threads, because we have a single shared resource. The platforms this is
319:     // aimed at have intra-op parallelism as their focus though, so it shouldn&apos;t
320:     // be an issue.
321:     mutex_lock lock_buffer(im2col_buffer_resource-&gt;mu);
322:     core::ScopedUnref unref_buffer(im2col_buffer_resource);
323:     T1* im2col_buffer = im2col_buffer_resource-&gt;data;
324: 
325:     const int64 patch_count = (input_batches * output_height * output_width);
326:     const int64 chunk_count =
327:         (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;
328:     for (int64 chunk_index = 0; chunk_index &lt; chunk_count; ++chunk_index) {
329:       const int64 patch_index_start = chunk_index * patches_per_chunk;
330:       const int64 patch_index_end =
331:           std::min(patch_index_start + patches_per_chunk, patch_count);
332:       for (int64 patch_index = patch_index_start; patch_index &lt; patch_index_end;
333:            ++patch_index) {
334:         const int64 batch = patch_index / (output_height * output_width);
335:         const int64 out_y = (patch_index / output_width) % output_height;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/data/group_by_window_dataset_op.cc" line="202" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Iterator::current_key_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Iterator::current_key_,&quot;}" func_info="GroupByWindowDatasetOp::Dataset::Iterator" content="192:             reduce_func_other_arguments_types_attr},
193:            {&quot;Twindow_size_func_other_arguments&quot;,
194:             window_size_func_other_arguments_types_attr}},
195:           output));
196:       return Status::OK();
197:     }
198: 
199:    private:
200:     class Iterator : public DatasetIterator&lt;Dataset&gt; {
201:      public:
202:       explicit Iterator(const Params&amp; params)
203:           : DatasetIterator&lt;Dataset&gt;(params) {}
204: 
205:       Status Initialize(IteratorContext* ctx) override {
206:         return dataset()-&gt;input_-&gt;MakeIterator(ctx, prefix(), &amp;input_impl_);
207:       }
208: 
209:       Status GetNextInternal(IteratorContext* ctx,
210:                              std::vector&lt;Tensor&gt;* out_tensors,
211:                              bool* end_of_sequence) override {
212:         mutex_lock l(mu_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/data/optimize_dataset_op.cc" line="64" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Dataset::optimized_input_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Dataset::optimized_input_,&quot;}" func_info="OptimizeDatasetOp::Dataset" content="54:         ctx, ParseVectorArgument&lt;string&gt;(ctx, &quot;optimizations&quot;, &amp;optimizations));
55:     Dataset* dataset =
56:         new Dataset(ctx, input, optimizations, output_types_, output_shapes_);
57:     OP_REQUIRES_OK(ctx, dataset-&gt;Optimize(ctx));
58:     *output = dataset;
59:   }
60: 
61:  private:
62:   class Dataset : public GraphDatasetBase {
63:    public:
64:     Dataset(OpKernelContext* ctx, const DatasetBase* input,
65:             const std::vector&lt;string&gt;&amp; optimizations,
66:             const DataTypeVector&amp; output_types,
67:             const std::vector&lt;PartialTensorShape&gt;&amp; output_shapes)
68:         : GraphDatasetBase(ctx),
69:           input_(input),
70:           optimizations_(optimizations),
71:           output_types_(output_types),
72:           output_shapes_(output_shapes) {
73:       input_-&gt;Ref();
74:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/data/tensor_queue_dataset_op.cc" line="469" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [queue_] to null at line 468 implies that [queue_ ] might be null.Dereferencing null pointer [queue_]." web_identify="{&quot;identify&quot;:&quot;queue_&quot;}" func_info="Status TensorQueueInserter::Insert ( const std :: vector &lt; Tensor &gt; &amp; tensors ) const" content="459:         if (queue_) {
460:           mutex_lock lock(*queue_-&gt;mu());
461:           queue_-&gt;Unref();
462:           queue_-&gt;NotifyLocked();
463:           queue_ = nullptr;
464:         }
465:       }
466: 
467:       Status Insert(const std::vector&lt;Tensor&gt;&amp; tensors) const {
468:         CHECK(queue_);
469:         return queue_-&gt;Insert(tensors);
470:       }
471: 
472:      private:
473:       mutable TensorQueue* queue_;
474:     };
475: 
476:    private:
477:     TensorQueue* queue_;
478:   };
479: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/decode_image_op.cc" line="231" id="nullpointer" subid="explicitNullDereference" severity="Critical" msg="Dereferencing null pointer [output], [output] is assigned with null at line 211. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="void DecodeImageOp::DecodeJpeg ( OpKernelContext * context , StringPiece input )" content="221:                       : TensorShape({height, width, channels}),
222:                   &amp;output));
223:               if (!status.ok()) {
224:                 VLOG(1) &lt;&lt; status;
225:                 context-&gt;SetStatus(status);
226:                 return nullptr;
227:               }
228:               return output-&gt;flat&lt;uint8&gt;().data();
229:             }),
230:         errors::InvalidArgument(&quot;Invalid JPEG data or crop window, data size &quot;,
231:                                 input.size()));
232:   }
233: 
234:   void DecodePng(OpKernelContext* context, StringPiece input) {
235:     // Start decoding png to get shape details
236:     png::DecodeContext decode;
237:     OP_REQUIRES(context,
238:                 png::CommonInitDecode(input, channels_, channel_bits_, &amp;decode),
239:                 errors::InvalidArgument(&quot;Invalid PNG header, data size &quot;,
240:                                         input.size()));
241: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/decode_image_op.cc" line="327" id="nullpointer" subid="explicitNullDereference" severity="Critical" msg="Dereferencing null pointer [output], [output] is assigned with null at line 296. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="void DecodeImageOp::DecodeGif ( OpKernelContext * context , StringPiece input )" content="317:                       }
318:                       if (!status.ok()) {
319:                         VLOG(1) &lt;&lt; status;
320:                         context-&gt;SetStatus(status);
321:                         return nullptr;
322:                       }
323:                       return output-&gt;flat&lt;uint8&gt;().data();
324:                     },
325:                     &amp;error_string),
326:         errors::InvalidArgument(&quot;Invalid GIF data (size &quot;, input.size(), &quot;), &quot;,
327:                                 error_string));
328:   }
329: 
330:  private:
331:   FileFormat format_;
332:   int channels_;
333:   int channel_bits_ = 8;
334:   jpeg::UncompressFlags flags_;
335: };
336: 
337: REGISTER_KERNEL_BUILDER(Name(&quot;DecodeJpeg&quot;).Device(DEVICE_CPU), DecodeImageOp);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/deep_conv2d.cc" line="52" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_tile_rowsinput_tile_cols*&quot;}" func_info="static long tensorflow::GetDeepConvCost ( int input_tile_rows , int input_tile_cols , int out_tile_rows , int out_tile_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="42: //
43: // The transform matrices and input, filter and output tile sizes are all
44: // specified by the DeepConv2DTransform implementation selected at the
45: // start of the DeepConv2D call, based on convolution parameters.
46: 
47: // Approximate cost models for direct and deep convolutions.
48: static int64 GetDeepConvCost(int input_tile_rows, int input_tile_cols,
49:                              int out_tile_rows, int out_tile_cols, int in_depth,
50:                              int out_depth, int out_rows, int out_cols) {
51:   // Input transform cost.
52:   const int64 input_tile_spatial_size = input_tile_rows * input_tile_cols;
53:   const int64 input_transform_cost =
54:       input_tile_spatial_size * input_tile_spatial_size * in_depth;
55: 
56:   // Element-wise products (each product is a MatMul across depth).
57:   const int64 product_cost = input_tile_spatial_size * in_depth * out_depth;
58: 
59:   // Output transform cost.
60:   const int64 output_tile_spatial_size = out_tile_rows * out_tile_cols;
61:   const int64 output_transform_cost =
62:       output_tile_spatial_size * input_tile_spatial_size * out_depth;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/deep_conv2d.cc" line="60" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;out_tile_rowsout_tile_cols*&quot;}" func_info="static long tensorflow::GetDeepConvCost ( int input_tile_rows , int input_tile_cols , int out_tile_rows , int out_tile_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="50:                              int out_depth, int out_rows, int out_cols) {
51:   // Input transform cost.
52:   const int64 input_tile_spatial_size = input_tile_rows * input_tile_cols;
53:   const int64 input_transform_cost =
54:       input_tile_spatial_size * input_tile_spatial_size * in_depth;
55: 
56:   // Element-wise products (each product is a MatMul across depth).
57:   const int64 product_cost = input_tile_spatial_size * in_depth * out_depth;
58: 
59:   // Output transform cost.
60:   const int64 output_tile_spatial_size = out_tile_rows * out_tile_cols;
61:   const int64 output_transform_cost =
62:       output_tile_spatial_size * input_tile_spatial_size * out_depth;
63: 
64:   // Calculate number of input tiles to process.
65:   const int64 row_tiles = (out_rows + out_tile_rows - 1) / out_tile_rows;
66:   const int64 col_tiles = (out_cols + out_tile_cols - 1) / out_tile_cols;
67:   const int64 num_tiles = row_tiles * col_tiles;
68: 
69:   // Return total cost.
70:   return num_tiles *
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/deep_conv2d.cc" line="76" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;filter_rowsfilter_cols*&quot;}" func_info="static long tensorflow::GetDirectConvCost ( int filter_rows , int filter_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="66:   const int64 col_tiles = (out_cols + out_tile_cols - 1) / out_tile_cols;
67:   const int64 num_tiles = row_tiles * col_tiles;
68: 
69:   // Return total cost.
70:   return num_tiles *
71:          (input_transform_cost + product_cost + output_transform_cost);
72: }
73: 
74: static int64 GetDirectConvCost(int filter_rows, int filter_cols, int in_depth,
75:                                int out_depth, int out_rows, int out_cols) {
76:   return filter_rows * filter_cols * in_depth * out_depth * out_rows * out_cols;
77: }
78: 
79: // Reads environment variable &apos;env_var_name&apos;.
80: // Returns &apos;true&apos; if environment variable is enabled, false otherwise.
81: static bool ReadBoolFromEnvVar(const char* env_var_name, bool default_val) {
82:   const char* tf_env_var_val = getenv(env_var_name);
83:   if (tf_env_var_val != nullptr) {
84:     StringPiece tf_env_var_val_str(tf_env_var_val);
85:     if (tf_env_var_val_str == &quot;0&quot;) {
86:       return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="115" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed64Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="105:     data_size += WireFormatLite::Int32Size(
106:         input_t(static_cast&lt;int64&gt;(message_index), i));
107:   }
108:   return data_size;
109: }
110: 
111: template &lt;&gt;
112: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64, int64&gt;(const Tensor&amp; input,
113:                                                             int message_index,
114:                                                             int size) {
115:   return size * WireFormatLite::kFixed64Size;
116: }
117: 
118: template &lt;&gt;
119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="122" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="112: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64, int64&gt;(const Tensor&amp; input,
113:                                                             int message_index,
114:                                                             int size) {
115:   return size * WireFormatLite::kFixed64Size;
116: }
117: 
118: template &lt;&gt;
119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="129" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32,int&gt; ( const Tensor &amp; input , int message_index , int size )" content="119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
133: size_t TotalPackedSize&lt;WireFormatLite::TYPE_BOOL, bool&gt;(const Tensor&amp; input,
134:                                                         int message_index,
135:                                                         int size) {
136:   return size * WireFormatLite::kBoolSize;
137: }
138: 
139: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="136" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekBoolSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_BOOL,bool&gt; ( const Tensor &amp; input , int message_index , int size )" content="126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
133: size_t TotalPackedSize&lt;WireFormatLite::TYPE_BOOL, bool&gt;(const Tensor&amp; input,
134:                                                         int message_index,
135:                                                         int size) {
136:   return size * WireFormatLite::kBoolSize;
137: }
138: 
139: template &lt;&gt;
140: size_t TotalPackedSize&lt;WireFormatLite::TYPE_UINT32, int64&gt;(const Tensor&amp; input,
141:                                                            int message_index,
142:                                                            int size) {
143:   size_t data_size = 0;
144:   auto input_t = input.flat_inner_dims&lt;int64&gt;();
145:   for (int64 i = 0; i &lt; size; i++) {
146:     data_size += WireFormatLite::UInt32Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="181" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekSFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32,int&gt; ( const Tensor &amp; input , int message_index , int size )" content="171:   for (int64 i = 0; i &lt; size; i++) {
172:     data_size +=
173:         WireFormatLite::EnumSize(input_t(static_cast&lt;int64&gt;(message_index), i));
174:   }
175:   return data_size;
176: }
177: 
178: template &lt;&gt;
179: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32, int32&gt;(
180:     const Tensor&amp; input, int message_index, int size) {
181:   return size * WireFormatLite::kSFixed32Size;
182: }
183: 
184: template &lt;&gt;
185: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64, int64&gt;(
186:     const Tensor&amp; input, int message_index, int size) {
187:   return size * WireFormatLite::kSFixed64Size;
188: }
189: 
190: template &lt;&gt;
191: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SINT32, int32&gt;(const Tensor&amp; input,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="187" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekSFixed64Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="177: 
178: template &lt;&gt;
179: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32, int32&gt;(
180:     const Tensor&amp; input, int message_index, int size) {
181:   return size * WireFormatLite::kSFixed32Size;
182: }
183: 
184: template &lt;&gt;
185: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64, int64&gt;(
186:     const Tensor&amp; input, int message_index, int size) {
187:   return size * WireFormatLite::kSFixed64Size;
188: }
189: 
190: template &lt;&gt;
191: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SINT32, int32&gt;(const Tensor&amp; input,
192:                                                            int message_index,
193:                                                            int size) {
194:   size_t data_size = 0;
195:   auto input_t = input.flat_inner_dims&lt;int32&gt;();
196:   for (int64 i = 0; i &lt; size; i++) {
197:     data_size += WireFormatLite::SInt32Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="55" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekDoubleSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE,double&gt; ( const Tensor &amp; input , int message_index , int size )" content="45: // Computes the total serialized size for a packed repeated field.
46: // For fixed-size types this can just multiply, but for variable-sized
47: // types it has to iterate through the values in the tensor.
48: template &lt;WireFormatLite::FieldType FieldType, typename TensorT&gt;
49: size_t TotalPackedSize(const Tensor&amp; input, int message_index, int size);
50: 
51: template &lt;&gt;
52: size_t TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE, double&gt;(const Tensor&amp; input,
53:                                                             int message_index,
54:                                                             int size) {
55:   return size * WireFormatLite::kDoubleSize;
56: }
57: 
58: template &lt;&gt;
59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="62" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFloatSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT,double&gt; ( const Tensor &amp; input , int message_index , int size )" content="52: size_t TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE, double&gt;(const Tensor&amp; input,
53:                                                             int message_index,
54:                                                             int size) {
55:   return size * WireFormatLite::kDoubleSize;
56: }
57: 
58: template &lt;&gt;
59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
66: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, float&gt;(const Tensor&amp; input,
67:                                                           int message_index,
68:                                                           int size) {
69:   return size * WireFormatLite::kFloatSize;
70: }
71: 
72: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/encode_proto_op.cc" line="69" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFloatSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT,float&gt; ( const Tensor &amp; input , int message_index , int size )" content="59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
66: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, float&gt;(const Tensor&amp; input,
67:                                                           int message_index,
68:                                                           int size) {
69:   return size * WireFormatLite::kFloatSize;
70: }
71: 
72: template &lt;&gt;
73: size_t TotalPackedSize&lt;WireFormatLite::TYPE_INT64, int64&gt;(const Tensor&amp; input,
74:                                                           int message_index,
75:                                                           int size) {
76:   size_t data_size = 0;
77:   auto input_t = input.flat_inner_dims&lt;int64&gt;();
78:   for (int64 i = 0; i &lt; size; i++) {
79:     data_size += WireFormatLite::Int64Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/functional_ops.cc" line="413" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;State::limit_,delta_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;State::limit_,delta_,&quot;}" func_info="ForOp::State" content="403: 
404:   void ComputeAsync(OpKernelContext* ctx, DoneCallback done) override {
405:     (new State(this, ctx, done))-&gt;Start();
406:   }
407: 
408:  private:
409:   FHandle body_handle_;
410: 
411:   class State {
412:    public:
413:     State(ForOp* kernel, OpKernelContext* ctx, DoneCallback done)
414:         : kernel_(kernel),
415:           ctx_(ctx),
416:           done_(std::move(done)),
417:           lib_(CHECK_NOTNULL(ctx_-&gt;function_library())),
418:           args_(1 + ctx_-&gt;num_inputs() - 3) {
419:       args_[0] = Tensor(DT_INT32, {});
420:       iter_ = &amp;args_[0].scalar&lt;int32&gt;()();
421: 
422:       const int32 num_loop_inputs = ctx_-&gt;num_inputs() - 3;
423:       rets_.reserve(num_loop_inputs);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/hexagon/graph_transfer_utils.cc" line="39" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [data] to null at line 35 implies that [data ] might be null.Dereferencing null pointer [data]." web_identify="{&quot;identify&quot;:&quot;data&quot;}" func_info="&gt; GraphTransferUtils::GetTopNFloatResults ( const float * data , const string * labels , const int element_count )" content="29:     &amp;RemoteFusedGraphExecuteUtils::AddOutputTensorShapeTypeByTensorShapeMap;
30: 
31: /* static */ std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt;
32: GraphTransferUtils::GetTopNFloatResults(const float* const data,
33:                                         const string* const labels,
34:                                         const int element_count) {
35:   CHECK(data != nullptr);
36:   CHECK(labels != nullptr);
37:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue;
38:   for (int i = 0; i &lt; element_count; ++i) {
39:     queue.emplace(data[i], i, labels[i]);
40:   }
41:   return queue;
42: }
43: 
44: /* static */ void GraphTransferUtils::DumpTopNFloatResults(
45:     const float* const data, const string* const labels,
46:     const int element_count, const int top_n) {
47:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
48:       GetTopNFloatResults(data, labels, element_count);
49:   LOG(INFO) &lt;&lt; &quot;=== Dump ranking ===&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/hexagon/graph_transfer_utils.cc" line="39" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [labels] to null at line 36 implies that [labels ] might be null.Dereferencing null pointer [labels]." web_identify="{&quot;identify&quot;:&quot;labels&quot;}" func_info="&gt; GraphTransferUtils::GetTopNFloatResults ( const float * data , const string * labels , const int element_count )" content="29:     &amp;RemoteFusedGraphExecuteUtils::AddOutputTensorShapeTypeByTensorShapeMap;
30: 
31: /* static */ std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt;
32: GraphTransferUtils::GetTopNFloatResults(const float* const data,
33:                                         const string* const labels,
34:                                         const int element_count) {
35:   CHECK(data != nullptr);
36:   CHECK(labels != nullptr);
37:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue;
38:   for (int i = 0; i &lt; element_count; ++i) {
39:     queue.emplace(data[i], i, labels[i]);
40:   }
41:   return queue;
42: }
43: 
44: /* static */ void GraphTransferUtils::DumpTopNFloatResults(
45:     const float* const data, const string* const labels,
46:     const int element_count, const int top_n) {
47:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
48:       GetTopNFloatResults(data, labels, element_count);
49:   LOG(INFO) &lt;&lt; &quot;=== Dump ranking ===&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/hexagon/hexagon_control_wrapper.cc" line="392" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [outputs] to null at line 382 implies that [outputs ] might be null.Dereferencing null pointer [outputs]." web_identify="{&quot;identify&quot;:&quot;outputs&quot;}" func_info="bool HexagonControlWrapper::ReadOutputNode ( const string &amp; node_name , std::vector &lt; ByteArray &gt; * outputs )" content="382:   CHECK(outputs != nullptr);
383:   ByteArray output;
384:   const string tensor_name = AddPort(node_name);
385:   CHECK(output_port_map_.count(tensor_name) &gt; 0);
386:   const int port = output_port_map_.at(tensor_name);
387:   soc_interface_ReadOutputNodeWithPort(
388:       port, &amp;std::get&lt;0&gt;(output),
389:       reinterpret_cast&lt;uint64_t*&gt;(&amp;std::get&lt;1&gt;(output)));
390:   // TODO: Accept all results
391:   // std::get&lt;2&gt;(output) = DT_FLOAT;
392:   outputs-&gt;emplace_back(output);
393:   return true;
394: }
395: 
396: Status HexagonControlWrapper::FuseRemoteGraph(
397:     const GraphDef&amp; original_graph_def, const std::vector&lt;string&gt;&amp; inputs,
398:     const std::vector&lt;string&gt;&amp; outputs, GraphDef* fused_graph_def) {
399:   const std::unordered_set&lt;string&gt; fused_node_names =
400:       RemoteFusedGraphExecuteUtils::BuildNodeMapFromOpsDefinitions(
401:           original_graph_def, HexagonOpsDefinitions::getInstance());
402:   // TODO(satok): We may want to place shape and type inside this function
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc" line="126" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [img_floats_ptr] to null at line 125 implies that [img_floats_ptr ] might be null.Dereferencing null pointer [img_floats_ptr]." web_identify="{&quot;identify&quot;:&quot;img_floats_ptr&quot;}" func_info="static void tensorflow::LoadImage ( std :: vector &lt; float &gt; * img_floats_ptr )" content="116:   std::vector&lt;string&gt; labels(element_count);
117:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
118:       GraphTransferUtils::GetTopNFloatResults(float_array, labels.data(),
119:                                               element_count);
120:   const std::tuple&lt;float, int, string&gt;&amp; entry = queue.top();
121:   EXPECT_EQ(expected_first_id, std::get&lt;1&gt;(entry));
122: }
123: 
124: static void LoadImage(std::vector&lt;float&gt;* img_floats_ptr) {
125:   CHECK(img_floats_ptr != nullptr);
126:   std::vector&lt;float&gt;&amp; img_floats = *img_floats_ptr;
127:   // Read the data from the bitmap file into memory
128:   string bmp;
129:   TF_CHECK_OK(ReadFileToString(Env::Default(), IMAGE_FILENAME, &amp;bmp));
130:   const int fsize = bmp.size();
131:   LOG(INFO) &lt;&lt; &quot;Read &quot; &lt;&lt; IMAGE_FILENAME &lt;&lt; &quot;, size = &quot; &lt;&lt; fsize &lt;&lt; &quot;bytes&quot;;
132:   const int64 pixel_count = WIDTH * HEIGHT * DEPTH;
133:   CHECK(fsize &gt;= 22 /* pos of height */ + sizeof(int));
134:   CHECK(bmp.data() != nullptr);
135:   uint8* const img_bytes = bit_cast&lt;uint8*&gt;(bmp.data());
136:   const int header_size = *(reinterpret_cast&lt;int*&gt;(img_bytes + 10));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/image_resizer_state.h" line="133" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ImageResizerGradientState::batch_size,channels,resized_height,resized_width,original_height,original_width,height_scale,width_scale,output,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ImageResizerGradientState::batch_size,channels,resized_height,resized_width,original_height,original_width,height_scale,width_scale,output,&quot;}" func_info="tensorflow::ImageResizerGradientState" content="123:   int64 channels;
124:   float height_scale;
125:   float width_scale;
126:   Tensor* output = nullptr;
127: 
128:  private:
129:   bool align_corners_;
130: };
131: 
132: struct ImageResizerGradientState {
133:   explicit ImageResizerGradientState(bool align_corners)
134:       : align_corners_(align_corners) {}
135: 
136:   void ValidateAndCreateOutput(OpKernelContext* context, const Tensor&amp; input,
137:                                const Tensor&amp; original_image) {
138:     OP_REQUIRES(context, input.dims() == 4,
139:                 errors::InvalidArgument(&quot;input_grad must be 4-dimensional&quot;,
140:                                         input.shape().DebugString()));
141:     // Resizers always produce float images, so input gradient must
142:     // always be a float.
143:     OP_REQUIRES(context, input.dtype() == DT_FLOAT,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/image_resizer_state.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ImageResizerState::batch_size,out_height,out_width,in_height,in_width,channels,height_scale,width_scale,output,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ImageResizerState::batch_size,out_height,out_width,in_height,in_width,channels,height_scale,width_scale,output,&quot;}" func_info="tensorflow::ImageResizerState" content="39: 
40: // CalculateResizeScale determines the float scaling factor.
41: inline float CalculateResizeScale(int64 in_size, int64 out_size,
42:                                   bool align_corners) {
43:   return (align_corners &amp;&amp; out_size &gt; 1)
44:              ? (in_size - 1) / static_cast&lt;float&gt;(out_size - 1)
45:              : in_size / static_cast&lt;float&gt;(out_size);
46: }
47: 
48: struct ImageResizerState {
49:   explicit ImageResizerState(bool align_corners)
50:       : align_corners_(align_corners) {}
51: 
52:   // ValidateAndCalculateOutputSize checks the bounds on the input tensors
53:   // and requested size, sets up some of the resizing state such as the
54:   // height_scale and width_scale, and calculates the output size.
55:   // If any of these operations fails, it sets an error status in
56:   // the context, which the caller must check.
57:   void ValidateAndCalculateOutputSize(OpKernelContext* context,
58:                                       const Tensor&amp; input) {
59:     OP_REQUIRES(context, input.dims() == 4,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/lookup_util.cc" line="60" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TextFileLineIterator::key_index_,value_index_,env_,next_id_,delimiter_,ignore_split_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TextFileLineIterator::key_index_,value_index_,env_,next_id_,delimiter_,ignore_split_,&quot;}" func_info="TextFileLineIterator" content="50: 
51: // Iterator that reads a text file. Each iteration process one line, it parses
52: // the line and populates the keys and values tensors used for initialization
53: // with a single key and corresponding value.
54: //
55: // What information of the line to populate the key or values is specified by
56: // providing key_index and value_index.
57: class TextFileLineIterator
58:     : public InitializableLookupTable::InitTableIterator {
59:  public:
60:   TextFileLineIterator()
61:       : valid_(false),
62:         vocab_size_(-1),
63:         status_(errors::FailedPrecondition(&quot;Not initialized&quot;)) {}
64: 
65:   // Initialize iterator.
66:   //
67:   // Prepares the file &apos;filename&apos; and sets the data types to return the keys and
68:   // values tensors. It requires the indices of the tokens in the line given a
69:   // delimiter to specify where to pick the data from.
70:   //
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/mfcc_dct.cc" line="23" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccDct::coefficient_count_,input_length_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccDct::coefficient_count_,input_length_,&quot;}" func_info="tensorflow" content="13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/core/kernels/mfcc_dct.h&quot;
17: 
18: #include &lt;math.h&gt;
19: #include &quot;tensorflow/core/platform/logging.h&quot;
20: 
21: namespace tensorflow {
22: 
23: MfccDct::MfccDct() : initialized_(false) {}
24: 
25: bool MfccDct::Initialize(int input_length, int coefficient_count) {
26:   coefficient_count_ = coefficient_count;
27:   input_length_ = input_length;
28: 
29:   if (coefficient_count_ &lt; 1) {
30:     LOG(ERROR) &lt;&lt; &quot;Coefficient count must be positive.&quot;;
31:     return false;
32:   }
33: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/mfcc_mel_filterbank.cc" line="103" id="bufoverrun" subid="arrayIndexThenCheck" severity="Critical" msg="Array index &apos;channel&apos; is used before limits check." web_identify="{&quot;identify&quot;:&quot;channel&quot;}" func_info="bool MfccMelFilterbank::Initialize ( int input_length , double input_sample_rate , int output_channel_count , double lower_frequency_limit , double upper_frequency_limit )" content="93:   // each FFT bin, band_mapper tells us which channel this bin contributes to
94:   // on the right side of the triangle.  Thus this bin also contributes to the
95:   // left side of the next channel&apos;s triangle response.
96:   band_mapper_.resize(input_length_);
97:   int channel = 0;
98:   for (int i = 0; i &lt; input_length_; ++i) {
99:     double melf = FreqToMel(i * hz_per_sbin);
100:     if ((i &lt; start_index_) || (i &gt; end_index_)) {
101:       band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.
102:     } else {
103:       while ((center_frequencies_[channel] &lt; melf) &amp;&amp;
104:              (channel &lt; num_channels_)) {
105:         ++channel;
106:       }
107:       band_mapper_[i] = channel - 1;  // Can be == -1
108:     }
109:   }
110: 
111:   // Create the weighting functions to taper the band edges.  The contribution
112:   // of any one FFT bin is based on its distance along the continuum between two
113:   // mel-channel center frequencies.  This bin contributes weights_[i] to the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/mfcc_mel_filterbank.cc" line="39" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&quot;}" func_info="tensorflow" content="29: // spectrum output will have some channels that are always zero.
30: 
31: #include &quot;tensorflow/core/kernels/mfcc_mel_filterbank.h&quot;
32: 
33: #include &lt;math.h&gt;
34: 
35: #include &quot;tensorflow/core/platform/logging.h&quot;
36: 
37: namespace tensorflow {
38: 
39: MfccMelFilterbank::MfccMelFilterbank() : initialized_(false) {}
40: 
41: bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,
42:                                    int output_channel_count,
43:                                    double lower_frequency_limit,
44:                                    double upper_frequency_limit) {
45:   num_channels_ = output_channel_count;
46:   sample_rate_ = input_sample_rate;
47:   input_length_ = input_length;
48: 
49:   if (num_channels_ &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/quantization_utils.h" line="922" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [task] to null at line 921 implies that [task ] might be null.Dereferencing null pointer [task]." web_identify="{&quot;identify&quot;:&quot;task&quot;}" func_info="void TensorflowGemmlowpWorkersPool::Execute ( const std :: vector &lt; gemmlowp :: Task * &gt; &amp; tasks )" content="912: 
913:   void Execute(const std::vector&lt;gemmlowp::Task*&gt;&amp; tasks) {
914:     assert(!tasks.empty());
915:     assert(workers_ != nullptr);
916:     counter_to_decrement_when_ready_.Reset(tasks.size());
917:     for (gemmlowp::Task* task : tasks) {
918:       workers_-&gt;Schedule([this, task]() {
919:         // TODO(cwhipkey): get a local_allocator from a thread local storage.
920:         gemmlowp::Allocator local_allocator;
921:         CHECK(task != nullptr);
922:         task-&gt;local_allocator = &amp;local_allocator;
923:         task-&gt;Run();
924:         counter_to_decrement_when_ready_.DecrementCount();
925:       });
926:     }
927:     counter_to_decrement_when_ready_.Wait();
928:     for (gemmlowp::Task* task : tasks) {
929:       delete task;
930:     }
931:   }
932: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/quantized_conv_ops.cc" line="292" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_batchesoutput_height*&quot;}" func_info="void Im2ColConvFunctor::operator() ( OpKernelContext * context , const T1 * input_data , int input_batches , int input_height , int input_width , int input_depth , int input_offset , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int filter_offset , int stride , Padding padding , T3 * output_data , int output_height , int output_width , int output_shift , int output_offset , int output_mult )" content="282:                                 &quot;Conv2d&quot;, &quot;im2col_buffer&quot;,
283:                                 &amp;im2col_buffer_resource, creator));
284:     // This means that multiple ops can&apos;t be run simultaneously on different
285:     // threads, because we have a single shared resource. The platforms this is
286:     // aimed at have intra-op parallelism as their focus though, so it shouldn&apos;t
287:     // be an issue.
288:     mutex_lock lock_buffer(im2col_buffer_resource-&gt;mu);
289:     core::ScopedUnref unref_buffer(im2col_buffer_resource);
290:     T1* im2col_buffer = im2col_buffer_resource-&gt;data;
291: 
292:     const int64 patch_count = (input_batches * output_height * output_width);
293:     const int64 chunk_count =
294:         (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;
295: 
296:     for (int64 chunk_index = 0; chunk_index &lt; chunk_count; ++chunk_index) {
297:       const int64 patch_index_start = chunk_index * patches_per_chunk;
298:       const int64 patch_index_end =
299:           std::min(patch_index_start + patches_per_chunk, patch_count);
300:       for (int64 patch_index = patch_index_start; patch_index &lt; patch_index_end;
301:            ++patch_index) {
302:         const int64 batch = patch_index / (output_height * output_width);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/reference_gemm.h" line="75" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;ia_i_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="65: 
66:   const int32 highest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::highest());
67:   const int32 lowest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::lowest());
68:   const int32 rounding = (shift_c &lt; 1) ? 0 : (1 &lt;&lt; (shift_c - 1));
69: 
70:   int i, j, l;
71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/reference_gemm.h" line="77" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;jb_j_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="67:   const int32 lowest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::lowest());
68:   const int32 rounding = (shift_c &lt; 1) ? 0 : (1 &lt;&lt; (shift_c - 1));
69: 
70:   int i, j, l;
71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
86:       if (output &lt; lowest) {
87:         output = lowest;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/reference_gemm.h" line="81" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;ic_i_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
86:       if (output &lt; lowest) {
87:         output = lowest;
88:       }
89:       c[c_index] = static_cast&lt;T3&gt;(output);
90:     }
91:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/remote_fused_graph_execute_op.cc" line="52" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [remote_fused_graph_executor_] suggests that it may be null, but it has already been dereferenced at line 45." web_identify="{&quot;identify&quot;:&quot;remote_fused_graph_executor_&quot;}" func_info="explicit RemoteFusedGraphExecuteOp::RemoteFusedGraphExecuteOp ( OpKernelConstruction * ctx ) : OpKernel ( ctx ) , execute_info_ ( )" content="42:               execute_info_.executor_name());
43:       if (build_func != nullptr) {
44:         TF_CHECK_OK((*build_func)(&amp;remote_fused_graph_executor_));
45:         CHECK(remote_fused_graph_executor_-&gt;IsEnabled());
46:       } else {
47:         LOG(ERROR) &lt;&lt; &quot;Executor not found for &quot;
48:                    &lt;&lt; execute_info_.executor_name();
49:       }
50:     }
51: 
52:     if (remote_fused_graph_executor_) {
53:       // 1. Initialize remote processor
54:       remote_fused_graph_executor_-&gt;Init(execute_info_);
55:       // Explicitly clear serialized executor parameter after initialization
56:       // to release unnecessary memory.
57:       execute_info_.clear_serialized_executor_parameters();
58: 
59:       // 2. Setup graph in remote processor
60:       remote_fused_graph_executor_-&gt;SetupGraph();
61:     }
62:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/remote_fused_graph_execute_op.cc" line="76" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ctx] to null at line 75 implies that [ctx ] might be null.Dereferencing null pointer [ctx]." web_identify="{&quot;identify&quot;:&quot;ctx&quot;}" func_info="void RemoteFusedGraphExecuteOp::Compute ( OpKernelContext * ctx )" content="66:       // 6. Teardown graph in remote processor
67:       remote_fused_graph_executor_-&gt;TeardownGraph();
68: 
69:       // 7. Finalize remote processor
70:       remote_fused_graph_executor_-&gt;Finalize();
71:     }
72:   }
73: 
74:   void Compute(OpKernelContext* const ctx) final {
75:     CHECK(ctx != nullptr);
76:     const int input_count = ctx-&gt;num_inputs();
77:     const int graph_input_count = execute_info_.graph_input_node_name_size();
78:     CHECK(input_count == graph_input_count &amp;&amp;
79:           input_count == input_types_.size())
80:         &lt;&lt; &quot;input_count = &quot; &lt;&lt; input_count
81:         &lt;&lt; &quot;, gt input count = &quot; &lt;&lt; execute_info_.graph_input_node_name_size()
82:         &lt;&lt; &quot;, type count = &quot; &lt;&lt; input_types_.size();
83: 
84:     // 3. Send first data type inputs into remote processor
85:     for (int i = 0; i &lt; graph_input_count; ++i) {
86:       const Tensor&amp; input_tensor = ctx-&gt;input(i);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/remote_fused_graph_execute_op_test.cc" line="180" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [info_] to null at line 176 implies that [info_ ] might be null.Dereferencing null pointer [info_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;info_&quot;}" func_info="bool SampleRemoteFusedGraphExecutor::ExecuteGraph ( )" content="170:     }
171:     return true;
172:   }
173:   bool Finalize() final { return true; }
174:   bool SetupGraph() final { return true; }
175:   bool ExecuteGraph() final {
176:     CHECK(info_ != nullptr);
177:     // TODO(satok): Add utilities to implement this function more easily.
178:     // CAVEAT: This test only handles add op. You can implement here as you
179:     // like.
180:     CHECK_EQ(1, info_-&gt;graph_input_node_name_size());
181:     const string&amp; input_node_name = info_-&gt;graph_input_node_name(0);
182:     const Tensor&amp; input_tensor = input_tensor_cache_[input_node_name];
183:     const float input_val = *input_tensor.scalar&lt;float&gt;().data();
184:     // TODO(satok): Read NAME_B from node_a_plus_b
185:     const NodeDef&amp; node_b = *node_def_map_.at(NAME_B);
186:     const TensorProto* proto = nullptr;
187:     TF_CHECK_OK(GetNodeAttr(node_b, &quot;value&quot;, &amp;proto));
188:     Tensor const_tensor;
189:     TF_CHECK_OK(RemoteFusedGraphExecuteUtils::MakeTensorFromProto(
190:         *proto, &amp;const_tensor));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/remote_fused_graph_execute_utils.cc" line="312" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor_shape_map] to null at line 272 implies that [tensor_shape_map ] might be null.Dereferencing null pointer [tensor_shape_map]." web_identify="{&quot;identify&quot;:&quot;tensor_shape_map&quot;}" func_info="Status RemoteFusedGraphExecuteUtils::DryRunInferenceForAllNode ( const GraphDef &amp; graph_def , const std::vector &lt; std::pair &lt; string , Tensor &gt; &gt; &amp; input_node_info_list , const bool initialize_by_zero , RemoteFusedGraphExecuteUtils::TensorShapeMap * tensor_shape_map )" content="302:   // Append output tensor of input node in advance to create a map
303:   // to avoid memory reallocation inside vector
304:   for (const std::pair&lt;string, Tensor&gt;&amp; input_node_info :
305:        input_node_info_list) {
306:     output_tensors.push_back(input_node_info.second);
307:   }
308: 
309:   for (int i = 0; static_cast&lt;size_t&gt;(i) &lt; output_node_names.size(); ++i) {
310:     const string&amp; name = output_node_names.at(i);
311:     const Tensor&amp; tensor = output_tensors.at(i);
312:     EmplaceTensorShapeType(name, tensor, tensor_shape_map);
313:   }
314:   for (int i = 0; static_cast&lt;size_t&gt;(i) &lt; input_node_info_list.size(); ++i) {
315:     const string&amp; name = input_node_info_list.at(i).first;
316:     const Tensor&amp; tensor = output_tensors.at(output_node_names.size() + i);
317:     EmplaceTensorShapeType(name, tensor, tensor_shape_map);
318:   }
319:   CHECK_EQ(output_node_names.size() + input_node_info_list.size(),
320:            output_tensors.size());
321:   return status;
322: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/spectrogram.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 133 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; bool Spectrogram::ComputeSquaredMagnitudeSpectrogram ( const std::vector &lt; InputSample &gt; &amp; input , std::vector &lt; std::vector &lt; OutputSample &gt; &gt; * output )" content="124: template &lt;class InputSample, class OutputSample&gt;
125: bool Spectrogram::ComputeSquaredMagnitudeSpectrogram(
126:     const std::vector&lt;InputSample&gt;&amp; input,
127:     std::vector&lt;std::vector&lt;OutputSample&gt;&gt;* output) {
128:   if (!initialized_) {
129:     LOG(ERROR) &lt;&lt; &quot;ComputeSquaredMagnitudeSpectrogram() called before &quot;
130:                &lt;&lt; &quot;successful call to Initialize().&quot;;
131:     return false;
132:   }
133:   CHECK(output);
134:   output-&gt;clear();
135:   int input_start = 0;
136:   while (GetNextWindowOfSamples(input, &amp;input_start)) {
137:     DCHECK_EQ(input_queue_.size(), window_length_);
138:     ProcessCoreFFT();  // Processes input_queue_ to fft_input_output_.
139:     // Add a new slice vector onto the output, to save new result to.
140:     output-&gt;resize(output-&gt;size() + 1);
141:     // Get a reference to the newly added slice to fill in.
142:     auto&amp; spectrogram_slice = output-&gt;back();
143:     spectrogram_slice.resize(output_frequency_channels_);
144:     for (int i = 0; i &lt; output_frequency_channels_; ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/spectrogram.cc" line="93" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 92 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; bool Spectrogram::ComputeComplexSpectrogram ( const std::vector &lt; InputSample &gt; &amp; input , std::vector &lt; std::vector &lt; complex &lt; OutputSample &gt; &gt; &gt; * output )" content="83: template &lt;class InputSample, class OutputSample&gt;
84: bool Spectrogram::ComputeComplexSpectrogram(
85:     const std::vector&lt;InputSample&gt;&amp; input,
86:     std::vector&lt;std::vector&lt;complex&lt;OutputSample&gt;&gt;&gt;* output) {
87:   if (!initialized_) {
88:     LOG(ERROR) &lt;&lt; &quot;ComputeComplexSpectrogram() called before successful call &quot;
89:                &lt;&lt; &quot;to Initialize().&quot;;
90:     return false;
91:   }
92:   CHECK(output);
93:   output-&gt;clear();
94:   int input_start = 0;
95:   while (GetNextWindowOfSamples(input, &amp;input_start)) {
96:     DCHECK_EQ(input_queue_.size(), window_length_);
97:     ProcessCoreFFT();  // Processes input_queue_ to fft_input_output_.
98:     // Add a new slice vector onto the output, to save new result to.
99:     output-&gt;resize(output-&gt;size() + 1);
100:     // Get a reference to the newly added slice to fill in.
101:     auto&amp; spectrogram_slice = output-&gt;back();
102:     spectrogram_slice.resize(output_frequency_channels_);
103:     for (int i = 0; i &lt; output_frequency_channels_; ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/kernels/spectrogram.h" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&quot;}" func_info="tensorflow::Spectrogram" content="36: #include &lt;vector&gt;
37: 
38: #include &quot;third_party/fft2d/fft.h&quot;
39: #include &quot;map/base/mlp/tf/tensorflow/core/framework/op_kernel.h&quot;
40: #include &quot;map/base/mlp/tf/tensorflow/core/framework/tensor.h&quot;
41: 
42: namespace tensorflow {
43: 
44: class Spectrogram {
45:  public:
46:   Spectrogram() : initialized_(false) {}
47:   ~Spectrogram() {}
48: 
49:   // Initializes the class with a given window length and step length
50:   // (both in samples). Internally a Hann window is used as the window
51:   // function. Returns true on success, after which calls to Process()
52:   // are possible. window_length must be greater than 1 and step
53:   // length must be greater than 0.
54:   bool Initialize(int window_length, int step_length);
55: 
56:   // Initialize with an explicit window instead of a length.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/gif/gif_io.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gif_file] to null at line 65 implies that [gif_file ] might be null.Dereferencing null pointer [gif_file]." web_identify="{&quot;identify&quot;:&quot;gif_file&quot;}" func_info="char * gif::Decode ( const void * srcdata , int datasize , const std :: function &lt; char * ( int , int , int , int ) &gt; &amp; allocate_output , string * error_string )" content="67:                    &lt;&lt; GifErrorStringNonNull(error_code);
68:     }
69:   });
70:   if (error_code != D_GIF_SUCCEEDED) {
71:     *error_string = strings::StrCat(&quot;failed to open gif file: &quot;,
72:                                     GifErrorStringNonNull(error_code));
73:     return nullptr;
74:   }
75:   if (DGifSlurp(gif_file) != GIF_OK) {
76:     *error_string = strings::StrCat(&quot;failed to slurp gif file: &quot;,
77:                                     GifErrorStringNonNull(gif_file-&gt;Error));
78:     return nullptr;
79:   }
80:   if (gif_file-&gt;ImageCount &lt;= 0) {
81:     *error_string = strings::StrCat(&quot;gif file does not contain any image&quot;);
82:     return nullptr;
83:   }
84: 
85:   const int num_frames = gif_file-&gt;ImageCount;
86:   const int width = gif_file-&gt;SWidth;
87:   const int height = gif_file-&gt;SHeight;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/gtl/inlined_vector.h" line="296" id="compute" subid="SizeofForPointerSize" severity="Warning" msg="Use sizeof data of &apos;ptr&apos; instead of sizeof the pointer." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="T * InlinedVector::outofline_pointer ( ) const" content="286:     unsigned char data[kSize];
287:     // Force data to be aligned enough for a pointer.
288:     T* unused_aligner;
289:   } u_;
290: 
291:   inline void InitRep() { u_.data[kSize - 1] = 0; }
292:   inline bool is_inline() const { return u_.data[kSize - 1] != kSentinel; }
293: 
294:   inline T* outofline_pointer() const {
295:     T* ptr;
296:     memcpy(&amp;ptr, &amp;u_.data[0], sizeof(ptr));
297:     return ptr;
298:   }
299: 
300:   inline void set_outofline_pointer(T* p) {
301:     memcpy(&amp;u_.data[0], &amp;p, sizeof(p));
302:   }
303: 
304:   inline uint64_t outofline_word() const {
305:     uint64_t word;
306:     memcpy(&amp;word, &amp;u_.data[kSize - 8], sizeof(word));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/gtl/top_n.h" line="304" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 303 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; void TopN &lt; T , Cmp &gt;::ExtractNondestructive ( std::vector &lt; T &gt; * output ) const" content="294: template &lt;class T, class Cmp&gt;
295: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractNondestructive() const {
296:   auto out = new std::vector&lt;T&gt;;
297:   ExtractNondestructive(out);
298:   return out;
299: }
300: 
301: template &lt;class T, class Cmp&gt;
302: void TopN&lt;T, Cmp&gt;::ExtractNondestructive(std::vector&lt;T&gt; *output) const {
303:   CHECK(output);
304:   *output = elements_;
305:   if (state_ != HEAP_SORTED) {
306:     std::sort(output-&gt;begin(), output-&gt;end(), cmp_);
307:   } else {
308:     output-&gt;pop_back();
309:     std::sort_heap(output-&gt;begin(), output-&gt;end(), cmp_);
310:   }
311: }
312: 
313: template &lt;class T, class Cmp&gt;
314: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive() const {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/gtl/top_n.h" line="323" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 322 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; void TopN &lt; T , Cmp &gt;::ExtractUnsortedNondestructive ( std::vector &lt; T &gt; * output ) const" content="313: template &lt;class T, class Cmp&gt;
314: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive() const {
315:   auto elements = new std::vector&lt;T&gt;;
316:   ExtractUnsortedNondestructive(elements);
317:   return elements;
318: }
319: 
320: template &lt;class T, class Cmp&gt;
321: void TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive(std::vector&lt;T&gt; *output) const {
322:   CHECK(output);
323:   *output = elements_;
324:   if (state_ == HEAP_SORTED) {
325:     // Remove the limit_+1&apos;th element.
326:     output-&gt;pop_back();
327:   }
328: }
329: 
330: template &lt;class T, class Cmp&gt;
331: void TopN&lt;T, Cmp&gt;::Reset() {
332:   elements_.clear();
333:   state_ = UNORDERED;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/io/snappy/snappy_inputbuffer.cc" line="20" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SnappyInputBuffer::next_out_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SnappyInputBuffer::next_out_,&quot;}" func_info="tensorflow::io" content="10: distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
11: WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12: See the License for the specific language governing permissions and
13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/core/lib/io/snappy/snappy_inputbuffer.h&quot;
17: 
18: namespace tensorflow {
19: namespace io {
20: SnappyInputBuffer::SnappyInputBuffer(
21:     RandomAccessFile* file,
22:     size_t input_buffer_bytes,  // size of input_buffer_
23:     size_t output_buffer_bytes  // size of output_buffer_
24:     )
25:     : file_(file),
26:       input_buffer_capacity_(input_buffer_bytes),
27:       output_buffer_capacity_(output_buffer_bytes),
28:       input_buffer_(new char[input_buffer_capacity_]),
29:       output_buffer_(new char[output_buffer_capacity_]),
30:       next_in_(input_buffer_.get()) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/jpeg/jpeg_mem.cc" line="607" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [output] suggests that it may be null, but it has already been dereferenced at line 580. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="bool CompressInternal ( const char * srcdata , int width , int height , const CompressFlags &amp; flags , string * output )" content="597:     in_stride = width * (static_cast&lt;int&gt;(flags.format) &amp; 0xff);
598:   } else if (in_stride &lt; width * components) {
599:     LOG(ERROR) &lt;&lt; &quot;Incompatible input stride&quot;;
600:     return false;
601:   }
602: 
603:   JOCTET* buffer = nullptr;
604: 
605:   // NOTE: for broader use xmp_metadata should be made a unicode string
606:   CHECK(srcdata != nullptr);
607:   CHECK(output != nullptr);
608:   // This struct contains the JPEG compression parameters and pointers to
609:   // working space
610:   struct jpeg_compress_struct cinfo;
611:   // This struct represents a JPEG error handler.
612:   struct jpeg_error_mgr jerr;
613:   jmp_buf jpeg_jmpbuf;  // recovery point in case of error
614: 
615:   // Step 1: allocate and initialize JPEG compression object
616:   // Use the usual jpeg error manager.
617:   cinfo.err = jpeg_std_error(&amp;jerr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/jpeg/jpeg_mem.cc" line="709" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [srcdata] to null at line 606 implies that [srcdata ] might be null.Dereferencing null pointer [srcdata]." web_identify="{&quot;identify&quot;:&quot;srcdata&quot;}" func_info="bool CompressInternal ( const char * srcdata , int width , int height , const CompressFlags &amp; flags , string * output )" content="699:     }
700:     jpeg_write_marker(&amp;cinfo, JPEG_APP0 + 1, joctet_packet.get(),
701:                       packet_length);
702:   }
703: 
704:   // JSAMPLEs per row in image_buffer
705:   std::unique_ptr&lt;JSAMPLE[]&gt; row_temp(
706:       new JSAMPLE[width * cinfo.input_components]);
707:   while (cinfo.next_scanline &lt; cinfo.image_height) {
708:     JSAMPROW row_pointer[1];  // pointer to JSAMPLE row[s]
709:     const uint8* r = &amp;srcdata[cinfo.next_scanline * in_stride];
710:     uint8* p = static_cast&lt;uint8*&gt;(row_temp.get());
711:     switch (flags.format) {
712:       case FORMAT_RGBA: {
713:         for (int i = 0; i &lt; width; ++i, p += 3, r += 4) {
714:           p[0] = r[0];
715:           p[1] = r[1];
716:           p[2] = r[2];
717:         }
718:         row_pointer[0] = row_temp.get();
719:         break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/png/png_io.h" line="57" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DecodeContext::data,data_left,num_passes,color_type,bit_depth,channels,need_to_synthesize_16,error_condition,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DecodeContext::data,data_left,num_passes,color_type,bit_depth,channels,need_to_synthesize_16,error_condition,&quot;}" func_info="tensorflow::png::DecodeContext" content="47:   int data_left;
48:   png_structp png_ptr;
49:   png_infop info_ptr;
50:   png_uint_32 width, height;
51:   int num_passes;
52:   int color_type;
53:   int bit_depth;
54:   int channels;
55:   bool need_to_synthesize_16;
56:   bool error_condition;
57:   DecodeContext() : png_ptr(NULL), info_ptr(NULL) {}
58: };
59: 
60: bool DecodeHeader(StringPiece png_string, int* width, int* height,
61:                   int* components, int* channel_bit_depth,
62:                   std::vector&lt;std::pair&lt;string, string&gt; &gt;* metadata);
63: 
64: // Sample usage for reading PNG:
65: //
66: // string png_string;  /* fill with input PNG format data */
67: // DecodeContext context;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/numbers.cc" line="105" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [endptr] suggests that it may be null, but it has already been dereferenced at line 71." web_identify="{&quot;identify&quot;:&quot;endptr&quot;}" func_info="&gt; T locale_independent_strtonum ( const char * str , const char * * endptr )" content="95:         result == std::numeric_limits&lt;T&gt;::infinity()) {
96:       result = std::numeric_limits&lt;T&gt;::infinity();
97:       s.clear(s.rdstate() &amp; ~std::ios::failbit);
98:     } else if (result == -std::numeric_limits&lt;T&gt;::max() ||
99:                result == -std::numeric_limits&lt;T&gt;::infinity()) {
100:       result = -std::numeric_limits&lt;T&gt;::infinity();
101:       s.clear(s.rdstate() &amp; ~std::ios::failbit);
102:     }
103:   }
104: 
105:   if (endptr) {
106:     *endptr =
107:         str +
108:         (s.fail() ? static_cast&lt;std::iostream::pos_type&gt;(0)
109:                   : (s.eof() ? static_cast&lt;std::iostream::pos_type&gt;(strlen(str))
110:                              : s.tellg()));
111:   }
112:   return result;
113: }
114: 
115: static inline const double_conversion::StringToDoubleConverter&amp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="103" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="93:                                  : sizeof(v) == 4 ? static_cast&lt;uint32&gt;(v)
94:                                                   : static_cast&lt;uint64&gt;(v);
95:   }
96: };
97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="105" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="95:   }
96: };
97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="107" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="109" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="111" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="113" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="116" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="118" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="123" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="124" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
134:   char digits_[kFastToBufferSize];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/lib/strings/strcat.h" line="125" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
134:   char digits_[kFastToBufferSize];
135: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/ops/array_ops.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [perm] to null at line 122 implies that [perm ] might be null.Dereferencing null pointer [perm]." web_identify="{&quot;identify&quot;:&quot;perm&quot;}" func_info="Status TransposeShapeFn ( InferenceContext * c )" content="124:     return Status::OK();
125:   }
126: 
127:   // Find our value of the rank.
128:   int64 rank;
129:   if (c-&gt;RankKnown(input)) {
130:     rank = c-&gt;Rank(input);
131:   } else if (c-&gt;ValueKnown(perm_elems)) {
132:     rank = c-&gt;Value(perm_elems);
133:   } else {
134:     rank = perm-&gt;NumElements();
135:   }
136:   std::vector&lt;DimensionHandle&gt; dims;
137:   dims.resize(rank);
138:   TF_RETURN_IF_ERROR(c-&gt;WithRank(input, rank, &amp;input));
139:   // Ensure that perm is a vector and has rank elements.
140:   TF_RETURN_IF_ERROR(c-&gt;WithRank(perm_shape, 1, &amp;perm_shape));
141:   TF_RETURN_IF_ERROR(c-&gt;WithValue(perm_elems, rank, &amp;perm_elems));
142: 
143:   // If we know the rank of the input and the value of perm, we can return
144:   // all shape informantion, otherwise we can only return rank information,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request.cc" line="299" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [out_buffer] to null at line 297 implies that [out_buffer ] might be null.Dereferencing null pointer [out_buffer]." web_identify="{&quot;identify&quot;:&quot;out_buffer&quot;}" func_info="void CurlHttpRequest::SetResultBuffer ( std::vector &lt; char &gt; * out_buffer )" content="289:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_READDATA,
290:                                            reinterpret_cast&lt;void*&gt;(this)));
291:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_READFUNCTION,
292:                                            &amp;CurlHttpRequest::ReadCallback));
293: }
294: 
295: void CurlHttpRequest::SetResultBuffer(std::vector&lt;char&gt;* out_buffer) {
296:   CheckNotSent();
297:   CHECK(out_buffer != nullptr);
298: 
299:   out_buffer-&gt;clear();
300:   response_buffer_ = out_buffer;
301: 
302:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_WRITEDATA,
303:                                            reinterpret_cast&lt;void*&gt;(this)));
304:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_WRITEFUNCTION,
305:                                            &amp;CurlHttpRequest::WriteCallback));
306: }
307: 
308: void CurlHttpRequest::SetResultBufferDirect(char* buffer, size_t size) {
309:   CHECK(buffer != nullptr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request.cc" line="336" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ptr] to null at line 325 implies that [ptr ] might be null.Dereferencing null pointer [ptr]." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="long CurlHttpRequest::WriteCallbackDirect ( const void * ptr , long size , long nmemb , void * userdata )" content="326:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(userdata);
327:   DirectResponseState* state = &amp;that-&gt;direct_response_;
328:   CHECK(state-&gt;buffer_ != nullptr);
329:   CHECK(state-&gt;bytes_transferred_ &lt;= state-&gt;buffer_size_);
330: 
331:   size_t curl_bytes_received = size * nmemb;
332:   size_t user_buffer_bytes_available =
333:       state-&gt;buffer_size_ - state-&gt;bytes_transferred_;
334:   size_t bytes_to_copy =
335:       std::min&lt;size_t&gt;(curl_bytes_received, user_buffer_bytes_available);
336:   memcpy(&amp;state-&gt;buffer_[state-&gt;bytes_transferred_], ptr, bytes_to_copy);
337:   state-&gt;bytes_transferred_ += bytes_to_copy;
338:   state-&gt;bytes_received_ += curl_bytes_received;
339:   // If we didn&apos;t have room to store the full response, returning less than
340:   // curl_bytes_received here will abort the transfer and curl_easy_perform()
341:   // will return CURLE_WRITE_ERROR. We will detect and handle this error there,
342:   // and can use state-&gt;bytes_received_ as stored above for logging purposes.
343:   return bytes_to_copy;
344: }
345: 
346: size_t CurlHttpRequest::GetResultBufferDirectBytesTransferred() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request.cc" line="336" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [state.buffer_] to null at line 328 implies that [state.buffer_ ] might be null.Dereferencing null pointer [state.buffer_]." web_identify="{&quot;identify&quot;:&quot;state.buffer_&quot;}" func_info="long CurlHttpRequest::WriteCallbackDirect ( const void * ptr , long size , long nmemb , void * userdata )" content="326:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(userdata);
327:   DirectResponseState* state = &amp;that-&gt;direct_response_;
328:   CHECK(state-&gt;buffer_ != nullptr);
329:   CHECK(state-&gt;bytes_transferred_ &lt;= state-&gt;buffer_size_);
330: 
331:   size_t curl_bytes_received = size * nmemb;
332:   size_t user_buffer_bytes_available =
333:       state-&gt;buffer_size_ - state-&gt;bytes_transferred_;
334:   size_t bytes_to_copy =
335:       std::min&lt;size_t&gt;(curl_bytes_received, user_buffer_bytes_available);
336:   memcpy(&amp;state-&gt;buffer_[state-&gt;bytes_transferred_], ptr, bytes_to_copy);
337:   state-&gt;bytes_transferred_ += bytes_to_copy;
338:   state-&gt;bytes_received_ += curl_bytes_received;
339:   // If we didn&apos;t have room to store the full response, returning less than
340:   // curl_bytes_received here will abort the transfer and curl_easy_perform()
341:   // will return CURLE_WRITE_ERROR. We will detect and handle this error there,
342:   // and can use state-&gt;bytes_received_ as stored above for logging purposes.
343:   return bytes_to_copy;
344: }
345: 
346: size_t CurlHttpRequest::GetResultBufferDirectBytesTransferred() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request.cc" line="365" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [that.response_buffer_] to null at line 363 implies that [that.response_buffer_ ] might be null.Dereferencing null pointer [that.response_buffer_]." web_identify="{&quot;identify&quot;:&quot;that.response_buffer_&quot;}" func_info="long CurlHttpRequest::WriteCallback ( const void * ptr , long size , long nmemb , void * this_object )" content="355:   inactivity_timeout_secs_ = inactivity;
356:   request_timeout_secs_ = total;
357: }
358: 
359: size_t CurlHttpRequest::WriteCallback(const void* ptr, size_t size,
360:                                       size_t nmemb, void* this_object) {
361:   CHECK(ptr);
362:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
363:   CHECK(that-&gt;response_buffer_);
364:   const size_t bytes_to_copy = size * nmemb;
365:   that-&gt;response_buffer_-&gt;insert(
366:       that-&gt;response_buffer_-&gt;end(), reinterpret_cast&lt;const char*&gt;(ptr),
367:       reinterpret_cast&lt;const char*&gt;(ptr) + bytes_to_copy);
368: 
369:   return bytes_to_copy;
370: }
371: 
372: size_t CurlHttpRequest::ReadCallback(void* ptr, size_t size, size_t nmemb,
373:                                      FILE* this_object) {
374:   CHECK(ptr);
375:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request.cc" line="379" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ptr] to null at line 374 implies that [ptr ] might be null.Dereferencing null pointer [ptr]." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="long CurlHttpRequest::ReadCallback ( void * ptr , long size , long nmemb , FILE * this_object )" content="369:   return bytes_to_copy;
370: }
371: 
372: size_t CurlHttpRequest::ReadCallback(void* ptr, size_t size, size_t nmemb,
373:                                      FILE* this_object) {
374:   CHECK(ptr);
375:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
376:   CHECK(that-&gt;post_body_read_ &lt;= that-&gt;post_body_buffer_.size());
377:   const size_t bytes_to_copy = std::min(
378:       size * nmemb, that-&gt;post_body_buffer_.size() - that-&gt;post_body_read_);
379:   memcpy(ptr, that-&gt;post_body_buffer_.data() + that-&gt;post_body_read_,
380:          bytes_to_copy);
381:   that-&gt;post_body_read_ += bytes_to_copy;
382:   return bytes_to_copy;
383: }
384: 
385: size_t CurlHttpRequest::HeaderCallback(const void* ptr, size_t size,
386:                                        size_t nmemb, void* this_object) {
387:   CHECK(ptr);
388:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
389:   StringPiece header(reinterpret_cast&lt;const char*&gt;(ptr), size * nmemb);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cloud/curl_http_request_test.cc" line="716" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;StatsTestFakeLibCurl::stats_had_recorded_request_,stats_had_recorded_response_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;StatsTestFakeLibCurl::stats_had_recorded_request_,stats_had_recorded_response_,&quot;}" func_info="StatsTestFakeLibCurl" content="706:   HttpRequest::RequestMethod record_response_method_ =
707:       HttpRequest::RequestMethod::kGet;
708:   Status record_response_result_;
709: 
710:   bool has_recorded_request_ = false;
711:   bool has_recorded_response_ = false;
712: };
713: 
714: class StatsTestFakeLibCurl : public FakeLibCurl {
715:  public:
716:   StatsTestFakeLibCurl(TestStats* stats, const string&amp; response_content,
717:                        uint64 response_code)
718:       : FakeLibCurl(response_content, response_code), stats_(stats) {}
719:   CURLcode curl_easy_perform(CURL* curl) override {
720:     CHECK(!performed_request_);
721:     performed_request_ = true;
722:     stats_had_recorded_request_ = stats_-&gt;has_recorded_request_;
723:     stats_had_recorded_response_ = stats_-&gt;has_recorded_response_;
724:     return FakeLibCurl::curl_easy_perform(curl);
725:   };
726: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/cpu_info.cc" line="72" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CPUIDInfo::family_,model_num_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CPUIDInfo::family_,model_num_,&quot;}" func_info="CPUIDInfo" content="62: int GetXCR0EAX() {
63:   int eax, edx;
64:   asm(&quot;XGETBV&quot; : &quot;=a&quot;(eax), &quot;=d&quot;(edx) : &quot;c&quot;(0));
65:   return eax;
66: }
67: #endif
68: 
69: // Structure for basic CPUID info
70: class CPUIDInfo {
71:  public:
72:   CPUIDInfo()
73:       : have_adx_(0),
74:         have_aes_(0),
75:         have_avx_(0),
76:         have_avx2_(0),
77:         have_avx512f_(0),
78:         have_avx512cd_(0),
79:         have_avx512er_(0),
80:         have_avx512pf_(0),
81:         have_avx512vl_(0),
82:         have_avx512bw_(0),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/env.cc" line="449" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FileStream::scratch_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FileStream::scratch_,&quot;}" func_info="FileStream" content="439:     TF_RETURN_IF_ERROR(target_file-&gt;Append(result));
440:     offset += result.size();
441:   }
442:   return target_file-&gt;Close();
443: }
444: 
445: // A ZeroCopyInputStream on a RandomAccessFile.
446: namespace {
447: class FileStream : public ::tensorflow::protobuf::io::ZeroCopyInputStream {
448:  public:
449:   explicit FileStream(RandomAccessFile* file) : file_(file), pos_(0) {}
450: 
451:   void BackUp(int count) override { pos_ -= count; }
452:   bool Skip(int count) override {
453:     pos_ += count;
454:     return true;
455:   }
456:   protobuf_int64 ByteCount() const override { return pos_; }
457:   Status status() const { return status_; }
458: 
459:   bool Next(const void** data, int* size) override {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/posix/subprocess.cc" line="255" id="memleak" subid="resourceLeak" severity="Warning" msg="Resource leak: devnull_fd" web_identify="{&quot;identify&quot;:&quot;devnull_fd&quot;}" func_info="" content="245:         close(child_pipe_[i]);
246:         child_pipe_[i] = -1;
247:         break;
248: 
249:       case ACTION_CLOSE:
250:       default:
251:         // Do not close stdin/out/err, instead redirect them to /dev/null so
252:         // their file descriptors remain unavailable for reuse by open(), etc.
253:         if (i &lt;= CHAN_STDERR) {
254:           if (devnull_fd &lt; 0) {
255:             while ((devnull_fd = open(&quot;/dev/null&quot;, O_RDWR, 0)) &lt; 0) {
256:               if (!retry(errno)) {
257:                 _exit(1);
258:               }
259:             }
260:           }
261:           while (dup2(devnull_fd, i) &lt; 0) {
262:             if (!retry(errno)) {
263:               _exit(1);
264:             }
265:           }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/vmodule_test.cc" line="80" id="memleak" subid="resourceLeak" severity="Warning" msg="Resource leak: f" web_identify="{&quot;identify&quot;:&quot;f&quot;}" func_info="" content="70:     return EXIT_FAILURE;
71:   }
72: 
73:   // Read data from the child&apos;s stdout.
74:   constexpr int kBufferSizeBytes = 4096;
75:   char buffer[kBufferSizeBytes];
76:   size_t result = fread(buffer, sizeof(buffer[0]), kBufferSizeBytes - 1, f);
77:   if (result == 0) {
78:     fprintf(stderr, &quot;Failed to read from child stdout: %zu %s\n&quot;, result,
79:             strerror(errno));
80:     return EXIT_FAILURE;
81:   }
82:   buffer[result] = &apos;\0&apos;;
83:   int status = pclose(f);
84:   if (status == -1) {
85:     fprintf(stderr, &quot;Failed to close popen child: %s\n&quot;, strerror(errno));
86:     return EXIT_FAILURE;
87:   }
88: 
89:   // Check output is as expected.
90:   const char kExpected[] =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/platform/windows/port.cc" line="160" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;data1e6*&quot;}" func_info="double port::NominalCPUFrequency ( )" content="150: string Demangle(const char* mangled) { return mangled; }
151: 
152: double NominalCPUFrequency() {
153:   DWORD data;
154:   DWORD data_size = sizeof(data);
155:   #pragma comment(lib, &quot;shlwapi.lib&quot;)  // For SHGetValue().
156:   if (SUCCEEDED(
157:           SHGetValueA(HKEY_LOCAL_MACHINE,
158:                       &quot;HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0&quot;,
159:                       &quot;~MHz&quot;, nullptr, &amp;data, &amp;data_size))) {
160:     return data * 1e6;  // Value is MHz.
161:   }
162:   return 1.0;
163: }
164: 
165: int64 AvailableRam() {
166:   MEMORYSTATUSEX statex;
167:   statex.dwLength = sizeof(statex);
168:   if (GlobalMemoryStatusEx(&amp;statex)) {
169:     return statex.ullAvailPhys;
170:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="113" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [filename] to null at line 112 implies that [filename ] might be null.Dereferencing null pointer [filename]." web_identify="{&quot;identify&quot;:&quot;filename&quot;}" func_info="void tfprof::ProfilerFromFile ( const string * filename )" content="103:     }
104:   }
105:   tf_stat = new TFStats(std::move(graph_ptr), nullptr, std::move(op_log_ptr),
106:                         nullptr);
107:   return true;
108: }
109: 
110: void ProfilerFromFile(const string* filename) {
111:   CHECK(!tf_stat) &lt;&lt; &quot;Currently only 1 living tfprof profiler is allowed&quot;;
112:   CHECK(filename) &lt;&lt; &quot;Missing profile filename to init profiler from file&quot;;
113:   tf_stat = new TFStats(*filename, nullptr);
114: }
115: 
116: void DeleteProfiler() {
117:   if (tf_stat) {
118:     delete tf_stat;
119:     tf_stat = nullptr;
120:   }
121: }
122: 
123: double AddStep(int64 step, const string* graph, const string* run_meta,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 125 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="double tfprof::AddStep ( long step , const string * graph , const string * run_meta , const string * op_log )" content="124:                const string* op_log) {
125:   CHECK(tf_stat);
126: 
127:   if (graph &amp;&amp; !graph-&gt;empty()) {
128:     std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
129:     if (!graph_ptr-&gt;ParseFromString(*graph)) {
130:       if (!protobuf::TextFormat::ParseFromString(*graph, graph_ptr.get())) {
131:         fprintf(stderr, &quot;Failed to parse graph\n&quot;);
132:       }
133:     }
134:     tf_stat-&gt;AddGraph(std::move(graph_ptr));
135:   }
136: 
137:   CHECK(run_meta &amp;&amp; !run_meta-&gt;empty());
138:   // TODO(xpan): Better error handling.
139:   std::unique_ptr&lt;RunMetadata&gt; run_meta_ptr(new RunMetadata());
140:   run_meta_ptr-&gt;ParseFromString(*run_meta);
141:   tf_stat-&gt;AddRunMeta(step, std::move(run_meta_ptr));
142: 
143:   if (op_log &amp;&amp; !op_log-&gt;empty()) {
144:     std::unique_ptr&lt;OpLogProto&gt; op_log_ptr;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="140" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [run_meta] to null at line 137 implies that [run_meta ] might be null.Dereferencing null pointer [run_meta]." web_identify="{&quot;identify&quot;:&quot;run_meta&quot;}" func_info="double tfprof::AddStep ( long step , const string * graph , const string * run_meta , const string * op_log )" content="130:       if (!protobuf::TextFormat::ParseFromString(*graph, graph_ptr.get())) {
131:         fprintf(stderr, &quot;Failed to parse graph\n&quot;);
132:       }
133:     }
134:     tf_stat-&gt;AddGraph(std::move(graph_ptr));
135:   }
136: 
137:   CHECK(run_meta &amp;&amp; !run_meta-&gt;empty());
138:   // TODO(xpan): Better error handling.
139:   std::unique_ptr&lt;RunMetadata&gt; run_meta_ptr(new RunMetadata());
140:   run_meta_ptr-&gt;ParseFromString(*run_meta);
141:   tf_stat-&gt;AddRunMeta(step, std::move(run_meta_ptr));
142: 
143:   if (op_log &amp;&amp; !op_log-&gt;empty()) {
144:     std::unique_ptr&lt;OpLogProto&gt; op_log_ptr;
145:     op_log_ptr.reset(new OpLogProto());
146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [command] to null at line 154 implies that [command ] might be null.Dereferencing null pointer [command]." web_identify="{&quot;identify&quot;:&quot;command&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options] to null at line 155 implies that [options ] might be null.Dereferencing null pointer [options]." web_identify="{&quot;identify&quot;:&quot;options&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 153 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="162" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 160 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="string tfprof::SerializeToString ( )" content="152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="169" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [filename] to null at line 168 implies that [filename ] might be null.Dereferencing null pointer [filename]." web_identify="{&quot;identify&quot;:&quot;filename&quot;}" func_info="void tfprof::WriteProfile ( const string * filename )" content="159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
173:                           const string* op_log, const string* command,
174:                           const string* options) {
175:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
176:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
177:   std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
178:   if (graph &amp;&amp; !graph-&gt;empty()) {
179:     graph_ptr-&gt;ParseFromString(*graph);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="169" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 167 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="void tfprof::WriteProfile ( const string * filename )" content="159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
173:                           const string* op_log, const string* command,
174:                           const string* options) {
175:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
176:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
177:   std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
178:   if (graph &amp;&amp; !graph-&gt;empty()) {
179:     graph_ptr-&gt;ParseFromString(*graph);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [command] to null at line 175 implies that [command ] might be null.Dereferencing null pointer [command]." web_identify="{&quot;identify&quot;:&quot;command&quot;}" func_info="string tfprof::PrintModelAnalysis ( const string * graph , const string * run_meta , const string * op_log , const string * command , const string * options )" content="190:     op_log_ptr.reset(new OpLogProto());
191:     op_log_ptr-&gt;ParseFromString(*op_log);
192:   }
193: 
194:   // TODO(xpan): Maybe need to init the checkpoint reader?
195:   std::unique_ptr&lt;checkpoint::CheckpointReader&gt; ckpt_reader;
196: 
197:   TFStats tf_stats(std::move(graph_ptr), std::move(run_meta_ptr),
198:                    std::move(op_log_ptr), std::move(ckpt_reader));
199: 
200:   return RunProfile(*command, *options, &amp;tf_stats);
201: }
202: 
203: }  // namespace tfprof
204: }  // namespace tensorflow
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/print_model_analysis.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options] to null at line 176 implies that [options ] might be null.Dereferencing null pointer [options]." web_identify="{&quot;identify&quot;:&quot;options&quot;}" func_info="string tfprof::PrintModelAnalysis ( const string * graph , const string * run_meta , const string * op_log , const string * command , const string * options )" content="190:     op_log_ptr.reset(new OpLogProto());
191:     op_log_ptr-&gt;ParseFromString(*op_log);
192:   }
193: 
194:   // TODO(xpan): Maybe need to init the checkpoint reader?
195:   std::unique_ptr&lt;checkpoint::CheckpointReader&gt; ckpt_reader;
196: 
197:   TFStats tf_stats(std::move(graph_ptr), std::move(run_meta_ptr),
198:                    std::move(op_log_ptr), std::move(ckpt_reader));
199: 
200:   return RunProfile(*command, *options, &amp;tf_stats);
201: }
202: 
203: }  // namespace tfprof
204: }  // namespace tensorflow
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/profiler/internal/tfprof_utils.cc" line="103" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [value] to null at line 100 implies that [value ] might be null.Dereferencing null pointer [value]." web_identify="{&quot;identify&quot;:&quot;value&quot;}" func_info="bool StringToBool ( StringPiece str , bool * value )" content="93: 
94: bool CaseEqual(StringPiece s1, StringPiece s2) {
95:   if (s1.size() != s2.size()) return false;
96:   return str_util::Lowercase(s1) == str_util::Lowercase(s2);
97: }
98: 
99: bool StringToBool(StringPiece str, bool* value) {
100:   CHECK(value != nullptr) &lt;&lt; &quot;NULL output boolean given.&quot;;
101:   if (CaseEqual(str, &quot;true&quot;) || CaseEqual(str, &quot;t&quot;) || CaseEqual(str, &quot;yes&quot;) ||
102:       CaseEqual(str, &quot;y&quot;) || CaseEqual(str, &quot;1&quot;)) {
103:     *value = true;
104:     return true;
105:   }
106:   if (CaseEqual(str, &quot;false&quot;) || CaseEqual(str, &quot;f&quot;) || CaseEqual(str, &quot;no&quot;) ||
107:       CaseEqual(str, &quot;n&quot;) || CaseEqual(str, &quot;0&quot;)) {
108:     *value = false;
109:     return true;
110:   }
111:   return false;
112: }
113: }  // namespace
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="158" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="148: Flag::Flag(const char* name, tensorflow::int64* dst, const string&amp; usage_text)
149:     : name_(name),
150:       type_(TYPE_INT64),
151:       int64_hook_([dst](int64 value) {
152:         *dst = value;
153:         return true;
154:       }),
155:       int64_default_for_display_(*dst),
156:       usage_text_(usage_text) {}
157: 
158: Flag::Flag(const char* name, float* dst, const string&amp; usage_text)
159:     : name_(name),
160:       type_(TYPE_FLOAT),
161:       float_hook_([dst](float value) {
162:         *dst = value;
163:         return true;
164:       }),
165:       float_default_for_display_(*dst),
166:       usage_text_(usage_text) {}
167: 
168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="168" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&quot;}" func_info="tensorflow" content="158: Flag::Flag(const char* name, float* dst, const string&amp; usage_text)
159:     : name_(name),
160:       type_(TYPE_FLOAT),
161:       float_hook_([dst](float value) {
162:         *dst = value;
163:         return true;
164:       }),
165:       float_default_for_display_(*dst),
166:       usage_text_(usage_text) {}
167: 
168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
169:     : name_(name),
170:       type_(TYPE_BOOL),
171:       bool_hook_([dst](bool value) {
172:         *dst = value;
173:         return true;
174:       }),
175:       bool_default_for_display_(*dst),
176:       usage_text_(usage_text) {}
177: 
178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="178" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
169:     : name_(name),
170:       type_(TYPE_BOOL),
171:       bool_hook_([dst](bool value) {
172:         *dst = value;
173:         return true;
174:       }),
175:       bool_default_for_display_(*dst),
176:       usage_text_(usage_text) {}
177: 
178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
179:     : name_(name),
180:       type_(TYPE_STRING),
181:       string_hook_([dst](string value) {
182:         *dst = std::move(value);
183:         return true;
184:       }),
185:       string_default_for_display_(*dst),
186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="188" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
179:     : name_(name),
180:       type_(TYPE_STRING),
181:       string_hook_([dst](string value) {
182:         *dst = std::move(value);
183:         return true;
184:       }),
185:       string_default_for_display_(*dst),
186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
189:            int32 default_value_for_display, const string&amp; usage_text)
190:     : name_(name),
191:       type_(TYPE_INT32),
192:       int32_hook_(std::move(int32_hook)),
193:       int32_default_for_display_(default_value_for_display),
194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="196" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
189:            int32 default_value_for_display, const string&amp; usage_text)
190:     : name_(name),
191:       type_(TYPE_INT32),
192:       int32_hook_(std::move(int32_hook)),
193:       int32_default_for_display_(default_value_for_display),
194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
199:       type_(TYPE_INT64),
200:       int64_hook_(std::move(int64_hook)),
201:       int64_default_for_display_(default_value_for_display),
202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="204" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
199:       type_(TYPE_INT64),
200:       int64_hook_(std::move(int64_hook)),
201:       int64_default_for_display_(default_value_for_display),
202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
207:       type_(TYPE_FLOAT),
208:       float_hook_(std::move(float_hook)),
209:       float_default_for_display_(default_value_for_display),
210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="212" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&quot;}" func_info="tensorflow" content="202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
207:       type_(TYPE_FLOAT),
208:       float_hook_(std::move(float_hook)),
209:       float_default_for_display_(default_value_for_display),
210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
215:       type_(TYPE_BOOL),
216:       bool_hook_(std::move(bool_hook)),
217:       bool_default_for_display_(default_value_for_display),
218:       usage_text_(usage_text) {}
219: 
220: Flag::Flag(const char* name, std::function&lt;bool(string)&gt; string_hook,
221:            string default_value_for_display, const string&amp; usage_text)
222:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/command_line_flags.cc" line="220" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
215:       type_(TYPE_BOOL),
216:       bool_hook_(std::move(bool_hook)),
217:       bool_default_for_display_(default_value_for_display),
218:       usage_text_(usage_text) {}
219: 
220: Flag::Flag(const char* name, std::function&lt;bool(string)&gt; string_hook,
221:            string default_value_for_display, const string&amp; usage_text)
222:     : name_(name),
223:       type_(TYPE_STRING),
224:       string_hook_(std::move(string_hook)),
225:       string_default_for_display_(std::move(default_value_for_display)),
226:       usage_text_(usage_text) {}
227: 
228: bool Flag::Parse(string arg, bool* value_parsing_ok) const {
229:   bool result = false;
230:   if (type_ == TYPE_INT32) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/events_writer.cc" line="109" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [recordio_writer_] to null at line 102 implies that [recordio_writer_ ] might be null.Dereferencing null pointer [recordio_writer_]." web_identify="{&quot;identify&quot;:&quot;recordio_writer_&quot;}" func_info="void EventsWriter::WriteSerializedEvent ( StringPiece event_str )" content="99: }
100: 
101: void EventsWriter::WriteSerializedEvent(StringPiece event_str) {
102:   if (recordio_writer_ == nullptr) {
103:     if (!InitIfNeeded().ok()) {
104:       LOG(ERROR) &lt;&lt; &quot;Write failed because file could not be opened.&quot;;
105:       return;
106:     }
107:   }
108:   num_outstanding_events_++;
109:   recordio_writer_-&gt;WriteRecord(event_str).IgnoreError();
110: }
111: 
112: // NOTE(touts); This is NOT the function called by the Python code.
113: // Python calls WriteSerializedEvent(), see events_writer.i.
114: void EventsWriter::WriteEvent(const Event&amp; event) {
115:   string record;
116:   event.AppendToString(&amp;record);
117:   WriteSerializedEvent(record);
118: }
119: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/events_writer.cc" line="129" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [recordio_file_] to null at line 122 implies that [recordio_file_ ] might be null.Dereferencing null pointer [recordio_file_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;recordio_file_&quot;}" func_info="Status EventsWriter::Flush ( )" content="119: 
120: Status EventsWriter::Flush() {
121:   if (num_outstanding_events_ == 0) return Status::OK();
122:   CHECK(recordio_file_ != nullptr) &lt;&lt; &quot;Unexpected NULL file&quot;;
123: 
124:   TF_RETURN_WITH_CONTEXT_IF_ERROR(recordio_writer_-&gt;Flush(), &quot;Failed to flush &quot;,
125:                                   num_outstanding_events_, &quot; events to &quot;,
126:                                   filename_);
127:   TF_RETURN_WITH_CONTEXT_IF_ERROR(recordio_file_-&gt;Sync(), &quot;Failed to sync &quot;,
128:                                   num_outstanding_events_, &quot; events to &quot;,
129:                                   filename_);
130: 
131:   // The FileStillExists() condition is necessary because
132:   // recordio_writer_-&gt;Sync() can return OK even if the underlying
133:   // file has been deleted.  EventWriter.FileDeletionBeforeWriting
134:   // demonstrates this and will fail if the FileHasDisappeared()
135:   // condition is removed.
136:   // Also, we deliberately attempt to Sync() before checking for a
137:   // disappearing file, in case for some file system File::Exists() is
138:   // false after File::Open() but before File::Sync().
139:   TF_RETURN_WITH_CONTEXT_IF_ERROR(FileStillExists(), &quot;Failed to flush &quot;,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/presized_cuckoo_map.h" line="195" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CuckooPathQueue::queue_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CuckooPathQueue::queue_,&quot;}" func_info="tensorflow::PresizedCuckooMap::CuckooPathQueue" content="185:     int parent;       // To index in the visited array.
186:     int parent_slot;  // Which slot in our parent did we come from?  -1 == root.
187:   };
188: 
189:   // CuckooPathQueue is a trivial circular queue for path entries.
190:   // The caller is responsible for not inserting more than kMaxQueueSize
191:   // entries.  Each PresizedCuckooMap has one (heap-allocated) CuckooPathQueue
192:   // that it reuses across inserts.
193:   class CuckooPathQueue {
194:    public:
195:     CuckooPathQueue() : head_(0), tail_(0) {}
196: 
197:     void push_back(CuckooPathEntry e) {
198:       queue_[tail_] = e;
199:       tail_ = (tail_ + 1) % kMaxQueueSize;
200:     }
201: 
202:     CuckooPathEntry pop_front() {
203:       CuckooPathEntry&amp; e = queue_[head_];
204:       head_ = (head_ + 1) % kMaxQueueSize;
205:       return e;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/sparse/dim_comparator.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DimComparator::ix_order_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DimComparator::ix_order_,&quot;}" func_info="tensorflow::sparse::DimComparator" content="39: //    IX(ai,2) &lt; IX(bi,2).
40: // If IX(ai,2) == IX(bi,2), it compares
41: //    IX(ai,1) &lt; IX(bi,1).
42: //
43: // This can be used to sort a vector of row indices into IX according to
44: // the values in IX in particular columns (dimensions) of interest.
45: class DimComparator {
46:  public:
47:   typedef typename gtl::ArraySlice&lt;int64&gt; VarDimArray;
48: 
49:   DimComparator(const TTypes&lt;int64&gt;::Matrix&amp; ix, const VarDimArray&amp; order,
50:                 const VarDimArray&amp; shape)
51:       : ix_(ix), order_(order), dims_(shape.size()) {
52:     DCHECK_GT(order.size(), size_t{0}) &lt;&lt; &quot;Must order using at least one index&quot;;
53:     DCHECK_LE(order.size(), shape.size()) &lt;&lt; &quot;Can only sort up to dims&quot;;
54:     for (size_t d = 0; d &lt; order.size(); ++d) {
55:       DCHECK_GE(order[d], 0);
56:       DCHECK_LT(order[d], shape.size());
57:     }
58:   }
59: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/sparse/sparse_tensor.h" line="609" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [status] to null at line 602 implies that [status ] might be null.Dereferencing null pointer [status]." web_identify="{&quot;identify&quot;:&quot;status&quot;}" func_info="&gt; std::vector &lt; SparseTensor &gt; SparseTensor::Split ( const SparseTensor &amp; input_tensor , const int split_dim , const int num_split , Status * status )" content="599:   const int split_dim_size = input_tensor.shape()[split_dim];
600:   const int split_size = split_dim_size / num_split;
601: 
602:   if (!(num_split &gt; 0 &amp;&amp; num_split &lt;= split_dim_size) &amp;&amp; status != nullptr) {
603:     *status = Status(error::INVALID_ARGUMENT,
604:                      strings::StrCat(&quot;num_split must be in the interval (0, &quot;,
605:                                      split_dim_size, &quot;]&quot;));
606:     return {};
607:   }
608:   if (!(split_dim &gt;= 0 &amp;&amp; split_dim &lt; num_dim)) {
609:     *status = Status(
610:         error::INVALID_ARGUMENT,
611:         strings::StrCat(&quot;num_dim must be in the interval [0, &quot;, num_dim, &quot;)&quot;));
612:     return {};
613:   }
614: 
615:   const int residual = split_dim_size % num_split;
616:   for (int i = 0; i &lt; input_tensor.indices().dim_size(0); ++i) {
617:     const int dim = input_tensor.indices().matrix&lt;int64&gt;()(i, split_dim);
618:     int slice_index = GetSliceIndex(dim, split_size, residual);
619:     num_values[slice_index]++;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/sparse/sparse_tensor.h" line="615" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;num_split&gt;0&apos; is redundant or there is division by zero at line 615." web_identify="" func_info="&gt; std::vector &lt; SparseTensor &gt; SparseTensor::Split ( const SparseTensor &amp; input_tensor , const int split_dim , const int num_split , Status * status )" content="605:                                      split_dim_size, &quot;]&quot;));
606:     return {};
607:   }
608:   if (!(split_dim &gt;= 0 &amp;&amp; split_dim &lt; num_dim)) {
609:     *status = Status(
610:         error::INVALID_ARGUMENT,
611:         strings::StrCat(&quot;num_dim must be in the interval [0, &quot;, num_dim, &quot;)&quot;));
612:     return {};
613:   }
614: 
615:   const int residual = split_dim_size % num_split;
616:   for (int i = 0; i &lt; input_tensor.indices().dim_size(0); ++i) {
617:     const int dim = input_tensor.indices().matrix&lt;int64&gt;()(i, split_dim);
618:     int slice_index = GetSliceIndex(dim, split_size, residual);
619:     num_values[slice_index]++;
620:   }
621: 
622:   for (int i = 0; i &lt; num_split; ++i) {
623:     // TODO(ataei): Pass an allocator to avoid allocating large memory buffer.
624:     output_indices.emplace_back(DT_INT64,
625:                                 TensorShape({num_values[i], num_dim}));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="867" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 862 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::Lookup ( StringPiece key , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="857:   if (ret != val) delete ret;
858:   return Status::OK();
859: }
860: 
861: Status BundleReader::Lookup(StringPiece key, Tensor* val) {
862:   CHECK(val != nullptr);
863:   BundleEntryProto entry;
864:   TF_RETURN_IF_ERROR(GetBundleEntryProto(key, &amp;entry));
865: 
866:   if (entry.slices().empty()) {
867:     return GetValue(entry, val);
868:   } else {
869:     return GetSliceValue(
870:         key, entry,
871:         /* a full slice */ TensorSlice(TensorShape(entry.shape()).dims()), val);
872:   }
873: }
874: 
875: Status BundleReader::ReadCurrent(Tensor* val) {
876:   CHECK(val != nullptr);
877:   BundleEntryProto entry;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="885" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 876 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::ReadCurrent ( Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="875: Status BundleReader::ReadCurrent(Tensor* val) {
876:   CHECK(val != nullptr);
877:   BundleEntryProto entry;
878:   TF_RETURN_IF_ERROR(ParseEntryProto(iter_-&gt;key(), iter_-&gt;value(), &amp;entry));
879:   if (!TensorShape::IsValid(entry.shape())) {
880:     return errors::DataLoss(&quot;Invaid tensor shape: &quot;, iter_-&gt;key(), &quot; &quot;,
881:                             ProtoShortDebugString(entry.shape()));
882:   }
883: 
884:   if (entry.slices().empty()) {
885:     return GetValue(entry, val);
886:   } else {
887:     return GetSliceValue(
888:         iter_-&gt;key(), entry,
889:         /* a full slice */ TensorSlice(TensorShape(entry.shape()).dims()), val);
890:   }
891: }
892: 
893: Status BundleReader::LookupTensorSlices(StringPiece key,
894:                                         std::vector&lt;TensorSlice&gt;* slices) {
895:   slices-&gt;clear();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="910" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 907 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::LookupSlice ( StringPiece full_tensor_key , const TensorSlice &amp; slice_spec , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="900:     slices-&gt;emplace_back(slice);
901:   }
902:   return Status::OK();
903: }
904: 
905: Status BundleReader::LookupSlice(StringPiece full_tensor_key,
906:                                  const TensorSlice&amp; slice_spec, Tensor* val) {
907:   CHECK(val != nullptr);
908:   BundleEntryProto entry;
909:   TF_RETURN_IF_ERROR(GetBundleEntryProto(full_tensor_key, &amp;entry));
910:   return GetSliceValue(full_tensor_key, entry, slice_spec, val);
911: }
912: 
913: Status BundleReader::GetSliceValue(StringPiece full_tensor_key,
914:                                    const BundleEntryProto&amp; full_tensor_entry,
915:                                    const TensorSlice&amp; slice_spec, Tensor* val) {
916:   using checkpoint::RegisterTensorSlice;
917:   using checkpoint::TensorSliceSet;
918:   DCHECK_GE(full_tensor_entry.slices_size(), 0);
919: 
920:   const TensorShape full_shape(TensorShape(full_tensor_entry.shape()));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/examples/android/jni/object_tracking/frame_pair.h" line="27" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FramePair::optical_flow_found_keypoint_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FramePair::optical_flow_found_keypoint_,&quot;}" func_info="tf_tracking::FramePair" content="17: #define TENSORFLOW_EXAMPLES_ANDROID_JNI_OBJECT_TRACKING_FRAME_PAIR_H_
18: 
19: #include &quot;map/base/mlp/tf/tensorflow/examples/android/jni/object_tracking/keypoint.h&quot;
20: 
21: namespace tf_tracking {
22: 
23: // A class that records keypoint correspondences from pairs of
24: // consecutive frames.
25: class FramePair {
26:  public:
27:   FramePair()
28:       : start_time_(0),
29:         end_time_(0),
30:         number_of_keypoints_(0) {}
31: 
32:   // Cleans up the FramePair so that they can be reused.
33:   void Init(const int64_t start_time, const int64_t end_time);
34: 
35:   void AdjustBox(const BoundingBox box,
36:                  float* const translation_x,
37:                  float* const translation_y,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/examples/android/jni/object_tracking/object_tracker.cc" line="670" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [detector_] suggests that it may be null, but it has already been dereferenced at line 652." web_identify="{&quot;identify&quot;:&quot;detector_&quot;}" func_info="void ObjectTracker::TrackObjects ( )" content="660:         object-&gt;GetPosition(), frame_pairs_[GetNthIndexFromEnd(0)]);
661:     object-&gt;UpdatePosition(tracked_position, curr_time_, *frame2_, false);
662: 
663:     if (automatic_removal_allowed &amp;&amp;
664:         object-&gt;GetNumConsecutiveFramesBelowThreshold() &gt;
665:         kMaxNumDetectionFailures * 5) {
666:       dead_objects.push_back(iter-&gt;first);
667:     }
668:   }
669: 
670:   if (detector_ != NULL &amp;&amp; automatic_removal_allowed) {
671:     for (std::vector&lt;std::string&gt;::iterator iter = dead_objects.begin();
672:          iter != dead_objects.end(); iter++) {
673:       LOGE(&quot;Removing object! %s&quot;, iter-&gt;c_str());
674:       ForgetTarget(*iter);
675:     }
676:   }
677:   TimeLog(&quot;Tracked all objects.&quot;);
678: 
679:   LOGV(&quot;%zu objects tracked!&quot;, objects_.size());
680: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/examples/speech_commands/test_streaming_accuracy.cc" line="233" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;clip_duration_mssample_rate*&quot;}" func_info="int main ( int argc , char * argv [ ] )" content="223:   if (!decode_wav_status.ok()) {
224:     LOG(ERROR) &lt;&lt; decode_wav_status;
225:     return -1;
226:   }
227:   if (channel_count != 1) {
228:     LOG(ERROR) &lt;&lt; &quot;Only mono .wav files can be used, but input has &quot;
229:                &lt;&lt; channel_count &lt;&lt; &quot; channels.&quot;;
230:     return -1;
231:   }
232: 
233:   const int64 clip_duration_samples = (clip_duration_ms * sample_rate) / 1000;
234:   const int64 clip_stride_samples = (clip_stride_ms * sample_rate) / 1000;
235:   Tensor audio_data_tensor(tensorflow::DT_FLOAT,
236:                            tensorflow::TensorShape({clip_duration_samples, 1}));
237: 
238:   Tensor sample_rate_tensor(tensorflow::DT_INT32, tensorflow::TensorShape({}));
239:   sample_rate_tensor.scalar&lt;int32&gt;()() = sample_rate;
240: 
241:   tensorflow::RecognizeCommands recognize_commands(
242:       labels_list, average_window_ms, detection_threshold, suppression_ms);
243: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/examples/speech_commands/test_streaming_accuracy.cc" line="234" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;clip_stride_mssample_rate*&quot;}" func_info="int main ( int argc , char * argv [ ] )" content="224:     LOG(ERROR) &lt;&lt; decode_wav_status;
225:     return -1;
226:   }
227:   if (channel_count != 1) {
228:     LOG(ERROR) &lt;&lt; &quot;Only mono .wav files can be used, but input has &quot;
229:                &lt;&lt; channel_count &lt;&lt; &quot; channels.&quot;;
230:     return -1;
231:   }
232: 
233:   const int64 clip_duration_samples = (clip_duration_ms * sample_rate) / 1000;
234:   const int64 clip_stride_samples = (clip_stride_ms * sample_rate) / 1000;
235:   Tensor audio_data_tensor(tensorflow::DT_FLOAT,
236:                            tensorflow::TensorShape({clip_duration_samples, 1}));
237: 
238:   Tensor sample_rate_tensor(tensorflow::DT_INT32, tensorflow::TensorShape({}));
239:   sample_rate_tensor.scalar&lt;int32&gt;()() = sample_rate;
240: 
241:   tensorflow::RecognizeCommands recognize_commands(
242:       labels_list, average_window_ms, detection_threshold, suppression_ms);
243: 
244:   std::vector&lt;std::pair&lt;string, int64&gt;&gt; all_found_words;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/python/eager/pywrap_tfe_src.cc" line="1355" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;PyVSpace::num_elements_,aggregate_fn_,zeros_,ones_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;PyVSpace::num_elements_,aggregate_fn_,zeros_,ones_,&quot;}" func_info="PyVSpace" content="1345: 
1346: void TFE_Py_TapeSetDeleteTrace(tensorflow::int64 tensor_id) {
1347:   for (TFE_Py_Tape* tape : SafeTapeSet()) {
1348:     tape-&gt;tape-&gt;DeleteTrace(tensor_id);
1349:   }
1350: }
1351: 
1352: class PyVSpace
1353:     : public tensorflow::eager::VSpace&lt;PyObject, PyBackwardFunction&gt; {
1354:  public:
1355:   explicit PyVSpace(PyObject* py_vspace) : py_vspace_(py_vspace) {}
1356: 
1357:   tensorflow::Status Initialize() {
1358:     num_elements_ = PyObject_GetAttrString(py_vspace_, &quot;num_elements_fn&quot;);
1359:     if (num_elements_ == nullptr) {
1360:       return tensorflow::errors::InvalidArgument(&quot;invalid vspace&quot;);
1361:     }
1362:     aggregate_fn_ = PyObject_GetAttrString(py_vspace_, &quot;aggregate_fn&quot;);
1363:     if (aggregate_fn_ == nullptr) {
1364:       return tensorflow::errors::InvalidArgument(&quot;invalid vspace&quot;);
1365:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/python/eager/pywrap_tfe_src.cc" line="1697" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="PyObject * MaybeGetDTypeForAttr ( const string &amp; attr , FastPathOpExecInfo * op_exec_info )" content="1687:   if (cached_it != op_exec_info-&gt;cached_dtypes.end()) {
1688:     return GetPythonObjectFromInt(cached_it-&gt;second);
1689:   }
1690: 
1691:   auto it = op_exec_info-&gt;attr_to_inputs_map-&gt;find(attr);
1692:   if (it == op_exec_info-&gt;attr_to_inputs_map-&gt;end()) {
1693:     // No other inputs - this should never happen.
1694:     Py_RETURN_NONE;
1695:   }
1696: 
1697:   for (const auto&amp; input_info : it-&gt;second) {
1698:     PyObject* item = PyTuple_GET_ITEM(
1699:         op_exec_info-&gt;args, kFastPathExecuteInputStartIndex + input_info.i);
1700:     if (input_info.is_list) {
1701:       for (int i = 0; i &lt; PySequence_Fast_GET_SIZE(item); i++) {
1702:         auto* dtype = MaybeGetDType(PySequence_Fast_GET_ITEM(item, i));
1703:         if (dtype != nullptr) return dtype;
1704:       }
1705:     } else {
1706:       auto* dtype = MaybeGetDType(item);
1707:       if (dtype != nullptr) return dtype;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/python/grappler/cost_analyzer.cc" line="26" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CostAnalyzer::total_time_measured_,total_time_analytical_,total_time_measured_serialized_,total_time_analytical_upper_,total_time_analytical_lower_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CostAnalyzer::total_time_measured_,total_time_analytical_,total_time_measured_serialized_,total_time_analytical_upper_,total_time_analytical_lower_,&quot;}" func_info="tensorflow::grappler" content="16: #include &quot;tensorflow/python/grappler/cost_analyzer.h&quot;
17: 
18: #include &lt;iomanip&gt;
19: #include &quot;tensorflow/core/grappler/costs/utils.h&quot;
20: #include &quot;tensorflow/core/grappler/grappler_item.h&quot;
21: #include &quot;tensorflow/core/lib/core/status.h&quot;
22: 
23: namespace tensorflow {
24: namespace grappler {
25: 
26: CostAnalyzer::CostAnalyzer(const GrapplerItem&amp; item, Cluster* cluster,
27:                            const string&amp; suffix)
28:     : item_(&amp;item),
29:       measure_estimator_(cluster, 10, 0),
30:       analytical_estimator_(cluster, false),
31:       suffix_(suffix) {}
32: 
33: Status CostAnalyzer::GenerateReport(std::ostream&amp; os, bool per_node_report,
34:                                     bool verbose) {
35:   GatherCosts();
36:   PreprocessCosts();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2090" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2073 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemvWithProfilingImpl ( Stream * stream , blas::Transpose trans , long m , long n , const T &amp; alpha , const DeviceMemory &lt; T &gt; &amp; a , int lda , const DeviceMemory &lt; T &gt; &amp; x , int incx , const T &amp; beta , DeviceMemory &lt; T &gt; * y , int incy , blas::ProfileResult * output_profile_result )" content="2080:   // Call blasGemm
2081:   bool result =
2082:       DoBlasGemv(stream, trans, m, n, alpha, a, lda, x, incx, beta, y, incy);
2083: 
2084:   if (timer != nullptr &amp;&amp; result) {
2085:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2086:     // state.
2087:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2088:       return false;
2089:     }
2090:     output_profile_result-&gt;set_is_valid(true);
2091:     output_profile_result-&gt;set_algorithm(blas::kDefaultBlasGemv);
2092:     output_profile_result-&gt;set_elapsed_time_in_ms(
2093:         timer-&gt;GetElapsedMilliseconds());
2094:   }
2095:   return result;
2096: }
2097: 
2098: template &lt;typename T, typename ParamType&gt;
2099: bool CUDABlas::DoBlasGemmWithProfilingImpl(
2100:     Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64 m,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2105 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemmWithProfilingImpl ( Stream * stream , blas::Transpose transa , blas::Transpose transb , long m , long n , long k , const ParamType &amp; alpha , const DeviceMemory &lt; T &gt; &amp; a , int lda , const DeviceMemory &lt; T &gt; &amp; b , int ldb , const ParamType &amp; beta , DeviceMemory &lt; T &gt; * c , int ldc , blas::ProfileResult * output_profile_result )" content="2112:   // Call blasGemm
2113:   bool result = DoBlasGemm(stream, transa, transb, m, n, k, alpha, a, lda, b,
2114:                            ldb, beta, c, ldc);
2115: 
2116:   if (timer != nullptr &amp;&amp; result) {
2117:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2118:     // state.
2119:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2120:       return false;
2121:     }
2122:     output_profile_result-&gt;set_is_valid(true);
2123:     output_profile_result-&gt;set_algorithm(blas::kDefaultBlasGemm);
2124:     output_profile_result-&gt;set_elapsed_time_in_ms(
2125:         timer-&gt;GetElapsedMilliseconds());
2126:   }
2127:   return result;
2128: }
2129: 
2130: static bool UsesTensorOps(blas::AlgorithmType algo) {
2131: #if CUDA_VERSION &gt;= 9000
2132:   cublasGemmAlgo_t cublas_algo = static_cast&lt;cublasGemmAlgo_t&gt;(algo);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2216" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2177 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemmWithAlgorithmImpl ( Stream * stream , blas::Transpose transa , blas::Transpose transb , long m , long n , long k , const HostOrDeviceScalar &lt; CompT &gt; &amp; alpha , const DeviceMemory &lt; InT &gt; &amp; a , int lda , const DeviceMemory &lt; InT &gt; &amp; b , int ldb , const HostOrDeviceScalar &lt; CompT &gt; &amp; beta , DeviceMemory &lt; OutT &gt; * c , int ldc , blas::ComputationType computation_type , blas::AlgorithmType algorithm , blas::ProfileResult * output_profile_result )" content="2206:       CUDAMemoryMutable(c), CUDADataType&lt;OutT&gt;::type, ldc,
2207:       CUDAComputationType(computation_type),
2208:       static_cast&lt;cublasGemmAlgo_t&gt;(algorithm));
2209: 
2210:   if (timer != nullptr &amp;&amp; result) {
2211:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2212:     // state.
2213:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2214:       return false;
2215:     }
2216:     output_profile_result-&gt;set_is_valid(true);
2217:     output_profile_result-&gt;set_algorithm(algorithm);
2218:     output_profile_result-&gt;set_elapsed_time_in_ms(
2219:         timer-&gt;GetElapsedMilliseconds());
2220:   }
2221:   return result;
2222: }
2223: 
2224: bool CUDABlas::GetBlasGemmAlgorithms(
2225:     std::vector&lt;blas::AlgorithmType&gt; *out_algorithms) {
2226: // cublasGemmAlgo_t (and the function that accepts this type, cublasGemmEx)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_driver.cc" line="809" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [kernel_name] to null at line 806 implies that [kernel_name ] might be null.Dereferencing null pointer [kernel_name]." web_identify="{&quot;identify&quot;:&quot;kernel_name&quot;}" func_info="bool CUDADriver::GetModuleFunction ( CudaContext * context , CUmodule module , const char * kernel_name , CUfunction * function )" content="799: }
800: 
801: /* static */ bool CUDADriver::GetModuleFunction(CudaContext *context,
802:                                                 CUmodule module,
803:                                                 const char *kernel_name,
804:                                                 CUfunction *function) {
805:   ScopedActivateContext activated{context};
806:   CHECK(module != nullptr &amp;&amp; kernel_name != nullptr);
807:   CUresult res = cuModuleGetFunction(function, module, kernel_name);
808:   if (res != CUDA_SUCCESS) {
809:     LOG(ERROR) &lt;&lt; &quot;failed to get PTX kernel \&quot;&quot; &lt;&lt; kernel_name
810:                &lt;&lt; &quot;\&quot; from module: &quot; &lt;&lt; ToString(res);
811:     return false;
812:   }
813: 
814:   return true;
815: }
816: 
817: /* static */ bool CUDADriver::GetModuleSymbol(CudaContext* context,
818:                                               CUmodule module,
819:                                               const char *symbol_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_driver.cc" line="829" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [symbol_name] to null at line 824 implies that [symbol_name ] might be null.Dereferencing null pointer [symbol_name]." web_identify="{&quot;identify&quot;:&quot;symbol_name&quot;}" func_info="bool CUDADriver::GetModuleSymbol ( CudaContext * context , CUmodule module , const char * symbol_name , CUdeviceptr * dptr , long * bytes )" content="819:                                               const char *symbol_name,
820:                                               CUdeviceptr *dptr,
821:                                               size_t *bytes) {
822:   ScopedActivateContext activated{context};
823:   CHECK(module != nullptr &amp;&amp; symbol_name != nullptr &amp;&amp;
824:         (dptr != nullptr || bytes != nullptr));
825:   CUresult res = cuModuleGetGlobal(dptr, bytes, module, symbol_name);
826:   if (res != CUDA_SUCCESS) {
827:     // symbol may not be found in the current module, but it may reside in
828:     // another module.
829:     VLOG(2) &lt;&lt; &quot;failed to get symbol \&quot;&quot; &lt;&lt; symbol_name
830:             &lt;&lt; &quot;\&quot; from module: &quot; &lt;&lt; ToString(res);
831:     return false;
832:   }
833: 
834:   return true;
835: }
836: 
837: /* static */ void CUDADriver::UnloadModule(CudaContext *context,
838:                                            CUmodule module) {
839:   ScopedActivateContext activated{context};
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc" line="112" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cuda_exec] to null at line 111 implies that [cuda_exec ] might be null.Dereferencing null pointer [cuda_exec]." web_identify="{&quot;identify&quot;:&quot;cuda_exec&quot;}" func_info="CudaContext * cuda::ExtractCudaContext ( CUDAExecutor * cuda_exec )" content="102:   return reinterpret_cast&lt;CUdeviceptr&gt;(gpu_mem.opaque());
103: }
104: 
105: // See description on const version above.
106: static CUdeviceptr AsCudaDevicePtr(DeviceMemoryBase *gpu_mem) {
107:   return AsCudaDevicePtr(*gpu_mem);
108: }
109: 
110: CudaContext* ExtractCudaContext(CUDAExecutor *cuda_exec) {
111:   CHECK(cuda_exec != nullptr);
112:   return cuda_exec-&gt;cuda_context();
113: }
114: 
115: CUDAExecutor *ExtractCudaExecutor(StreamExecutor *stream_exec) {
116:   return static_cast&lt;CUDAExecutor *&gt;(stream_exec-&gt;implementation());
117: }
118: 
119: CUDAExecutor::~CUDAExecutor() {
120:   CHECK(kernel_to_gpu_binary_.empty()) &lt;&lt; &quot;CUDAExecutor has live kernels.&quot;;
121:   CHECK(gpu_binary_to_module_.empty()) &lt;&lt; &quot;CUDAExecutor has loaded modules.&quot;;
122:   if (context_ != nullptr) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/kernel.h" line="103" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;KernelMetadata::registers_per_thread_,shared_memory_bytes_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;KernelMetadata::registers_per_thread_,shared_memory_bytes_,&quot;}" func_info="stream_executor::KernelMetadata" content="93: class KernelInterface;
94: }  // namespace internal
95: 
96: // KernelMetadata holds runtime-queryable attributes of a loaded kernel, such as
97: // registers allocated, shared memory used, etc.
98: // Not all platforms support reporting of all information, so each accessor
99: // returns false if the associated field is not populated in the underlying
100: // platform.
101: class KernelMetadata {
102:  public:
103:   KernelMetadata()
104:       : has_registers_per_thread_(false), has_shared_memory_bytes_(false) {}
105: 
106:   // Returns the number of registers used per thread executing this kernel.
107:   bool registers_per_thread(int *registers_per_thread) const;
108: 
109:   // Sets the number of registers used per thread executing this kernel.
110:   void set_registers_per_thread(int registers_per_thread);
111: 
112:   // Returns the amount of [static] shared memory used per block executing this
113:   // kernel. Note that dynamic shared memory allocations are not (and can not)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/multi_platform_manager.cc" line="54" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [platform] to null at line 53 implies that [platform ] might be null.Dereferencing null pointer [platform]." web_identify="{&quot;identify&quot;:&quot;platform&quot;}" func_info="port::Status MultiPlatformManager::RegisterPlatform ( std::unique_ptr &lt; Platform &gt; platform )" content="44:     return port::Status(
45:         port::error::NOT_FOUND,
46:         port::Printf(&quot;could not find registered platform with id: 0x%p&quot;, id));
47:   }
48:   return it-&gt;second;
49: }
50: 
51: /* static */ port::Status MultiPlatformManager::RegisterPlatform(
52:     std::unique_ptr&lt;Platform&gt; platform) {
53:   CHECK(platform != nullptr);
54:   string key = port::Lowercase(platform-&gt;Name());
55:   mutex_lock lock(platforms_mutex_);
56:   if (GetPlatformMap()-&gt;find(key) != GetPlatformMap()-&gt;end()) {
57:     return port::Status(port::error::INTERNAL,
58:                         &quot;platform is already registered with name: \&quot;&quot; +
59:                             platform-&gt;Name() + &quot;\&quot;&quot;);
60:   }
61:   GetPlatformByIdMap()-&gt;insert(std::make_pair(platform-&gt;id(), platform.get()));
62:   // Release ownership/uniqueness to prevent destruction on program exit.
63:   // This avoids Platforms &quot;cleaning up&quot; on program exit, because otherwise,
64:   // there are _very_ tricky races between StreamExecutor and underlying
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tensorflow-1.10.1/tensorflow/stream_executor/temporary_memory_manager.h" line="58" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TemporaryMemoryManager::generation_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TemporaryMemoryManager::generation_,&quot;}" func_info="stream_executor::internal::TemporaryMemoryManager" content="48:   // synchronization time.
49:   bool finalized;
50: };
51: 
52: // Manages temporary memories associated with a stream -- keeps records of
53: // outstanding temporaries and their state, and can deallocate them
54: // appropriately at points in the Stream lifecycle (e.g. BlockHostUntilDone,
55: // destruction).
56: class TemporaryMemoryManager {
57:  public:
58:   explicit TemporaryMemoryManager(Stream* stream) : stream_(stream) {}
59: 
60:   // Allocates a temporary array that is then managed by this object.
61:   template &lt;typename T&gt;
62:   port::StatusOr&lt;std::unique_ptr&lt;TemporaryDeviceMemory&lt;T&gt;&gt;&gt; AllocateArray(
63:       uint64 element_count);
64: 
65:   // Forces deallocation of all managed temporary memory regions.
66:   //
67:   // Called, for example, when the Stream owning this temporary memory manager
68:   // is destroyed.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf-serving/tensorflow_serving/batching/streaming_batch_scheduler.h" line="365" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [open_batch_] to null at line 348 implies that [open_batch_ ] might be null.Dereferencing null pointer [open_batch_]." web_identify="{&quot;identify&quot;:&quot;open_batch_&quot;}" func_info="&gt; Status StreamingBatchScheduler &lt; TaskType &gt;::Schedule ( std::unique_ptr &lt; TaskType &gt; * task )" content="355:     if (num_batches_in_progress_ &gt; options_.num_batch_threads) {
356:       DCHECK(open_batch_-&gt;empty());
357:       return errors::Unavailable(
358:           &quot;This task would start a fresh batch, but all batch threads are &quot;
359:           &quot;busy, so at present there is no processing capacity available for &quot;
360:           &quot;this task&quot;);
361:     }
362: 
363:     // If we are about to add the first task to a batch, schedule the batch to
364:     // be closed after the timeout.
365:     if (options_.batch_timeout_micros &gt; 0 &amp;&amp; open_batch_-&gt;empty()) {
366:       const uint64 batch_deadline =
367:           options_.env-&gt;NowMicros() + options_.batch_timeout_micros;
368:       ScheduleCloseOfCurrentOpenBatch(batch_deadline);
369:     }
370: 
371:     open_batch_-&gt;AddTask(std::move(*task));
372: 
373:     // If we&apos;ve exactly reached the target size, we can close this batch now.
374:     if (open_batch_-&gt;size() == options_.max_batch_size) {
375:       StartNewBatch();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf-serving/tensorflow_serving/util/net_http/client/testing/evhttp_echo_client.cc" line="38" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [connection] to null at line 31 implies that [connection ] might be null.Dereferencing null pointer [connection]." web_identify="{&quot;identify&quot;:&quot;connection&quot;}" func_info="bool SendRequest ( const char * url )" content="28: 
29: bool SendRequest(const char* url) {
30:   auto connection = EvHTTPConnection::Connect(url);
31:   if (connection == nullptr) {
32:     std::cerr &lt;&lt; &quot;Fail to connect to %s&quot; &lt;&lt; url;
33:   }
34: 
35:   ClientRequest request = {url, &quot;GET&quot;, {}, nullptr};
36:   ClientResponse response = {};
37: 
38:   if (!connection-&gt;BlockingSendRequest(request, &amp;response)) {
39:     std::cerr &lt;&lt; &quot;Request failed.&quot;;
40:     return false;
41:   }
42: 
43:   std::cout &lt;&lt; &quot;Response received: &quot; &lt;&lt; std::endl
44:             &lt;&lt; &quot;Status: &quot; &lt;&lt; response.status &lt;&lt; std::endl;
45: 
46:   for (auto keyval : response.headers) {
47:     std::cout &lt;&lt; keyval.first &lt;&lt; &quot; : &quot; &lt;&lt; keyval.second &lt;&lt; std::endl;
48:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf-serving/tensorflow_serving/util/net_http/server/internal/evhttp_request.cc" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ParsedEvRequest::method,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ParsedEvRequest::method,&quot;}" func_info="tensorflow::serving::net_http" content="36: ParsedEvRequest::~ParsedEvRequest() {
37:   if (decoded_uri) {
38:     evhttp_uri_free(decoded_uri);
39:   }
40: 
41:   if (request &amp;&amp; evhttp_request_is_owned(request)) {
42:     evhttp_request_free(request);
43:   }
44: }
45: 
46: ParsedEvRequest::ParsedEvRequest(evhttp_request* request_in)
47:     : request(request_in) {}
48: 
49: bool ParsedEvRequest::decode() {
50:   switch (evhttp_request_get_command(request)) {
51:     case EVHTTP_REQ_GET:
52:       method = &quot;GET&quot;;
53:       break;
54:     case EVHTTP_REQ_POST:
55:       method = &quot;POST&quot;;
56:       break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf-serving/tensorflow_serving/util/net_http/server/internal/evhttp_server.cc" line="55" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;EvHTTPServer::immediate_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;EvHTTPServer::immediate_,&quot;}" func_info="tensorflow::serving::net_http" content="45:     ABSL_RAW_LOG(FATAL, &quot;Server requires pthread support.&quot;);
46:   }
47: 
48:   // TODO(wenboz): windows support needed?
49: }
50: 
51: void GlobalInitialize() { absl::call_once(libevent_init_once, &amp;InitLibEvent); }
52: 
53: }  // namespace
54: 
55: EvHTTPServer::EvHTTPServer(std::unique_ptr&lt;ServerOptions&gt; options)
56:     : server_options_(std::move(options)), accepting_requests_() {}
57: 
58: // May crash the server if called before WaitForTermination() returns
59: EvHTTPServer::~EvHTTPServer() {
60:   if (!is_terminating()) {
61:     ABSL_RAW_LOG(ERROR,
62:                  &quot;Serer has not been terminated. Force termination now.&quot;);
63:     Terminate();
64:   }
65: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/c_api_test.cc" line="1175" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CApiColocationTest::feed1_,feed2_,constant_,desc_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CApiColocationTest::feed1_,feed2_,constant_,desc_,&quot;}" func_info="CApiColocationTest" content="1165:   ptrs-&gt;reset(new const void*[v.size()]);
1166:   lens-&gt;reset(new size_t[v.size()]);
1167:   for (size_t i = 0; i &lt; v.size(); ++i) {
1168:     (*ptrs)[i] = v[i].data();
1169:     (*lens)[i] = v[i].size();
1170:   }
1171: }
1172: 
1173: class CApiColocationTest : public ::testing::Test {
1174:  protected:
1175:   CApiColocationTest() : s_(TF_NewStatus()), graph_(TF_NewGraph()) {}
1176: 
1177:   void SetUp() override {
1178:     feed1_ = Placeholder(graph_, s_, &quot;feed1&quot;);
1179:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
1180: 
1181:     feed2_ = Placeholder(graph_, s_, &quot;feed2&quot;);
1182:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
1183: 
1184:     constant_ = ScalarConst(10, graph_, s_);
1185:     ASSERT_EQ(TF_OK, TF_GetCode(s_)) &lt;&lt; TF_Message(s_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/checkpoint_reader.cc" line="114" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v2_reader_] to null at line 113 implies that [v2_reader_ ] might be null.Dereferencing null pointer [v2_reader_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;v2_reader_&quot;}" func_info="&gt; CheckpointReader::BuildV2VarMaps ( )" content="104:   }
105:   if (!status.ok()) {
106:     Set_TF_Status_from_Status(out_status, status);
107:   }
108: }
109: 
110: std::pair&lt;std::unique_ptr&lt;TensorSliceReader::VarToShapeMap&gt;,
111:           std::unique_ptr&lt;TensorSliceReader::VarToDataTypeMap&gt;&gt;
112: CheckpointReader::BuildV2VarMaps() {
113:   CHECK(v2_reader_ != nullptr);
114:   CHECK(v2_reader_-&gt;status().ok());
115: 
116:   // First pass: filters out the entries of the slices.
117:   std::unordered_set&lt;string&gt; filtered_keys;
118:   BundleEntryProto entry;
119:   v2_reader_-&gt;Seek(kHeaderEntryKey);
120:   for (v2_reader_-&gt;Next(); v2_reader_-&gt;Valid(); v2_reader_-&gt;Next()) {
121:     CHECK(entry.ParseFromArray(v2_reader_-&gt;value().data(),
122:                                v2_reader_-&gt;value().size()))
123:         &lt;&lt; entry.InitializationErrorString();
124:     for (int i = 0; i &lt; entry.slices_size(); ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/checkpoint_reader.cc" line="75" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [var_to_shape_map_] to null at line 74 implies that [var_to_shape_map_ ] might be null.Dereferencing null pointer [var_to_shape_map_]." web_identify="{&quot;identify&quot;:&quot;var_to_shape_map_&quot;}" func_info="&amp; CheckpointReader::GetVariableToShapeMap ( ) const" content="65: bool CheckpointReader::HasTensor(const string&amp; name) const {
66:   if (reader_ != nullptr) {
67:     return reader_-&gt;HasTensor(name, nullptr, nullptr);
68:   }
69:   return v2_reader_-&gt;Contains(name);
70: }
71: 
72: const TensorSliceReader::VarToShapeMap&amp;
73: CheckpointReader::GetVariableToShapeMap() const {
74:   CHECK(var_to_shape_map_);
75:   return *var_to_shape_map_;
76: }
77: 
78: const TensorSliceReader::VarToDataTypeMap&amp;
79: CheckpointReader::GetVariableToDataTypeMap() const {
80:   CHECK(var_to_data_type_map_);
81:   return *var_to_data_type_map_;
82: }
83: 
84: const string CheckpointReader::DebugString() const {
85:   if (reader_ != nullptr) return reader_-&gt;DebugString();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/checkpoint_reader.cc" line="81" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [var_to_data_type_map_] to null at line 80 implies that [var_to_data_type_map_ ] might be null.Dereferencing null pointer [var_to_data_type_map_]." web_identify="{&quot;identify&quot;:&quot;var_to_data_type_map_&quot;}" func_info="&amp; CheckpointReader::GetVariableToDataTypeMap ( ) const" content="71: 
72: const TensorSliceReader::VarToShapeMap&amp;
73: CheckpointReader::GetVariableToShapeMap() const {
74:   CHECK(var_to_shape_map_);
75:   return *var_to_shape_map_;
76: }
77: 
78: const TensorSliceReader::VarToDataTypeMap&amp;
79: CheckpointReader::GetVariableToDataTypeMap() const {
80:   CHECK(var_to_data_type_map_);
81:   return *var_to_data_type_map_;
82: }
83: 
84: const string CheckpointReader::DebugString() const {
85:   if (reader_ != nullptr) return reader_-&gt;DebugString();
86:   return v2_reader_-&gt;DebugString();
87: }
88: 
89: void CheckpointReader::GetTensor(
90:     const string&amp; name, std::unique_ptr&lt;tensorflow::Tensor&gt;* out_tensor,
91:     TF_Status* out_status) const {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/eager/c_api.cc" line="182" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [grpc_server] to null at line 177 implies that [grpc_server ] might be null.Dereferencing null pointer [grpc_server]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;grpc_server&quot;}" func_info="tensorflow::Status NewRemoteAwareTFE_Context ( const struct TFE_ContextOptions * opts , struct TFE_Context * * ctx )" content="172:   std::unique_ptr&lt;tensorflow::ServerInterface&gt; server;
173:   LOG_AND_RETURN_IF_ERROR(tensorflow::NewServer(opts-&gt;server_def, &amp;server));
174: 
175:   tensorflow::GrpcServer* grpc_server =
176:       dynamic_cast&lt;tensorflow::GrpcServer*&gt;(server.get());
177:   if (grpc_server == nullptr) {
178:     LOG_AND_RETURN_IF_ERROR(tensorflow::errors::Internal(
179:         &quot;Currently, TFE_NewContext only supports tensorflow::GrpcServer.&quot;));
180:   }
181: 
182:   LOG_AND_RETURN_IF_ERROR(grpc_server-&gt;Start());
183: 
184:   int64 rendezvous_id = tensorflow::random::New64();
185: 
186:   std::vector&lt;string&gt; remote_workers;
187:   grpc_server-&gt;master_env()-&gt;worker_cache-&gt;ListWorkers(&amp;remote_workers);
188:   remote_workers.erase(
189:       std::remove(remote_workers.begin(), remote_workers.end(), worker_name),
190:       remote_workers.end());
191: 
192:   std::unique_ptr&lt;tensorflow::DeviceMgr&gt; remote_device_mgr;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/eager/c_api.cc" line="458" id="memleak" subid="memleak" severity="Warning" msg="Memory leak: op" web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="" content="448:   return ret;
449: }
450: 
451: TF_AttrType TFE_OpNameGetAttrType(TFE_Context* ctx,
452:                                   const char* op_or_function_name,
453:                                   const char* attr_name, unsigned char* is_list,
454:                                   TF_Status* status) {
455:   TF_AttrType ret;
456:   TFE_Op* op = TFE_NewOp(ctx, op_or_function_name, status);
457:   if (!status-&gt;status.ok()) {
458:     return TF_ATTR_INT;  // Same dummy return as TFE_OpGetAttrType.
459:   }
460:   ret = TFE_OpGetAttrType(op, attr_name, is_list, status);
461:   TFE_DeleteOp(op);
462:   return ret;
463: }
464: 
465: void TFE_OpSetAttrString(TFE_Op* op, const char* attr_name, const void* value,
466:                          size_t length) {
467:   op-&gt;operation.MutableAttrs()-&gt;Set(
468:       attr_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/eager/tape.h" line="263" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [op_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;op_it&quot;}" func_info="&gt; void GradientTape &lt; Gradient , BackwardFunction &gt;::DeleteTrace ( long tensor_id )" content="253:     return;
254:   }
255:   const int64 op_id = tensor_op_it-&gt;second;
256:   if (op_id == -1) {
257:     // Do not delete watched tensors.
258:     return;
259:   }
260:   tensor_tape_.erase(tensor_op_it);
261:   auto op_it = op_tape_.find(op_id);
262:   CHECK(op_it != op_tape_.end());
263:   for (const auto&amp; output : op_it-&gt;second.output_tensor_info) {
264:     if (tensor_usage_.find(output.id) != tensor_usage_.end()) {
265:       // Found a usage for an output, so cannot delete the op.
266:       return;
267:     }
268:   }
269:   for (int64 id : op_it-&gt;second.input_tensor_id) {
270:     DeleteTrace(id);
271:   }
272:   op_it-&gt;second.backward_function_deleter(op_it-&gt;second.backward_function);
273:   op_tape_.erase(op_it);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/c/python_api.cc" line="122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ic] to null at line 121 implies that [ic ] might be null.Dereferencing null pointer [ic]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;ic&quot;}" func_info="std::string tensorflow::GetResourceHandleShapeAndType ( struct TF_Graph * graph , struct TF_Output output )" content="112: 
113: std::string GetResourceHandleShapeAndType(TF_Graph* graph, TF_Output output) {
114:   Node* node = &amp;output.oper-&gt;node;
115:   CppShapeInferenceResult::HandleData handle_data;
116:   handle_data.set_is_set(true);
117:   {
118:     mutex_lock l(graph-&gt;mu);
119:     tensorflow::shape_inference::InferenceContext* ic =
120:         graph-&gt;refiner.GetContext(node);
121:     CHECK(ic != nullptr);
122:     CHECK_LT(output.index, ic-&gt;num_outputs());
123:     const auto* shapes_and_types =
124:         ic-&gt;output_handle_shapes_and_types(output.index);
125:     if (shapes_and_types == nullptr) return &quot;&quot;;
126: 
127:     for (const auto&amp; p : *shapes_and_types) {
128:       auto* out_shape_and_type = handle_data.add_shape_and_type();
129:       ic-&gt;ShapeHandleToProto(p.shape, out_shape_and_type-&gt;mutable_shape());
130:       out_shape_and_type-&gt;set_dtype(p.dtype);
131:     }
132:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/cc/framework/cc_op_gen_test.cc" line="76" id="logic" subid="STLFindError" severity="Warning" msg="Using int as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void ExpectSubstrOrder ( const string &amp; s , const string &amp; before , const string &amp; after )" content="66:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; does not contain &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
67: }
68: 
69: void ExpectDoesNotHaveSubstr(StringPiece s, StringPiece expected) {
70:   EXPECT_FALSE(str_util::StrContains(s, expected))
71:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; contains &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
72: }
73: 
74: void ExpectSubstrOrder(const string&amp; s, const string&amp; before,
75:                        const string&amp; after) {
76:   int before_pos = s.find(before);
77:   int after_pos = s.find(after);
78:   ASSERT_NE(std::string::npos, before_pos);
79:   ASSERT_NE(std::string::npos, after_pos);
80:   EXPECT_LT(before_pos, after_pos)
81:       &lt;&lt; before &lt;&lt; &quot; is not before &quot; &lt;&lt; after &lt;&lt; &quot; in &quot; &lt;&lt; s;
82: }
83: 
84: // Runs WriteCCOps and stores output in (internal_)cc_file_path and
85: // (internal_)h_file_path.
86: void GenerateCcOpFiles(Env* env, const OpList&amp; ops,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/cc/framework/cc_op_gen_test.cc" line="77" id="logic" subid="STLFindError" severity="Warning" msg="Using int as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void ExpectSubstrOrder ( const string &amp; s , const string &amp; before , const string &amp; after )" content="67: }
68: 
69: void ExpectDoesNotHaveSubstr(StringPiece s, StringPiece expected) {
70:   EXPECT_FALSE(str_util::StrContains(s, expected))
71:       &lt;&lt; &quot;&apos;&quot; &lt;&lt; s &lt;&lt; &quot;&apos; contains &apos;&quot; &lt;&lt; expected &lt;&lt; &quot;&apos;&quot;;
72: }
73: 
74: void ExpectSubstrOrder(const string&amp; s, const string&amp; before,
75:                        const string&amp; after) {
76:   int before_pos = s.find(before);
77:   int after_pos = s.find(after);
78:   ASSERT_NE(std::string::npos, before_pos);
79:   ASSERT_NE(std::string::npos, after_pos);
80:   EXPECT_LT(before_pos, after_pos)
81:       &lt;&lt; before &lt;&lt; &quot; is not before &quot; &lt;&lt; after &lt;&lt; &quot; in &quot; &lt;&lt; s;
82: }
83: 
84: // Runs WriteCCOps and stores output in (internal_)cc_file_path and
85: // (internal_)h_file_path.
86: void GenerateCcOpFiles(Env* env, const OpList&amp; ops,
87:                        const ApiDefMap&amp; api_def_map, string* h_file_text,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/create_xla_launch_op.cc" line="125" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [*fbody] to null at line 124 implies that [*fbody ] might be null.Dereferencing null pointer [*fbody]." web_identify="{&quot;identify&quot;:&quot;*fbody&quot;}" func_info="Status GetBodyAndConstantsAndResources ( FunctionLibraryRuntime * flr , const NodeDef &amp; node_def , const FunctionBody * * fbody , std::vector &lt; int &gt; * constant_arg_indices , std::vector &lt; int &gt; * resource_arg_indices )" content="115:                                        const FunctionBody** fbody,
116:                                        std::vector&lt;int&gt;* constant_arg_indices,
117:                                        std::vector&lt;int&gt;* resource_arg_indices) {
118:   FunctionLibraryRuntime::Handle handle;
119:   // If node_def is not instantiable, e.g., the function does not exist,
120:   // simply bail out.
121:   TF_RETURN_IF_ERROR(
122:       flr-&gt;Instantiate(node_def.op(), AttrSlice(&amp;node_def.attr()), &amp;handle));
123:   *fbody = flr-&gt;GetFunctionBody(handle);
124:   CHECK(*fbody);  // Can&apos;t be nullptr since we just instantiated it.
125:   const DataTypeVector&amp; arg_types = (*fbody)-&gt;arg_types;
126:   std::vector&lt;bool&gt; const_args(arg_types.size());
127:   // If we can&apos;t analyze the const args. Bail out.
128:   TF_RETURN_IF_ERROR(BackwardsConstAnalysis(*((*fbody)-&gt;graph), &amp;const_args));
129: 
130:   for (int i = 0; i &lt; const_args.size(); ++i) {
131:     if (const_args[i]) {
132:       constant_arg_indices-&gt;push_back(i);
133:     }
134:   }
135: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc" line="1237" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [host_compute_key_placeholder_] to null at line 1209 implies that [host_compute_key_placeholder_ ] might be null.Dereferencing null pointer [host_compute_key_placeholder_]." web_identify="{&quot;identify&quot;:&quot;host_compute_key_placeholder_&quot;}" func_info="Status Encapsulator::Subgraph::AddRecvAtHostNode ( const string &amp; group_attribute , const string &amp; subgraph_name , const string &amp; outside_compilation_attribute , const string &amp; oc_subgraph_name , OutsideCompilationSubgraph * oc_subgraph , Graph * graph_out )" content="1227:                          kRecvAtHostOp);
1228:   builder.Device(device_);
1229:   builder.Attr(&quot;Toutputs&quot;, dtypes);
1230:   // The correct device_ordinal will be inserted during replication in a
1231:   // subsequent rewrite.
1232:   builder.Attr(&quot;device_ordinal&quot;, 0);
1233:   builder.Attr(&quot;key&quot;, strings::StrCat(&quot;host_compute_channel_&quot;, subgraph_name,
1234:                                       &quot;_&quot;, oc_subgraph_name));
1235:   builder.Attr(group_attribute, subgraph_name);
1236:   builder.Attr(outside_compilation_attribute, oc_subgraph_name);
1237:   builder.Input(host_compute_key_placeholder_-&gt;name(), 0, DT_STRING);
1238:   Status s = builder.Finalize(&amp;recv_def);
1239:   if (!s.ok()) return s;
1240: 
1241:   oc_subgraph-&gt;recv_at_host = graph_out-&gt;AddNode(recv_def, &amp;s);
1242:   if (!s.ok()) return s;
1243:   graph_out-&gt;AddEdge(host_compute_key_placeholder_, 0,
1244:                      oc_subgraph-&gt;recv_at_host, 0);
1245: 
1246:   // Add a control dependency forcing the RecvAtHost to run before the subgraph
1247:   // completes. This has no effect on execution order but prevents the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/encapsulate_subgraphs_pass.cc" line="1293" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [host_compute_key_placeholder_] to null at line 1260 implies that [host_compute_key_placeholder_ ] might be null.Dereferencing null pointer [host_compute_key_placeholder_]." web_identify="{&quot;identify&quot;:&quot;host_compute_key_placeholder_&quot;}" func_info="Status Encapsulator::Subgraph::AddSendFromHostNode ( const std::unordered_map &lt; const Node * , Node * &gt; &amp; node_images , const string &amp; group_attribute , const string &amp; subgraph_name , const string &amp; outside_compilation_attribute , const string &amp; oc_subgraph_name , OutsideCompilationSubgraph * oc_subgraph , Graph * graph_out )" content="1283:   builder.Device(device_);
1284:   builder.Attr(&quot;Tinputs&quot;, dtypes);
1285:   builder.Attr(&quot;key&quot;, strings::StrCat(&quot;host_compute_channel_&quot;, subgraph_name,
1286:                                       &quot;_&quot;, oc_subgraph_name));
1287:   // The correct device_ordinal will be inserted during replication in a
1288:   // subsequent rewrite.
1289:   builder.Attr(&quot;device_ordinal&quot;, 0);
1290:   builder.Attr(group_attribute, subgraph_name);
1291:   builder.Attr(outside_compilation_attribute, oc_subgraph_name);
1292:   builder.Input(inputs);
1293:   builder.Input(host_compute_key_placeholder_-&gt;name(), 0, DT_STRING);
1294:   Status s = builder.Finalize(&amp;send_def);
1295:   if (!s.ok()) return s;
1296: 
1297:   oc_subgraph-&gt;send_from_host = graph_out-&gt;AddNode(send_def, &amp;s);
1298:   if (!s.ok()) return s;
1299:   graph_out-&gt;AddEdge(host_compute_key_placeholder_, 0,
1300:                      oc_subgraph-&gt;send_from_host, inputs.size());
1301: 
1302:   // Add a control dependency forcing the SendFromHost to run before the
1303:   // subgraph completes. This has no effect on execution order but prevents the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/graphcycles/graphcycles.cc" line="53" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Node::rank,visited,data,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Node::rank,visited,data,&quot;}" func_info="Node" content="43: 
44: typedef std::unordered_set&lt;int32&gt; NodeSet;
45: template &lt;typename T&gt;
46: struct VecStruct {
47:   typedef gtl::InlinedVector&lt;T, 4&gt; type;
48: };
49: template &lt;typename T&gt;
50: using Vec = typename VecStruct&lt;T&gt;::type;
51: 
52: struct Node {
53:   Node() : in(4), out(4) {}  // Small hashtables for in/out edges
54: 
55:   int32 rank;    // rank number assigned by Pearce-Kelly algorithm
56:   bool visited;  // Temporary marker used by depth-first-search
57:   void* data;    // User-supplied data
58:   NodeSet in;    // List of immediate predecessor nodes in graph
59:   NodeSet out;   // List of immediate successor nodes in graph
60: };
61: 
62: }  // namespace
63: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/mark_for_compilation_pass.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fbody] to null at line 141 implies that [fbody ] might be null.Dereferencing null pointer [fbody]." web_identify="{&quot;identify&quot;:&quot;fbody&quot;}" func_info="bool IsCompilableCall ( const NodeDef &amp; call_def , const DeviceType &amp; jit_device_type , int depth , FunctionLibraryRuntime * lib_runtime )" content="132: 
133:   FunctionLibraryRuntime::Handle handle;
134:   Status status =
135:       lib_runtime-&gt;Instantiate(call_def.op(), AttrSlice(call_def), &amp;handle);
136:   if (!status.ok()) {
137:     VLOG(2) &lt;&lt; &quot;Could not instantiate &quot; &lt;&lt; call_def.op() &lt;&lt; &quot;: &quot; &lt;&lt; status;
138:     return false;
139:   }
140:   const FunctionBody* fbody = lib_runtime-&gt;GetFunctionBody(handle);
141:   CHECK(fbody);
142:   const FunctionDef&amp; fdef = fbody-&gt;fdef;
143:   bool noinline = false;
144:   if (GetNodeAttr(AttrSlice(&amp;fdef.attr()), &quot;_noinline&quot;, &amp;noinline).ok() &amp;&amp;
145:       noinline) {
146:     // The underlying mechanism that calls non-inlined functions uses
147:     // LocalExecutor, which interacts poorly with the LocalExecutor used by
148:     // tf2xla to translate the TF graph into XLA.  So we avoid this for now.
149:     //
150:     // TODO(b/36139787): Create a mechanism to set inlining hints.
151:     VLOG(2) &lt;&lt; &quot;Can&apos;t compile noinline function: &quot; &lt;&lt; fdef.DebugString();
152:     return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_compile_on_demand_op.cc" line="153" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rm] to null at line 144 implies that [rm ] might be null.Dereferencing null pointer [rm]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;rm&quot;}" func_info="Status XlaCompileOnDemandOp::Compile ( OpKernelContext * ctx , const XlaDevice::Metadata &amp; metadata , const XlaCompiler::CompilationResult * * result , xla::LocalExecutable * * executable )" content="143:   ResourceMgr* rm = ctx-&gt;resource_manager();
144:   CHECK(rm);
145: 
146:   XlaCompilationCache* cache;
147:   TF_RETURN_IF_ERROR(rm-&gt;LookupOrCreate&lt;XlaCompilationCache&gt;(
148:       rm-&gt;default_container(), &quot;xla_cache&quot;, &amp;cache,
149:       [&amp;](XlaCompilationCache** cache) {
150:         *cache = new XlaCompilationCache(metadata.client(),
151:                                          metadata.jit_device_type());
152:         return Status::OK();
153:       }));
154:   // Hold the reference to the JIT during evaluation. (We could probably
155:   // free it sooner because the ResourceMgr will retain a reference, but
156:   // this is more obviously correct.)
157:   core::ScopedUnref cache_ref(cache);
158: 
159:   XlaCompiler::Options options;
160:   options.device_type = metadata.jit_device_type();
161:   options.client = metadata.client();
162:   options.flib_def =
163:       new FunctionLibraryDefinition(OpRegistry::Global(), FunctionDefLibrary{});
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_compile_on_demand_op.cc" line="91" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [constant_inputs] to null at line 89 implies that [constant_inputs ] might be null.Dereferencing null pointer [constant_inputs]." web_identify="{&quot;identify&quot;:&quot;constant_inputs&quot;}" func_info="bool XlaCompileOnDemandOp::MustArgumentBeConstant ( const OpKernel * op_kernel , long argument_idx )" content="81:   return Status::OK();
82: }
83: 
84: bool XlaCompileOnDemandOp::MustArgumentBeConstant(const OpKernel* op_kernel,
85:                                                   int64 argument_idx) {
86:   // TODO(jmolloy): This could be expensive, so memoize.
87:   auto* constant_inputs = tensorflow::XlaOpRegistry::CompileTimeConstantInputs(
88:       op_kernel-&gt;def().op());
89:   CHECK(constant_inputs);
90:   std::set&lt;int64&gt; constant_input_indices;
91:   for (const auto&amp; name : *constant_inputs) {
92:     int start, stop;
93:     TF_CHECK_OK(op_kernel-&gt;InputRange(name, &amp;start, &amp;stop));
94:     for (int i = start; i &lt; stop; ++i) {
95:       constant_input_indices.insert(i);
96:     }
97:   }
98:   return constant_input_indices.count(argument_idx) &gt; 0;
99: }
100: 
101: bool XlaCompileOnDemandOp::ShouldArgumentBeConstant(const OpKernel* op_kernel,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_device_context.cc" line="147" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 138 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaTransferManager::CopyCPUTensorToDevice ( const Tensor * cpu_tensor , Device * device , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * device_tensor , StatusCallback done ) const" content="137:   XlaTensor* xla_tensor = XlaTensor::FromTensor(device_tensor);
138:   CHECK(xla_tensor);
139: 
140:   xla::StatusOr&lt;TensorShape&gt; shape_or_status =
141:       shape_representation_fn_(device_tensor-&gt;shape(), device_tensor-&gt;dtype());
142:   if (!shape_or_status.ok()) {
143:     done(shape_or_status.status());
144:     return;
145:   }
146:   TensorShape shape = shape_or_status.ValueOrDie();
147:   if (!xla_tensor-&gt;has_shaped_buffer()) {
148:     Status s =
149:         xla_tensor-&gt;AllocateShapedBuffer(device_tensor-&gt;dtype(), shape, client_,
150:                                          stream_-&gt;parent()-&gt;device_ordinal());
151:     if (!s.ok()) {
152:       done(s);
153:       return;
154:     }
155:   }
156: 
157:   Status status;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_device_context.cc" line="250" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_dst] to null at line 248 implies that [xla_dst ] might be null.Dereferencing null pointer [xla_dst]." web_identify="{&quot;identify&quot;:&quot;xla_dst&quot;}" func_info="void XlaTransferManager::CopyDeviceTensorToDevice ( const Tensor &amp; src_tensor , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst_tensor , const StatusCallback &amp; done )" content="240:       return Status::OK();
241:     }
242:     // TODO(jmolloy): We co-opt the device_to_host stream for device to device
243:     // transfers; perhaps we should have a dedicated device to device stream? or
244:     // one per device?
245:     auto device_to_device_stream = device_to_host_stream_;
246:     XlaTensor* xla_src = XlaTensor::FromTensor(&amp;src_tensor);
247:     XlaTensor* xla_dst = XlaTensor::FromTensor(dst_tensor);
248:     CHECK(xla_src &amp;&amp; xla_dst)
249:         &lt;&lt; &quot;Missing destination tensor for device-to-device copy&quot;;
250:     if (!xla_dst-&gt;has_shaped_buffer()) {
251:       TF_ASSIGN_OR_RETURN(
252:           TensorShape shape,
253:           shape_representation_fn_(src_tensor.shape(), src_tensor.dtype()));
254:       TF_RETURN_IF_ERROR(
255:           xla_dst-&gt;AllocateShapedBuffer(src_tensor.dtype(), shape, client_,
256:                                         stream_-&gt;parent()-&gt;device_ordinal()));
257:     }
258: 
259:     if (se::Event* event =
260:             xla_src-&gt;GetDefinitionEvent(device_to_device_stream)) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_device_context.cc" line="260" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_src] to null at line 248 implies that [xla_src ] might be null.Dereferencing null pointer [xla_src]." web_identify="{&quot;identify&quot;:&quot;xla_src&quot;}" func_info="void XlaTransferManager::CopyDeviceTensorToDevice ( const Tensor &amp; src_tensor , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst_tensor , const StatusCallback &amp; done )" content="250:     if (!xla_dst-&gt;has_shaped_buffer()) {
251:       TF_ASSIGN_OR_RETURN(
252:           TensorShape shape,
253:           shape_representation_fn_(src_tensor.shape(), src_tensor.dtype()));
254:       TF_RETURN_IF_ERROR(
255:           xla_dst-&gt;AllocateShapedBuffer(src_tensor.dtype(), shape, client_,
256:                                         stream_-&gt;parent()-&gt;device_ordinal()));
257:     }
258: 
259:     if (se::Event* event =
260:             xla_src-&gt;GetDefinitionEvent(device_to_device_stream)) {
261:       device_to_device_stream-&gt;ThenWaitFor(event);
262:       xla_src-&gt;SetDefinedOn(device_to_device_stream);
263:       TF_RETURN_IF_ERROR(device_to_device_stream-&gt;BlockHostUntilDone());
264:     }
265:     TF_RETURN_IF_ERROR(
266:         xla_dst-&gt;shaped_buffer().buffers().ForEachMutableElementWithStatus(
267:             [&amp;](const xla::ShapeIndex&amp; index, se::DeviceMemoryBase* buffer) {
268:               const se::DeviceMemoryBase&amp; from_buffer =
269:                   xla_src-&gt;shaped_buffer().buffers().element(index);
270:               CHECK_EQ(buffer-&gt;size(), from_buffer.size());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_device_context.cc" line="66" id="nullpointer" subid="dereferenceIfNull" severity="Critical" msg="[shape_representation_fn_] is null dereferenced here, as codes at line 65 make it a null pointer." web_identify="{&quot;identify&quot;:&quot;shape_representation_fn_&quot;}" func_info="XlaTransferManager::XlaTransferManager ( se::Stream * compute_stream , se::Stream * host_to_device_stream , se::Stream * device_to_host_stream , xla::LocalClient * client , bool transfer_as_literal , XlaCompiler::ShapeRepresentationFn shape_representation_fn ) : stream_ ( compute_stream ) , host_to_device_stream_ ( host_to_device_stream ) , device_to_host_stream_ ( device_to_host_stream ) , client_ ( client ) , transfer_manager_ ( client . backend ( ) . transfer_manager ( ) ) , transfer_as_literal_ ( transfer_as_literal ) , shape_representation_fn_ ( std::move ( shape_representation_fn ) )" content="56:       host_to_device_stream_(host_to_device_stream),
57:       device_to_host_stream_(device_to_host_stream),
58:       client_(client),
59:       transfer_manager_(client-&gt;backend().transfer_manager()),
60:       transfer_as_literal_(transfer_as_literal),
61:       shape_representation_fn_(std::move(shape_representation_fn)) {
62:   CHECK(host_to_device_stream_ != nullptr);
63:   CHECK(device_to_host_stream_ != nullptr);
64:   CHECK(stream_ != nullptr);
65:   if (!shape_representation_fn_) {
66:     shape_representation_fn_ =
67:         [](const TensorShape&amp; shape,
68:            DataType dtype) -&gt; xla::StatusOr&lt;TensorShape&gt; { return shape; };
69:   }
70: }
71: 
72: Status XlaTransferManager::TransferLiteralToDevice(
73:     const Tensor&amp; host_tensor, Tensor* device_tensor) const {
74:   xla::Shape xla_shape;
75:   TF_RETURN_IF_ERROR(TensorShapeToXLAShape(host_tensor.dtype(),
76:                                            host_tensor.shape(), &amp;xla_shape));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_device_context.cc" line="81" id="nullpointer" subid="funcRetNullStatistic" severity="Serious" msg="return value of function [FromTensor] [xla_tensor] isn&apos;t checked-null, however [10] times checked-null elsewhere." web_identify="FromTensor|xla_tensor" func_info="XlaTensor* FromTensor(Tensor*)" content="71: 
72: Status XlaTransferManager::TransferLiteralToDevice(
73:     const Tensor&amp; host_tensor, Tensor* device_tensor) const {
74:   xla::Shape xla_shape;
75:   TF_RETURN_IF_ERROR(TensorShapeToXLAShape(host_tensor.dtype(),
76:                                            host_tensor.shape(), &amp;xla_shape));
77:   xla::BorrowingLiteral literal(
78:       static_cast&lt;const char*&gt;(DMAHelper::base(&amp;host_tensor)), xla_shape);
79: 
80:   XlaTensor* xla_tensor = XlaTensor::FromTensor(device_tensor);
81:   const xla::ShapedBuffer&amp; shaped_buffer = xla_tensor-&gt;shaped_buffer();
82:   VLOG(1) &lt;&lt; &quot;Transfer to device as literal: &quot; &lt;&lt; literal.ToString() &lt;&lt; &quot; &quot;
83:           &lt;&lt; shaped_buffer.ToString();
84:   TF_RETURN_IF_ERROR(transfer_manager_-&gt;TransferLiteralToDevice(
85:       host_to_device_stream_, literal, shaped_buffer));
86:   if (UseMultipleStreams()) {
87:     se::Event event(stream_-&gt;parent());
88:     TF_RET_CHECK(event.Init()) &lt;&lt; &quot;Event failed to initialize!&quot;;
89:     host_to_device_stream_-&gt;ThenRecordEvent(&amp;event);
90:     xla_tensor-&gt;SetDefinedOn(host_to_device_stream_, std::move(event));
91:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_launch_util.cc" line="155" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 154 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="145:       t = &amp;(variables.at(arg_num).value);
146:       CHECK(t);
147:     } else {
148:       t = &amp;(ctx-&gt;input(arg_num));
149:     }
150: 
151:     if (use_multiple_streams_) {
152:       CHECK(stream) &lt;&lt; &quot;Must have a stream available when using XLA tensors!&quot;;
153:       XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
154:       CHECK(xla_tensor);
155:       if (se::Event* event = xla_tensor-&gt;GetDefinitionEvent(stream)) {
156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_launch_util.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [stream] to null at line 152 implies that [stream ] might be null.Dereferencing null pointer [stream]." web_identify="{&quot;identify&quot;:&quot;stream&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="146:       CHECK(t);
147:     } else {
148:       t = &amp;(ctx-&gt;input(arg_num));
149:     }
150: 
151:     if (use_multiple_streams_) {
152:       CHECK(stream) &lt;&lt; &quot;Must have a stream available when using XLA tensors!&quot;;
153:       XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
154:       CHECK(xla_tensor);
155:       if (se::Event* event = xla_tensor-&gt;GetDefinitionEvent(stream)) {
156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
166:       arg_ptrs_[i] = const_cast&lt;ShapedBuffer*&gt;(&amp;xla_tensor-&gt;shaped_buffer());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_launch_util.cc" line="166" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 165 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateInputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , const std::map &lt; int , OptionalTensor &gt; &amp; variables )" content="156:         stream-&gt;ThenWaitFor(event);
157:         xla_tensor-&gt;SetDefinedOn(stream);
158:       }
159:     }
160: 
161:     const xla::Shape on_device_shape =
162:         client_-&gt;backend().transfer_manager()-&gt;HostShapeToDeviceShape(shape);
163:     if (xla::ShapeUtil::IsTuple(on_device_shape)) {
164:       const XlaTensor* xla_tensor = XlaTensor::FromTensor(t);
165:       CHECK(xla_tensor &amp;&amp; xla_tensor-&gt;has_shaped_buffer());
166:       arg_ptrs_[i] = const_cast&lt;ShapedBuffer*&gt;(&amp;xla_tensor-&gt;shaped_buffer());
167:     } else {
168:       CHECK(xla::ShapeUtil::Equal(shape, on_device_shape))
169:           &lt;&lt; &quot;On-device shape &quot;
170:           &lt;&lt; xla::ShapeUtil::HumanStringWithLayout(on_device_shape)
171:           &lt;&lt; &quot; not the same as on-host shape &quot;
172:           &lt;&lt; xla::ShapeUtil::HumanStringWithLayout(shape);
173:       se::DeviceMemoryBase dmem = XlaTensor::DeviceMemoryFromTensor(*t);
174:       arg_buffers_[i] = xla::MakeUnique&lt;ShapedBuffer&gt;(
175:           /*on_host_shape=*/shape, /*on_device_shape=*/shape,
176:           client_-&gt;platform(), client_-&gt;default_device_ordinal());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/jit/xla_launch_util.cc" line="327" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [xla_tensor] to null at line 326 implies that [xla_tensor ] might be null.Dereferencing null pointer [xla_tensor]." web_identify="{&quot;identify&quot;:&quot;xla_tensor&quot;}" func_info="void XlaComputationLaunchContext::PopulateOutputs ( OpKernelContext * ctx , const XlaCompiler::CompilationResult * kernel , ScopedShapedBuffer output )" content="317:     mutex_lock ml(*variable-&gt;mu());
318:     OP_REQUIRES(ctx, variable-&gt;tensor()-&gt;dtype() == write.type,
319:                 errors::Internal(&quot;Mismatched type in variable write&quot;));
320: 
321:     if (allocate_xla_tensors_) {
322:       Tensor output_tensor;
323:       OP_REQUIRES_OK(
324:           ctx, ctx-&gt;allocate_temp(write.type, write.shape, &amp;output_tensor));
325:       XlaTensor* xla_tensor = XlaTensor::FromTensor(&amp;output_tensor);
326:       CHECK(xla_tensor);
327:       xla_tensor-&gt;set_shaped_buffer(
328:           ExtractSubShapedBuffer(&amp;output, output_num, xla_allocator_));
329:       if (use_multiple_streams_) {
330:         se::Event event(stream-&gt;parent());
331:         CHECK(event.Init());
332:         stream-&gt;ThenRecordEvent(&amp;event);
333:         xla_tensor-&gt;SetDefinedOn(stream, std::move(event));
334:       }
335:       *variable-&gt;tensor() = output_tensor;
336:     } else {
337:       Tensor output_tensor = XlaTensorBuffer::MakeTensor(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/tf2xla/functionalize_control_flow.cc" line="924" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="&gt; FunctionalizeCond::DeterminePredicateSwitchOrder ( )" content="914:   auto find_output_cluster = [&amp;](Node* n) {
915:     UnionFind&lt;Cluster&gt;* cluster = &amp;clusters[n-&gt;id()];
916:     if (!IsMerge(n)) return cluster;
917:     auto it = entry_cluster.find(clusters[n-&gt;id()].Get().representative);
918:     // If the cluster is not found in the entry_cluster map then an
919:     // instruction not dominated by a switch node has been merged into the
920:     // cluster of the merge. This indicates a failure of the clustering.
921:     CHECK(it != entry_cluster.end())
922:         &lt;&lt; &quot;Unable to find entry for n=&quot; &lt;&lt; n-&gt;id() &lt;&lt; &quot; (&quot;
923:         &lt;&lt; cluster-&gt;Get().representative &lt;&lt; &quot;)&quot;;
924:     return it-&gt;second;
925:   };
926: 
927:   // TODO(jpienaar): This could be combined with DetermineBranchMapAndFrontier.
928:   std::vector&lt;int&gt; switch_depth(graph_-&gt;num_node_ids());
929:   for (auto it = rev_topo_sorted_nodes.rbegin();
930:        it != rev_topo_sorted_nodes.rend(); ++it) {
931:     Node* n = *it;
932: 
933:     // Compute switch depth.
934:     int new_switch_depth = 0;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/tf2xla/kernels/sequence_ops.cc" line="83" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;delta&gt;0&apos; is redundant or there is division by zero at line 83." web_identify="" func_info="&gt; Status CreateRangeTensor ( const xla::LiteralSlice &amp; start_literal , const xla::LiteralSlice &amp; limit_literal , const xla::LiteralSlice &amp; delta_literal , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * output )" content="73:     }
74:   } else {
75:     if (start &lt; limit) {
76:       return errors::InvalidArgument(
77:           &quot;Requires start &gt;= limit when delta &lt; 0: &quot;, start, &quot;/&quot;, limit);
78:     }
79:   }
80:   int64 size =
81:       (std::is_integral&lt;T&gt;::value
82:            ? ((std::abs(limit - start) + std::abs(delta) - 1) / std::abs(delta))
83:            : std::ceil(std::abs((limit - start) / delta)));
84: 
85:   *output = Tensor(DataTypeToEnum&lt;T&gt;::v(), TensorShape({size}));
86:   auto flat = output-&gt;flat&lt;T&gt;();
87:   T val = start;
88:   for (int64 i = 0; i &lt; size; ++i) {
89:     flat(i) = val;
90:     val += delta;
91:   }
92:   return Status::OK();
93: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/tf2xla/xla_op_registry.cc" line="314" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="std::vector &lt; const KernelDef * &gt; XlaOpRegistry::DeviceKernels ( const string &amp; compilation_device_name , bool include_compilation_only_kernels )" content="304:     const string&amp; compilation_device_name,
305:     bool include_compilation_only_kernels) {
306:   // Ensure compilation kernels registered.
307:   RegisterCompilationKernels();
308:   std::vector&lt;const KernelDef*&gt; kernels;
309:   XlaOpRegistry&amp; registry = Instance();
310:   mutex_lock lock(registry.mutex_);
311:   auto it = registry.backends_.find(compilation_device_name);
312:   CHECK(it != registry.backends_.end())
313:       &lt;&lt; &quot;Unknown backend &quot; &lt;&lt; compilation_device_name;
314:   for (const std::unique_ptr&lt;KernelDef&gt;&amp; k : it-&gt;second.kernel_defs) {
315:     auto op_iter = registry.ops_.find(k-&gt;op());
316:     CHECK(op_iter != registry.ops_.end() &amp;&amp; !op_iter-&gt;second.empty());
317:     // The test in IsCompatible ensures that if there are multiple matching
318:     // registrations for this op name, they all have the same value of
319:     // compilation_only, so only the first match needs to be tested.
320:     if (include_compilation_only_kernels ||
321:         !op_iter-&gt;second.front()-&gt;compilation_only) {
322:       kernels.push_back(k.get());
323:     }
324:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/tf2xla/xla_op_registry.cc" line="321" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [op_iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;op_iter&quot;}" func_info="std::vector &lt; const KernelDef * &gt; XlaOpRegistry::DeviceKernels ( const string &amp; compilation_device_name , bool include_compilation_only_kernels )" content="311:   auto it = registry.backends_.find(compilation_device_name);
312:   CHECK(it != registry.backends_.end())
313:       &lt;&lt; &quot;Unknown backend &quot; &lt;&lt; compilation_device_name;
314:   for (const std::unique_ptr&lt;KernelDef&gt;&amp; k : it-&gt;second.kernel_defs) {
315:     auto op_iter = registry.ops_.find(k-&gt;op());
316:     CHECK(op_iter != registry.ops_.end() &amp;&amp; !op_iter-&gt;second.empty());
317:     // The test in IsCompatible ensures that if there are multiple matching
318:     // registrations for this op name, they all have the same value of
319:     // compilation_only, so only the first match needs to be tested.
320:     if (include_compilation_only_kernels ||
321:         !op_iter-&gt;second.front()-&gt;compilation_only) {
322:       kernels.push_back(k.get());
323:     }
324:   }
325:   return kernels;
326: }
327: 
328: /* static */ const std::unordered_set&lt;string&gt;*
329: XlaOpRegistry::CompileTimeConstantInputs(const string&amp; op) {
330:   XlaOpRegistry&amp; registry = Instance();
331:   mutex_lock lock(registry.mutex_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/client/client.cc" line="228" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [argument] to null at line 227 implies that [argument ] might be null.Dereferencing null pointer [argument]." web_identify="{&quot;identify&quot;:&quot;argument&quot;}" func_info="StatusOr &lt; std::unique_ptr &lt; GlobalData &gt; &gt; Client::Execute ( const XlaComputation &amp; computation , tensorflow::gtl::ArraySlice &lt; GlobalData * &gt; arguments , const ExecutionOptions * execution_options , ExecutionProfile * execution_profile )" content="218:   ExecuteGraphRequest request;
219:   *request.mutable_computation() = computation.proto();
220: 
221:   if (execution_options == nullptr) {
222:     *request.mutable_execution_options() = CreateDefaultExecutionOptions();
223:   } else {
224:     *request.mutable_execution_options() = *execution_options;
225:   }
226:   for (GlobalData* argument : arguments) {
227:     CHECK(argument != nullptr) &lt;&lt; &quot;Argument pointers must not be null.&quot;;
228:     *request.add_arguments() = argument-&gt;handle();
229:   }
230: 
231:   ExecuteResponse response;
232:   VLOG(1) &lt;&lt; &quot;making execute request: &quot; &lt;&lt; request.ShortDebugString();
233:   Status s = stub_-&gt;ExecuteGraph(&amp;request, &amp;response);
234:   VLOG(1) &lt;&lt; &quot;done with request&quot;;
235: 
236:   if (!s.ok()) {
237:     return s;
238:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/client/client_library.cc" line="120" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="LocalService * ClientLibrary::GetXlaService ( se::Platform * platform )" content="110:   TF_CHECK_OK(client_status.status());
111:   return client_status.ValueOrDie();
112: }
113: 
114: /* static */ LocalService* ClientLibrary::GetXlaService(
115:     se::Platform* platform) {
116:   ClientLibrary&amp; client_library = Singleton();
117:   tensorflow::mutex_lock lock(client_library.service_mutex_);
118:   auto it = client_library.local_instances_.find(platform-&gt;id());
119:   CHECK(it != client_library.local_instances_.end());
120:   return it-&gt;second-&gt;service.get();
121: }
122: 
123: /* static */ StatusOr&lt;CompileOnlyClient*&gt;
124: ClientLibrary::GetOrCreateCompileOnlyClient(se::Platform* platform) {
125:   ClientLibrary&amp; client_library = Singleton();
126:   tensorflow::mutex_lock lock(client_library.service_mutex_);
127: 
128:   if (platform == nullptr) {
129:     TF_ASSIGN_OR_RETURN(platform, PlatformUtil::GetDefaultPlatform());
130:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/metric_table_report.cc" line="83" id="logic" subid="STLFindError" severity="Warning" msg="Using long as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="void MetricTableReport::WriteReportToInfoLog ( double expected_metric_sum )" content="73:   return std::move(report_);
74: }
75: 
76: void MetricTableReport::WriteReportToInfoLog(double expected_metric_sum) {
77:   // Write something to the log normally to get the date-time and file prefix.
78:   LOG(INFO) &lt;&lt; &quot;Writing report to log.&quot;;
79: 
80:   int64 pos = 0;
81:   const string report = MakeReport(expected_metric_sum);
82:   while (pos &lt; report.size()) {
83:     int64 end_of_line = report.find(&apos;\n&apos;, pos);
84:     if (end_of_line == string::npos) {
85:       end_of_line = report.size();
86:     }
87:     tensorflow::StringPiece line(report.data() + pos, end_of_line - pos);
88: 
89:     // TODO(b/34779244): Figure out how to do this without the verbose log-line
90:     // prefix. The usual way didn&apos;t compile on open source.
91:     LOG(INFO) &lt;&lt; line;
92: 
93:     pos = end_of_line + 1;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1027" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [buffers_to_assign_sequentially] to null at line 846 implies that [buffers_to_assign_sequentially ] might be null.Dereferencing null pointer [buffers_to_assign_sequentially]." web_identify="{&quot;identify&quot;:&quot;buffers_to_assign_sequentially&quot;}" func_info="Status BufferAssigner::AssignBuffersForComputation ( const HloComputation * computation , const DebugOptions &amp; debug_options , bool is_thread_local , const FlatSet &lt; const LogicalBuffer * &gt; &amp; colocated_buffers , const FlatSet &lt; BufferAllocation::Index &gt; &amp; colocated_allocations , FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; * buffers_to_assign_sequentially , BufferAssignment * assignment )" content="1017:       // There is a sequential instruction ordering, so we delay assignment of
1018:       // temp buffers until after the loop. We do this right before we decide to
1019:       // create a new allocation, to ensure we&apos;ve exhausted all the buffer
1020:       // re-use cases above.
1021:       //
1022:       // Entry parameters and thread local buffers were already handled earlier
1023:       // in this loop iteration.  See BufferAllocation::IsPreallocatedTempBuffer
1024:       // for the definition of temp buffers.
1025:       CHECK(!is_entry_parameter) &lt;&lt; *buffer;
1026:       CHECK(!is_thread_local) &lt;&lt; *buffer;
1027:       (*buffers_to_assign_sequentially)[computation].insert(buffer);
1028:       VLOG(3) &lt;&lt; &quot;Delaying assignment of temp buffer: &quot; &lt;&lt; *buffer;
1029:       continue;
1030:     }
1031: 
1032:     if (!assignment-&gt;HasAllocation(*buffer)) {
1033:       BufferAllocation* allocation = assignment-&gt;NewAllocation(
1034:           *buffer, buffer_size, is_thread_local, /*is_reusable=*/true);
1035:       allocation_indices.push_back(allocation-&gt;index());
1036:       VLOG(3) &lt;&lt; &quot;New allocation #&quot; &lt;&lt; allocation-&gt;index()
1037:               &lt;&lt; &quot; for: &quot; &lt;&lt; *buffer;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1078" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [instruction_sequence] to null at line 1077 implies that [instruction_sequence ] might be null.Dereferencing null pointer [instruction_sequence]." web_identify="{&quot;identify&quot;:&quot;instruction_sequence&quot;}" func_info="Status BufferAssigner::AssignBuffersWithSequentialOrdering ( const FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; &amp; buffers_to_assign_sequentially , bool run_whole_module_heap_simulation , BufferAssignment * assignment )" content="1068:     // only live for the duration of their calling instructions.
1069:     VLOG(1) &lt;&lt; &quot;Running whole-module heap simulation&quot;;
1070:     SequentialHloOrdering::HloModuleSequence module_sequence;
1071:     FlatSet&lt;const LogicalBuffer*&gt; all_buffers_to_assign;
1072:     for (const auto&amp; pair : buffers_to_assign_sequentially) {
1073:       const HloComputation* computation = pair.first;
1074:       const FlatSet&lt;const LogicalBuffer*&gt;&amp; buffers_to_assign = pair.second;
1075:       const std::vector&lt;const HloInstruction*&gt;* instruction_sequence =
1076:           hlo_ordering.SequentialOrder(*computation);
1077:       CHECK(instruction_sequence != nullptr) &lt;&lt; computation-&gt;name();
1078:       module_sequence[computation] = *instruction_sequence;
1079:       all_buffers_to_assign.insert(buffers_to_assign.begin(),
1080:                                    buffers_to_assign.end());
1081:     }
1082:     auto color_map = SplitBuffersByColor(all_buffers_to_assign);
1083:     for (auto&amp; single_colored_set : color_map) {
1084:       auto color = single_colored_set.first;
1085:       VLOG(2) &lt;&lt; &quot;Simulating heap for color &quot; &lt;&lt; color;
1086:       int64 alignment = assignment-&gt;color_alignment_(color);
1087:       HeapSimulator::Options options;
1088:       BufferValueFlatSet buffer_value_set =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/buffer_assignment.cc" line="1127" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [instruction_sequence] to null at line 1111 implies that [instruction_sequence ] might be null.Dereferencing null pointer [instruction_sequence]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;instruction_sequence&quot;}" func_info="Status BufferAssigner::AssignBuffersWithSequentialOrdering ( const FlatMap &lt; const HloComputation * , FlatSet &lt; const LogicalBuffer * &gt; &gt; &amp; buffers_to_assign_sequentially , bool run_whole_module_heap_simulation , BufferAssignment * assignment )" content="1117:         HeapSimulator::Options options;
1118:         BufferValueFlatSet buffer_value_set =
1119:             ToBufferValueFlatSet(single_colored_set.second);
1120:         options.buffers_to_assign = &amp;buffer_value_set;
1121:         TF_ASSIGN_OR_RETURN(
1122:             const HeapSimulator::Result result,
1123:             HeapSimulator::Run(MakeUnique&lt;DecreasingSizeRunsHeap&gt;(
1124:                                    MakeUnique&lt;LazyBestFitHeap&gt;(alignment)),
1125:                                *computation, *instruction_sequence,
1126:                                assignment-&gt;points_to_analysis(),
1127:                                assignment-&gt;buffer_size_, options));
1128:         AssignBuffersFromHeapSimulator(result, assignment,
1129:                                        single_colored_set.first);
1130:       }
1131:     }
1132:   }
1133:   return Status::OK();
1134: }
1135: 
1136: namespace {
1137: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/call_graph.cc" line="129" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const CallGraphNode &amp; CallGraph::GetNode ( const HloComputation * computation ) const" content="119:     }
120:   }
121: }
122: 
123: CallGraph::CallGraph(const HloModule* module) : module_(module) {}
124: 
125: const CallGraphNode&amp; CallGraph::GetNode(
126:     const HloComputation* computation) const {
127:   auto it = node_indices_.find(computation);
128:   CHECK(it != node_indices_.end());
129:   return nodes_[it-&gt;second];
130: }
131: 
132: CallGraphNode&amp; CallGraph::GetNode(const HloComputation* computation) {
133:   auto it = node_indices_.find(computation);
134:   CHECK(it != node_indices_.end());
135:   return nodes_[it-&gt;second];
136: }
137: 
138: bool CallGraph::DominatesHelper(
139:     const HloComputation* a, const HloComputation* b,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/call_graph.cc" line="135" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="CallGraphNode &amp; CallGraph::GetNode ( const HloComputation * computation )" content="125: const CallGraphNode&amp; CallGraph::GetNode(
126:     const HloComputation* computation) const {
127:   auto it = node_indices_.find(computation);
128:   CHECK(it != node_indices_.end());
129:   return nodes_[it-&gt;second];
130: }
131: 
132: CallGraphNode&amp; CallGraph::GetNode(const HloComputation* computation) {
133:   auto it = node_indices_.find(computation);
134:   CHECK(it != node_indices_.end());
135:   return nodes_[it-&gt;second];
136: }
137: 
138: bool CallGraph::DominatesHelper(
139:     const HloComputation* a, const HloComputation* b,
140:     tensorflow::gtl::FlatSet&lt;const HloComputation*&gt;* visited) const {
141:   if (a == b || ContainsKey(*visited, b)) {
142:     // The call graph is guaranteed to be acyclic so any previously visited node
143:     // we encounter was already determined to be dominated.
144:     return true;
145:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/cpu/ir_emitter.cc" line="2699" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * IrEmitter::GetEmittedValueFor ( const HloInstruction * hlo )" content="2689:       std::back_inserter(arrays),
2690:       [&amp;](const HloInstruction* operand) { return GetIrArrayFor(operand); });
2691:   return arrays;
2692: }
2693: 
2694: llvm::Value* IrEmitter::GetEmittedValueFor(const HloInstruction* hlo) {
2695:   auto it = emitted_value_.find(hlo);
2696:   if (it == emitted_value_.end()) {
2697:     LOG(FATAL) &lt;&lt; &quot;could not find emitted value for: &quot; &lt;&lt; hlo-&gt;ToString();
2698:   }
2699:   return it-&gt;second;
2700: }
2701: 
2702: llvm::Type* IrEmitter::IrShapeType(const Shape&amp; shape) {
2703:   return llvm_ir::ShapeToIrType(shape, module_);
2704: }
2705: 
2706: llvm::Value* IrEmitter::GetProfileCountersArgument() {
2707:   return compute_function_-&gt;profile_counters_arg();
2708: }
2709: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/cpu/xfeed_manager.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [current_buffer_] to null at line 76 implies that [current_buffer_ ] might be null.Dereferencing null pointer [current_buffer_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;current_buffer_&quot;}" func_info="void XfeedQueueManager::ReleaseCurrentBuffer ( int length , void * data , StatusOr &lt; Shape &gt; shape )" content="67:   return current_buffer_;
68: }
69: 
70: void XfeedQueueManager::ReleaseCurrentBuffer(int32 length, void* data,
71:                                              StatusOr&lt;Shape&gt; shape) {
72:   VLOG(3) &lt;&lt; &quot;Releasing buffer with shape: &quot;
73:           &lt;&lt; (shape.ok() ? ShapeUtil::HumanString(shape.ValueOrDie())
74:                          : &quot;&lt;error status&gt;&quot;);
75:   tensorflow::mutex_lock l(mu_);
76:   CHECK(current_buffer_ != nullptr);
77:   CHECK_EQ(length, current_buffer_-&gt;length());
78:   CHECK_EQ(data, current_buffer_-&gt;data());
79:   current_buffer_-&gt;Done(std::move(shape));
80:   current_buffer_ = nullptr;
81: }
82: 
83: }  // namespace runtime
84: }  // namespace cpu
85: }  // namespace xla
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/fusion_merger.cc" line="68" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;instruction&quot;}" func_info="double CalculateBytesReadByFusionParameter ( HloInstruction * param )" content="58:   std::vector&lt;HloInstruction*&gt; instructions;
59:   MaybeResolveTupleElements(param, &amp;instructions);
60: 
61:   // Iterate through &apos;instructions&apos; accumulating byte sizes of each instruction
62:   // shape. For each &apos;instruction&apos; in &apos;instructions&apos;, if all users of
63:   // &apos;instruction&apos; are Slice instructions, accumuates the byte sizes of each
64:   // Slice for a more accurate estimate of bytes read.
65:   double bytes = 0.0;
66:   for (auto&amp; instruction : instructions) {
67:     if (c_all_of(instruction-&gt;users(), [](const HloInstruction* instruction) {
68:           return instruction-&gt;opcode() == HloOpcode::kSlice ||
69:                  instruction-&gt;opcode() == HloOpcode::kDynamicSlice;
70:         })) {
71:       // All users are slice: accumulate bytes of all user slice instructions.
72:       for (auto&amp; user : instruction-&gt;users()) {
73:         bytes += ShapeUtil::ByteSizeOf(user-&gt;shape());
74:       }
75:     } else {
76:       // Some users are not slice: accumulate full size of &apos;instruction&apos;.
77:       bytes += ShapeUtil::ByteSizeOf(instruction-&gt;shape());
78:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/hlo_to_ir_bindings.h" line="77" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * HloToIrBindings::GetBasePointer ( const HloInstruction &amp; hlo , ShapeIndexView shape_index = { } ) const" content="67: 
68:   llvm::Value* GetTempBufferBase() const { return temp_buffer_base_; }
69:   void SetTempBufferBase(llvm::Value* v) { temp_buffer_base_ = v; }
70: 
71:   // A helper method that returns the base pointer of the IrArray containing the
72:   // output of &quot;inst&quot;.at the given ShapeIndex.
73:   llvm::Value* GetBasePointer(const HloInstruction&amp; hlo,
74:                               ShapeIndexView shape_index = {}) const {
75:     auto it = base_ptrs_.find(&amp;hlo);
76:     CHECK(it != base_ptrs_.end()) &lt;&lt; hlo.ToString();
77:     return it-&gt;second.element(shape_index);
78:   }
79: 
80:   // Returns the IrArray which contains the output of hlo.
81:   //
82:   // consumer is the HLO in which this IrArray is used -- we use this to (try
83:   // to) add metadata indicating that the array is invariant within consumer.
84:   //
85:   // To get the buffer into which hlo should write its own output, call
86:   // GetIrArray(hlo, hlo).
87:   llvm_ir::IrArray GetIrArray(const HloInstruction&amp; hlo,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/ir_emitter_unnested.cc" line="628" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [first_reduce] to null at line 593 implies that [first_reduce ] might be null.Dereferencing null pointer [first_reduce]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;first_reduce&quot;}" func_info="Status IrEmitterUnnested::HandleFusion ( HloInstruction * fusion )" content="618:           const HloInstruction* inst = output_instructions[i];
619:           ShapeIndex output_shape_index;
620:           if (root-&gt;opcode() == HloOpcode::kTuple) {
621:             output_shape_index = {i};
622:           }
623:           if (inst-&gt;opcode() == HloOpcode::kReduce) {
624:             CHECK(IsReductionToVector(*inst))
625:                 &lt;&lt; &quot;Only reductions to vector are supported&quot;;
626:             // Shapes, layouts and dimensions must be the same for all reduces
627:             // inside of this fusion.
628:             CHECK(ShapeUtil::Equal(first_reduce-&gt;shape(), inst-&gt;shape()));
629:             CHECK(ShapeUtil::Equal(first_reduce-&gt;operand(0)-&gt;shape(),
630:                                    inst-&gt;operand(0)-&gt;shape()));
631:             CHECK(ShapeUtil::Equal(first_reduce-&gt;operand(1)-&gt;shape(),
632:                                    inst-&gt;operand(1)-&gt;shape()));
633:             CHECK(first_reduce-&gt;dimensions() == inst-&gt;dimensions());
634:             input_gens.push_back(fused_emitter.GetGenerator(inst-&gt;operand(0)));
635:             init_value_gens.push_back(
636:                 fused_emitter.GetGenerator(inst-&gt;operand(1)));
637:             reducers.push_back(inst-&gt;to_apply());
638:             reduce_output_shapes.push_back(std::move(output_shape_index));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/kernel_thunk.cc" line="92" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Status KernelThunk::ExecuteOnStream ( const BufferAllocations &amp; buffer_allocations , se::Stream * stream , HloExecutionProfiler * profiler )" content="82:   se::StreamExecutor* executor = stream-&gt;parent();
83:   LaunchDimensions launch_dimensions;
84:   const se::KernelBase* kernel = nullptr;
85: 
86:   {
87:     tensorflow::mutex_lock lock(mutex_);
88:     auto it = kernel_cache_.find(executor);
89:     CHECK(it != kernel_cache_.end())
90:         &lt;&lt; &quot;Initialize() not called for StreamExecutor &quot; &lt;&lt; executor;
91:     launch_dimensions = launch_dimensions_;
92:     kernel = &amp;it-&gt;second;
93:   }
94: 
95:   VLOG(3) &lt;&lt; &quot;Launching &quot; &lt;&lt; kernel-&gt;name();
96:   // Launch the kernel with potentially multiple blocks and threads.
97:   static constexpr int kKernelArgsLimit = 1024;
98:   auto kernel_args = MakeUnique&lt;se::KernelArgsArray&lt;kKernelArgsLimit&gt;&gt;();
99:   for (const BufferAllocation* arg : args_) {
100:     const auto&amp; buf = buffer_allocations.GetDeviceAddress(arg-&gt;index());
101:     kernel_args-&gt;add_device_memory_argument(buf);
102:     VLOG(3) &lt;&lt; &quot;  Arg: alloc #&quot; &lt;&lt; arg-&gt;index() &lt;&lt; &quot;: &quot; &lt;&lt; buf.opaque() &lt;&lt; &quot; (&quot;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/multi_output_fusion.cc" line="223" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;producer&quot;}" func_info="bool GpuMultiOutputFusion::DoProducerConsumerMultiOutputFusion ( )" content="213:       break;
214:     }
215:   }
216: 
217:   // Filter out pairs that will be no longer fusable because of reachability
218:   // change.
219:   for (auto&amp; fusion_pair : potential_fusion_list) {
220:     HloInstruction* producer = fusion_pair.first;
221:     HloInstruction* consumer = fusion_pair.second;
222:     if (!c_any_of(consumer-&gt;operands(), [&amp;](HloInstruction* operand) {
223:           return producer != operand &amp;&amp;
224:                  reachability()-&gt;IsReachable(producer, operand);
225:         })) {
226:       UpdateReachability(producer, consumer, instrs_to_update_reachability);
227:       fusion_list.push_back(fusion_pair);
228:     }
229:   }
230: 
231:   for (auto fusions_to_create : fusion_list) {
232:     HloInstruction* producer = fusions_to_create.first;
233:     HloInstruction* consumer = fusions_to_create.second;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/gpu/while_transformer.cc" line="139" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fused_root_tree_] to null at line 136 implies that [fused_root_tree_ ] might be null.Dereferencing null pointer [fused_root_tree_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;fused_root_tree_&quot;}" func_info="Status ExprTree::Match ( const HloInstruction * instruction , std :: unordered_map &lt; string , const HloInstruction * &gt; * tagged_instructions ) const" content="129: 
130:     VLOG(2) &lt;&lt; &quot;Matched &quot; &lt;&lt; HloOpcodeString(opcode_) &lt;&lt; &quot;: &quot; &lt;&lt; tag_;
131:     if (!tag_.empty()) {
132:       tagged_instructions-&gt;insert({tag_, instruction});
133:     }
134: 
135:     if (instruction-&gt;opcode() == HloOpcode::kFusion) {
136:       CHECK(fused_root_tree_ != nullptr);
137:       // Match fused instructions for this node starting a &apos;fused_root_tree&apos;.
138:       TF_RETURN_IF_ERROR(fused_root_tree_-&gt;Match(
139:           instruction-&gt;fused_expression_root(), tagged_instructions));
140:     }
141: 
142:     // Match each operand in &apos;operands_&apos;.
143:     for (auto&amp; pair : operands_) {
144:       TF_RETURN_IF_ERROR(pair.second-&gt;Match(instruction-&gt;operand(pair.first),
145:                                             tagged_instructions));
146:     }
147:     return Status::OK();
148:   }
149: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/heap_simulator.cc" line="508" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [share_with_canonical] to null at line 507 implies that [share_with_canonical ] might be null.Dereferencing null pointer [share_with_canonical]." web_identify="{&quot;identify&quot;:&quot;share_with_canonical&quot;}" func_info="void HeapSimulator::FillDebugTrace ( HeapSimulatorTrace::Event::Kind kind , const BufferValue * buffer , const HloInstruction * instruction , const BufferValue * share_with_canonical )" content="498:                                    const BufferValue* buffer,
499:                                    const HloInstruction* instruction,
500:                                    const BufferValue* share_with_canonical) {
501:   HeapSimulatorTrace::Event* event = debug_trace_.add_events();
502:   event-&gt;set_kind(kind);
503:   event-&gt;set_buffer_id(buffer-&gt;id());
504:   event-&gt;set_computation_name(instruction-&gt;parent()-&gt;name());
505:   event-&gt;set_instruction_name(instruction-&gt;name());
506:   if (kind == HeapSimulatorTrace::Event::SHARE_WITH) {
507:     CHECK(share_with_canonical != nullptr);
508:     event-&gt;set_share_with_canonical_id(share_with_canonical-&gt;id());
509:   } else {
510:     CHECK(share_with_canonical == nullptr);
511:   }
512: }
513: 
514: void NoFragmentationStatsHeap::Alloc(const BufferValue* buffer, int64 size) {
515:   current_heap_size_ += size;
516:   if (current_heap_size_ &gt; max_heap_size_) {
517:     max_heap_size_ = current_heap_size_;
518:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/heap_simulator.cc" line="671" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [alloc_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;alloc_it&quot;}" func_info="void LazyBestFitHeap::Free ( const BufferValue * buffer , long size )" content="661:   }
662: 
663:   // Otherwise lazily allocate the buffer in Free.
664:   result_.chunk_map.emplace(buffer, Chunk{kLazyAllocOffset, size});
665: }
666: 
667: void LazyBestFitHeap::Free(const BufferValue* buffer, int64 size) {
668:   auto alloc_it = result_.chunk_map.find(buffer);
669:   CHECK(alloc_it != result_.chunk_map.end())
670:       &lt;&lt; &quot;Free called on non-allocated buffer: &quot; &lt;&lt; *buffer;
671:   Chunk* alloc = &amp;alloc_it-&gt;second;
672:   CHECK_EQ(alloc-&gt;size, size) &lt;&lt; &quot;Free with mismatched sizes: &quot; &lt;&lt; *buffer;
673:   if (alloc-&gt;offset != kLazyAllocOffset) {
674:     // The buffer was already allocated in Alloc, do a normal free.
675:     AddFreeChunk(alloc-&gt;offset, alloc-&gt;size);
676:   } else {
677:     // This buffer is lazily allocated, so we *can not* allocate out of existing
678:     // free chunks, since that might cause interference between buffers.  The
679:     // buffer is allocated by growing the heap, accounting for alignment.
680:     alloc-&gt;offset = RoundUpToNearest(result_.heap_size, alignment_);
681:     const int64 new_end = alloc-&gt;chunk_end();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_cost_analysis.cc" line="35" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloCostAnalysis::current_should_compute_bottleneck_time_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloCostAnalysis::current_should_compute_bottleneck_time_,&quot;}" func_info="xla" content="25: #include &quot;tensorflow/core/lib/core/errors.h&quot;
26: #include &quot;tensorflow/core/lib/gtl/map_util.h&quot;
27: 
28: namespace xla {
29: 
30: constexpr char HloCostAnalysis::kFlopsKey[];
31: constexpr char HloCostAnalysis::kTranscendentalsKey[];
32: constexpr char HloCostAnalysis::kBytesAccessedKey[];
33: constexpr char HloCostAnalysis::kOptimalSecondsKey[];
34: 
35: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size)
36:     : HloCostAnalysis(shape_size, {}) {}
37: 
38: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size,
39:                                  const Properties&amp; per_second_rates)
40:     : shape_size_(shape_size), per_second_rates_(per_second_rates) {}
41: 
42: Status HloCostAnalysis::Preprocess(const HloInstruction* hlo) {
43:   // Set current instruction cost values to reasonable default values. Each
44:   // handler can overwrite these values. In Postprocess, these values are
45:   // accumulated and written to the per-instruction maps.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_cost_analysis.cc" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloCostAnalysis::current_should_compute_bottleneck_time_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloCostAnalysis::current_should_compute_bottleneck_time_,&quot;}" func_info="xla" content="28: namespace xla {
29: 
30: constexpr char HloCostAnalysis::kFlopsKey[];
31: constexpr char HloCostAnalysis::kTranscendentalsKey[];
32: constexpr char HloCostAnalysis::kBytesAccessedKey[];
33: constexpr char HloCostAnalysis::kOptimalSecondsKey[];
34: 
35: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size)
36:     : HloCostAnalysis(shape_size, {}) {}
37: 
38: HloCostAnalysis::HloCostAnalysis(const ShapeSizeFunction&amp; shape_size,
39:                                  const Properties&amp; per_second_rates)
40:     : shape_size_(shape_size), per_second_rates_(per_second_rates) {}
41: 
42: Status HloCostAnalysis::Preprocess(const HloInstruction* hlo) {
43:   // Set current instruction cost values to reasonable default values. Each
44:   // handler can overwrite these values. In Postprocess, these values are
45:   // accumulated and written to the per-instruction maps.
46:   current_properties_.clear();
47:   current_should_compute_bottleneck_time_ = true;
48: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_dataflow_analysis_test.cc" line="64" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [analysis_] to null at line 61 implies that [analysis_ ] might be null.Dereferencing null pointer [analysis_]." web_identify="{&quot;identify&quot;:&quot;analysis_&quot;}" func_info="std::vector &lt; HloValue &gt; HloDataflowAnalysisTest::HloValuesAt ( const HloInstruction * instruction , const ShapeIndex &amp; index = { } )" content="54:             .ConsumeValueOrDie();
55:     return *analysis_;
56:   }
57: 
58:   // Return a vector of the HloValues at the given program position.
59:   std::vector&lt;HloValue&gt; HloValuesAt(const HloInstruction* instruction,
60:                                     const ShapeIndex&amp; index = {}) {
61:     CHECK(analysis_ != nullptr);
62:     std::vector&lt;HloValue&gt; values;
63:     for (const HloValue* value :
64:          analysis_-&gt;GetValueSet(instruction, index).values()) {
65:       values.push_back(*value);
66:     }
67:     return values;
68:   }
69: 
70:   // Returns true if the top-level values for instructions &apos;a&apos; and &apos;b&apos; may
71:   // interfere. Precondition: &apos;a&apos; and &apos;b&apos; define array-shaped values.
72:   bool InstructionsMayInterfere(const HloOrdering&amp; ordering,
73:                                 const HloInstruction* a,
74:                                 const HloInstruction* b) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_evaluator.h" line="199" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const Literal &amp; HloEvaluator::GetEvaluatedLiteralFor ( const HloInstruction * hlo )" content="189:   // A Constant instruction is considered evaluated and its literal will be
190:   // returned directly without looking up the cache.
191:   // Crash with log if the given instruction has not been evaluated previously.
192:   const Literal&amp; GetEvaluatedLiteralFor(const HloInstruction* hlo) {
193:     if (hlo-&gt;IsConstant()) {
194:       return hlo-&gt;literal();
195:     }
196:     auto it = evaluated_.find(hlo);
197:     CHECK(it != evaluated_.end())
198:         &lt;&lt; &quot;could not find evaluated value for: &quot; &lt;&lt; hlo-&gt;ToString();
199:     return *(it-&gt;second);
200:   }
201: 
202:   // Tracks the HLO instruction and its evaluated literal result.
203:   // TODO(b/35950897): have better memory management here to free instructions
204:   // that are no longer a parent for any other subsequent instruction in
205:   // post-orderring.
206:   // Must be cleared for each evaluation.
207:   tensorflow::gtl::FlatMap&lt;const HloInstruction*, std::unique_ptr&lt;Literal&gt;&gt;
208:       evaluated_;
209: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_graph_dumper.cc" line="1461" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph_renderer] to null at line 1458 implies that [graph_renderer ] might be null.Dereferencing null pointer [graph_renderer]." web_identify="{&quot;identify&quot;:&quot;graph_renderer&quot;}" func_info="string ExportGraph ( const string &amp; graph , int graph_kind , const DebugOptions &amp; debug_options )" content="1451:                    const DebugOptions&amp; debug_options) {
1452:   string path = debug_options.xla_hlo_graph_path();
1453:   if (!path.empty()) {
1454:     return SaveGraph(graph, graph_kind, path);
1455:   } else {
1456:     auto graph_renderer =
1457:         GraphRendererRegistry::Default()-&gt;GetDefaultRenderer();
1458:     CHECK(graph_renderer != nullptr)
1459:         &lt;&lt; &quot;No registered renderer for the HLO graph. &quot;
1460:            &quot;Use --xla_hlo_graph_path=PATH to export to local file system&quot;;
1461:     return graph_renderer-&gt;RenderGraph(graph, graph_kind, debug_options);
1462:   }
1463: }
1464: 
1465: }  // namespace
1466: 
1467: string DumpGraph(const HloComputation&amp; computation, const string&amp; label,
1468:                  const DebugOptions&amp; debug_options,
1469:                  const HloExecutionProfile* hlo_execution_profile,
1470:                  bool show_backend_config) {
1471:   GraphRendererInterface::GraphKind graph_kind;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_graph_dumper.cc" line="325" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloDotDumper::root_node_id_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloDotDumper::root_node_id_,&quot;}" func_info="HloDotDumper" content="315:     case HloOpcode::kNe:
316:       return &quot;not-equal-to&quot;;
317:     default:
318:       return nullopt;
319:   }
320: }
321: 
322: // Encapsulates logic for dumping an HLO module to DOT (i.e. graphviz syntax).
323: class HloDotDumper {
324:  public:
325:   HloDotDumper(const HloComputation* computation, tensorflow::StringPiece label,
326:                const DebugOptions&amp; debug_options, bool show_backend_config,
327:                const HloExecutionProfile* profile, NodeFilter filter)
328:       : computation_(computation),
329:         label_(std::string(label)),
330:         debug_options_(debug_options),
331:         show_backend_config_(show_backend_config),
332:         profile_(profile),
333:         filter_(std::move(filter)) {}
334: 
335:   string Dump();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instruction.cc" line="2316" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [child] to null at line 2315 implies that [child ] might be null.Dereferencing null pointer [child]." web_identify="{&quot;identify&quot;:&quot;child&quot;}" func_info="&gt; bool xla::PushDFSChild ( Visitor * visitor , DFSStack * dfs_stack , HloInstruction * child )" content="2306: 
2307: using DFSStack =
2308:     tensorflow::gtl::InlinedVector&lt;std::pair&lt;int, HloInstruction*&gt;, 16&gt;;
2309: 
2310: // Push &quot;child&quot; onto the dfs_stack if not already visited.  Returns false if a
2311: // cycle was detected, and true otherwise.
2312: template &lt;typename Visitor&gt;
2313: inline bool PushDFSChild(Visitor* visitor, DFSStack* dfs_stack,
2314:                          HloInstruction* child) {
2315:   CHECK(child != nullptr);
2316:   const int id = child-&gt;unique_id();
2317:   CHECK_GE(id, 0) &lt;&lt; &quot;instruction may not have a parent computation&quot;;
2318:   switch (visitor-&gt;GetVisitState(id)) {
2319:     case Visitor::kVisiting:
2320:       return false;
2321: 
2322:     case Visitor::kVisited:
2323:       // Nothing to do
2324:       return true;
2325: 
2326:     case Visitor::kNotVisited:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instruction.h" line="1071" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dot_dimension_numbers_] to null at line 1070 implies that [dot_dimension_numbers_ ] might be null.Dereferencing null pointer [dot_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;dot_dimension_numbers_&quot;}" func_info="const DotDimensionNumbers &amp; HloInstruction::dot_dimension_numbers ( ) const" content="1061:   }
1062: 
1063:   void SetCopyElisionAllowed(bool value) {
1064:     CHECK_EQ(HloOpcode::kCopy, opcode_);
1065:     copy_elision_allowed_ = value;
1066:   }
1067: 
1068:   // Returns data on the dimension numbers used for a dot operation.
1069:   const DotDimensionNumbers&amp; dot_dimension_numbers() const {
1070:     CHECK(dot_dimension_numbers_ != nullptr);
1071:     return *dot_dimension_numbers_;
1072:   }
1073: 
1074:   // Returns the dump string of the dot dimension numbers.
1075:   string DotDimensionNumbersToString() const;
1076: 
1077:   // Clones the HLO instruction. The clone will have the same opcode, shape, and
1078:   // operands. After creation the clone has no uses. &quot;this&quot; (the instruction
1079:   // cloned from) is not changed. Suffix is the string to append to the name of
1080:   // the instruction to form the name of the cloned instruction.
1081:   // Ignores the control predecessors and successors of this HLO instruction.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instructions.cc" line="1934" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gather_dimension_numbers_] to null at line 1931 implies that [gather_dimension_numbers_ ] might be null.Dereferencing null pointer [gather_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;gather_dimension_numbers_&quot;}" func_info="string HloGatherInstruction::GatherDimensionNumbersToString ( ) const" content="1924:   AppendOperand(gather_indices);
1925:   gather_dimension_numbers_ =
1926:       MakeUnique&lt;GatherDimensionNumbers&gt;(gather_dim_numbers);
1927:   c_copy(window_bounds, std::back_inserter(gather_window_bounds_));
1928: }
1929: 
1930: string HloGatherInstruction::GatherDimensionNumbersToString() const {
1931:   CHECK(gather_dimension_numbers_ != nullptr);
1932:   string output_window_dims =
1933:       StrCat(&quot;output_window_dims={&quot;,
1934:              Join(gather_dimension_numbers_-&gt;output_window_dims(), &quot;,&quot;), &quot;}&quot;);
1935:   string elided_window_dims =
1936:       StrCat(&quot;elided_window_dims={&quot;,
1937:              Join(gather_dimension_numbers_-&gt;elided_window_dims(), &quot;,&quot;), &quot;}&quot;);
1938:   string gather_dims_to_operand_dims = StrCat(
1939:       &quot;gather_dims_to_operand_dims={&quot;,
1940:       Join(gather_dimension_numbers_-&gt;gather_dims_to_operand_dims(), &quot;,&quot;), &quot;}&quot;);
1941:   string index_vector_dim = StrCat(
1942:       &quot;index_vector_dim=&quot;, gather_dimension_numbers_-&gt;index_vector_dim());
1943: 
1944:   return Join&lt;std::initializer_list&lt;string&gt;&gt;(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instructions.cc" line="841" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fused_root] to null at line 839 implies that [fused_root ] might be null.Dereferencing null pointer [fused_root]." web_identify="{&quot;identify&quot;:&quot;fused_root&quot;}" func_info="HloFusionInstruction::HloFusionInstruction ( const Shape &amp; shape , int fusion_kind , HloInstruction * fused_root ) : HloInstruction ( HloOpcode::kFusion , shape ) , fusion_kind_ ( fusion_kind )" content="831:     HloCloneContext* context) const {
832:   LOG(FATAL) &lt;&lt; &quot;Not yet implemented, clone: &quot; &lt;&lt; HloOpcodeString(opcode());
833: }
834: 
835: HloFusionInstruction::HloFusionInstruction(const Shape&amp; shape,
836:                                            FusionKind fusion_kind,
837:                                            HloInstruction* fused_root)
838:     : HloInstruction(HloOpcode::kFusion, shape), fusion_kind_(fusion_kind) {
839:   CHECK(fused_root != nullptr);
840:   SetAndSanitizeName(&quot;fusion&quot;);
841:   set_parent(fused_root-&gt;parent());
842:   set_metadata(fused_root-&gt;metadata());
843:   CloneAndFuseInternal(fused_root);
844: }
845: 
846: HloFusionInstruction::HloFusionInstruction(
847:     const Shape&amp; shape, FusionKind fusion_kind,
848:     tensorflow::gtl::ArraySlice&lt;HloInstruction*&gt; operands,
849:     HloComputation* fusion_computation)
850:     : HloInstruction(HloOpcode::kFusion, shape), fusion_kind_(fusion_kind) {
851:   for (auto operand : operands) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instructions.h" line="1020" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [window_] to null at line 1019 implies that [window_ ] might be null.Dereferencing null pointer [window_]." web_identify="{&quot;identify&quot;:&quot;window_&quot;}" func_info="const Window &amp; HloCustomCallInstruction::window ( ) const" content="1010:   Window window_;
1011: };
1012: 
1013: class HloCustomCallInstruction : public HloInstruction {
1014:  public:
1015:   explicit HloCustomCallInstruction(
1016:       const Shape&amp; shape, tensorflow::gtl::ArraySlice&lt;HloInstruction*&gt; operands,
1017:       tensorflow::StringPiece custom_call_target);
1018:   const Window&amp; window() const override {
1019:     CHECK(window_ != nullptr);
1020:     return *window_;
1021:   }
1022: 
1023:   void set_window(const Window&amp; window) override {
1024:     window_ = MakeUnique&lt;Window&gt;(window);
1025:   }
1026: 
1027:   const ConvolutionDimensionNumbers&amp; convolution_dimension_numbers() const {
1028:     CHECK(convolution_dimension_numbers_ != nullptr);
1029:     return *convolution_dimension_numbers_;
1030:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instructions.h" line="1029" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [convolution_dimension_numbers_] to null at line 1028 implies that [convolution_dimension_numbers_ ] might be null.Dereferencing null pointer [convolution_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;convolution_dimension_numbers_&quot;}" func_info="const ConvolutionDimensionNumbers &amp; HloCustomCallInstruction::convolution_dimension_numbers ( ) const" content="1019:     CHECK(window_ != nullptr);
1020:     return *window_;
1021:   }
1022: 
1023:   void set_window(const Window&amp; window) override {
1024:     window_ = MakeUnique&lt;Window&gt;(window);
1025:   }
1026: 
1027:   const ConvolutionDimensionNumbers&amp; convolution_dimension_numbers() const {
1028:     CHECK(convolution_dimension_numbers_ != nullptr);
1029:     return *convolution_dimension_numbers_;
1030:   }
1031: 
1032:   void set_convolution_dimension_numbers(
1033:       const ConvolutionDimensionNumbers&amp; dnums) {
1034:     convolution_dimension_numbers_ =
1035:         MakeUnique&lt;ConvolutionDimensionNumbers&gt;(dnums);
1036:   }
1037:   const string&amp; custom_call_target() const { return custom_call_target_; }
1038:   // Returns a serialized representation of this instruction.
1039:   HloInstructionProto ToProto() const override;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_instructions.h" line="1161" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gather_dimension_numbers_] to null at line 1160 implies that [gather_dimension_numbers_ ] might be null.Dereferencing null pointer [gather_dimension_numbers_]." web_identify="{&quot;identify&quot;:&quot;gather_dimension_numbers_&quot;}" func_info="const GatherDimensionNumbers &amp; HloGatherInstruction::gather_dimension_numbers ( ) const" content="1151: 
1152: class HloGatherInstruction : public HloInstruction {
1153:  public:
1154:   explicit HloGatherInstruction(
1155:       const Shape&amp; shape, HloInstruction* operand,
1156:       HloInstruction* gather_indices,
1157:       const GatherDimensionNumbers&amp; gather_dim_numbers,
1158:       tensorflow::gtl::ArraySlice&lt;int64&gt; window_bounds);
1159:   const GatherDimensionNumbers&amp; gather_dimension_numbers() const {
1160:     CHECK(gather_dimension_numbers_ != nullptr);
1161:     return *gather_dimension_numbers_;
1162:   }
1163:   tensorflow::gtl::ArraySlice&lt;int64&gt; gather_window_bounds() const {
1164:     return gather_window_bounds_;
1165:   }
1166:   // Returns the dump string of the gather dimension numbers.
1167:   string GatherDimensionNumbersToString() const;
1168:   // Returns a serialized representation of this instruction.
1169:   HloInstructionProto ToProto() const override;
1170: 
1171:   // Creates an instance of GatherDimensionNumbers.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_lexer.h" line="37" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;HloLexer::token_start_,current_kind_,decimal_val_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;HloLexer::token_start_,current_kind_,decimal_val_,&quot;}" func_info="xla::HloLexer" content="27: #include &quot;map/base/mlp/tf/tensorflow/core/platform/types.h&quot;
28: 
29: namespace xla {
30: 
31: // Lexer for the HloModule::ToString() format text.
32: //
33: // This class is meant to be used by hlo_parser.cc.  You shouldn&apos;t need to use
34: // it directly.
35: class HloLexer {
36:  public:
37:   explicit HloLexer(tensorflow::StringPiece buf) : buf_(buf) {
38:     current_ptr_ = buf_.begin();
39:   }
40: 
41:   TokKind Lex() { return current_kind_ = LexToken(); }
42: 
43:   TokKind GetKind() const { return current_kind_; }
44:   string GetStrVal() const {
45:     switch (GetKind()) {
46:       case TokKind::kName:
47:       case TokKind::kAttributeName:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_rematerialization.cc" line="189" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="Item * InstructionList::GetItem ( const HloInstruction * inst ) const" content="179:     Item* item = new Item;
180:     item-&gt;instruction = inst;
181:     CHECK(item_map_.insert({inst, item}).second) &lt;&lt; &quot;inserting inst twice&quot;;
182:     return item;
183:   }
184: 
185:   // Return the Item corresponding to inst.
186:   Item* GetItem(const HloInstruction* inst) const {
187:     auto iter = item_map_.find(inst);
188:     CHECK(iter != item_map_.end()) &lt;&lt; &quot;Did not find &quot; &lt;&lt; inst-&gt;name();
189:     return iter-&gt;second;
190:   }
191: 
192:   // Insert instruction &apos;to_insert&apos; immediately before the earliest instruction
193:   // in &apos;before_instructions&apos;.
194:   //
195:   // Each instruction gets a non-decreasing ordinal number. We use this to let
196:   // InsertBeforeInstructions quickly insert an instruction before the earliest
197:   // instruction in a set of instructions.  If position_number_[a] &lt;
198:   // position_number_[b] then &apos;a&apos; comes before &apos;b&apos; in the list. If the position
199:   // numbers are the same then nothing can be said about their order without
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_runner.cc" line="114" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [literal] to null at line 112 implies that [literal ] might be null.Dereferencing null pointer [literal]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;literal&quot;}" func_info="StatusOr &lt; std::vector &lt; ScopedShapedBuffer &gt; &gt; HloRunner::TransferLiteralsToDevice ( const tensorflow::gtl::ArraySlice &lt; const Literal * &gt; literals )" content="104:       stream.get(), literal, buffer));
105:   return std::move(buffer);
106: }
107: 
108: StatusOr&lt;std::vector&lt;ScopedShapedBuffer&gt;&gt; HloRunner::TransferLiteralsToDevice(
109:     const tensorflow::gtl::ArraySlice&lt;const Literal*&gt; literals) {
110:   std::vector&lt;ScopedShapedBuffer&gt; buffers;
111:   for (const Literal* literal : literals) {
112:     CHECK(literal != nullptr);
113:     TF_ASSIGN_OR_RETURN(ScopedShapedBuffer buffer,
114:                         TransferLiteralToDevice(*literal));
115:     buffers.push_back(std::move(buffer));
116:   }
117:   return std::move(buffers);
118: }
119: 
120: StatusOr&lt;std::vector&lt;ScopedShapedBuffer&gt;&gt; HloRunner::TransferLiteralsToDevice(
121:     const tensorflow::gtl::ArraySlice&lt;std::unique_ptr&lt;Literal&gt;&gt; literals) {
122:   std::vector&lt;const Literal*&gt; literal_pointers;
123:   literal_pointers.reserve(literals.size());
124:   for (const auto&amp; literal : literals) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_scheduling.cc" line="192" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [unscheduled_use_count_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;unscheduled_use_count_it&quot;}" func_info="ReadyListEntry ListScheduler::MakeReadyListEntry ( const HloInstruction * instruction )" content="182:       }
183:     }
184: 
185:     for (auto* buffer : buffer_uses_.at(instruction)) {
186:       if (IgnoreBuffer(*buffer)) {
187:         continue;
188:       }
189:       auto unscheduled_use_count_it = unscheduled_use_count_.find(buffer);
190:       CHECK(unscheduled_use_count_it != unscheduled_use_count_.end());
191:       entry.used_buffer_unscheduled_use_counts.push_back(
192:           &amp;*unscheduled_use_count_it);
193:     }
194:     return entry;
195:   }
196: 
197:   // Returns the number of bytes freed if the HLO instruction is scheduled.
198:   // If the instruction calls subcomputations, we count the memory used by the
199:   // subcomputations as memory &quot;defined&quot; by the instruction. This is not
200:   // entirely accurate, because subcomputation memory will be freed after the
201:   // instruction finishes. But it is more accurate than not taking
202:   // subcomputations into account at all. In the future, we may improve
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_sharding_metadata.cc" line="208" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [operand_sharding] to null at line 206 implies that [operand_sharding ] might be null.Dereferencing null pointer [operand_sharding]." web_identify="{&quot;identify&quot;:&quot;operand_sharding&quot;}" func_info="StatusOr &lt; long &gt; ApplyDomainShardingPass ( const DomainMetadata::Domain &amp; domain , const HloSharding &amp; sharding )" content="198:         ++assigned;
199:       }
200:     } else if (instruction-&gt;opcode() == HloOpcode::kTuple) {
201:       int64 tuple_assigned = 0;
202:       ShapeTree&lt;HloSharding&gt; shape_tree = GetTupleSharding(instruction);
203:       for (int64 i = 0; i &lt; instruction-&gt;operand_count(); ++i) {
204:         const HloSharding* operand_sharding =
205:             GetOperandSharding(instruction-&gt;operand(i), domain, sharding);
206:         if (operand_sharding != nullptr &amp;&amp;
207:             shape_tree.element({i}) != *operand_sharding) {
208:           *shape_tree.mutable_element({i}) = *operand_sharding;
209:           ++tuple_assigned;
210:         }
211:       }
212:       if (tuple_assigned &gt; 0) {
213:         HloSharding tuple_sharding = HloSharding::Tuple(shape_tree);
214:         VLOG(4) &lt;&lt; &quot;  &quot; &lt;&lt; instruction-&gt;name() &lt;&lt; &quot; to sharding &quot;
215:                 &lt;&lt; tuple_sharding;
216:         instruction-&gt;set_sharding(tuple_sharding);
217:         ++assigned;
218:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/hlo_tfgraph_builder_test.cc" line="59" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [attr] may be invalid here." web_identify="{&quot;identify&quot;:&quot;attr&quot;}" func_info="static const tensorflow::AttrValue &amp; GetNodeAttr ( const tensorflow::NodeDef &amp; node , const string &amp; attr_name )" content="49:         HloInstruction::CreateMap(r0f32_, {param}, map_computation));
50:     return builder.Build();
51:   }
52:   Shape r0f32_ = ShapeUtil::MakeShape(PrimitiveType::F32, {});
53: };
54: 
55: static const tensorflow::AttrValue &amp;GetNodeAttr(const tensorflow::NodeDef &amp;node,
56:                                                 const string &amp;attr_name) {
57:   auto attr = node.attr().find(attr_name);
58:   CHECK(attr != node.attr().end());
59:   return attr-&gt;second;
60: }
61: 
62: TEST_F(HloTfGraphBuilderTest, CheckConcatenateDimsAndShapes) {
63:   auto builder = HloComputation::Builder(&quot;Concatenate&quot;);
64:   Shape shape = ShapeUtil::MakeShape(PrimitiveType::F32, {2, 2});
65:   auto param_1 = builder.AddInstruction(
66:       HloInstruction::CreateParameter(0, shape, &quot;param0&quot;));
67:   auto param_2 = builder.AddInstruction(
68:       HloInstruction::CreateParameter(1, shape, &quot;param1&quot;));
69:   builder.AddInstruction(HloInstruction::CreateConcatenate(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/indexed_array_analysis.cc" line="438" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="long MapPassthroughOperandDimToResultDim ( ArraySlice &lt; ReshapePassthroughDimPair &gt; passthrough_dims , long operand_dim )" content="428: 
429: // Maps `operand_dim` which must be an passthrough operand dimension to its
430: // corresponding passthrough result dimension based on `passthrough_dims`.
431: int64 MapPassthroughOperandDimToResultDim(
432:     ArraySlice&lt;ReshapePassthroughDimPair&gt; passthrough_dims, int64 operand_dim) {
433:   auto it = c_find_if(passthrough_dims,
434:                       [&amp;](ReshapePassthroughDimPair passthrough_dim_pair) {
435:                         return passthrough_dim_pair.operand_dim == operand_dim;
436:                       });
437:   CHECK(it != passthrough_dims.end());
438:   return it-&gt;result_dim;
439: }
440: 
441: int64 FindSourcePositionForPassthroughResultDim(ArraySlice&lt;int64&gt; operand_shape,
442:                                                 ArraySlice&lt;int64&gt; result_shape,
443:                                                 int64 source_passthrough_dim) {
444:   VLOG(3) &lt;&lt; &quot;FindSourcePositionForPassthroughResultDim([&quot;
445:           &lt;&lt; Join(operand_shape, &quot;,&quot;) &lt;&lt; &quot;], [&quot; &lt;&lt; Join(result_shape, &quot;,&quot;)
446:           &lt;&lt; &quot;], &quot; &lt;&lt; source_passthrough_dim &lt;&lt; &quot;)&quot;;
447: 
448:   int64 indexed_source_subarray_size =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/instruction_fusion.h" line="34" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;InstructionFusion::computation_,module_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;InstructionFusion::computation_,module_,&quot;}" func_info="xla::InstructionFusion" content="24: 
25: namespace xla {
26: 
27: // HLO pass which performs instruction fusion. Instructions are fused
28: // &quot;vertically&quot;, meaning producing instructions are fused into their consumers
29: // with the intent that the loops which compute their values will be fused in
30: // code generation. Derived classes define ShouldFuse method to select which
31: // instructions to fuse.
32: class InstructionFusion : public HloPassInterface {
33:  public:
34:   explicit InstructionFusion(
35:       std::function&lt;bool(const HloInstruction&amp; instruction)&gt; is_expensive,
36:       bool may_duplicate = true)
37:       : is_expensive_(is_expensive), may_duplicate_(may_duplicate) {}
38:   ~InstructionFusion() override = default;
39:   tensorflow::StringPiece name() const override { return &quot;fusion&quot;; }
40: 
41:   // Run instruction fusion on the given computation. Returns whether the
42:   // computation was changed (instructions were fused).
43:   StatusOr&lt;bool&gt; Run(HloModule* module) override;
44: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/layout_assignment.cc" line="444" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [channel_constraints] to null at line 441 implies that [channel_constraints ] might be null.Dereferencing null pointer [channel_constraints]." web_identify="{&quot;identify&quot;:&quot;channel_constraints&quot;}" func_info="Status LayoutAssignment::AddMandatoryConstraints ( const ComputationLayout * computation_layout , ChannelLayoutConstraints * channel_constraints , HloComputation * computation , LayoutConstraints * constraints )" content="434:     if (shape_with_layout != nullptr) {
435:       TF_RETURN_IF_ERROR(
436:           constraints-&gt;SetInstructionLayout(*shape_with_layout, instruction));
437:     }
438: 
439:     if (instruction-&gt;opcode() == HloOpcode::kSend ||
440:         instruction-&gt;opcode() == HloOpcode::kRecv) {
441:       CHECK(channel_constraints)
442:           &lt;&lt; &quot;Multi-module layout assignment requires ChannelLayoutConstraints&quot;;
443:       int64 channel_id = instruction-&gt;channel_id();
444:       if (!channel_constraints-&gt;IsChannelConstrained(channel_id)) {
445:         continue;
446:       }
447:       if (instruction-&gt;opcode() == HloOpcode::kSend) {
448:         // TODO(b/68493863): Change to use SetOperandLayout().
449:         const Shape send_buffer_shape = instruction-&gt;operand(0)-&gt;shape();
450:         TF_RET_CHECK(ShapeUtil::IsArray(send_buffer_shape));
451:         Shape new_buffer_shape = channel_constraints-&gt;LayoutShapeForChannel(
452:             send_buffer_shape, instruction-&gt;channel_id());
453:         TF_RETURN_IF_ERROR(constraints-&gt;SetInstructionLayout(
454:             new_buffer_shape, instruction-&gt;operand(0)));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/layout_assignment.h" line="254" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Shape ChannelLayoutConstraints::LayoutShapeForChannel ( Shape shape , long channel_id ) const" content="244:   // Returns true if channel_id has a layout constraint.
245:   bool IsChannelConstrained(int64 channel_id) const {
246:     return constraints_.count(channel_id) &gt; 0;
247:   }
248: 
249:   // Given `shape`, apply the layout for `channel_id`. `channel_id` must already
250:   // be constrained.
251:   Shape LayoutShapeForChannel(Shape shape, int64 channel_id) const {
252:     auto it = constraints_.find(channel_id);
253:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
254:     *shape.mutable_layout() = it-&gt;second;
255:     return shape;
256:   }
257: 
258:   // Returns the layout constraint for `channel_id`, which must already be
259:   // constrained.
260:   const Layout&amp; LayoutForChannel(int64 channel_id) const {
261:     auto it = constraints_.find(channel_id);
262:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
263:     return it-&gt;second;
264:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/layout_assignment.h" line="263" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const Layout &amp; ChannelLayoutConstraints::LayoutForChannel ( long channel_id ) const" content="253:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
254:     *shape.mutable_layout() = it-&gt;second;
255:     return shape;
256:   }
257: 
258:   // Returns the layout constraint for `channel_id`, which must already be
259:   // constrained.
260:   const Layout&amp; LayoutForChannel(int64 channel_id) const {
261:     auto it = constraints_.find(channel_id);
262:     CHECK(it != constraints_.end()) &lt;&lt; &quot;Channel &quot; &lt;&lt; channel_id;
263:     return it-&gt;second;
264:   }
265: 
266:   // Adds a new layout constraint for `channel_id`. If a constraint for
267:   // `channel_id` has been added, this API returns nullptr, otherwise returns
268:   // the layout which has already been set for the channel.
269:   const Layout* ConstrainChannel(int64 channel_id, const Layout&amp; layout) {
270:     auto it = constraints_.emplace(std::make_pair(channel_id, layout));
271:     if (it.second) {
272:       return nullptr;
273:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/fused_ir_emitter.h" line="88" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="llvm::Value * FusedIrEmitter::GetIrValueForGTE ( const HloInstruction * hlo ) const" content="78:   // Returns the generator function for the root of the fused computation.
79:   Generator GetRootGenerator() const;
80: 
81:   // Returns the generator function for the given instruction.
82:   Generator GetGenerator(const HloInstruction* instruction) const;
83: 
84:   // Returns the ir value for instruction &apos;hlo&apos;.
85:   llvm::Value* GetIrValueForGTE(const HloInstruction* hlo) const {
86:     auto it = gte_values_.find(hlo);
87:     CHECK(it != gte_values_.end());
88:     return it-&gt;second;
89:   }
90: 
91:   void SetTiledParameterInfo(const llvm_ir::TiledParameterInfo* info) {
92:     tiled_parameter_info_ = info;
93:   }
94: 
95:  private:
96:   // Arrays of parameters of fusion instruction
97:   tensorflow::gtl::ArraySlice&lt;llvm_ir::IrArray&gt; parameter_arrays_;
98:   const llvm_ir::TiledParameterInfo* tiled_parameter_info_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/ir_array.h" line="217" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;IrArray::element_type_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;IrArray::element_type_,&quot;}" func_info="xla::llvm_ir::IrArray" content="207:     // If a loop is emitted with a multidimensional index space, `linear_` would
208:     // be null and `layout_` and `dims_` would be ignored.
209:     llvm::Value* linear_ = nullptr;
210:     Layout layout_;
211:     std::vector&lt;int64&gt; dims_;
212: 
213:     llvm::Type* index_type_;
214:   };
215: 
216:   // Default constructor. Constructs an IrArray in a null status.
217:   IrArray() : base_ptr_(nullptr), shape_(nullptr) {}
218: 
219:   // Construct an IrArray with the given base pointer and shape. base_ptr is a
220:   // pointer type pointing to the first element(lowest address) of the array.
221:   IrArray(llvm::Value* base_ptr, const Shape&amp; shape);
222: 
223:   // Default implementations of copying and moving.
224:   IrArray(IrArray&amp;&amp; other) = default;
225:   IrArray(const IrArray&amp; other) = default;
226:   IrArray&amp; operator=(IrArray&amp;&amp; other) = default;
227:   IrArray&amp; operator=(const IrArray&amp; other) = default;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/ir_array.h" line="234" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [shape_] to null at line 233 implies that [shape_ ] might be null.Dereferencing null pointer [shape_]." web_identify="{&quot;identify&quot;:&quot;shape_&quot;}" func_info="const Shape &amp; IrArray::GetShape ( ) const" content="224:   IrArray(IrArray&amp;&amp; other) = default;
225:   IrArray(const IrArray&amp; other) = default;
226:   IrArray&amp; operator=(IrArray&amp;&amp; other) = default;
227:   IrArray&amp; operator=(const IrArray&amp; other) = default;
228: 
229:   llvm::Value* GetBasePointer() const { return base_ptr_; }
230:   llvm::Type* GetElementLlvmType() const { return element_type_; }
231: 
232:   const Shape&amp; GetShape() const {
233:     CHECK(shape_ != nullptr);
234:     return *shape_;
235:   }
236: 
237:   // Emit a sequence of instructions to compute the address of the element in
238:   // the given array at the given index. Returns the address of the element as
239:   // an LLVM Value.
240:   //
241:   // The optional name is useful for debugging when looking at
242:   // the emitted LLVM IR.
243:   llvm::Value* EmitArrayElementAddress(const Index&amp; index,
244:                                        llvm::IRBuilder&lt;&gt;* ir_builder,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="35" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="25: #include &quot;tensorflow/compiler/xla/xla_data.pb.h&quot;
26: #include &quot;tensorflow/core/lib/core/errors.h&quot;
27: #include &quot;tensorflow/core/lib/strings/stringprintf.h&quot;
28: #include &quot;tensorflow/core/platform/logging.h&quot;
29: #include &quot;tensorflow/core/platform/protobuf.h&quot;
30: #include &quot;tensorflow/core/platform/types.h&quot;
31: 
32: namespace xla {
33: namespace llvm_ir {
34: 
35: LoopEmitter::LoopEmitter(const BodyEmitter&amp; body_emitter, const Shape&amp; shape,
36:                          llvm::IRBuilder&lt;&gt;* ir_builder)
37:     : body_emitter_(body_emitter), shape_(shape), ir_builder_(ir_builder) {}
38: 
39: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
40:                          const IrArray&amp; target_array,
41:                          llvm::IRBuilder&lt;&gt;* ir_builder)
42:     : body_emitter_([=](const llvm_ir::IrArray::Index array_index) -&gt; Status {
43:         // Convert target_element_generator to a BodyEmitter.
44:         TF_ASSIGN_OR_RETURN(llvm::Value * target_element,
45:                             target_element_generator(array_index));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="39" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="29: #include &quot;tensorflow/core/platform/protobuf.h&quot;
30: #include &quot;tensorflow/core/platform/types.h&quot;
31: 
32: namespace xla {
33: namespace llvm_ir {
34: 
35: LoopEmitter::LoopEmitter(const BodyEmitter&amp; body_emitter, const Shape&amp; shape,
36:                          llvm::IRBuilder&lt;&gt;* ir_builder)
37:     : body_emitter_(body_emitter), shape_(shape), ir_builder_(ir_builder) {}
38: 
39: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
40:                          const IrArray&amp; target_array,
41:                          llvm::IRBuilder&lt;&gt;* ir_builder)
42:     : body_emitter_([=](const llvm_ir::IrArray::Index array_index) -&gt; Status {
43:         // Convert target_element_generator to a BodyEmitter.
44:         TF_ASSIGN_OR_RETURN(llvm::Value * target_element,
45:                             target_element_generator(array_index));
46:         target_array.EmitWriteArrayElement(array_index, target_element,
47:                                            ir_builder);
48:         return Status::OK();
49:       }),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.cc" line="74" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopEmitter::exit_bb_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopEmitter::exit_bb_,&quot;}" func_info="xla::llvm_ir" content="64: 
65:     for (int64 i = 0; i &lt; target_arrays.size(); ++i) {
66:       target_arrays[i].EmitWriteArrayElement(
67:           array_index, ir_builder-&gt;CreateExtractValue(target_element, i),
68:           ir_builder);
69:     }
70:     return Status::OK();
71:   };
72: }
73: 
74: LoopEmitter::LoopEmitter(const ElementGenerator&amp; target_element_generator,
75:                          tensorflow::gtl::ArraySlice&lt;IrArray&gt; target_arrays,
76:                          llvm::IRBuilder&lt;&gt;* ir_builder)
77:     : body_emitter_(MakeBodyEmitterForMultiOutputFusion(
78:           target_element_generator,
79:           std::vector&lt;IrArray&gt;(target_arrays.begin(), target_arrays.end()),
80:           ir_builder)),
81:       shape_(target_arrays[0].GetShape()),
82:       ir_builder_(ir_builder) {
83:   // Sanity check: In multi-output fusion, all shapes produced must have the
84:   // same dimensions.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/multi_output_fusion.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MultiOutputFusion::computation_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MultiOutputFusion::computation_,&quot;}" func_info="xla::MultiOutputFusion" content="39: //
40: //  Function Perform() applies the optimization. It picks up the most profitable
41: //  pair in the worklist_, check if it&apos;s legal to fuse and fuse the pair.
42: //  After fusion, it updates the associated structure such as reachability_,
43: //  candidates_ and worklist_.
44: //  Note that the reachability map is updated based on the original computation.
45: //  This works because the reachability is monotonically increasing with
46: //  instruction fusion.
47: class MultiOutputFusion : public HloPassInterface {
48:  public:
49:   MultiOutputFusion(int64 fuel) : fuel_(fuel) {}
50: 
51:   tensorflow::StringPiece name() const override {
52:     return &quot;multi_output_fusion&quot;;
53:   }
54: 
55:   // Run multi-output fusion on the given module. Returns whether the module
56:   // was changed.
57:   StatusOr&lt;bool&gt; Run(HloModule* module) override;
58: 
59:  protected:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/owning_device_memory.cc" line="26" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [allocator_] to null at line 23 implies that [allocator_ ] might be null.Dereferencing null pointer [allocator_]." web_identify="{&quot;identify&quot;:&quot;allocator_&quot;}" func_info="void OwningDeviceMemory::Free ( )" content="16: #include &quot;tensorflow/compiler/xla/service/owning_device_memory.h&quot;
17: 
18: #include &quot;tensorflow/compiler/xla/service/device_memory_allocator.h&quot;
19: 
20: namespace xla {
21: 
22: void OwningDeviceMemory::Free() {
23:   CHECK(allocator_ != nullptr)
24:       &lt;&lt; &quot;Can&apos;t call Free() on an inactive (i.e. moved from, Forget()&apos;ten, &quot;
25:          &quot;or Free()&apos;ed) instance.&quot;;
26:   auto status = allocator_-&gt;Deallocate(device_ordinal_, mem_);
27:   if (!status.ok()) {
28:     LOG(WARNING) &lt;&lt; &quot;Deallocating buffer &quot; &lt;&lt; mem_.opaque() &lt;&lt; &quot; failed.&quot;;
29:   }
30: 
31:   allocator_ = nullptr;
32:   mem_ = se::DeviceMemoryBase();
33: }
34: 
35: }  // namespace xla
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/reshape_mover.cc" line="378" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;!&quot;}" func_info="StatusOr &lt; bool &gt; TryReshapeMoveOnCandidates ( HloInstructionSet * reshape_candidates )" content="368:       for (const auto* operand : instruction-&gt;operands()) {
369:         if (IsNontrivialReshape(operand)) {
370:           nontrivial_operands.insert(operand);
371:         }
372:       }
373:     }
374: 
375:     removed = false;
376:     for (auto operand : nontrivial_operands) {
377:       if (c_any_of(operand-&gt;users(), [&amp;](HloInstruction* user) {
378:             return !reshape_candidates-&gt;count(user);
379:           })) {
380:         for (auto* user : operand-&gt;users()) {
381:           removed |= reshape_candidates-&gt;erase(user) &gt; 0;
382:         }
383:       }
384:     }
385:   }
386: 
387:   if (reshape_candidates-&gt;empty()) {
388:     return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/tuple_points_to_analysis.cc" line="631" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="bool TuplePointsToAnalysis::DoesNotUseOperandBuffer ( const HloInstruction * operand , const ShapeIndex &amp; index , const HloInstruction * user ) const" content="621:     // Find fusion parameter associated with &apos;operand&apos;.
622:     auto it = std::find_if(
623:         user-&gt;fused_parameters().begin(), user-&gt;fused_parameters().end(),
624:         [=](HloInstruction* fused_param) {
625:           return user-&gt;operand(fused_param-&gt;parameter_number()) == operand;
626:         });
627:     CHECK(it != user-&gt;fused_parameters().end());
628:     // Iterate through all users of all buffer aliases of the buffer in the
629:     // points-to set of fusion parameter at &apos;index&apos;.
630:     // Return false if any uses are detected at &apos;index&apos;, returns true otherwise.
631:     const LogicalBuffer* buffer = GetBufferDefinedAt(*it, index).ValueOrDie();
632:     for (const BufferAlias&amp; alias : GetBufferAliases(*buffer)) {
633:       for (HloInstruction* alias_user : alias.instruction()-&gt;users()) {
634:         if (DoesNotUseOperandBuffer(alias.instruction(), alias.index(),
635:                                     alias_user)) {
636:           continue;
637:         }
638:         // Return false: use detected at &apos;buffer&apos; -&gt; &apos;alias&apos; -&gt; &apos;alias_user&apos;.
639:         return false;
640:       }
641:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/service/tuple_points_to_analysis_test.cc" line="717" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="HloInstruction * FusionPointsToAnalysisTest::GetFusionParameterForOperand ( HloInstruction * fusion , HloInstruction * operand )" content="707:   // to fusion &apos;operand&apos;.
708:   HloInstruction* GetFusionParameterForOperand(HloInstruction* fusion,
709:                                                HloInstruction* operand) {
710:     auto it = std::find_if(
711:         fusion-&gt;fused_instructions().begin(),
712:         fusion-&gt;fused_instructions().end(), [=](const HloInstruction* fused) {
713:           return fused-&gt;opcode() == HloOpcode::kParameter &amp;&amp;
714:                  fusion-&gt;operand(fused-&gt;parameter_number()) == operand;
715:         });
716:     CHECK(it != fusion-&gt;fused_instructions().end());
717:     return *it;
718:   }
719: 
720:   // Returns all users of &apos;fusion_paran&apos; at &apos;tuple_index&apos;.
721:   std::vector&lt;HloInstruction*&gt; GetFusionParameterUsersAt(
722:       HloInstruction* fusion_param, int64 tuple_index) {
723:     CHECK(ShapeUtil::IsTuple(fusion_param-&gt;shape()));
724:     std::vector&lt;HloInstruction*&gt; users_at_tuple_index;
725:     for (auto user : fusion_param-&gt;users()) {
726:       CHECK_EQ(HloOpcode::kGetTupleElement, user-&gt;opcode());
727:       if (user-&gt;tuple_index() == tuple_index) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/tests/test_utils.cc" line="100" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 92 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="&gt; void PopulateWithRandomIntegralData ( Literal * literal , std::minstd_rand0 * engine )" content="90: void PopulateWithRandomIntegralData(Literal* literal,
91:                                     std::minstd_rand0* engine) {
92:   CHECK(engine != nullptr);
93:   CHECK_EQ(literal-&gt;shape().element_type(),
94:            primitive_util::NativeToPrimitiveType&lt;IntT&gt;());
95:   std::uniform_int_distribution&lt;IntT&gt; generator(
96:       std::numeric_limits&lt;IntT&gt;::lowest(), std::numeric_limits&lt;IntT&gt;::max());
97:   TF_CHECK_OK(literal-&gt;Populate&lt;IntT&gt;(
98:       [&amp;](tensorflow::gtl::ArraySlice&lt;int64&gt; /*indices*/) {
99:         return generator(*engine);
100:       }));
101: }
102: 
103: // Similar to MakeFakeLiteral but takes a random number generator engine to
104: // enable reusing the engine across randomly generated literals.
105: StatusOr&lt;std::unique_ptr&lt;Literal&gt;&gt; MakeFakeLiteralInternal(
106:     const Shape&amp; shape, std::minstd_rand0* engine) {
107:   if (ShapeUtil::IsTuple(shape)) {
108:     std::vector&lt;std::unique_ptr&lt;Literal&gt;&gt; elements;
109:     for (const Shape&amp; element_shape : shape.tuple_shapes()) {
110:       TF_ASSIGN_OR_RETURN(std::unique_ptr&lt;Literal&gt; element,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/tests/test_utils.cc" line="58" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 30 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="&gt; void PopulateWithRandomFloatingPointDataImpl ( Literal * literal , std::minstd_rand0 * engine )" content="48:         // indices are zero.
49:         int64 index_product = 1;
50:         for (int64 i : indices) {
51:           index_product *= (1 + i);
52:         }
53:         const int64 negative_bias = should_index_bias ? 47 : 0;
54:         FloatT index_bias =
55:             static_cast&lt;FloatT&gt;(index_product % 113 - negative_bias) /
56:             static_cast&lt;FloatT&gt;(256.0f);
57:         return static_cast&lt;FloatT&gt;(generator(*engine) - 1.0625f) + index_bias;
58:       }));
59: }
60: 
61: template &lt;typename FloatT&gt;
62: void PopulateWithRandomFloatingPointData(Literal* literal,
63:                                          std::minstd_rand0* engine) {
64:   CHECK(engine != nullptr);
65:   PopulateWithRandomFloatingPointDataImpl&lt;FloatT, FloatT&gt;(literal, engine);
66: }
67: 
68: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/compiler/xla/tests/test_utils.cc" line="86" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [engine] to null at line 80 implies that [engine ] might be null.Dereferencing null pointer [engine]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;engine&quot;}" func_info="void PopulateWithRandomFloatingPointData&lt;bfloat16&gt; ( Literal * literal , std::minstd_rand0 * engine )" content="76: // handle that one specially.
77: template &lt;&gt;
78: void PopulateWithRandomFloatingPointData&lt;bfloat16&gt;(Literal* literal,
79:                                                    std::minstd_rand0* engine) {
80:   CHECK(engine != nullptr);
81:   CHECK_EQ(literal-&gt;shape().element_type(), BF16);
82:   std::uniform_real_distribution&lt;float&gt; generator(-0.9f, 1.0f);
83:   TF_CHECK_OK(literal-&gt;Populate&lt;bfloat16&gt;(
84:       [&amp;](tensorflow::gtl::ArraySlice&lt;int64&gt; /*indices*/) {
85:         return static_cast&lt;bfloat16&gt;(generator(*engine));
86:       }));
87: }
88: 
89: template &lt;typename IntT&gt;
90: void PopulateWithRandomIntegralData(Literal* literal,
91:                                     std::minstd_rand0* engine) {
92:   CHECK(engine != nullptr);
93:   CHECK_EQ(literal-&gt;shape().element_type(),
94:            primitive_util::NativeToPrimitiveType&lt;IntT&gt;());
95:   std::uniform_int_distribution&lt;IntT&gt; generator(
96:       std::numeric_limits&lt;IntT&gt;::lowest(), std::numeric_limits&lt;IntT&gt;::max());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/boosted_trees/kernels/training_ops.cc" line="677" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [mapped_node_it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;mapped_node_it&quot;}" func_info="void GrowTreeEnsembleOp::PruneTree ( boosted_trees :: trees :: DecisionTreeConfig * tree_config )" content="667:     for (size_t node_idx = 0; node_idx &lt; tree_nodes.size(); ++node_idx) {
668:       // Skip pruned nodes.
669:       auto&amp; original_node = tree_nodes[node_idx];
670:       if (original_node.node_case() == TreeNode::NODE_NOT_SET) {
671:         continue;
672:       }
673: 
674:       // Find node mapped in tree ensemble.
675:       auto mapped_node_it = nodes_map.find(node_idx);
676:       CHECK(mapped_node_it != nodes_map.end());
677:       auto&amp; mapped_node = (*tree_config-&gt;mutable_nodes(mapped_node_it-&gt;second));
678: 
679:       // Get node children
680:       auto children =
681:           boosted_trees::trees::DecisionTree::GetChildren(original_node);
682:       for (int32&amp; child_idx : children) {
683:         auto new_idx = tree_config-&gt;nodes_size();
684:         (*tree_config-&gt;add_nodes()) = tree_nodes[child_idx];
685:         nodes_map[child_idx] = new_idx;
686:         child_idx = new_idx;
687:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/data/kernels/csv_dataset_op.cc" line="158" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Iterator::pos_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Iterator::pos_,&quot;}" func_info="CSVDatasetOp::Dataset::Iterator" content="148:                               Node** output) const override {
149:       // TODO(rachelim): Implement this
150:       std::vector&lt;Node*&gt; input_tensors;
151:       TF_RETURN_IF_ERROR(b-&gt;AddDataset(this, input_tensors, output));
152:       return errors::Unimplemented(&quot;CSVDataset: AsGraphDefInternal&quot;);
153:     }
154: 
155:    private:
156:     class Iterator : public DatasetIterator&lt;Dataset&gt; {
157:      public:
158:       explicit Iterator(const Params&amp; params)
159:           : DatasetIterator&lt;Dataset&gt;(params) {}
160: 
161:       Status GetNextInternal(IteratorContext* ctx,
162:                              std::vector&lt;Tensor&gt;* out_tensors,
163:                              bool* end_of_sequence) override {
164:         mutex_lock l(mu_);
165:         bool select_all = dataset()-&gt;select_cols_.empty();
166:         do {
167:           // We are currently processing a file, so try to read the next record
168:           if (input_stream_) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/ffmpeg/decode_audio_op.cc" line="221" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DecodeAudioOp::samples_per_second_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DecodeAudioOp::samples_per_second_,&quot;}" func_info="tensorflow::ffmpeg::DecodeAudioOp" content="211: sampled_audio: A rank-2 tensor containing all tracks of the audio.
212:     Dimension 0 is time and dimension 1 is the channel. If ffmpeg fails
213:     to decode the audio then an empty tensor will be returned.
214: )doc&quot;);
215: 
216: /*
217:  * Deprecated in favor of DecodeAudioOpV2.
218:  */
219: class DecodeAudioOp : public OpKernel {
220:  public:
221:   explicit DecodeAudioOp(OpKernelConstruction* context) : OpKernel(context) {
222:     OP_REQUIRES_OK(context, context-&gt;GetAttr(&quot;file_format&quot;, &amp;file_format_));
223:     file_format_ = str_util::Lowercase(file_format_);
224:     const std::set&lt;string&gt; valid_file_formats(
225:         kValidFileFormats, kValidFileFormats + TF_ARRAYSIZE(kValidFileFormats));
226:     OP_REQUIRES(
227:         context, valid_file_formats.count(file_format_) == 1,
228:         errors::InvalidArgument(&quot;file_format must be one of {&quot;,
229:                                 str_util::Join(valid_file_formats, &quot;, &quot;),
230:                                 &quot;}, but was: \&quot;&quot;, file_format_, &quot;\&quot;&quot;));
231: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/gdr/gdr_memory_manager.cc" line="208" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GdrMemoryManager::epfd_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GdrMemoryManager::epfd_,&quot;}" func_info="tensorflow::" content="198: // cpu_allocator() returns visitable allocator
199: class BFCRdmaAllocator : public BFCAllocator {
200:  public:
201:   BFCRdmaAllocator()
202:       : BFCAllocator(new BasicCPUAllocator(), 1LL &lt;&lt; 36, true, &quot;cpu_rdma_bfc&quot;) {
203:   }
204: };
205: 
206: REGISTER_MEM_ALLOCATOR(&quot;BFCRdmaAllocator&quot;, 101, BFCRdmaAllocator);
207: 
208: GdrMemoryManager::GdrMemoryManager(const string&amp; host, const string&amp; port)
209:     : host_(host),
210:       port_(port),
211:       listening_(nullptr, EndpointDeleter),
212:       stopped_(true),
213:       next_key_(0) {}
214: 
215: GdrMemoryManager::~GdrMemoryManager() { close(epfd_); }
216: 
217: Status GdrMemoryManager::Init() {
218:   epfd_ = epoll_create1(0);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/gdr/gdr_memory_manager.cc" line="299" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [visitable_allocator] to null at line 295 implies that [visitable_allocator ] might be null.Dereferencing null pointer [visitable_allocator]." web_identify="{&quot;identify&quot;:&quot;visitable_allocator&quot;}" func_info="Status GdrMemoryManager::Init ( )" content="289: 
290:   std::set&lt;Allocator*&gt; instrumented_;
291: 
292:   // Host memory allocators
293:   for (Allocator* allocator : allocators) {
294:     auto* visitable_allocator = dynamic_cast&lt;VisitableAllocator*&gt;(allocator);
295:     CHECK(visitable_allocator)
296:         &lt;&lt; &quot;is not visitable for instrumentation&quot; &lt;&lt; allocator-&gt;Name();
297:     // Make sure we don&apos;t instrument the same allocator twice
298:     if (instrumented_.find(allocator) == std::end(instrumented_)) {
299:       visitable_allocator-&gt;AddAllocVisitor(alloc_visitor);
300:       visitable_allocator-&gt;AddFreeVisitor(free_visitor);
301:       instrumented_.insert(allocator);
302:       LOG(INFO) &lt;&lt; &quot;Instrumenting CPU allocator &quot; &lt;&lt; allocator-&gt;Name();
303:     }
304:   }
305: 
306: #if GOOGLE_CUDA
307:   VisitableAllocator::Visitor cuda_alloc_visitor =
308:       std::bind(&amp;GdrMemoryManager::InsertMemoryRegion, this, _1, _2);
309:   if (IsGDRAvailable()) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/delegates/nnapi/nnapi_delegate_test.cc" line="589" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SqueezeOpModel::new_shape_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SqueezeOpModel::new_shape_,&quot;}" func_info="SqueezeOpModel" content="579: TEST(NNAPIDelegate, ReshapeSimpleTest) {
580:   ReshapeOpModel m({1, 2, 4, 1}, {2, 2, 2});
581:   m.SetInput({1, 2, 3, 4, 5, 6, 7, 8});
582:   m.Invoke();
583:   EXPECT_THAT(m.GetOutput(), ElementsAreArray({1, 2, 3, 4, 5, 6, 7, 8}));
584:   EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 2, 2}));
585: }
586: 
587: class SqueezeOpModel : public SingleOpModelWithNNAPI {
588:  public:
589:   SqueezeOpModel(const TensorData&amp; input, const TensorData&amp; output,
590:                  std::initializer_list&lt;int&gt; axis) {
591:     input_ = AddInput(input);
592:     output_ = AddOutput(output);
593:     SetBuiltinOp(
594:         BuiltinOperator_SQUEEZE, BuiltinOptions_SqueezeOptions,
595:         CreateSqueezeOptions(builder_, builder_.CreateVector&lt;int&gt;(axis))
596:             .Union());
597:     BuildInterpreter({GetShape(input_)});
598:   }
599: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/fully_connected.cc" line="124" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias] to null at line 114 implies that [bias ] might be null.Dereferencing null pointer [bias]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias&quot;}" func_info="TfLiteStatus fully_connected::Prepare ( TfLiteContext * context , TfLiteNode * node )" content="114:   if (bias) {
115:     TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));
116:   }
117: 
118:   // Note that quantized inference requires that all tensors have their
119:   // parameters set. This is usually done during quantized training.
120:   TfLiteType data_type = input-&gt;type;
121:   if (data_type != kTfLiteFloat32) {
122:     double real_multiplier = 0.0;
123:     TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(
124:         context, input, filter, bias, output, &amp;real_multiplier));
125:     TF_LITE_ENSURE(context, real_multiplier &lt; 1.0);
126:     QuantizeMultiplierSmallerThanOneExp(
127:         real_multiplier, &amp;data-&gt;output_multiplier, &amp;data-&gt;output_shift);
128:     data-&gt;output_shift *= -1;
129:     TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized(
130:         context, params-&gt;activation, output, &amp;data-&gt;output_activation_min,
131:         &amp;data-&gt;output_activation_max));
132:   }
133: 
134:   // If we have to perform on-the-fly quantization (with quantized weights and
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/fully_connected.cc" line="220" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [bias] suggests that it may be null, but it has already been dereferenced at line 207." web_identify="{&quot;identify&quot;:&quot;bias&quot;}" func_info="TfLiteStatus fully_connected::EvalPieQuantized ( TfLiteContext * context , TfLiteNode * node , TfLiteFullyConnectedParams * params , OpData * data , const TfLiteTensor * input , const TfLiteTensor * filter , const TfLiteTensor * bias , TfLiteTensor * input_quantized , TfLiteTensor * output )" content="210:   int total_input_size = 1;
211:   for (int i = 0; i &lt; input-&gt;dims-&gt;size; i++) {
212:     total_input_size *= input-&gt;dims-&gt;data[i];
213:   }
214: 
215:   const int input_size = filter-&gt;dims-&gt;data[1];
216:   const int batch_size = total_input_size / filter-&gt;dims-&gt;data[1];
217:   const int num_units = filter-&gt;dims-&gt;data[0];
218: 
219:   // Output = bias if bias tensor exists.
220:   if (bias) {
221:     tensor_utils::VectorBatchVectorAssign(bias-&gt;data.f, num_units, batch_size,
222:                                           output-&gt;data.f);
223:   } else {
224:     tensor_utils::ZeroVector(output-&gt;data.f, batch_size * num_units);
225:   }
226: 
227:   // Save matrix multiplication computation for all zero input.
228:   if (tensor_utils::IsZeroVector(input-&gt;data.f, total_input_size)) {
229:     tensor_utils::ApplyActivationToVector(output-&gt;data.f,
230:                                           batch_size * num_units,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/internal/mfcc_dct.cc" line="23" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccDct::coefficient_count_,input_length_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccDct::coefficient_count_,input_length_,&quot;}" func_info="tflite::internal" content="13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/contrib/lite/kernels/internal/mfcc_dct.h&quot;
17: 
18: #include &lt;math.h&gt;
19: 
20: namespace tflite {
21: namespace internal {
22: 
23: MfccDct::MfccDct() : initialized_(false) {}
24: 
25: bool MfccDct::Initialize(int input_length, int coefficient_count) {
26:   coefficient_count_ = coefficient_count;
27:   input_length_ = input_length;
28: 
29:   if (coefficient_count_ &lt; 1) {
30:     return false;
31:   }
32: 
33:   if (input_length &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.cc" line="102" id="bufoverrun" subid="arrayIndexThenCheck" severity="Critical" msg="Array index &apos;channel&apos; is used before limits check." web_identify="{&quot;identify&quot;:&quot;channel&quot;}" func_info="bool MfccMelFilterbank::Initialize ( int input_length , double input_sample_rate , int output_channel_count , double lower_frequency_limit , double upper_frequency_limit )" content="92:   // each FFT bin, band_mapper tells us which channel this bin contributes to
93:   // on the right side of the triangle.  Thus this bin also contributes to the
94:   // left side of the next channel&apos;s triangle response.
95:   band_mapper_.resize(input_length_);
96:   int channel = 0;
97:   for (int i = 0; i &lt; input_length_; ++i) {
98:     double melf = FreqToMel(i * hz_per_sbin);
99:     if ((i &lt; start_index_) || (i &gt; end_index_)) {
100:       band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.
101:     } else {
102:       while ((center_frequencies_[channel] &lt; melf) &amp;&amp;
103:              (channel &lt; num_channels_)) {
104:         ++channel;
105:       }
106:       band_mapper_[i] = channel - 1;  // Can be == -1
107:     }
108:   }
109: 
110:   // Create the weighting functions to taper the band edges.  The contribution
111:   // of any one FFT bin is based on its distance along the continuum between two
112:   // mel-channel center frequencies.  This bin contributes weights_[i] to the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.cc" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&quot;}" func_info="tflite::internal" content="28: // channels may end up with no contributing FFT bins.  The resulting mel
29: // spectrum output will have some channels that are always zero.
30: 
31: #include &quot;tensorflow/contrib/lite/kernels/internal/mfcc_mel_filterbank.h&quot;
32: 
33: #include &lt;math.h&gt;
34: 
35: namespace tflite {
36: namespace internal {
37: 
38: MfccMelFilterbank::MfccMelFilterbank() : initialized_(false) {}
39: 
40: bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,
41:                                    int output_channel_count,
42:                                    double lower_frequency_limit,
43:                                    double upper_frequency_limit) {
44:   num_channels_ = output_channel_count;
45:   sample_rate_ = input_sample_rate;
46:   input_length_ = input_length;
47: 
48:   if (num_channels_ &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h" line="3008" id="logic" subid="redundantCondition" severity="Information" msg="Redundant condition: params.output_depth&lt;=64. &apos;A || (!A &amp;&amp; B)&apos; is equivalent to &apos;A || B&apos;" web_identify="{&quot;identify&quot;:&quot;params.output_depth&lt;=64. &apos;A || (!A &amp;&amp; B)&apos; is equivalent to &apos;A || B&apos;&quot;}" func_info="static void DepthwiseConvMultiRow::Run ( const char * input_data , int start_x , int end_x , const char * filter_data , const int * bias_data , char * output_data , const DepthwiseConvParams &amp; params , const ShuffleParams &amp; shuffle_params , char * shuffle_workspace )" content="2998:         get_shuffle_input_size(kStrideWidth, shuffle_params.output_width));
2999:     TFLITE_DCHECK(64 * shuffle_params.input_width * shuffle_params.input_height
3000:                   &lt;= DEPTHWISECONV_SHUFFLE_WORKSPACE_SIZE);
3001: 
3002:     int32 out_x = start_x;
3003: 
3004:     // Run shuffling on inputs with sufficiently large depth and width. When
3005:     // these parameters are large enough, more time is taken to load inputs
3006:     // from memory. At this point, it becomes useful to prefetch and
3007:     // preshuffle the input data to maximize locality.
3008:     if (params.output_depth &gt; 64 ||
3009:         (params.output_depth &lt;= 64 &amp;&amp; params.input_width &gt; 150)) {
3010:       for (; out_x &lt;= (end_x - shuffle_params.output_width);
3011:              out_x += shuffle_params.output_width) {
3012:         const uint8* input_ptr = input_data;
3013:         const int32* bias_ptr = bias_data;
3014:         const uint8* filter_ptr = filter_data;
3015:         uint8* output_ptr = output_data;
3016:         int64_t depth = 0;
3017:         const int64_t shuffle_row_size = 64 * shuffle_params.input_width;
3018: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/internal/spectrogram.h" line="45" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&quot;}" func_info="tflite::internal::Spectrogram" content="35: #include &lt;deque&gt;
36: #include &lt;vector&gt;
37: 
38: #include &quot;third_party/fft2d/fft.h&quot;
39: 
40: namespace tflite {
41: namespace internal {
42: 
43: class Spectrogram {
44:  public:
45:   Spectrogram() : initialized_(false) {}
46:   ~Spectrogram() {}
47: 
48:   // Initializes the class with a given window length and step length
49:   // (both in samples). Internally a Hann window is used as the window
50:   // function. Returns true on success, after which calls to Process()
51:   // are possible. window_length must be greater than 1 and step
52:   // length must be greater than 0.
53:   bool Initialize(int window_length, int step_length);
54: 
55:   // Initialize with an explicit window instead of a length.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/test_util.cc" line="110" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [interpreter_] to null at line 106 implies that [interpreter_ ] might be null.Dereferencing null pointer [interpreter_]." web_identify="{&quot;identify&quot;:&quot;interpreter_&quot;}" func_info="void SingleOpModel::BuildInterpreter ( std::vector &lt; std::vector &lt; int &gt; &gt; input_shapes )" content="100:       resolver-&gt;AddCustom(reg.first.data(), reg.second());
101:     }
102:     resolver_ = std::unique_ptr&lt;OpResolver&gt;(resolver);
103:   }
104:   CHECK(InterpreterBuilder(model, *resolver_)(&amp;interpreter_) == kTfLiteOk);
105: 
106:   CHECK(interpreter_ != nullptr);
107: 
108:   int i = 0;
109:   for (const auto&amp; shape : input_shapes) {
110:     int input_idx = interpreter_-&gt;inputs()[i++];
111:     if (input_idx == kOptionalTensor) continue;
112:     if (shape.empty()) continue;
113:     CHECK(interpreter_-&gt;ResizeInputTensor(input_idx, shape) == kTfLiteOk);
114:   }
115: 
116:   // Modify delegate with function.
117:   if (apply_delegate_fn_) {
118:     apply_delegate_fn_(interpreter_.get());
119:   }
120: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/test_util.cc" line="132" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [t] to null at line 130 implies that [t ] might be null.Dereferencing null pointer [t]." web_identify="{&quot;identify&quot;:&quot;t&quot;}" func_info="int SingleOpModel::GetTensorSize ( int index ) const" content="122:       &lt;&lt; &quot;Cannot allocate tensors&quot;;
123:   interpreter_-&gt;ResetVariableTensorsToZero();
124: }
125: 
126: void SingleOpModel::Invoke() { CHECK(interpreter_-&gt;Invoke() == kTfLiteOk); }
127: 
128: int32_t SingleOpModel::GetTensorSize(int index) const {
129:   TfLiteTensor* t = interpreter_-&gt;tensor(index);
130:   CHECK(t);
131:   int total_size = 1;
132:   for (int i = 0; i &lt; t-&gt;dims-&gt;size; ++i) {
133:     total_size *= t-&gt;dims-&gt;data[i];
134:   }
135:   return total_size;
136: }
137: 
138: template &lt;&gt;
139: std::vector&lt;string&gt; SingleOpModel::ExtractVector(int index) {
140:   TfLiteTensor* tensor_ptr = interpreter_-&gt;tensor(index);
141:   CHECK(tensor_ptr != nullptr);
142:   const int num_strings = GetStringCount(tensor_ptr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/test_util.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor_ptr] to null at line 141 implies that [tensor_ptr ] might be null.Dereferencing null pointer [tensor_ptr]." web_identify="{&quot;identify&quot;:&quot;tensor_ptr&quot;}" func_info="&gt; std::vector &lt; string &gt; SingleOpModel::ExtractVector ( int index )" content="132:   for (int i = 0; i &lt; t-&gt;dims-&gt;size; ++i) {
133:     total_size *= t-&gt;dims-&gt;data[i];
134:   }
135:   return total_size;
136: }
137: 
138: template &lt;&gt;
139: std::vector&lt;string&gt; SingleOpModel::ExtractVector(int index) {
140:   TfLiteTensor* tensor_ptr = interpreter_-&gt;tensor(index);
141:   CHECK(tensor_ptr != nullptr);
142:   const int num_strings = GetStringCount(tensor_ptr);
143:   std::vector&lt;string&gt; result;
144:   result.reserve(num_strings);
145:   for (int i = 0; i &lt; num_strings; ++i) {
146:     const auto str = GetString(tensor_ptr, i);
147:     result.emplace_back(str.str, str.len);
148:   }
149:   return result;
150: }
151: }  // namespace tflite
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/test_util.h" line="205" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v] to null at line 203 implies that [v ] might be null.Dereferencing null pointer [v]." web_identify="{&quot;identify&quot;:&quot;v&quot;}" func_info="&gt; void SingleOpModel::PopulateTensor ( int index , const std :: initializer_list &lt; T &gt; &amp; data )" content="195:     buf.WriteToTensor(tensor);
196:   }
197: 
198:   // Populate the tensor given its index.
199:   // TODO(b/110696148) clean up and merge with vector-taking variant below.
200:   template &lt;typename T&gt;
201:   void PopulateTensor(int index, const std::initializer_list&lt;T&gt;&amp; data) {
202:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
203:     CHECK(v) &lt;&lt; &quot;No tensor with index &apos;&quot; &lt;&lt; index &lt;&lt; &quot;&apos;.&quot;;
204:     for (T f : data) {
205:       *v = f;
206:       ++v;
207:     }
208:   }
209: 
210:   // Populate the tensor given its index.
211:   // TODO(b/110696148) clean up and merge with initializer_list-taking variant
212:   // above.
213:   template &lt;typename T&gt;
214:   void PopulateTensor(int index, const std::vector&lt;T&gt;&amp; data) {
215:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/kernels/test_util.h" line="218" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [v] to null at line 216 implies that [v ] might be null.Dereferencing null pointer [v]." web_identify="{&quot;identify&quot;:&quot;v&quot;}" func_info="&gt; void SingleOpModel::PopulateTensor ( int index , const std :: vector &lt; T &gt; &amp; data )" content="208:   }
209: 
210:   // Populate the tensor given its index.
211:   // TODO(b/110696148) clean up and merge with initializer_list-taking variant
212:   // above.
213:   template &lt;typename T&gt;
214:   void PopulateTensor(int index, const std::vector&lt;T&gt;&amp; data) {
215:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
216:     CHECK(v) &lt;&lt; &quot;No tensor with index &apos;&quot; &lt;&lt; index &lt;&lt; &quot;&apos;.&quot;;
217:     for (T f : data) {
218:       *v = f;
219:       ++v;
220:     }
221:   }
222: 
223:   // Partially populate the tensor, starting at the given offset.
224:   template &lt;typename T&gt;
225:   void PopulateTensor(int index, int offset, T* begin, T* end) {
226:     T* v = interpreter_-&gt;typed_tensor&lt;T&gt;(index);
227:     memcpy(v + offset, begin, (end - begin) * sizeof(T));
228:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/simple_memory_arena.h" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SimpleMemoryArena::underlying_buffer_aligned_ptr_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SimpleMemoryArena::underlying_buffer_aligned_ptr_,&quot;}" func_info="tflite::SimpleMemoryArena" content="36:   }
37: };
38: 
39: // This small class is responsible for allocating, deallocating and reusing
40: // dynamic memory from a common underlying buffer. The arena can be used in
41: // scenarios when the pattern of memory allocations and deallocations is
42: // repetitive, e.g. running NN inference in multiple iterations. Note that
43: // zero-sized allocations are explicitly allowed, and will resolve to null.
44: class SimpleMemoryArena {
45:  public:
46:   explicit SimpleMemoryArena(size_t arena_alignment)
47:       : committed_(false),
48:         arena_alignment_(arena_alignment),
49:         high_water_mark_(0),
50:         underlying_buffer_size_(0),
51:         allocs_() {}
52: 
53:   TfLiteStatus Allocate(TfLiteContext* context, size_t alignment, size_t size,
54:                         ArenaAlloc* new_alloc);
55: 
56:   TfLiteStatus Deallocate(TfLiteContext* context, const ArenaAlloc&amp; alloc);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/allocate_transient_arrays.cc" line="133" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here. The error is in macros." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="void Allocator::Deallocate ( const Alloc &amp; a )" content="123:     // We may then have to grow total_size_.
124:     total_size_ = std::max(total_size_, pos + size);
125:     result-&gt;start = pos;
126:     result-&gt;end = pos + size;
127:     live_allocs_.insert(*result);
128:   }
129: 
130:   void Deallocate(const Alloc&amp; a) {
131:     auto iter = std::lower_bound(live_allocs_.begin(), live_allocs_.end(), a);
132:     CHECK(iter != live_allocs_.end());
133:     CHECK(*iter == a);
134:     live_allocs_.erase(iter);
135:   }
136: 
137:   std::size_t total_size() const { return total_size_; }
138: 
139:  private:
140:   std::size_t total_size_;
141:   std::set&lt;Alloc&gt; live_allocs_;
142: };
143: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/allocate_transient_arrays.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [array.alloc] to null at line 199 implies that [array.alloc ] might be null.Dereferencing null pointer [array.alloc]." web_identify="{&quot;identify&quot;:&quot;array.alloc&quot;}" func_info="void DeallocateTransientArray ( const Model &amp; model , const string &amp; array_name , Allocator * allocator )" content="190: 
191: // Deallocates an array: call this for every array just after the last
192: // op where it is used.
193: void DeallocateTransientArray(const Model&amp; model, const string&amp; array_name,
194:                               Allocator* allocator) {
195:   if (!IsAllocatableTransientArray(model, array_name)) {
196:     return;
197:   }
198:   const auto&amp; array = &amp;model.GetArray(array_name);
199:   CHECK(!!array-&gt;alloc);
200:   allocator-&gt;Deallocate(*array-&gt;alloc);
201: }
202: 
203: void PushBackIfNotFound(const string&amp; s, std::vector&lt;string&gt;* v) {
204:   if (std::find(v-&gt;begin(), v-&gt;end(), s) == v-&gt;end()) {
205:     v-&gt;push_back(s);
206:   }
207: }
208: 
209: }  // namespace
210: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1337" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [weights_array.buffer] to null at line 1336 implies that [weights_array.buffer ] might be null.Dereferencing null pointer [weights_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;weights_array.buffer&quot;}" func_info="void ConvertLstmCellOperator ( const Model &amp; model , const LstmCellOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1327:   // Write weights
1328:   const string weights_output = base + &quot;weights&quot;;
1329:   CHECK(model.HasArray(src_op.inputs[LstmCellOperator::WEIGHTS_INPUT]));
1330:   const string weights_name = WalkUpToConstantArray(
1331:       model, src_op.inputs[LstmCellOperator::WEIGHTS_INPUT]);
1332:   const auto&amp; weights_array = model.GetArray(weights_name);
1333:   // Convert 4D FullyConnected weights into 2D matrix
1334:   const auto&amp; weights_shape = weights_array.shape();
1335:   CHECK_EQ(weights_shape.dimensions_count(), 2);
1336:   CHECK(weights_array.buffer);
1337:   CHECK(weights_array.buffer-&gt;type == ArrayDataType::kFloat);
1338:   const float* weights_data =
1339:       weights_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
1340:   ConvertFloatTensorConst(weights_output, weights_shape, weights_data,
1341:                           AxesOrder::kCR, AxesOrder::kRC, tensorflow_graph);
1342: 
1343:   // Fully connected matrix multiply
1344:   const string matmul_output = base + &quot;MatMul&quot;;
1345:   tensorflow::NodeDef* matmul_op = tensorflow_graph-&gt;add_node();
1346:   matmul_op-&gt;set_op(&quot;MatMul&quot;);
1347:   matmul_op-&gt;set_name(matmul_output);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1364" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_array.buffer] to null at line 1363 implies that [bias_array.buffer ] might be null.Dereferencing null pointer [bias_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias_array.buffer&quot;}" func_info="void ConvertLstmCellOperator ( const Model &amp; model , const LstmCellOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1354:   // Write biases
1355:   const string biases_output = base + &quot;biases&quot;;
1356:   CHECK(model.HasArray(src_op.inputs[LstmCellOperator::BIASES_INPUT]));
1357:   const string bias_name = WalkUpToConstantArray(
1358:       model, src_op.inputs[LstmCellOperator::BIASES_INPUT]);
1359:   const auto&amp; bias_array = model.GetArray(bias_name);
1360:   // TODO(b/62904716) Bias arrays should be 1-D, and used directly.
1361:   Shape bias_shape_1d = bias_array.shape();
1362:   UnextendShape(&amp;bias_shape_1d, 1);
1363:   CHECK(bias_array.buffer);
1364:   CHECK(bias_array.buffer-&gt;type == ArrayDataType::kFloat);
1365:   const float* bias_data =
1366:       bias_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
1367:   ConvertFloatTensorConst(biases_output, bias_shape_1d, bias_data,
1368:                           AxesOrder::kOneAxis, AxesOrder::kOneAxis,
1369:                           tensorflow_graph,
1370:                           LegacyScalarPolicy::kDoCreateLegacyScalars);
1371: 
1372:   // Add biases
1373:   string biasadd_output = base + &quot;BiasAdd&quot;;
1374:   tensorflow::NodeDef* biasadd_op = tensorflow_graph-&gt;add_node();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="1765" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensorflow_graph] to null at line 1764 implies that [tensorflow_graph ] might be null.Dereferencing null pointer [tensorflow_graph]." web_identify="{&quot;identify&quot;:&quot;tensorflow_graph&quot;}" func_info="void ConvertRandomUniformOperator ( const Model &amp; model , const RandomUniformOperator &amp; src_op , GraphDef * tensorflow_graph )" content="1755:   CHECK_EQ(src_op.inputs.size(), 2);
1756:   *topk_op-&gt;add_input() = src_op.inputs[0];
1757:   *topk_op-&gt;add_input() = src_op.inputs[1];
1758:   (*topk_op-&gt;mutable_attr())[&quot;sorted&quot;].set_b(true);
1759: }
1760: 
1761: void ConvertRandomUniformOperator(const Model&amp; model,
1762:                                   const RandomUniformOperator&amp; src_op,
1763:                                   GraphDef* tensorflow_graph) {
1764:   CHECK(tensorflow_graph != nullptr);
1765:   tensorflow::NodeDef* new_op = tensorflow_graph-&gt;add_node();
1766:   new_op-&gt;set_op(&quot;RandomUniform&quot;);
1767:   CHECK_EQ(src_op.inputs.size(), 1);
1768:   new_op-&gt;set_name(src_op.outputs[0]);
1769:   *new_op-&gt;add_input() = src_op.inputs[0];
1770:   const tensorflow::DataType shape_type =
1771:       GetTensorFlowDataType(model, src_op.inputs[0]);
1772:   (*new_op-&gt;mutable_attr())[&quot;T&quot;].set_type(shape_type);
1773:   (*new_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(
1774:       GetTensorFlowDataType(src_op.dtype));
1775:   (*new_op-&gt;mutable_attr())[&quot;seed&quot;].set_i(src_op.seed);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="190" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 189 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="void ConvertFloatTensorConst ( const Model &amp; model , const string &amp; name , int input_axes_order , int output_axes_order , GraphDef * tensorflow_graph )" content="180:   }
181:   tensorflow::NodeDef* const_op = tensorflow_graph-&gt;add_node();
182:   const_op-&gt;set_op(&quot;Const&quot;);
183:   const_op-&gt;set_name(name);
184:   (*const_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(DT_FLOAT);
185:   auto* tensor = (*const_op-&gt;mutable_attr())[&quot;value&quot;].mutable_tensor();
186:   CHECK(model.HasArray(name));
187:   const auto&amp; input_array = model.GetArray(name);
188:   const auto&amp; input_shape = input_array.shape();
189:   CHECK(input_array.buffer);
190:   CHECK(input_array.buffer-&gt;type == ArrayDataType::kFloat);
191:   const float* input_data =
192:       input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
193:   ExportFloatArray(input_axes_order, input_shape, input_data, output_axes_order,
194:                    tensor, LegacyScalarPolicy::kAvoidLegacyScalars);
195: }
196: 
197: void ConvertFloatTensorConst(const Model&amp; model, const string&amp; name,
198:                              GraphDef* tensorflow_graph) {
199:   if (HasAlreadyExportedConst(name, *tensorflow_graph)) {
200:     return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="211" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 210 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="void ConvertFloatTensorConst ( const Model &amp; model , const string &amp; name , GraphDef * tensorflow_graph )" content="201:   }
202:   tensorflow::NodeDef* const_op = tensorflow_graph-&gt;add_node();
203:   const_op-&gt;set_op(&quot;Const&quot;);
204:   const_op-&gt;set_name(name);
205:   (*const_op-&gt;mutable_attr())[&quot;dtype&quot;].set_type(DT_FLOAT);
206:   auto* tensor = (*const_op-&gt;mutable_attr())[&quot;value&quot;].mutable_tensor();
207:   CHECK(model.HasArray(name));
208:   const auto&amp; input_array = model.GetArray(name);
209:   const auto&amp; input_shape = input_array.shape();
210:   CHECK(input_array.buffer);
211:   CHECK(input_array.buffer-&gt;type == ArrayDataType::kFloat);
212:   const float* input_data =
213:       input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
214:   ExportFloatArray(input_shape, input_data, tensor,
215:                    LegacyScalarPolicy::kAvoidLegacyScalars);
216: }
217: 
218: void ConvertIntTensorConst(const Model&amp; model, const string&amp; name,
219:                            GraphDef* tensorflow_graph) {
220:   if (HasAlreadyExportedConst(name, *tensorflow_graph)) {
221:     return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="329" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 328 implies that [op ] might be null.Dereferencing null pointer [op]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="string WalkUpToConstantArray ( const Model &amp; model , const string &amp; name )" content="319:   }
320: }
321: 
322: string WalkUpToConstantArray(const Model&amp; model, const string&amp; name) {
323:   const Array&amp; original_array = model.GetArray(name);
324:   if (original_array.buffer) {
325:     return name;
326:   }
327:   const auto* op = GetOpWithOutput(model, name);
328:   CHECK(op);
329:   CHECK(op-&gt;type == OperatorType::kFakeQuant);
330:   const string&amp; input_of_fakequant_name = op-&gt;inputs[0];
331:   const Array&amp; input_of_fakequant = model.GetArray(input_of_fakequant_name);
332:   CHECK(input_of_fakequant.buffer);
333:   return input_of_fakequant_name;
334: }
335: 
336: void ConvertConvOperator(const Model&amp; model, const ConvOperator&amp; src_op,
337:                          GraphDef* tensorflow_graph) {
338:   const bool has_bias = src_op.inputs.size() &gt;= 3;
339:   string conv_output = src_op.outputs[0];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="606" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_array.buffer] to null at line 605 implies that [bias_array.buffer ] might be null.Dereferencing null pointer [bias_array.buffer]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;bias_array.buffer&quot;}" func_info="void ConvertFullyConnectedOperator ( const Model &amp; model , const FullyConnectedOperator &amp; src_op , GraphDef * tensorflow_graph )" content="596:     biasadd_op-&gt;add_input(matmul_output);
597:     biasadd_op-&gt;add_input(src_op.inputs[2]);
598:     (*biasadd_op-&gt;mutable_attr())[&quot;T&quot;].set_type(
599:         GetTensorFlowDataType(model, src_op.inputs[0]));
600:     CHECK(model.HasArray(src_op.inputs[2]));
601:     const auto&amp; bias_array = model.GetArray(src_op.inputs[2]);
602:     // TODO(b/62904716) Bias arrays should be 1-D, and used directly.
603:     Shape bias_shape_1d = bias_array.shape();
604:     UnextendShape(&amp;bias_shape_1d, 1);
605:     CHECK(bias_array.buffer);
606:     CHECK(bias_array.buffer-&gt;type == ArrayDataType::kFloat);
607:     const float* bias_data =
608:         bias_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data.data();
609:     ConvertFloatTensorConst(WalkUpToConstantArray(model, src_op.inputs[2]),
610:                             bias_shape_1d, bias_data, AxesOrder::kOneAxis,
611:                             AxesOrder::kOneAxis, tensorflow_graph,
612:                             LegacyScalarPolicy::kDoCreateLegacyScalars);
613:   }
614: }
615: 
616: void ConvertAddOperator(const Model&amp; model, const AddOperator&amp; src_op,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/export_tensorflow.cc" line="882" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [src_op.minmax] to null at line 881 implies that [src_op.minmax ] might be null.Dereferencing null pointer [src_op.minmax]." web_identify="{&quot;identify&quot;:&quot;src_op.minmax&quot;}" func_info="void ConvertFakeQuantOperator ( const FakeQuantOperator &amp; src_op , GraphDef * tensorflow_graph )" content="872: }
873: 
874: void ConvertFakeQuantOperator(const FakeQuantOperator&amp; src_op,
875:                               GraphDef* tensorflow_graph) {
876:   tensorflow::NodeDef* fakequant_op = tensorflow_graph-&gt;add_node();
877:   fakequant_op-&gt;set_op(&quot;FakeQuantWithMinMaxArgs&quot;);
878:   fakequant_op-&gt;set_name(src_op.outputs[0]);
879:   CHECK_EQ(src_op.inputs.size(), 1);
880:   *fakequant_op-&gt;add_input() = src_op.inputs[0];
881:   CHECK(src_op.minmax);
882:   (*fakequant_op-&gt;mutable_attr())[&quot;min&quot;].set_f(src_op.minmax-&gt;min);
883:   (*fakequant_op-&gt;mutable_attr())[&quot;max&quot;].set_f(src_op.minmax-&gt;max);
884:   if (src_op.num_bits) {
885:     (*fakequant_op-&gt;mutable_attr())[&quot;num_bits&quot;].set_i(src_op.num_bits);
886:   }
887:   if (src_op.narrow_range) {
888:     (*fakequant_op-&gt;mutable_attr())[&quot;narrow_range&quot;].set_b(src_op.narrow_range);
889:   }
890: }
891: 
892: void ConvertMaxPoolOperator(const MaxPoolOperator&amp; src_op,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc" line="60" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [array.quantization_params] to null at line 57 implies that [array.quantization_params ] might be null.Dereferencing null pointer [array.quantization_params]." web_identify="{&quot;identify&quot;:&quot;array.quantization_params&quot;}" func_info="void ClearArrayQuantizationParams ( const string &amp; array_name , Model * model )" content="50:     }
51:   }
52:   return model-&gt;operators.end();
53: }
54: 
55: void ClearArrayQuantizationParams(const string&amp; array_name, Model* model) {
56:   auto* array = &amp;model-&gt;GetArray(array_name);
57:   CHECK(array-&gt;quantization_params);
58:   for (auto&amp; input_array : *model-&gt;flags.mutable_input_arrays()) {
59:     if (input_array.name() == array_name) {
60:       auto&amp; qparams = *array-&gt;quantization_params;
61:       const double new_std_value = 1. / qparams.scale;
62:       const double new_mean_value = qparams.zero_point;
63:       if (input_array.has_std_value()) {
64:         CHECK_LE(std::abs(new_std_value - input_array.std_value()), 0.001);
65:       } else {
66:         input_array.set_std_value(new_std_value);
67:       }
68:       if (input_array.has_mean_value()) {
69:         CHECK_LE(std::abs(new_mean_value - input_array.mean_value()), 0.001);
70:       } else {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc" line="148" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: output_depth" web_identify="{&quot;identify&quot;:&quot;output_depth&quot;}" func_info="void FuseMulOrDivParamsIntoPrecedingAffine ( Model * model , Operator * preceding_op , const Operator * mul_or_div_op , int index_of_constant_input )" content="138:   if (preceding_op-&gt;type == OperatorType::kConv ||
139:       preceding_op-&gt;type == OperatorType::kFullyConnected) {
140:     output_depth = weights_shape.dims(0);
141:   } else if (preceding_op-&gt;type == OperatorType::kDepthwiseConv) {
142:     output_depth = weights_shape.dims(weights_shape.dimensions_count() - 1);
143:   } else {
144:     LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
145:   }
146: 
147:   const int weights_size = RequiredBufferSizeForShape(weights_shape);
148:   const int weights_per_depth = weights_size / output_depth;
149:   CHECK_EQ(weights_size, weights_per_depth * output_depth);
150: 
151:   int operand_channel = 0;
152:   for (int c = 0; c &lt; output_depth; c++) {
153:     if (mul_or_div_op-&gt;type == OperatorType::kMul) {
154:       bias_data[c] *= operand_data[operand_channel];
155:     } else if (mul_or_div_op-&gt;type == OperatorType::kDiv) {
156:       bias_data[c] /= operand_data[operand_channel];
157:     } else {
158:       LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc" line="152" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: output_depth" web_identify="{&quot;identify&quot;:&quot;output_depth&quot;}" func_info="void FuseMulOrDivParamsIntoPrecedingAffine ( Model * model , Operator * preceding_op , const Operator * mul_or_div_op , int index_of_constant_input )" content="142:     output_depth = weights_shape.dims(weights_shape.dimensions_count() - 1);
143:   } else {
144:     LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
145:   }
146: 
147:   const int weights_size = RequiredBufferSizeForShape(weights_shape);
148:   const int weights_per_depth = weights_size / output_depth;
149:   CHECK_EQ(weights_size, weights_per_depth * output_depth);
150: 
151:   int operand_channel = 0;
152:   for (int c = 0; c &lt; output_depth; c++) {
153:     if (mul_or_div_op-&gt;type == OperatorType::kMul) {
154:       bias_data[c] *= operand_data[operand_channel];
155:     } else if (mul_or_div_op-&gt;type == OperatorType::kDiv) {
156:       bias_data[c] /= operand_data[operand_channel];
157:     } else {
158:       LOG(FATAL) &lt;&lt; &quot;Should not get here&quot;;
159:     }
160:     if (preceding_op-&gt;type == OperatorType::kConv ||
161:         preceding_op-&gt;type == OperatorType::kFullyConnected) {
162:       for (int i = 0; i &lt; weights_per_depth; i++) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc" line="44" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [source_op] to null at line 43 implies that [source_op ] might be null.Dereferencing null pointer [source_op]." web_identify="{&quot;identify&quot;:&quot;source_op&quot;}" func_info="bool ValidateSourceOp ( const Model &amp; model , const string &amp; array_name , OperatorType op_type , Operator * * source_op )" content="34:   }
35:   return it;
36: }
37: 
38: bool ValidateSourceOp(const Model&amp; model, const string&amp; array_name,
39:                       OperatorType op_type, Operator** source_op) {
40:   if (op_type == OperatorType::kNone) {
41:     CHECK(!source_op);
42:   } else {
43:     CHECK(source_op);
44:     *source_op = GetOpWithOutput(model, array_name);
45:     if (*source_op == nullptr) {
46:       return false;
47:     }
48: 
49:     // Check that first operator, if connected, is of correct type
50:     if ((*source_op)-&gt;type != op_type) {
51:       return false;
52:     }
53:   }
54: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc" line="124" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_array.buffer] to null at line 113 implies that [input_array.buffer ] might be null.Dereferencing null pointer [input_array.buffer]." web_identify="{&quot;identify&quot;:&quot;input_array.buffer&quot;}" func_info="bool ResolveConstantUnaryOperator::Run ( Model * model , long op_index )" content="114:   std::vector&lt;DataType&lt;ArrayDataType::kFloat&gt;&gt; const* input_float_data;
115:   if (unary_op-&gt;type == OperatorType::kCast) {
116:     CastOperator const* cast_op = static_cast&lt;CastOperator const*&gt;(unary_op);
117:     if (cast_op-&gt;dst_data_type != ArrayDataType::kFloat) {
118:       AddMessageF(
119:           &quot;Not resolving constant %s because we currently only support casting &quot;
120:           &quot;to float&quot;,
121:           LogName(*unary_op));
122:       return false;
123:     }
124:     if (cast_op-&gt;src_data_type != input_array.buffer-&gt;type) {
125:       AddMessageF(
126:           &quot;Not resolving constant %s because cast op source type does not &quot;
127:           &quot;match input type&quot;,
128:           LogName(*unary_op));
129:     }
130:   } else {
131:     if (input_array.buffer-&gt;type != ArrayDataType::kFloat) {
132:       return false;
133:     }
134:     input_float_data = &amp;(input_array.GetBuffer&lt;ArrayDataType::kFloat&gt;().data);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="115" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 114 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="105:       indices_data_array.GetBuffer&lt;ArrayDataType::kInt32&gt;().data;
106:   for (size_t i = 0; i &lt; indices_data_buffer.size(); ++i) {
107:     CHECK_EQ(indices_data_buffer[i], i) &lt;&lt; &quot;Indices range must be identity&quot;;
108:   }
109: 
110:   // Find all of the gathers used for the data inputs.
111:   std::vector&lt;GatherOperator*&gt; gather_ops;
112:   for (const string&amp; gather_output_name : stitch_data_inputs) {
113:     auto* op = GetOpWithOutput(*model, gather_output_name);
114:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; gather_output_name &lt;&lt; &quot; not found&quot;;
115:     if (op-&gt;type != OperatorType::kGather) {
116:       AddMessageF(
117:           &quot;Skipping because data input %s into %s &quot;
118:           &quot;is unexpected&quot;,
119:           LogName(*op), LogName(*stitch_op));
120:       return false;
121:     }
122:     gather_ops.push_back(static_cast&lt;GatherOperator*&gt;(op));
123:   }
124: 
125:   // Validate all gathers come from the same DynamicPartition.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="130" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 129 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="120:       return false;
121:     }
122:     gather_ops.push_back(static_cast&lt;GatherOperator*&gt;(op));
123:   }
124: 
125:   // Validate all gathers come from the same DynamicPartition.
126:   DynamicPartitionOperator* data_partition_op = nullptr;
127:   for (auto* gather_op : gather_ops) {
128:     auto* op = GetOpWithOutput(*model, gather_op-&gt;inputs[1]);
129:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; gather_op-&gt;inputs[1] &lt;&lt; &quot; not found&quot;;
130:     if (op-&gt;type != OperatorType::kDynamicPartition) {
131:       AddMessageF(
132:           &quot;Skipping because data input %s into &quot;
133:           &quot;%s is unexpected&quot;,
134:           LogName(*op), LogName(*gather_op));
135:       return false;
136:     }
137:     if (!data_partition_op) {
138:       data_partition_op = static_cast&lt;DynamicPartitionOperator*&gt;(op);
139:     } else {
140:       // Ensure this is the same op as previous ones.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="154" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [data_partition_op] to null at line 150 implies that [data_partition_op ] might be null.Dereferencing null pointer [data_partition_op]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;data_partition_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="144:             &quot;%s is from a different source op than others&quot;,
145:             LogName(*op), LogName(*gather_op));
146:         return false;
147:       }
148:     }
149:   }
150:   CHECK(data_partition_op) &lt;&lt; &quot;No data inputs&quot;;
151: 
152:   // Validate the partition ops have the same sizes.
153:   CHECK_EQ(indices_partition_op-&gt;num_partitions,
154:            data_partition_op-&gt;num_partitions)
155:       &lt;&lt; &quot;Indices and data partition ops have differing dimensions&quot;;
156:   int num_partitions = indices_partition_op-&gt;num_partitions;
157: 
158:   // Partition strategy of &apos;mod&apos; gives us a FloorMod and FloorDiv.
159:   // The gather partition uses the FloorDiv as the data and FloorMod as the
160:   // partitions and the indices use the FloorMod as their partitions.
161:   Operator* div_op = GetOpWithOutput(*model, data_partition_op-&gt;inputs[0]);
162:   Operator* mod_op = GetOpWithOutput(*model, data_partition_op-&gt;inputs[1]);
163:   CHECK(div_op &amp;&amp; div_op-&gt;type == OperatorType::kFloorDiv)
164:       &lt;&lt; &quot;Unsupported partition strategy&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="212" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [mod_op] to null at line 165 implies that [mod_op ] might be null.Dereferencing null pointer [mod_op]." web_identify="{&quot;identify&quot;:&quot;mod_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="202:   perm_data.resize(RequiredBufferSizeForShape(perm_array.shape()));
203:   // NOTE: this is what relies on the partition_strategy.
204:   for (int i = 0; i &lt; num_partitions * partition_array_dims[0]; ++i) {
205:     int p = i % num_partitions;
206:     perm_data[i] = p * partition_array_dims[0] + i / num_partitions;
207:   }
208: 
209:   // Insert the new unpartitioned gather op.
210:   auto* merged_gather_op = new GatherOperator;
211:   merged_gather_op-&gt;inputs = {gather_params_permute_op-&gt;outputs[0],
212:                               mod_op-&gt;inputs[0]};
213:   merged_gather_op-&gt;outputs = {stitch_op-&gt;outputs[0]};
214:   merged_gather_op-&gt;input_rank = partition_array.shape().dimensions_count();
215:   model-&gt;operators.emplace(op_it, merged_gather_op);
216: 
217:   AddMessageF(
218:       &quot;Replacing suspected partitioned tf.nn.embedding_lookup (starting at %s &quot;
219:       &quot;+ %s and ending at %s) with a single unpartitioned gather %s&quot;,
220:       LogName(*div_op), LogName(*mod_op), LogName(*stitch_op),
221:       LogName(*merged_gather_op));
222: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="220" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [div_op] to null at line 163 implies that [div_op ] might be null.Dereferencing null pointer [div_op]." web_identify="{&quot;identify&quot;:&quot;div_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="210:   auto* merged_gather_op = new GatherOperator;
211:   merged_gather_op-&gt;inputs = {gather_params_permute_op-&gt;outputs[0],
212:                               mod_op-&gt;inputs[0]};
213:   merged_gather_op-&gt;outputs = {stitch_op-&gt;outputs[0]};
214:   merged_gather_op-&gt;input_rank = partition_array.shape().dimensions_count();
215:   model-&gt;operators.emplace(op_it, merged_gather_op);
216: 
217:   AddMessageF(
218:       &quot;Replacing suspected partitioned tf.nn.embedding_lookup (starting at %s &quot;
219:       &quot;+ %s and ending at %s) with a single unpartitioned gather %s&quot;,
220:       LogName(*div_op), LogName(*mod_op), LogName(*stitch_op),
221:       LogName(*merged_gather_op));
222: 
223:   // Ensure the stitch output array is dead, as we don&apos;t want whatever was in it
224:   // previously now that we&apos;ve redefined it. It&apos;ll be recreated when needed.
225:   model-&gt;EraseArray(stitch_op-&gt;outputs[0]);
226:   model-&gt;GetOrCreateArray(merged_gather_op-&gt;outputs[0]);
227: 
228:   // Erase all the original ops.
229:   DeleteOpAndArraysIfUnused(model, div_op);
230:   DeleteOpAndArraysIfUnused(model, mod_op);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="70" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 69 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="60:   for (size_t i = stitch_op-&gt;num_partitions; i &lt; stitch_op-&gt;num_partitions * 2;
61:        ++i) {
62:     stitch_data_inputs.push_back(stitch_op-&gt;inputs[i]);
63:   }
64: 
65:   // Validate all indices come from the same DynamicPartition.
66:   DynamicPartitionOperator* indices_partition_op = nullptr;
67:   for (const string&amp; indices_partition_output_name : stitch_indices_inputs) {
68:     auto* op = GetOpWithOutput(*model, indices_partition_output_name);
69:     CHECK(op) &lt;&lt; &quot;Source of &quot; &lt;&lt; indices_partition_output_name &lt;&lt; &quot; not found&quot;;
70:     if (op-&gt;type != OperatorType::kDynamicPartition) {
71:       AddMessageF(
72:           &quot;Skipping because indices input %s into &quot;
73:           &quot;%s is unexpected&quot;,
74:           LogName(*op), LogName(*stitch_op));
75:       return false;
76:     }
77:     if (!indices_partition_op) {
78:       indices_partition_op = static_cast&lt;DynamicPartitionOperator*&gt;(op);
79:     } else {
80:       // Ensure this is the same op as previous ones.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc" line="93" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [indices_partition_op] to null at line 90 implies that [indices_partition_op ] might be null.Dereferencing null pointer [indices_partition_op]." web_identify="{&quot;identify&quot;:&quot;indices_partition_op&quot;}" func_info="bool UnpartitionEmbeddingLookup::Run ( Model * model , long op_index )" content="83:             &quot;Skipping because indices input %s into &quot;
84:             &quot;%s is from a different source op than others&quot;,
85:             LogName(*op), LogName(*stitch_op));
86:         return false;
87:       }
88:     }
89:   }
90:   CHECK(indices_partition_op) &lt;&lt; &quot;No indices inputs&quot;;
91: 
92:   // The data for the indices must be a constant range of the array shape.
93:   if (!IsConstantParameterArray(*model, indices_partition_op-&gt;inputs[0])) {
94:     AddMessageF(&quot;Skipping because indices partition data is non-constant&quot;);
95:     return false;
96:   }
97:   auto&amp; indices_data_array = model-&gt;GetArray(indices_partition_op-&gt;inputs[0]);
98:   if (indices_data_array.data_type == ArrayDataType::kNone) {
99:     // Yield until data types are propagated.
100:     return false;
101:   }
102:   CHECK(indices_data_array.data_type == ArrayDataType::kInt32)
103:       &lt;&lt; &quot;Indices partition inputs must be int32&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/import_tensorflow.cc" line="718" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [model] to null at line 717 implies that [model ] might be null.Dereferencing null pointer [model]." web_identify="{&quot;identify&quot;:&quot;model&quot;}" func_info="tensorflow::Status ConvertRandomUniform ( const NodeDef &amp; node , const TensorFlowImportFlags &amp; tf_import_flags , Model * model )" content="708:   TF_QCHECK_OK(CheckInputsCount(node, tf_import_flags, 1));
709: 
710:   CHECK_EQ(GetDataTypeAttr(node, &quot;T&quot;), DT_INT32);
711:   auto op = absl::make_unique&lt;RandomUniformOperator&gt;();
712:   op-&gt;inputs.push_back(node.input(0));
713:   op-&gt;outputs.push_back(node.name());
714:   op-&gt;dtype = ConvertDataType(GetDataTypeAttr(node, &quot;dtype&quot;));
715:   op-&gt;seed = GetIntAttr(node, &quot;seed&quot;);
716:   op-&gt;seed2 = GetIntAttr(node, &quot;seed2&quot;);
717:   CHECK(model != nullptr);
718:   model-&gt;operators.emplace_back(std::move(op));
719:   return tensorflow::Status::OK();
720: }
721: 
722: tensorflow::Status ConvertIdentityOperator(
723:     const NodeDef&amp; node, const TensorFlowImportFlags&amp; tf_import_flags,
724:     Model* model) {
725:   CHECK(node.op() == &quot;Identity&quot; || node.op() == &quot;CheckNumerics&quot; ||
726:         node.op() == &quot;PlaceholderWithDefault&quot; || node.op() == &quot;StopGradient&quot;);
727:   auto* op = new TensorFlowIdentityOperator;
728:   // Amazingly, some TensorFlow graphs (at least rajeev_lstm.pb) have
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/model.h" line="1081" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RandomUniformOperator::seed,seed2,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RandomUniformOperator::seed,seed2,&quot;}" func_info="toco::RandomUniformOperator" content="1071: // Inputs:
1072: //   inputs[0]: required: the left-hand side array
1073: //   inputs[1]: required: the right-hand side array
1074: //
1075: // TensorFlow equivalent: FloorMod
1076: struct FloorModOperator : Operator {
1077:   FloorModOperator() : Operator(OperatorType::kFloorMod) {}
1078: };
1079: 
1080: struct RandomUniformOperator : Operator {
1081:   RandomUniformOperator() : Operator(OperatorType::kRandomUniform) {}
1082:   ArrayDataType dtype = ArrayDataType::kNone;
1083:   int64 seed;
1084:   int64 seed2;
1085: };
1086: 
1087: // Creates a sequence of numbers that begins at start and extends by increments
1088: // of delta up to but not including limit.
1089: //
1090: // The dtype of the resulting tensor is inferred from the inputs unless it is
1091: // provided explicitly.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc" line="128" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [bias_input] to null at line 126 implies that [bias_input ] might be null.Dereferencing null pointer [bias_input]." web_identify="{&quot;identify&quot;:&quot;bias_input&quot;}" func_info="void SvdfCluster::CreateNodes ( )" content="118:   }
119:   for (const std::unique_ptr&lt;tensorflow::NodeDef&gt;&amp; node : new_nodes_) {
120:     const string node_name = node-&gt;name();
121:     if (StrContains(node_name, &quot;SVDF_weights_feature&quot;)) {
122:       *weights_feature_input = node_name;
123:     } else if (StrContains(node_name, &quot;SVDF_weights_time&quot;)) {
124:       *weights_time_input = node_name;
125:     } else if (StrContains(node_name, &quot;SVDF_bias&quot;)) {
126:       CHECK(bias_input) &lt;&lt; &quot;Bias input cannot be provided when there are only &quot;
127:                            &quot;two Const input nodes!&quot;;
128:       *bias_input = node_name;
129:     } else {
130:       // Unexpected input for Svdf op.
131:       LOG(FATAL) &lt;&lt; &quot;Unexpected input node for SVDF op! Accepted inputs are: &quot;
132:                     &quot;weights_feature, weights_time and bias.&quot;;
133:     }
134:   }
135:   const int rank = InferFilterRank();
136:   CHECK_GT(rank, 0);
137: 
138:   // Add Svdf activation and rank.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/toco/tooling_util.cc" line="1011" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [op] to null at line 1010 implies that [op ] might be null.Dereferencing null pointer [op]." web_identify="{&quot;identify&quot;:&quot;op&quot;}" func_info="void toco::FixOperatorOrdering ( Model * model )" content="1001:   for (std::size_t i = 0; i &lt; old_operators.size(); i++) {
1002:     remaining.insert(i);
1003:   }
1004:   std::unordered_map&lt;string, string&gt; reason_why_leftover;
1005:   while (true) {
1006:     bool inserted_something = false;
1007:     for (auto i : remaining) {
1008:       bool can_insert = true;
1009:       auto&amp; op = old_operators[i];
1010:       CHECK(op);
1011:       for (const auto&amp; input : op-&gt;inputs) {
1012:         if (!IsConstantParameterArray(*model, input) &amp;&amp;
1013:             !arrays_behind_us.count(input)) {
1014:           for (const string&amp; output : op-&gt;outputs) {
1015:             reason_why_leftover[output] = input;
1016:           }
1017:           can_insert = false;
1018:           break;
1019:         }
1020:       }
1021:       if (can_insert) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/tools/benchmark/benchmark_tflite_model.cc" line="239" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [model] to null at line 235 implies that [model ] might be null.Dereferencing null pointer [model]." web_identify="{&quot;identify&quot;:&quot;model&quot;}" func_info="void BenchmarkTfLiteModel::Init ( )" content="229:   return total_input_bytes;
230: }
231: 
232: void BenchmarkTfLiteModel::Init() {
233:   std::string graph = params_.Get&lt;std::string&gt;(&quot;graph&quot;);
234:   model = tflite::FlatBufferModel::BuildFromFile(graph.c_str());
235:   if (!model) {
236:     TFLITE_LOG(FATAL) &lt;&lt; &quot;Failed to mmap model &quot; &lt;&lt; graph;
237:   }
238:   TFLITE_LOG(INFO) &lt;&lt; &quot;Loaded model &quot; &lt;&lt; graph;
239:   model-&gt;error_reporter();
240:   TFLITE_LOG(INFO) &lt;&lt; &quot;resolved reporter&quot;;
241: 
242: #ifdef TFLITE_CUSTOM_OPS_HEADER
243:   tflite::MutableOpResolver resolver;
244:   RegisterSelectedOps(&amp;resolver);
245: #else
246:   tflite::ops::builtin::BuiltinOpResolver resolver;
247: #endif
248: 
249:   tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/lite/tools/benchmark/benchmark_tflite_model.cc" line="258" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [interpreter] to null at line 250 implies that [interpreter ] might be null.Dereferencing null pointer [interpreter]." web_identify="{&quot;identify&quot;:&quot;interpreter&quot;}" func_info="void BenchmarkTfLiteModel::Init ( )" content="248: 
249:   tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);
250:   if (!interpreter) {
251:     TFLITE_LOG(FATAL) &lt;&lt; &quot;Failed to construct interpreter&quot;;
252:   }
253:   profiling_listener_.SetInterpreter(interpreter.get());
254: 
255:   const int32_t num_threads = params_.Get&lt;int32_t&gt;(&quot;num_threads&quot;);
256: 
257:   if (num_threads != -1) {
258:     interpreter-&gt;SetNumThreads(num_threads);
259:   }
260: 
261:   bool use_nnapi = params_.Get&lt;bool&gt;(&quot;use_nnapi&quot;);
262: 
263:   interpreter-&gt;UseNNAPI(use_nnapi);
264:   auto interpreter_inputs = interpreter-&gt;inputs();
265: 
266:   if (!inputs.empty()) {
267:     TFLITE_BENCHMARK_CHECK_EQ(inputs.size(), interpreter_inputs.size())
268:         &lt;&lt; &quot;Inputs mismatch: Model inputs #:&quot; &lt;&lt; interpreter_inputs.size()
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/mpi/mpi_rendezvous_mgr.h" line="99" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MPIRequestTensorCall::request_buffer_size_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MPIRequestTensorCall::request_buffer_size_,&quot;}" func_info="tensorflow::MPIRequestTensorCall" content="89: 
90: class MPIRequestTensorCall {
91:  public:
92:   Rendezvous::DoneCallback done_;
93:   RecvTensorRequest req_;
94:   MPI_Request mpi_request_;
95:   char* request_buffer_;
96:   size_t request_buffer_size_;
97:   std::function&lt;void(MPIRecvTensorResponse)&gt; recv_call_;
98: 
99:   MPIRequestTensorCall() : request_buffer_(nullptr) {}
100:   ~MPIRequestTensorCall() {
101:     MPI_CHECK(MPI_Wait(&amp;mpi_request_, MPI_STATUS_IGNORE));
102:     // delete[] request_buffer_;
103:     MPI_CHECK(MPI_Free_mem(request_buffer_));
104:   }
105: 
106:   void Init(const Rendezvous::ParsedKey&amp; parsed, const int64 step_id) {
107:     req_.set_step_id(step_id);
108:     req_.set_rendezvous_key(parsed.FullKey().data(), parsed.FullKey().size());
109:     req_.set_request_id(GetUniqueRequestId());
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/mpi/mpi_utils.h" line="52" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="const int MPIUtils::GetSourceID ( const std :: string &amp; task_id ) const" content="42: namespace tensorflow {
43: class MPIUtils {
44:  public:
45:   explicit MPIUtils(const std::string&amp; worker_name);
46: 
47:   const int GetSourceID(const std::string&amp; task_id) const {
48:     auto it = name_to_id_.find(task_id);
49:     if (it == name_to_id_.end()) {
50:       LOG(FATAL) &lt;&lt; &quot;Failed to convert worker name to MPI index: &quot; &lt;&lt; task_id;
51:     }
52:     return it-&gt;second;
53:   }
54: 
55:  private:
56:   void InitMPI();
57: 
58:   std::map&lt;std::string, int&gt; name_to_id_;
59: };
60: }  // namespace tensorflow
61: 
62: #endif  // TENSORFLOW_USE_MPI
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/nccl/kernels/nccl_manager.cc" line="416" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [nccl_stream] to null at line 410 implies that [nccl_stream ] might be null.Dereferencing null pointer [nccl_stream]." web_identify="{&quot;identify&quot;:&quot;nccl_stream&quot;}" func_info="void NcclManager::RunCollective ( const string &amp; key , Collective * collective )" content="406: 
407:   for (int rank = 0; rank &lt; size; ++rank) {
408:     Participant* p = collective-&gt;participants[rank].get();
409:     NcclStream* nccl_stream = communicator-&gt;members[rank].nccl_stream;
410:     CHECK(nccl_stream != nullptr);
411: 
412:     if (p-&gt;in_t != nullptr) {
413:       // Wait to ensure that the kernel that produces the data in the input
414:       // tensor has finished running before the nccl kernel runs on the
415:       // communication stream.
416:       nccl_stream-&gt;stream-&gt;ThenWaitFor(p-&gt;tensor_stream);
417:     }
418:     if (p-&gt;root) {
419:       CHECK_EQ(collective-&gt;root_rank, -1);
420:       collective-&gt;root_rank = rank;
421:     }
422:   }
423: 
424:   if (collective-&gt;type == kBroadcast) {
425:     CHECK_NE(collective-&gt;root_rank, -1);
426:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/pi_examples/camera/camera.cc" line="352" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;image_widthimage_channels*&quot;}" func_info="Status TensorFromFrame ( char * image_data , int image_width , int image_height , int image_channels , const int wanted_height , const int wanted_width , const float input_mean , const float input_std , std::vector &lt; Tensor &gt; * out_tensors )" content="342:   // In these loops, we convert the eight-bit data in the image into float,
343:   // resize it using bilinear filtering, and scale it numerically to the float
344:   // range that the model expects (given by input_mean and input_std).
345:   tensorflow::Tensor image_tensor(
346:       tensorflow::DT_FLOAT,
347:       tensorflow::TensorShape(
348:           {1, wanted_height, wanted_width, wanted_channels}));
349:   auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;();
350:   tensorflow::uint8* in = image_data;
351:   float* out = image_tensor_mapped.data();
352:   const size_t image_rowlen = image_width * image_channels;
353:   const float width_scale = static_cast&lt;float&gt;(image_width) / wanted_width;
354:   const float height_scale = static_cast&lt;float&gt;(image_height) / wanted_height;
355:   for (int y = 0; y &lt; wanted_height; ++y) {
356:     const float in_y = y * height_scale;
357:     const int top_y_index = static_cast&lt;int&gt;(floorf(in_y));
358:     const int bottom_y_index =
359:         std::min(static_cast&lt;int&gt;(ceilf(in_y)), (image_height - 1));
360:     const float y_lerp = in_y - top_y_index;
361:     tensorflow::uint8* in_top_row = in + (top_y_index * image_rowlen);
362:     tensorflow::uint8* in_bottom_row = in + (bottom_y_index * image_rowlen);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/pi_examples/label_image/label_image.cc" line="163" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;image_widthimage_channels*&quot;}" func_info="Status ReadTensorFromImageFile ( string file_name , const int wanted_height , const int wanted_width , const float input_mean , const float input_std , std::vector &lt; Tensor &gt; * out_tensors )" content="153:   // In these loops, we convert the eight-bit data in the image into float,
154:   // resize it using bilinear filtering, and scale it numerically to the float
155:   // range that the model expects (given by input_mean and input_std).
156:   tensorflow::Tensor image_tensor(
157:       tensorflow::DT_FLOAT,
158:       tensorflow::TensorShape(
159:           {1, wanted_height, wanted_width, wanted_channels}));
160:   auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;();
161:   tensorflow::uint8* in = image_data.data();
162:   float* out = image_tensor_mapped.data();
163:   const size_t image_rowlen = image_width * image_channels;
164:   const float width_scale = static_cast&lt;float&gt;(image_width) / wanted_width;
165:   const float height_scale = static_cast&lt;float&gt;(image_height) / wanted_height;
166:   for (int y = 0; y &lt; wanted_height; ++y) {
167:     const float in_y = y * height_scale;
168:     const int top_y_index = static_cast&lt;int&gt;(floorf(in_y));
169:     const int bottom_y_index =
170:         std::min(static_cast&lt;int&gt;(ceilf(in_y)), (image_height - 1));
171:     const float y_lerp = in_y - top_y_index;
172:     tensorflow::uint8* in_top_row = in + (top_y_index * image_rowlen);
173:     tensorflow::uint8* in_bottom_row = in + (bottom_y_index * image_rowlen);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc" line="64" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ &lt;&lt; ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;tree_num16&lt;&lt;&quot;}" func_info="void tensorforest::GetFeatureSet ( int tree_num , int node_num , int random_seed , int num_features , int num_features_to_pick , std :: vector &lt; int &gt; * features )" content="54: 
55:   // TODO(thomaswc): At some point we should consider
56:   // //learning/logistic/logodds-to-prob.h
57:   return 1.0 / (1.0 + exp(-dot_product + bias));
58: }
59: 
60: void GetFeatureSet(int32 tree_num, int32 node_num, int32 random_seed,
61:                    int32 num_features, int32 num_features_to_pick,
62:                    std::vector&lt;int32&gt;* features) {
63:   features-&gt;clear();
64:   uint64 seed = node_num ^ (tree_num &lt;&lt; 16) ^ random_seed;
65:   random::PhiloxRandom rng(seed);
66:   for (int i = 0; i &lt; num_features_to_pick; ++i) {
67:     // PhiloxRandom returns an array of int32&apos;s
68:     const random::PhiloxRandom::ResultType rand = rng();
69:     const int32 feature = (rand[0] + rand[1]) % num_features;
70:     features-&gt;push_back(feature);
71:   }
72: }
73: 
74: }  // namespace tensorforest
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/tree_utils.cc" line="613" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;parent_sum&gt;=0&apos; is redundant or there is division by zero at line 613." web_identify="" func_info="void tensorforest::GetParentWeightedMean ( float leaf_sum , const float * leaf_data , float parent_sum , const float * parent_data , float valid_leaf_threshold , int num_outputs , std :: vector &lt; float &gt; * mean )" content="603:                            float valid_leaf_threshold, int num_outputs,
604:                            std::vector&lt;float&gt;* mean) {
605:   float parent_weight = 0.0;
606:   if (leaf_sum &lt; valid_leaf_threshold &amp;&amp; parent_sum &gt;= 0) {
607:     VLOG(1) &lt;&lt; &quot;not enough samples at leaf, including parent counts.&quot;
608:             &lt;&lt; &quot;child sum = &quot; &lt;&lt; leaf_sum;
609:     // Weight the parent&apos;s counts just enough so that the new sum is
610:     // valid_leaf_threshold_, but never give any counts a weight of
611:     // more than 1.
612:     parent_weight =
613:         std::min(1.0f, (valid_leaf_threshold - leaf_sum) / parent_sum);
614:     leaf_sum += parent_weight * parent_sum;
615:     VLOG(1) &lt;&lt; &quot;Sum w/ parent included = &quot; &lt;&lt; leaf_sum;
616:   }
617: 
618:   for (int c = 0; c &lt; num_outputs; c++) {
619:     float w = leaf_data[c];
620:     if (parent_weight &gt; 0.0) {
621:       w += parent_weight * parent_data[c];
622:     }
623:     (*mean)[c] = w / leaf_sum;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/graph_collection_operator.cc" line="34" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;node_idnum_splits_to_consider_*&quot;}" func_info="long GraphRunnerSplitCollectionOperator::UniqueId ( int node_id , int split_id ) const" content="24: REGISTER_SPLIT_COLLECTION(GRAPH_RUNNER_COLLECTION,
25:                           GraphRunnerSplitCollectionOperator);
26: 
27: std::unique_ptr&lt;GrowStats&gt; GraphRunnerSplitCollectionOperator::CreateGrowStats(
28:     int32 node_id, int32 depth) const {
29:   return std::unique_ptr&lt;GrowStats&gt;(new SimpleStats(params_, depth));
30: }
31: 
32: int64 GraphRunnerSplitCollectionOperator::UniqueId(int32 node_id,
33:                                                    int32 split_id) const {
34:   return node_id * num_splits_to_consider_ + split_id;
35: }
36: 
37: bool GraphRunnerSplitCollectionOperator::BestSplit(int32 node_id,
38:                                                    SplitCandidate* best,
39:                                                    int32* depth) const {
40:   float min_score = FLT_MAX;
41:   int best_index = -1;
42:   auto* slot = stats_.at(node_id).get();
43:   *depth = slot-&gt;depth();
44:   for (int i = 0; i &lt; slot-&gt;num_splits(); ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/graph_collection_operator.h" line="36" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GraphRunnerSplitCollectionOperator::features_per_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GraphRunnerSplitCollectionOperator::features_per_node_,&quot;}" func_info="tensorflow::tensorforest::GraphRunnerSplitCollectionOperator" content="26: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/split_collection_operators.h&quot;
27: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/proto/fertile_stats.pb.h&quot;
28: #include &quot;map/base/mlp/tf/tensorflow/contrib/tensor_forest/proto/tensor_forest_params.pb.h&quot;
29: 
30: namespace tensorflow {
31: namespace tensorforest {
32: 
33: // Holds split candidates that are trained by running any TF graph.
34: class GraphRunnerSplitCollectionOperator : public SplitCollectionOperator {
35:  public:
36:   explicit GraphRunnerSplitCollectionOperator(const TensorForestParams&amp; params)
37:       : SplitCollectionOperator(params) {
38:     if (params.num_splits_to_consider().ParamType_case() ==
39:         DepthDependentParam::PARAMTYPE_NOT_SET) {
40:       LOG(FATAL) &lt;&lt; &quot;GRAPH_RUNNER_COLLECTION must specify a constant value for &quot;
41:                  &lt;&lt; &quot; num_splits_to_consider&quot;;
42:     } else {
43:       num_splits_to_consider_ =
44:           params.num_splits_to_consider().constant_value();
45:     }
46:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/input_data.cc" line="141" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [sparse_indices_] to null at line 126 implies that [sparse_indices_ ] might be null.Dereferencing null pointer [sparse_indices_]." web_identify="{&quot;identify&quot;:&quot;sparse_indices_&quot;}" func_info="void TensorDataSet::RandomSample ( int example , decision_trees::FeatureId * feature_id , float * bias , int * type ) const" content="131:     }
132:   }
133:   int rand_feature = rng_-&gt;Uniform(num_total_features);
134:   if (rand_feature &lt; available_features_.size()) {  // it&apos;s dense.
135:     *feature_id = available_features_[rand_feature];
136:     *type = input_spec_.GetDenseFeatureType(rand_feature);
137:   } else {
138:     const int32 sparse_index =
139:         sparse_input_start + rand_feature - input_spec_.dense_features_size();
140:     const int32 saved_index =
141:         (*sparse_indices_)(sparse_index, 1) + input_spec_.dense_features_size();
142:     *feature_id = decision_trees::FeatureId();
143:     feature_id-&gt;mutable_id()-&gt;set_value(strings::StrCat(saved_index));
144: 
145:     // TODO(gilberth): Remove this shortcut when different sparse types are
146:     // allowed.
147:     *type = input_spec_.sparse(0).original_type();
148:   }
149: 
150:   *bias = GetExampleValue(example, *feature_id);
151: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensor_forest/kernels/v4/input_data.h" line="38" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TensorDataSet::sparse_batch_size_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TensorDataSet::sparse_batch_size_,&quot;}" func_info="tensorflow::tensorforest::TensorDataSet" content="28: 
29: namespace tensorflow {
30: namespace tensorforest {
31: 
32: typedef TTypes&lt;const float, 2&gt;::ConstTensor DenseStorageType;
33: typedef TTypes&lt;const int64, 2&gt;::ConstTensor SparseIndicesStorageType;
34: typedef TTypes&lt;const float, 1&gt;::ConstTensor SparseValuesStorageType;
35: 
36: class TensorDataSet {
37:  public:
38:   TensorDataSet(const tensorforest::TensorForestDataSpec&amp; input_spec,
39:                 int32 seed)
40:       : dense_data_(nullptr),
41:         sparse_indices_(nullptr),
42:         sparse_values_(nullptr),
43:         input_spec_(input_spec),
44:         split_sampling_random_seed_(seed) {
45:     int column_count = 0;
46:     for (int i = 0; i &lt; input_spec_.dense_size(); ++i) {
47:       for (int j = 0; j &lt; input_spec_.dense(i).size(); ++j) {
48:         ++column_count;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorboard/db/summary_file_writer.cc" line="32" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SummaryFileWriter::last_flush_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SummaryFileWriter::last_flush_,&quot;}" func_info="SummaryFileWriter" content="22: #include &quot;tensorflow/core/framework/types.h&quot;
23: #include &quot;tensorflow/core/lib/io/path.h&quot;
24: #include &quot;tensorflow/core/util/events_writer.h&quot;
25: #include &quot;tensorflow/core/util/ptr_util.h&quot;
26: 
27: namespace tensorflow {
28: namespace {
29: 
30: class SummaryFileWriter : public SummaryWriterInterface {
31:  public:
32:   SummaryFileWriter(int max_queue, int flush_millis, Env* env)
33:       : SummaryWriterInterface(),
34:         is_initialized_(false),
35:         max_queue_(max_queue),
36:         flush_millis_(flush_millis),
37:         env_(env) {}
38: 
39:   Status Initialize(const string&amp; logdir, const string&amp; filename_suffix) {
40:     const Status is_dir = env_-&gt;IsDirectory(logdir);
41:     if (!is_dir.ok()) {
42:       if (is_dir.code() != tensorflow::error::NOT_FOUND) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/convert/convert_graph.h" line="34" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ConversionParams::output_names,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ConversionParams::output_names,&quot;}" func_info="tensorflow::tensorrt::convert::ConversionParams" content="24: #include &quot;map/base/mlp/tf/tensorflow/core/platform/types.h&quot;
25: 
26: #if GOOGLE_CUDA
27: #if GOOGLE_TENSORRT
28: 
29: namespace tensorflow {
30: namespace tensorrt {
31: namespace convert {
32: 
33: struct ConversionParams {
34:   ConversionParams()
35:       : input_graph_def(nullptr),
36:         max_batch_size(1),
37:         max_workspace_size_bytes(1 &lt;&lt; 30),
38:         output_graph_def(nullptr),
39:         precision_mode(1),
40:         minimum_segment_size(3),
41:         graph_properties(nullptr),
42:         cluster(nullptr),
43:         is_dyn_op(false),
44:         fixed_input_size(true),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/convert/convert_nodes.cc" line="2715" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [tensor] suggests that it may be null, but it has already been dereferenced at line 2714." web_identify="{&quot;identify&quot;:&quot;tensor&quot;}" func_info="tensorflow::Status convert::ConvertGraphDefToEngine ( const tensorflow :: GraphDef &amp; gdef , int precision_mode , int max_batch_size , long max_workspace_size_bytes , const std :: vector &lt; tensorflow :: PartialTensorShape &gt; &amp; input_shapes , Logger * logger , nvinfer1 :: IGpuAllocator * allocator , TRTInt8Calibrator * calibrator , TrtUniquePtrType &lt; nvinfer1 :: ICudaEngine &gt; * engine , bool * convert_successfully )" content="2705:     }
2706:   }
2707:   for (const auto&amp; output : output_tensors) {
2708:     auto tensor_or_weights = converter.get_tensor(output.first);
2709:     if (!tensor_or_weights.is_tensor()) {
2710:       return tensorflow::errors::InvalidArgument(
2711:           &quot;Output node &apos;&quot; + output.first + &quot;&apos; is weights not tensor&quot;);
2712:     }
2713:     nvinfer1::ITensor* tensor = tensor_or_weights.tensor();
2714:     tensor-&gt;setName(output.second.c_str());
2715:     if (!tensor) {
2716:       return tensorflow::errors::NotFound(&quot;Output tensor not found: &quot; +
2717:                                           output.first);
2718:     }
2719:     VLOG(1) &lt;&lt; &quot;Marking output tensor &quot; &lt;&lt; output.first &lt;&lt; &quot;, as output tensor &quot;
2720:             &lt;&lt; output.second;
2721: 
2722:     converter.network()-&gt;markOutput(*tensor);
2723:   }
2724:   if (convert_successfully) *convert_successfully = true;
2725: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/convert/convert_nodes.h" line="78" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;EngineInfo::maximum_cached_engines,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;EngineInfo::maximum_cached_engines,&quot;}" func_info="tensorflow::tensorrt::convert::EngineInfo" content="68:   tensorflow::PartialTensorShape inside_shape;
69: 
70:   tensorflow::DataType connection_type;
71:   bool is_input_edge;
72: 
73:   // The port number of the TRT node connecting to this edge.
74:   int port_number;
75: };
76: 
77: struct EngineInfo {
78:   EngineInfo()
79:       : engine_type(EngineType::TRTStatic),
80:         max_workspace_size_bytes(0),
81:         precision_mode(FP32MODE) {}
82: 
83:   string engine_name;
84:   string device;
85:   tensorflow::GraphDef segment_graph_def;
86: 
87:   // The segment nodes that are on one side of the edges are topological sorted.
88:   std::vector&lt;EngineConnection&gt; connections;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc" line="179" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cluster] to null at line 93 implies that [cluster ] might be null.Dereferencing null pointer [cluster]." web_identify="{&quot;identify&quot;:&quot;cluster&quot;}" func_info="void TRTOptimizationPass::PrintDebugInfo ( tensorflow::grappler::Cluster * cluster , const tensorflow::grappler::GrapplerItem &amp; item )" content="169:   VLOG(1) &lt;&lt; &quot;save_restore_loc_tensor = &quot; &lt;&lt; item.save_restore_loc_tensor;
170:   if (item.keep_ops.size()) {
171:     VLOG(1) &lt;&lt; offset &lt;&lt; &quot;keep ops  :&quot;;
172:     for (const auto&amp; f : item.keep_ops) {
173:       VLOG(1) &lt;&lt; offset2 &lt;&lt; f;
174:     }
175:   } else {
176:     VLOG(1) &lt;&lt; offset &lt;&lt; &quot;No keep ops&quot;;
177:   }
178:   VLOG(3) &lt;&lt; item.graph.DebugString();
179:   for (const auto dev : cluster-&gt;GetDeviceSet()-&gt;devices()) {
180:     const auto&amp; pname = dev-&gt;parsed_name();
181:     VLOG(1) &lt;&lt; &quot;Device name= &quot; &lt;&lt; dev-&gt;name()
182:             &lt;&lt; &quot; parsedname job= &quot; &lt;&lt; pname.job &lt;&lt; &quot; id= &quot; &lt;&lt; pname.id
183:             &lt;&lt; &quot; has_id: &quot; &lt;&lt; pname.has_id &lt;&lt; &quot; has_job: &quot; &lt;&lt; pname.has_job
184:             &lt;&lt; &quot;has_type: &quot; &lt;&lt; pname.has_type &lt;&lt; &quot; type =&quot; &lt;&lt; pname.type;
185:   }
186: }
187: 
188: tensorflow::Status TRTOptimizationPass::Optimize(
189:     tensorflow::grappler::Cluster* cluster,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/convert/trt_optimization_pass.h" line="34" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TRTOptimizationPass::is_dynamic_op_,max_cached_batches_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TRTOptimizationPass::is_dynamic_op_,max_cached_batches_,&quot;}" func_info="tensorflow::tensorrt::convert::TRTOptimizationPass" content="24: 
25: #if GOOGLE_CUDA
26: #if GOOGLE_TENSORRT
27: 
28: namespace tensorflow {
29: namespace tensorrt {
30: namespace convert {
31: 
32: class TRTOptimizationPass : public tensorflow::grappler::CustomGraphOptimizer {
33:  public:
34:   TRTOptimizationPass(const string&amp; name = &quot;TRTOptimizationPass&quot;)
35:       : name_(name),
36:         minimum_segment_size_(3),
37:         precision_mode_(0),
38:         maximum_batch_size_(-1),
39:         maximum_workspace_size_(-1) {
40:     VLOG(1) &lt;&lt; &quot;Constructing &quot; &lt;&lt; name_;
41:   }
42: 
43:   string name() const override { return name_; };
44: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.cc" line="106" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="bool TRTInt8Calibrator::getBatch ( void * * bindings , const char * * names , int num_bindings )" content="96:   while ((!batch_is_set_ &amp;&amp; !done_)) cond_.wait(lock);
97:   if (done_) return false;
98: 
99:   // Gets the batch
100:   for (int i = 0; i &lt; num_bindings; i++) {
101:     auto it = dev_buffers_.find(names[i]);
102:     if (it == dev_buffers_.end()) {
103:       LOG(FATAL) &lt;&lt; &quot;Calibration engine asked for unknown tensor name &apos;&quot;
104:                  &lt;&lt; names[i] &lt;&lt; &quot;&apos; at position &quot; &lt;&lt; i;
105:     }
106:     bindings[i] = it-&gt;second.first;
107:   }
108:   batch_is_set_ = false;
109:   calib_running_ = true;
110:   return true;
111: }
112: 
113: void TRTInt8Calibrator::waitAndSetDone() {
114:   tensorflow::mutex_lock lock(cond_mtx_);
115:   // Wait while the queue is full or calibration is running, so we don&apos;t miss
116:   // the last batch.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/tensorrt/resources/trt_int8_calibrator.cc" line="68" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [devptr] may be invalid here." web_identify="{&quot;identify&quot;:&quot;devptr&quot;}" func_info="bool TRTInt8Calibrator::setBatch ( const std::unordered_map &lt; string , void * &gt; &amp; data , const cudaStream_t stream )" content="58:   CHECK(!calib_running_ &amp;&amp; !batch_is_set_);
59:   VLOG(1) &lt;&lt; &quot;Set Batch Waiting finished&quot;;
60: 
61:   // Sets the batch.
62:   for (const auto it : data) {
63:     auto devptr = dev_buffers_.find(it.first);
64:     if (devptr == dev_buffers_.end()) {
65:       LOG(FATAL) &lt;&lt; &quot;FATAL &quot; &lt;&lt; engine_name_ &lt;&lt; &quot; input name &apos;&quot; &lt;&lt; it.first
66:                  &lt;&lt; &quot;&apos; does not match with the buffer names&quot;;
67:     }
68:     const auto&amp; d = devptr-&gt;second;
69: 
70:     // TODO(sami,aaroey): Need to figure out a way to ensure synchronization
71:     // between stream, perhaps using a tensor?
72:     auto status = cudaMemcpyAsync(d.first, it.second, d.second,
73:                                   cudaMemcpyDeviceToDevice, stream);
74:     if (status != cudaSuccess) {
75:       LOG(FATAL) &lt;&lt; &quot;cudaMemcpy &quot; &lt;&lt; engine_name_ &lt;&lt; &quot; for &apos;&quot; &lt;&lt; it.first
76:                  &lt;&lt; &quot;&apos; failed with &quot; &lt;&lt; status;
77:     }
78:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/grpc_verbs_service.cc" line="122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rc] to null at line 115 implies that [rc ] might be null.Dereferencing null pointer [rc]." web_identify="{&quot;identify&quot;:&quot;rc&quot;}" func_info="Status GrpcVerbsService::GetRemoteAddressSync ( const GetRemoteAddressRequest * request , GetRemoteAddressResponse * response )" content="112:   // the channel setting part is redundant.
113:   const string remote_host_name = request-&gt;host_name();
114:   RdmaChannel* rc = rdma_mgr_-&gt;FindChannel(remote_host_name);
115:   CHECK(rc);
116:   RdmaAddress ra;
117:   ra.lid = request-&gt;channel().lid();
118:   ra.qpn = request-&gt;channel().qpn();
119:   ra.psn = request-&gt;channel().psn();
120:   ra.snp = request-&gt;channel().snp();
121:   ra.iid = request-&gt;channel().iid();
122:   rc-&gt;SetRemoteAddress(ra, false);
123:   rc-&gt;Connect();
124:   int i = 0;
125:   int idx[] = {1, 0};
126:   std::vector&lt;RdmaMessageBuffer*&gt; mb(rc-&gt;message_buffers());
127:   CHECK_EQ(request-&gt;mr_size(), RdmaChannel::kNumMessageBuffers);
128:   for (const auto&amp; mr : request-&gt;mr()) {
129:     // the connections are crossed, i.e.
130:     // local tx_message_buffer &lt;---&gt; remote rx_message_buffer_
131:     // local rx_message_buffer &lt;---&gt; remote tx_message_buffer_
132:     // hence idx[] = {1, 0}.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_list] to null at line 128 implies that [dev_list ] might be null.Dereferencing null pointer [dev_list]." web_identify="{&quot;identify&quot;:&quot;dev_list&quot;}" func_info="ibv_device * tensorflow::set_device ( )" content="124:   int num_devs_with_active_port = 0;
125:   string env_p_rdma_device, str_port_num;
126: 
127:   dev_list = ibv_get_device_list(&amp;dev_num);
128:   CHECK(dev_list) &lt;&lt; &quot;No InfiniBand device found&quot;;
129: 
130:   env_p_rdma_device = get_env_var(&quot;RDMA_DEVICE&quot;);
131:   if (!env_p_rdma_device.empty()) {
132:     for (device_index = 0; device_index &lt; dev_num; device_index++) {
133:       if (!env_p_rdma_device.compare(
134:               ibv_get_device_name(dev_list[device_index]))) {
135:         CHECK(get_dev_active_port_count(dev_list[device_index]) != 0)
136:             &lt;&lt; &quot;Device &quot; &lt;&lt; ibv_get_device_name(dev_list[device_index])
137:             &lt;&lt; &quot; has no active ports&quot;;
138:         return dev_list[device_index];
139:       }
140:     }
141:     // check validity of input device
142:     CHECK(false) &lt;&lt; &quot;The device &quot; &lt;&lt; env_p_rdma_device &lt;&lt; &quot; wasn&apos;t found&quot;;
143:   } else {
144:     // set default device
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="1426" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [mr] suggests that it may be null, but it has already been dereferenced at line 1423." web_identify="{&quot;identify&quot;:&quot;mr&quot;}" func_info="void RdmaMemoryMgr::InsertMemoryRegion ( void * addr , long length , const std::string &amp; allocator_name )" content="1416: }
1417: 
1418: void RdmaMemoryMgr::InsertMemoryRegion(void* addr, size_t length,
1419:                                        const std::string&amp; allocator_name) {
1420:   if (length == 0) return;
1421:   ibv_mr* mr = ibv_reg_mr(pd_, addr, length,
1422:                           IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);
1423:   RDMA_LOG(1) &lt;&lt; &quot;Insert memory region 0x&quot; &lt;&lt; std::hex &lt;&lt; mr-&gt;rkey &lt;&lt; &quot;. [&quot;
1424:               &lt;&lt; addr &lt;&lt; &quot;-&quot; &lt;&lt; (void*)((uint64_t)addr + length - 1) &lt;&lt; &quot;]&quot;
1425:               &lt;&lt; &quot; SIZE: 0x&quot; &lt;&lt; length &lt;&lt; &quot; (&quot; &lt;&lt; allocator_name &lt;&lt; &quot;).&quot;;
1426:   if (mr != nullptr) {
1427:     mutex_lock l(mrs_mu_);
1428:     auto iter = std::upper_bound(mrs_.begin(), mrs_.end(), addr, &amp;Comparator);
1429:     mrs_.insert(iter, {mr, &amp;MRDeleter});
1430:   } else {
1431:     LOG(WARNING) &lt;&lt; &quot;Cannot register memory region&quot;;
1432:   }
1433: }
1434: 
1435: void RdmaMemoryMgr::EvictMemoryRegion(void* addr, size_t length) {
1436:   if (length == 0) return;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="567" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [mr_] to null at line 562 implies that [mr_ ] might be null.Dereferencing null pointer [mr_]." web_identify="{&quot;identify&quot;:&quot;mr_&quot;}" func_info="RdmaChannel::RdmaChannel ( const RdmaAdapter * adapter , const string local_name , const string remote_name ) : adapter_ ( adapter ) , local_name_ ( local_name ) , remote_name_ ( remote_name ) , request_serial_ ( 0 )" content="557:       request_serial_(0) {
558:   struct ibv_sge list;
559: 
560:   mr_ = ibv_reg_mr(adapter_-&gt;pd_, ping_buff_, kPingBuffSize,
561:                    IBV_ACCESS_LOCAL_WRITE);
562:   CHECK(mr_) &lt;&lt; &quot;Failed to register memory region&quot;;
563: 
564:   memset(&amp;list, 0, sizeof(list));
565:   list.addr = (uintptr_t)ping_buff_;
566:   list.length = kPingBuffSize;
567:   list.lkey = mr_-&gt;lkey;
568: 
569:   ping_sge_list_ = list;
570:   // Create queue pair
571:   {
572:     struct ibv_qp_init_attr attr;
573:     memset(&amp;attr, 0, sizeof(ibv_qp_init_attr));
574:     attr.send_cq = adapter_-&gt;cq_;
575:     attr.recv_cq = adapter_-&gt;cq_;
576:     attr.cap.max_send_wr = adapter_-&gt;params_.queue_depth;
577:     attr.cap.max_recv_wr = adapter_-&gt;params_.queue_depth;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="607" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [qp_] to null at line 583 implies that [qp_ ] might be null.Dereferencing null pointer [qp_]." web_identify="{&quot;identify&quot;:&quot;qp_&quot;}" func_info="RdmaChannel::RdmaChannel ( const RdmaAdapter * adapter , const string local_name , const string remote_name ) : adapter_ ( adapter ) , local_name_ ( local_name ) , remote_name_ ( remote_name ) , request_serial_ ( 0 )" content="597:     CHECK(!ibv_modify_qp(qp_, &amp;attr, mask)) &lt;&lt; &quot;Failed to set QP to INIT&quot;;
598:   }
599: 
600:   // Local address
601:   {
602:     struct ibv_port_attr attr;
603:     CHECK(
604:         !ibv_query_port(adapter_-&gt;context_, adapter_-&gt;params_.port_num, &amp;attr))
605:         &lt;&lt; &quot;Query port&quot;;
606:     self_.lid = attr.lid;
607:     self_.qpn = qp_-&gt;qp_num;
608:     self_.psn = static_cast&lt;uint32_t&gt;(random::New64()) &amp; 0xffffff;
609:     union ibv_gid gid;
610:     CHECK(!ibv_query_gid(adapter_-&gt;context_, adapter_-&gt;params_.port_num,
611:                          adapter_-&gt;params_.sgid_index, &amp;gid))
612:         &lt;&lt; &quot;Query gid&quot;;
613:     self_.snp = gid.global.subnet_prefix;
614:     self_.iid = gid.global.interface_id;
615:   }
616: 
617:   // create message and ack buffers, then initialize the tables.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="692" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="RdmaTensorRequest * RdmaChannel::GetTensorRequest ( int request_index )" content="682: 
683: void RdmaChannel::RemoveTensorRequest(uint32_t request_index) {
684:   mutex_lock lock{ct_mu_};
685:   request_table_.erase(request_index);
686: }
687: 
688: RdmaTensorRequest* RdmaChannel::GetTensorRequest(uint32_t request_index) {
689:   mutex_lock lock{ct_mu_};
690:   RequestTable::iterator iter = request_table_.find(request_index);
691:   CHECK(iter != request_table_.end());
692:   return &amp;iter-&gt;second;
693: }
694: 
695: void RdmaChannel::Connect() {
696:   {
697:     mutex_lock lock{mu_};
698:     CHECK(remote_set_) &lt;&lt; &quot;remote channel is not set&quot;;
699:   }
700:   Connect(remote_);
701: }
702: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.cc" line="986" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="RdmaTensorResponse * RdmaChannel::UpdateTensorResponse ( const RdmaMessage &amp; rm )" content="976:       responses_table_.emplace(rm.request_index_, RdmaTensorResponse(this, rm));
977:   CHECK(it.second) &lt;&lt; &quot;Response with the ID &quot; &lt;&lt; rm.request_index_
978:                    &lt;&lt; &quot; already exists.&quot;;
979:   return &amp;it.first-&gt;second;
980: }
981: 
982: RdmaTensorResponse* RdmaChannel::UpdateTensorResponse(const RdmaMessage&amp; rm) {
983:   mutex_lock lock{mu_};
984:   auto it = responses_table_.find(rm.request_index_);
985:   CHECK(it != responses_table_.end()) &lt;&lt; &quot;No response found.&quot;;
986:   RdmaTensorResponse* response = &amp;it-&gt;second;
987:   response-&gt;Update(rm);
988:   return response;
989: }
990: 
991: void RdmaChannel::RemoveTensorResponse(uint32_t request_index) {
992:   mutex_lock lock{mu_};
993:   responses_table_.erase(request_index);
994: }
995: 
996: void RdmaTensorResponse::Start() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma.h" line="311" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RdmaTensorResponse::tensor_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RdmaTensorResponse::tensor_,&quot;}" func_info="tensorflow::RdmaTensorResponse" content="301: #ifdef RDMA_DATA_VALIDATION
302:   uint64_t checksum_;
303: #endif
304: };
305: 
306: // RdmaTensorResponse
307: // Represents a single tensor response.
308: class RdmaTensorResponse {
309:  public:
310:   // Creates a response for request message.
311:   RdmaTensorResponse(RdmaChannel* channel, const RdmaMessage&amp; rm)
312:       : channel_(channel), rm_(rm) {}
313: 
314:   void Update(const RdmaMessage&amp; rm) { rm_ = rm; }
315: 
316:   // Start the tensor response sequence.
317:   //
318:   // 1. Find the tensor in the local tag-match table and invoke RecvHandler.
319:   //    (Using RecvLocalAsync()).
320:   // 2. Compare the tensor&apos;s meta-data to the meta-data in the message (taken
321:   //    from the requester&apos;s local cache).
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma_mgr.cc" line="197" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="RdmaChannel * RdmaMgr::FindChannel ( const string &amp; name )" content="187: }
188: 
189: // Find a channel via the given name.
190: // Args:
191: //   name: peer name, e.g. worker1
192: // Returns
193: //   channel object that is connected to the named peer.
194: RdmaChannel* RdmaMgr::FindChannel(const string&amp; name) {
195:   ChannelTable::iterator iter = channel_table_.find(name);
196:   CHECK(iter != channel_table_.end());
197:   return iter-&gt;second;
198: }
199: 
200: bool IsGDRAvailable() {
201: #if defined(__APPLE__)
202:   return false;
203: #elif defined(PLATFORM_WINDOWS)
204:   return false;
205: #else
206:   std::ifstream ifs(&quot;/proc/modules&quot;);
207:   string line;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/contrib/verbs/rdma_mgr.cc" line="309" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [visitable_allocator] to null at line 305 implies that [visitable_allocator ] might be null.Dereferencing null pointer [visitable_allocator]." web_identify="{&quot;identify&quot;:&quot;visitable_allocator&quot;}" func_info="void RdmaMgr::InitAllocators ( )" content="299:         std::bind(&amp;RdmaMemoryMgr::InsertMemoryRegion,
300:                   &amp;RdmaMemoryMgr::Singleton(), _1, _2, allocator-&gt;Name());
301:     VisitableAllocator::Visitor free_visitor = std::bind(
302:         &amp;RdmaMemoryMgr::EvictMemoryRegion, &amp;RdmaMemoryMgr::Singleton(), _1, _2);
303: 
304:     auto* visitable_allocator = dynamic_cast&lt;VisitableAllocator*&gt;(allocator);
305:     CHECK(visitable_allocator)
306:         &lt;&lt; &quot;is not visitable for instrumentation&quot; &lt;&lt; allocator-&gt;Name();
307:     // Make sure we don&apos;t instrument the same allocator twice
308:     if (instrumented_.find(allocator) == std::end(instrumented_)) {
309:       visitable_allocator-&gt;AddAllocVisitor(alloc_visitor);
310:       visitable_allocator-&gt;AddFreeVisitor(free_visitor);
311:       instrumented_.insert(allocator);
312:       LOG(INFO) &lt;&lt; &quot;Instrumenting CPU allocator &quot; &lt;&lt; allocator-&gt;Name();
313:     }
314:   }
315: 
316: #if GOOGLE_CUDA
317:   if (IsGDRAvailable()) {
318:     // Note we don&apos;t free allocated GPU memory so there is no free visitor
319:     int32_t bus_id = TryToReadNumaNode(rdma_adapter_-&gt;context_-&gt;device) + 1;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/broadcaster_test.cc" line="191" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BroadcasterTest::rma_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BroadcasterTest::rma_,&quot;}" func_info="BroadcasterTest" content="181:         peer_device, peer_task, key, from_device, from_device_ctx,
182:         from_alloc_attr, from_tensor, client_locality, done);
183:   }
184: 
185:   mutex mu_;
186:   int fail_after_ GUARDED_BY(mu_);
187: };
188: 
189: class BroadcasterTest : public ::testing::Test {
190:  protected:
191:   BroadcasterTest() : device_type_(DEVICE_CPU) {}
192: 
193:   ~BroadcasterTest() override {
194:     stop_ = true;
195:     for (auto i : instances_) {
196:       delete i;
197:     }
198:     if (col_exec_) col_exec_-&gt;Unref();
199:   }
200: 
201:   void SetUp() override {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/broadcaster_test.cc" line="206" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [device_factory] to null at line 204 implies that [device_factory ] might be null.Dereferencing null pointer [device_factory]." web_identify="{&quot;identify&quot;:&quot;device_factory&quot;}" func_info="void BroadcasterTest::SetUp ( )" content="196:       delete i;
197:     }
198:     if (col_exec_) col_exec_-&gt;Unref();
199:   }
200: 
201:   void SetUp() override {
202: #if GOOGLE_CUDA
203:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
204:     CHECK(device_factory);
205:     SessionOptions options;
206:     Status s = device_factory-&gt;CreateDevices(
207:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
208:     CHECK(s.ok());
209: #endif
210:   }
211: 
212:   void Init(int num_workers, int num_devices, DataType dtype,
213:             const DeviceType&amp; device_type, int fail_after) {
214:     device_type_ = device_type;
215:     std::vector&lt;Device*&gt; local_devices;
216:     SessionOptions sess_opts;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/broadcaster_test.cc" line="414" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 413 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void BroadcasterTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int tensor_len , int fail_after , bool forward_input )" content="404:     int broadcast_dev_id =
405:         cp.instance.impl_details.subdiv_permutations
406:             [0][cp.instance.impl_details.subdiv_source_rank[0]];
407:     const Tensor* t = &amp;instances_[broadcast_dev_id]-&gt;tensor_;
408:     Tensor cpu_copy(dtype, TensorShape({tensor_len}));
409:     if (device_type == DEVICE_GPU) {
410:       Notification notification;
411:       Device* dev = instances_[broadcast_dev_id]-&gt;device_;
412:       auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
413:       CHECK(dev_info);
414:       dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
415:           t, &quot;&quot; /*tensor_name*/, dev, &amp;cpu_copy,
416:           [this, &amp;notification](Status s) {
417:             TF_CHECK_OK(s);
418:             notification.Notify();
419:           });
420:       notification.WaitForNotification();
421:       t = &amp;cpu_copy;
422:     }
423:     for (size_t i = 0; i &lt; t-&gt;NumElements(); ++i) {
424:       expected[i] = t-&gt;flat&lt;T&gt;()(i);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/broadcaster_test.cc" line="448" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 447 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void BroadcasterTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int tensor_len , int fail_after , bool forward_input )" content="438:       }
439:       Tensor* inst = &amp;instances_[di]-&gt;tensor_;
440:       Tensor actual(dtype, TensorShape({tensor_len}));
441:       if (device_type_ == DEVICE_CPU) {
442:         CHECK(actual.CopyFrom(*inst, inst-&gt;shape()));
443:       } else if (device_type_ == DEVICE_GPU) {
444:         Notification notification;
445:         Device* dev = instances_[di]-&gt;device_;
446:         auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
447:         CHECK(dev_info);
448:         dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
449:             inst, &quot;&quot; /*tensor_name*/, dev, &amp;actual,
450:             [this, &amp;notification](Status s) {
451:               TF_CHECK_OK(s);
452:               notification.Notify();
453:             });
454:         notification.WaitForNotification();
455:       }
456:       for (int i = 0; i &lt; tensor_len; ++i) {
457:         switch (dtype) {
458:           case DT_FLOAT:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/broadcaster_test.cc" line="566" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 565 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void DeviceInstance::InitTensor ( DataType dtype , const TensorShape &amp; shape , const std :: function &lt; void ( Tensor * ) &gt; &amp; f )" content="556:       tensor_ =
557:           Tensor(device_-&gt;GetAllocator(AllocatorAttributes()), dtype, shape);
558:       if (device_type_ == DEVICE_CPU) {
559:         f(&amp;tensor_);
560:       } else if (device_type_ == DEVICE_GPU) {
561:         Tensor cpu_tensor(dtype, shape);
562:         f(&amp;cpu_tensor);
563:         Notification notification;
564:         auto* dev_info = device_-&gt;tensorflow_gpu_device_info();
565:         CHECK(dev_info);
566:         dev_info-&gt;default_context-&gt;CopyCPUTensorToDevice(
567:             &amp;cpu_tensor, device_, &amp;tensor_, [this, &amp;notification](Status s) {
568:               TF_CHECK_OK(s);
569:               notification.Notify();
570:             });
571:         notification.WaitForNotification();
572:       } else {
573:         LOG(FATAL) &lt;&lt; &quot;Unsupported device_type &quot; &lt;&lt; device_type_;
574:       }
575:     }
576: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/collective_executor_mgr.cc" line="26" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CollectiveExecutorMgr::remote_access_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CollectiveExecutorMgr::remote_access_,&quot;}" func_info="tensorflow" content="16: 
17: #include &quot;tensorflow/core/common_runtime/base_collective_executor.h&quot;
18: #include &quot;tensorflow/core/common_runtime/build_graph_options.h&quot;
19: #include &quot;tensorflow/core/common_runtime/collective_rma_local.h&quot;
20: #include &quot;tensorflow/core/common_runtime/device_mgr.h&quot;
21: #include &quot;tensorflow/core/framework/collective.h&quot;
22: #include &quot;tensorflow/core/protobuf/config.pb.h&quot;
23: 
24: namespace tensorflow {
25: 
26: CollectiveExecutorMgr::CollectiveExecutorMgr(
27:     const ConfigProto&amp; config, const DeviceMgr* dev_mgr,
28:     std::unique_ptr&lt;DeviceResolverInterface&gt; dev_resolver,
29:     std::unique_ptr&lt;ParamResolverInterface&gt; param_resolver)
30:     : dev_mgr_(dev_mgr),
31:       dev_resolver_(std::move(dev_resolver)),
32:       param_resolver_(std::move(param_resolver)) {}
33: 
34: CollectiveExecutorMgr::~CollectiveExecutorMgr() {
35:   for (auto iter : executor_table_) {
36:     iter.second-&gt;Unref();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/collective_param_resolver_local.cc" line="295" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [cp] suggests that it may be null, but it has already been dereferenced at line 294. The error is in macros." web_identify="{&quot;identify&quot;:&quot;cp&quot;}" func_info="void SortDevicesAndTasks ( CollectiveParams * cp )" content="285:   }
286:   cp-&gt;instance.same_num_devices_per_task = true;
287:   CHECK_EQ((cp-&gt;group.group_size % cp-&gt;group.num_tasks), 0);
288: }
289: 
290: // Sort cp-&gt;instance.device_names lexicographically, but do by first
291: // computing a reordering permutation so we can keep cp-&gt;instance.task_names
292: // in corresponding order.
293: void SortDevicesAndTasks(CollectiveParams* cp) {
294:   VLOG(1) &lt;&lt; &quot;SortDevicesAndTasks &quot; &lt;&lt; cp &lt;&lt; &quot; instance &quot; &lt;&lt; &amp;cp-&gt;instance;
295:   CHECK(cp);
296:   CHECK_EQ(cp-&gt;group.group_size, cp-&gt;instance.device_names.size());
297:   CHECK_EQ(cp-&gt;group.group_size, cp-&gt;instance.task_names.size());
298:   std::vector&lt;int&gt; perm(cp-&gt;group.group_size);
299:   // TODO(tucker): substitute std::iota when the windows build supports it.
300:   // std::iota(perm.begin(), perm.end(), 0);
301:   for (int i = 0; i &lt; perm.size(); ++i) {
302:     perm[i] = i;
303:   }
304:   std::sort(perm.begin(), perm.end(), [cp](const int&amp; a, const int&amp; b) {
305:     return cp-&gt;instance.device_names[a] &lt; cp-&gt;instance.device_names[b];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/collective_rma_local.cc" line="107" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 106 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void CollectiveRemoteAccessLocal::MemCpyAsync ( DeviceContext * src_dev_ctx , DeviceContext * dst_dev_ctx , Device * src_dev , Device * dst_dev , const AllocatorAttributes &amp; src_attr , const AllocatorAttributes &amp; dst_attr , const Tensor * src , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst , int dev_to_dev_stream_index , const StatusCallback &amp; done )" content="97:       dst_attr.on_host() ? DEVICE_CPU : dst_dev-&gt;attributes().device_type());
98:   const bool non_cpu_src = src_device_type != DeviceType(DEVICE_CPU);
99:   const bool non_cpu_dst = dst_device_type != DeviceType(DEVICE_CPU);
100:   // For GPU devices when only one compute stream is used (the default)
101:   // the OpKernelContext does not supply a DeviceContext.  It&apos;s assumed
102:   // that all nodes use the default context.
103:   if (src_dev_ctx == nullptr &amp;&amp; src_device_type == DEVICE_GPU) {
104:     const DeviceBase::GpuDeviceInfo* dev_info =
105:         src_dev-&gt;tensorflow_gpu_device_info();
106:     CHECK(dev_info);
107:     src_dev_ctx = dev_info-&gt;default_context;
108:   }
109:   if (dst_dev_ctx == nullptr &amp;&amp; dst_device_type == DEVICE_GPU) {
110:     const DeviceBase::GpuDeviceInfo* dev_info =
111:         src_dev-&gt;tensorflow_gpu_device_info();
112:     CHECK(dev_info);
113:     dst_dev_ctx = dev_info-&gt;default_context;
114:   }
115:   if (non_cpu_src) CHECK(src_dev_ctx);
116:   if (non_cpu_dst) CHECK(dst_dev_ctx);
117:   if (non_cpu_src || non_cpu_dst) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/collective_rma_local.cc" line="113" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 112 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void CollectiveRemoteAccessLocal::MemCpyAsync ( DeviceContext * src_dev_ctx , DeviceContext * dst_dev_ctx , Device * src_dev , Device * dst_dev , const AllocatorAttributes &amp; src_attr , const AllocatorAttributes &amp; dst_attr , const Tensor * src , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * dst , int dev_to_dev_stream_index , const StatusCallback &amp; done )" content="103:   if (src_dev_ctx == nullptr &amp;&amp; src_device_type == DEVICE_GPU) {
104:     const DeviceBase::GpuDeviceInfo* dev_info =
105:         src_dev-&gt;tensorflow_gpu_device_info();
106:     CHECK(dev_info);
107:     src_dev_ctx = dev_info-&gt;default_context;
108:   }
109:   if (dst_dev_ctx == nullptr &amp;&amp; dst_device_type == DEVICE_GPU) {
110:     const DeviceBase::GpuDeviceInfo* dev_info =
111:         src_dev-&gt;tensorflow_gpu_device_info();
112:     CHECK(dev_info);
113:     dst_dev_ctx = dev_info-&gt;default_context;
114:   }
115:   if (non_cpu_src) CHECK(src_dev_ctx);
116:   if (non_cpu_dst) CHECK(dst_dev_ctx);
117:   if (non_cpu_src || non_cpu_dst) {
118:     CopyTensor::ViaDMA(&quot;&quot;,  // edge name (non-existent)
119:                        src_dev_ctx, dst_dev_ctx, src_dev, dst_dev, src_attr,
120:                        dst_attr, src, dst, dev_to_dev_stream_index, done);
121:   } else {
122:     int64 bytes = src-&gt;TotalBytes();
123:     DCHECK_EQ(dst-&gt;TotalBytes(), bytes);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/constant_folding.cc" line="364" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="void AddNodeToConstantGraph ( Node * n , std::unordered_map &lt; Node * , std::vector &lt; Node * &gt; &gt; * node_map , Graph * constant_graph )" content="354:     Graph* constant_graph) {
355:   std::vector&lt;Node*&gt;&amp; added = (*node_map)[n];
356:   added.push_back(constant_graph-&gt;CopyNode(n));
357:   for (const Edge* in_edge : n-&gt;in_edges()) {
358:     // Don&apos;t copy control edges to the constant graph.
359:     if (!in_edge-&gt;IsControlEdge()) {
360:       Node* in = in_edge-&gt;src();
361:       auto it = node_map-&gt;find(in);
362:       CHECK(it != node_map-&gt;end())
363:           &lt;&lt; n-&gt;DebugString() &lt;&lt; &quot; &lt;-&quot; &lt;&lt; in-&gt;DebugString();
364:       if (it-&gt;second.size() == 1) {
365:         constant_graph-&gt;AddEdge(it-&gt;second[0], in_edge-&gt;src_output(), added[0],
366:                                 in_edge-&gt;dst_input());
367:       } else {
368:         // The original source node had multiple outputs and was replaced by a
369:         // vector of constants, so the edge comes from the 0th output of the kth
370:         // added constant, rather than the kth output of the added node as in
371:         // the standard case above.
372:         constant_graph-&gt;AddEdge(it-&gt;second[in_edge-&gt;src_output()], 0, added[0],
373:                                 in_edge-&gt;dst_input());
374:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/constant_folding.cc" line="65" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [shape_map] to null at line 61 implies that [shape_map ] might be null.Dereferencing null pointer [shape_map]." web_identify="{&quot;identify&quot;:&quot;shape_map&quot;}" func_info="bool ReadPartialShapesFromShapeMap ( const Node * n , const std::unordered_map &lt; string , std::vector &lt; PartialTensorShape &gt; &gt; * shape_map , std::vector &lt; PartialTensorShape &gt; * input_shapes )" content="55: // in shape_map.
56: bool ReadPartialShapesFromShapeMap(
57:     const Node* n,
58:     const std::unordered_map&lt;string, std::vector&lt;PartialTensorShape&gt;&gt;*
59:         shape_map,
60:     std::vector&lt;PartialTensorShape&gt;* input_shapes) {
61:   CHECK(shape_map != nullptr);
62:   for (const Edge* in : n-&gt;in_edges()) {
63:     // Don&apos;t need to check if incoming control edges have known shapes.
64:     if (in-&gt;IsControlEdge()) continue;
65:     const auto known_shape_iter = shape_map-&gt;find(in-&gt;src()-&gt;name());
66:     if (known_shape_iter == shape_map-&gt;end()) {
67:       // One of n&apos;s inputs doesn&apos;t have known shapes, so don&apos;t replace n.
68:       return false;
69:     }
70:     const auto&amp; known_shape = known_shape_iter-&gt;second;
71:     CHECK_GT(known_shape.size(), in-&gt;src_output()) &lt;&lt; known_shape_iter-&gt;first;
72:     input_shapes-&gt;push_back(known_shape[in-&gt;src_output()]);
73:   }
74:   return true;
75: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/direct_session.cc" line="621" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [args.stats_collector] to null at line 605 implies that [args.stats_collector ] might be null.Dereferencing null pointer [args.stats_collector]." web_identify="{&quot;identify&quot;:&quot;args.stats_collector&quot;}" func_info="Status DirectSession::RunInternal ( long step_id , const RunOptions &amp; run_options , CallFrameInterface * call_frame , ExecutorsAndKeys * executors_and_keys , RunMetadata * run_metadata )" content="611:     // Build the cost model
612:     std::unordered_map&lt;string, const Graph*&gt; device_to_graph;
613:     for (const PerPartitionExecutorsAndLib&amp; partition :
614:          executors_and_keys-&gt;items) {
615:       const Graph* graph = partition.graph;
616:       const string device = partition.flib-&gt;device()-&gt;name();
617:       device_to_graph[device] = graph;
618:     }
619: 
620:     mutex_lock l(executor_lock_);
621:     args.stats_collector-&gt;BuildCostModel(&amp;cost_model_manager_, device_to_graph);
622: 
623:     // annotate stats onto cost graph.
624:     CostGraphDef* cost_graph = run_metadata-&gt;mutable_cost_graph();
625:     for (const auto&amp; item : executors_and_keys-&gt;items) {
626:       TF_RETURN_IF_ERROR(
627:           cost_model_manager_.AddToCostGraphDef(item.graph, cost_graph));
628:     }
629:   }
630: 
631:   // If requested via RunOptions, output the partition graphs.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/eager/tensor_handle.cc" line="116" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [remote_shape_] to null at line 115 implies that [remote_shape_ ] might be null.Dereferencing null pointer [remote_shape_]." web_identify="{&quot;identify&quot;:&quot;remote_shape_&quot;}" func_info="Status TensorHandle::NumDims ( int * num_dims )" content="106:   *tensor = &amp;tensor_;
107:   *device = device_;
108:   *op_device = op_device_;
109:   return Status::OK();
110: }
111: 
112: Status TensorHandle::NumDims(int* num_dims) {
113:   if (IsRemote()) {
114:     TF_RETURN_IF_ERROR(WaitForNode(remote_shape_node_id_, false));
115:     CHECK(remote_shape_ != nullptr);
116:     *num_dims = remote_shape_-&gt;dims();
117:   } else {
118:     TF_RETURN_IF_ERROR(WaitReady());
119:     DCHECK(IsReady());
120:     DCHECK(num_dims != nullptr);
121: 
122:     *num_dims = tensor_.dims();
123:   }
124: 
125:   return Status::OK();
126: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/executor.cc" line="1058" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FrameState::frame_id,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FrameState::frame_id,&quot;}" func_info="ExecutorState::FrameState" content="1048:                                     dead_result);
1049:     }
1050: 
1051:     ~IterationState() { delete[] input_tensors; }
1052: 
1053:    private:
1054:     PendingCounts counts_;
1055:   };
1056: 
1057:   struct FrameState {
1058:     explicit FrameState(const ExecutorImpl* impl, int parallel_iters)
1059:         : executor(impl),
1060:           max_parallel_iterations(parallel_iters),
1061:           num_outstanding_iterations(1) {}
1062: 
1063:     // A new frame is created for each loop. Execution starts at iteration 0.
1064:     // When a value at iteration 0 passes through a NextIteration node,
1065:     // iteration 1 is created and starts running. Note that iteration 0 may
1066:     // still be running so multiple iterations may run in parallel. The
1067:     // frame maintains the state of iterations in several data structures
1068:     // such as pending_count and input_tensors. When iteration 0 completes,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/executor.cc" line="2124" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [output_frame] suggests that it may be null, but it has already been dereferenced at line 2062." web_identify="{&quot;identify&quot;:&quot;output_frame&quot;}" func_info="void ExecutorState::PropagateOutputs ( const TaggedNode &amp; tagged_node , const NodeItem * item , gtl::InlinedVector &lt; Entry , 4 &gt; * outputs , gtl::InlinedVector &lt; TaggedNode , 8 &gt; * ready )" content="2114:         input_frame-&gt;next_iter_roots.push_back({node, (*outputs)[0]});
2115:         output_frame = nullptr;
2116:       } else {
2117:         // If this is a new iteration, start it.
2118:         if (input_iter == input_frame-&gt;iteration_count) {
2119:           input_frame-&gt;IncrementIteration(&amp;impl_-&gt;gview_, ready);
2120:         }
2121:         output_iter = input_iter + 1;
2122:       }
2123:     }
2124:     if (output_frame != nullptr) {
2125:       // This is the case when node is not Enter, Exit, or NextIteration.
2126:       DCHECK(input_frame == output_frame);
2127:       output_frame-&gt;ActivateNodes(item, is_dead, output_iter, outputs, ready);
2128:     }
2129:     is_frame_done = input_frame-&gt;DecrementOutstandingOpsLocked(
2130:         &amp;impl_-&gt;gview_, input_iter, ready);
2131:   }
2132: 
2133:   // At this point, this node is completely done. We also know if the
2134:   // completion of this node makes its frame completed.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/executor.cc" line="701" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [item.kernel] to null at line 700 implies that [item.kernel ] might be null.Dereferencing null pointer [item.kernel]." web_identify="{&quot;identify&quot;:&quot;item.kernel&quot;}" func_info="Status ExecutorImpl::Initialize ( )" content="691:     frame_info-&gt;total_inputs += n-&gt;num_inputs();
692: 
693:     Status s = params_.create_kernel(n-&gt;def(), &amp;item-&gt;kernel);
694:     if (!s.ok()) {
695:       item-&gt;kernel = nullptr;
696:       s = AttachDef(s, *n);
697:       LOG(ERROR) &lt;&lt; &quot;Executor failed to create kernel. &quot; &lt;&lt; s;
698:       return s;
699:     }
700:     CHECK(item-&gt;kernel);
701:     item-&gt;kernel_is_expensive = item-&gt;kernel-&gt;IsExpensive();
702:     item-&gt;kernel_is_async = (item-&gt;kernel-&gt;AsAsync() != nullptr);
703:     item-&gt;is_merge = IsMerge(n);
704:     item-&gt;is_enter = IsEnter(n);
705:     item-&gt;is_exit = IsExit(n);
706:     item-&gt;is_control_trigger = IsControlTrigger(n);
707:     item-&gt;is_sink = IsSink(n);
708:     item-&gt;is_enter_exit_or_next_iter =
709:         (IsEnter(n) || IsExit(n) || IsNextIteration(n));
710: 
711:     // Compute the maximum values we&apos;ll store for this node in the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/function.cc" line="965" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [out_flr] suggests that it may be null, but it has already been dereferenced at line 964." web_identify="{&quot;identify&quot;:&quot;out_flr&quot;}" func_info="Status FunctionLibraryRuntimeImpl::Clone ( std::unique_ptr &lt; FunctionLibraryDefinition &gt; * out_lib_def , std::unique_ptr &lt; ProcessFunctionLibraryRuntime &gt; * out_pflr , FunctionLibraryRuntime * * out_flr )" content="955: }
956: 
957: Status FunctionLibraryRuntimeImpl::Clone(
958:     std::unique_ptr&lt;FunctionLibraryDefinition&gt;* out_lib_def,
959:     std::unique_ptr&lt;ProcessFunctionLibraryRuntime&gt;* out_pflr,
960:     FunctionLibraryRuntime** out_flr) {
961:   TF_RETURN_IF_ERROR(
962:       parent_-&gt;Clone(env_, graph_def_version_, optimizer_.options(),
963:                      custom_kernel_creator_, out_lib_def, out_pflr));
964:   *out_flr = (*out_pflr)-&gt;GetFLR(device_-&gt;name());
965:   if (out_flr != nullptr) {
966:     return Status::OK();
967:   } else {
968:     return errors::Internal(&quot;Cloning FunctionLibraryRuntime failed.&quot;);
969:   }
970: }
971: 
972: namespace {
973: 
974: struct CustomCreatorSingleton {
975:   mutex mu;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_device.cc" line="263" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BaseGPUDevice::executor_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BaseGPUDevice::executor_,&quot;}" func_info="tensorflow" content="253:   mutex lock_;
254:   using key_type = std::tuple&lt;int, int&gt;;
255:   std::map&lt;key_type, StreamGroup&gt; streams_;
256: 
257:   // StreamGroupFactory cannot be created directly; Call
258:   // StreamGroupFactory::Global() to get the global instance.
259:   StreamGroupFactory() = default;
260:   TF_DISALLOW_COPY_AND_ASSIGN(StreamGroupFactory);
261: };
262: 
263: BaseGPUDevice::BaseGPUDevice(const SessionOptions&amp; options, const string&amp; name,
264:                              Bytes memory_limit, const DeviceLocality&amp; locality,
265:                              TfGpuId tf_gpu_id,
266:                              const string&amp; physical_device_desc,
267:                              Allocator* gpu_allocator, Allocator* cpu_allocator,
268:                              bool sync_every_op, int32 max_streams)
269:     : LocalDevice(options, Device::BuildDeviceAttributes(name, DEVICE_GPU,
270:                                                          memory_limit, locality,
271:                                                          physical_device_desc)),
272:       gpu_allocator_(gpu_allocator),
273:       cpu_allocator_(cpu_allocator),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_device.cc" line="89" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;EigenCudaStreamDevice::step_id_,stream_,device_prop_,allocator_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;EigenCudaStreamDevice::step_id_,stream_,device_prop_,allocator_,&quot;}" func_info="tensorflow::EigenCudaStreamDevice" content="79: // memory directly through the device allocator.  As an Open Source
80: // project, Eigen assumes allocator semantics similar to those of the
81: // CUDA memory allocator, and may not work correctly due to race
82: // conditions if used with some other allocator.  For safety, we need
83: // to delay deallocation calls out of Eigen until all events on the
84: // corresponding stream have completed.  The following two classes
85: // serve this purpose in two different compilation environments.
86: 
87: class EigenCudaStreamDevice : public ::Eigen::StreamInterface {
88:  public:
89:   EigenCudaStreamDevice()
90:       : scratch_(nullptr), semaphore_(nullptr), context_(nullptr) {
91:     Eigen::initializeDeviceProp();
92:   }
93:   ~EigenCudaStreamDevice() override {}
94:   void Reinitialize(OpKernelContext* context, const cudaStream_t* cuda_stream,
95:                     TfGpuId tf_gpu_id, ::tensorflow::Allocator* alloc,
96:                     char* scratch) {
97:     if (LogMemory::IsEnabled()) {
98:       operation_ = context-&gt;op_kernel().name() + &quot;/EigenAllocator&quot;;
99:       step_id_ = context-&gt;step_id();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_process_state.cc" line="163" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [process_state_] to null at line 161 implies that [process_state_ ] might be null.Dereferencing null pointer [process_state_]." web_identify="{&quot;identify&quot;:&quot;process_state_&quot;}" func_info="Allocator * GPUProcessState::GetCUDAHostAllocator ( int numa_node )" content="153:   return gpu_allocators_[tf_gpu_id.value()];
154: #else
155:   LOG(FATAL) &lt;&lt; &quot;GPUAllocator unavailable. Not compiled with --config=cuda.&quot;;
156:   return nullptr;
157: #endif  // GOOGLE_CUDA
158: }
159: 
160: Allocator* GPUProcessState::GetCUDAHostAllocator(int numa_node) {
161:   CHECK(process_state_);
162:   if (!HasGPUDevice() ||
163:       !process_state_-&gt;ProcessState::FLAGS_brain_mem_reg_cuda_dma) {
164:     return process_state_-&gt;GetCPUAllocator(numa_node);
165:   }
166:   CHECK_GE(numa_node, 0);
167:   {
168:     // Here we optimize the most common use case where cuda_host_allocators_
169:     // and cuda_al_ have already been populated and since we&apos;re only reading
170:     // these vectors, we can get by with a shared lock. In the slower case,
171:     // we take a unique lock and populate these vectors.
172:     tf_shared_lock lock(mu_);
173: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_stream_util.cc" line="52" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph] to null at line 36 implies that [graph ] might be null.Dereferencing null pointer [graph]." web_identify="{&quot;identify&quot;:&quot;graph&quot;}" func_info="Status gpu_stream_util::AssignStreams ( const Graph * graph , const AssignStreamsOpts &amp; opts , std :: unordered_map &lt; int , int &gt; * node_to_stream_id )" content="42:   if ((opts.max_streams &lt; 1) || (opts.send_stream &gt;= opts.max_streams) ||
43:       (opts.recv_stream &gt;= opts.max_streams) ||
44:       (opts.const_stream &gt;= opts.max_streams) ||
45:       (opts.compute_stream &gt;= opts.max_streams)) {
46:     status.Update(errors::InvalidArgument(&quot;Bad graph argument supplied.&quot;));
47:   }
48:   TF_RETURN_IF_ERROR(status);
49: 
50:   // Topologically sort the nodes.
51:   std::vector&lt;Node*&gt; order;
52:   GetReversePostOrder(*graph, &amp;order);
53:   if (VLOG_IS_ON(2)) {
54:     for (Node* n : order) {
55:       const int node_id = n-&gt;id();
56:       VLOG(2) &lt;&lt; &quot;Node &quot; &lt;&lt; node_id &lt;&lt; &quot; &quot; &lt;&lt; n-&gt;type_string() &lt;&lt; &quot; &quot;
57:               &lt;&lt; n-&gt;name() &lt;&lt; &quot; &quot; &lt;&lt; n-&gt;in_edges().size() &lt;&lt; &quot; inputs&quot;;
58:       for (const Edge* e : n-&gt;in_edges()) {
59:         VLOG(2) &lt;&lt; &quot;  Edge from &quot; &lt;&lt; e-&gt;src()-&gt;id() &lt;&lt; &quot;  &quot; &lt;&lt; e-&gt;src()-&gt;name()
60:                 &lt;&lt; &quot; fanout &quot; &lt;&lt; e-&gt;src()-&gt;out_edges().size();
61:       }
62:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_stream_util.cc" line="87" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [node_to_stream_id] to null at line 38 implies that [node_to_stream_id ] might be null.Dereferencing null pointer [node_to_stream_id]." web_identify="{&quot;identify&quot;:&quot;node_to_stream_id&quot;}" func_info="Status gpu_stream_util::AssignStreams ( const Graph * graph , const AssignStreamsOpts &amp; opts , std :: unordered_map &lt; int , int &gt; * node_to_stream_id )" content="77:   for (Node* n : order) {
78:     VLOG(3) &lt;&lt; &quot;Inspecting node &quot; &lt;&lt; n-&gt;DebugString();
79:     const int node_id = n-&gt;id();
80:     const string&amp; op = n-&gt;type_string();
81: 
82:     // Determine a suitable stream to use.
83:     int stream_id = highest_stream_id + 1;
84:     for (const Edge* e : n-&gt;in_edges()) {
85:       const size_t fanout = e-&gt;src()-&gt;out_edges().size();
86:       if (fanout == 1) {
87:         stream_id = (*node_to_stream_id)[e-&gt;src()-&gt;id()];
88:         break;
89:       }
90:     }
91:     // Override stream for specific op types.
92:     if (op == &quot;_Send&quot;) {
93:       if (opts.send_stream &gt;= 0) stream_id = opts.send_stream;
94:     } else if (op == &quot;_Recv&quot;) {
95:       if (opts.recv_stream &gt;= 0) stream_id = opts.recv_stream;
96:     } else if (op == &quot;Const&quot;) {
97:       if (opts.const_stream &gt;= 0) stream_id = opts.const_stream;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/gpu/gpu_util.cc" line="371" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor] to null at line 369 implies that [tensor ] might be null.Dereferencing null pointer [tensor]." web_identify="{&quot;identify&quot;:&quot;tensor&quot;}" func_info="string GPUUtil::MemoryDebugString ( const Device * device , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * tensor )" content="361:       !dev_info-&gt;stream-&gt;ok()) {
362:     return errors::Internal(&quot;GPU sync failed&quot;);
363:   }
364:   return Status::OK();
365: }
366: 
367: string GPUUtil::MemoryDebugString(const Device* device, Tensor* tensor) {
368:   string ret;
369:   CHECK(tensor);
370:   const int64 num_bytes = std::min&lt;int64&gt;(
371:       FLAGS_brain_gpu_util_debug_string_maxlen, tensor-&gt;TotalBytes());
372:   void* ptr = (num_bytes &gt; 0) ? GetBase(tensor) : nullptr;
373:   strings::Appendf(&amp;ret, &quot;%p:&quot;, ptr);
374:   if (num_bytes &gt; 0) {
375:     auto* dev_info = device-&gt;tensorflow_gpu_device_info();
376:     if (!dev_info) {
377:       strings::StrAppend(
378:           &amp;ret, PrintMemory(reinterpret_cast&lt;const char*&gt;(ptr), num_bytes));
379:     } else {
380:       string buf;
381:       buf.resize(num_bytes);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/graph_execution_state.cc" line="713" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rewrite_metadata_] to null at line 712 implies that [rewrite_metadata_ ] might be null.Dereferencing null pointer [rewrite_metadata_]." web_identify="{&quot;identify&quot;:&quot;rewrite_metadata_&quot;}" func_info="Status GraphExecutionState::BuildGraph ( const BuildGraphOptions &amp; options , std::unique_ptr &lt; ClientGraph &gt; * out )" content="703:   subgraph::RewriteGraphMetadata rewrite_metadata;
704:   if (session_options_ == nullptr ||
705:       !session_options_-&gt;config.graph_options().place_pruned_graph()) {
706:     TF_RETURN_IF_ERROR(
707:         PruneGraph(options, optimized_graph.get(), &amp;rewrite_metadata));
708:   } else {
709:     // This GraphExecutionState represents a graph that was
710:     // pruned when this was constructed, so we copy the metadata from
711:     // a member variable.
712:     CHECK(rewrite_metadata_);
713:     rewrite_metadata = *rewrite_metadata_;
714:   }
715: 
716:   CHECK_EQ(options.callable_options.feed_size(),
717:            rewrite_metadata.feed_types.size());
718:   CHECK_EQ(options.callable_options.fetch_size(),
719:            rewrite_metadata.fetch_types.size());
720: 
721:   // TODO(andydavis): Clarify optimization pass requirements around CostModel.
722:   GraphOptimizationPassOptions optimization_options;
723:   optimization_options.session_options = session_options_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/lower_if_op.cc" line="206" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [fdef] to null at line 199 implies that [fdef ] might be null.Dereferencing null pointer [fdef]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;fdef&quot;}" func_info="Status InlineCallInGraph ( Node * n , Graph * g )" content="196: Status InlineCallInGraph(Node* n, Graph* g) {
197:   const auto&amp; lib = g-&gt;flib_def();
198:   const FunctionDef* fdef = lib.Find(n-&gt;type_string());
199:   CHECK(fdef != nullptr);
200:   FunctionBody* fbody;
201:   TF_RETURN_IF_ERROR(
202:       FunctionDefToBodyHelper(*fdef, n-&gt;attrs(), &amp;lib,
203:                               [&amp;lib](const string&amp; op, const OpDef** sig) {
204:                                 return lib.LookUpOpDef(op, sig);
205:                               },
206:                               &amp;fbody));
207:   // TODO(jpienaar): Improve this interface to make the need to delete it
208:   // explicit.
209:   InlineFunctionBody(g-&gt;flib_def(), g, n, fbody, false);
210:   delete fbody;
211:   return Status::OK();
212: }
213: 
214: Status CondBuilder::BuildLoweredIfOutput() {
215:   // Build the identity node output.
216:   NodeBuilder ib(name_, &quot;IdentityN&quot;);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/lower_if_op.cc" line="98" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CondBuilder::control_predecessor_,lowered_if_output_,pivot_f_,pivot_t_,then_call_node_,else_call_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CondBuilder::control_predecessor_,lowered_if_output_,pivot_f_,pivot_t_,then_call_node_,else_call_node_,&quot;}" func_info="tensorflow::" content="88:   Node* pivot_t_;
89:   Node* then_call_node_;
90:   Node* else_call_node_;
91:   Graph* graph_;
92:   string name_;
93: 
94:   NodeBuilder then_call_builder_;
95:   NodeBuilder else_call_builder_;
96: };
97: 
98: CondBuilder::CondBuilder(Node* if_op, const string&amp; then_fn_name,
99:                          const string&amp; else_fn_name, Graph* graph)
100:     : if_op_(if_op),
101:       graph_(graph),
102:       name_(if_op-&gt;name()),
103:       then_call_builder_(NewName(&quot;then&quot;), then_fn_name, graph-&gt;op_registry()),
104:       else_call_builder_(NewName(&quot;else&quot;), else_fn_name, graph-&gt;op_registry()) {
105:   TF_CHECK_OK(if_op_-&gt;input_node(0, &amp;pred_));
106: }
107: 
108: Status CondBuilder::CreatePivotNodes() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/placer_test.cc" line="231" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [search] may be invalid here." web_identify="{&quot;identify&quot;:&quot;search&quot;}" func_info="Node * PlacerTest::GetNodeByName ( const Graph &amp; graph , const string &amp; name )" content="221:   }
222: 
223:   Status Place(Graph* graph) { return Place(graph, &amp;devices_, nullptr); }
224: 
225:   // Returns the node in &quot;graph&quot; with the given name.
226:   //
227:   // REQUIRES: &quot;graph&quot; was produced by the most recent call to BuildGraph.
228:   Node* GetNodeByName(const Graph&amp; graph, const string&amp; name) {
229:     const auto search = nodes_by_name_.find(name);
230:     CHECK(search != nodes_by_name_.end()) &lt;&lt; &quot;Unknown node name: &quot; &lt;&lt; name;
231:     return graph.FindNodeId(search-&gt;second);
232:   }
233: 
234:  protected:
235:   std::vector&lt;std::unique_ptr&lt;Device&gt;&gt; local_devices_;
236:   DeviceSet devices_;
237:   Placer::NodeNameToIdMap nodes_by_name_;
238: 
239:   Status ReferenceTestHelper(const string&amp; variable_op_type,
240:                              const string&amp; assign_op_type,
241:                              const DeviceType&amp; expected_device_type);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/ring_reducer.cc" line="139" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_mgr_] to null at line 138 implies that [dev_mgr_ ] might be null.Dereferencing null pointer [dev_mgr_]." web_identify="{&quot;identify&quot;:&quot;dev_mgr_&quot;}" func_info="void RingReducer::Run ( StatusCallback done )" content="129:       strings::StrAppend(&amp;buf, &quot;\nsubdiv &quot;, sd, &quot; perm: &quot;);
130:       for (auto x : col_params_.instance.impl_details.subdiv_permutations[sd]) {
131:         strings::StrAppend(&amp;buf, x, &quot;, &quot;);
132:       }
133:     }
134:     VLOG(1) &lt;&lt; &quot;RingReducer::Run for device &quot; &lt;&lt; device_name_
135:             &lt;&lt; &quot; default_rank &quot; &lt;&lt; col_params_.default_rank &lt;&lt; &quot;\n&quot;
136:             &lt;&lt; buf;
137:   }
138:   CHECK(dev_mgr_);
139:   Status status = dev_mgr_-&gt;LookupDevice(
140:       col_params_.instance.device_names[col_params_.default_rank], &amp;device_);
141:   if (!status.ok()) {
142:     LOG(ERROR) &lt;&lt; &quot;Failed to find device &quot;
143:                &lt;&lt; col_params_.instance.device_names[col_params_.default_rank];
144:     for (auto d : dev_mgr_-&gt;ListDevices()) {
145:       LOG(ERROR) &lt;&lt; &quot;Available device &quot; &lt;&lt; d-&gt;name();
146:     }
147:     done_(status);
148:     return;
149:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/ring_reducer_test.cc" line="136" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RingReducerTest::col_exec_,rma_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RingReducerTest::col_exec_,rma_,&quot;}" func_info="RingReducerTest" content="126:                   .Input(FakeInput(dtype))
127:                   .Input(FakeInput(dtype))
128:                   .Finalize(&amp;node_def));
129:   return GetKernel(node_def, device_type, device);
130: }
131: 
132: static int64 kStepId = 123;
133: 
134: class RingReducerTest : public ::testing::Test {
135:  protected:
136:   RingReducerTest() : device_type_(DEVICE_CPU) {}
137: 
138:   void SetUp() override {
139: #if GOOGLE_CUDA
140:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
141:     CHECK(device_factory);
142:     SessionOptions options;
143:     Status s = device_factory-&gt;CreateDevices(
144:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
145:     CHECK(s.ok());
146: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/ring_reducer_test.cc" line="143" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [device_factory] to null at line 141 implies that [device_factory ] might be null.Dereferencing null pointer [device_factory]." web_identify="{&quot;identify&quot;:&quot;device_factory&quot;}" func_info="void RingReducerTest::SetUp ( )" content="133: 
134: class RingReducerTest : public ::testing::Test {
135:  protected:
136:   RingReducerTest() : device_type_(DEVICE_CPU) {}
137: 
138:   void SetUp() override {
139: #if GOOGLE_CUDA
140:     auto device_factory = DeviceFactory::GetFactory(&quot;GPU&quot;);
141:     CHECK(device_factory);
142:     SessionOptions options;
143:     Status s = device_factory-&gt;CreateDevices(
144:         options, &quot;/job:worker/replica:0/task:0&quot;, &amp;gpu_devices_);
145:     CHECK(s.ok());
146: #endif
147:   }
148: 
149:   ~RingReducerTest() override {
150:     stop_ = true;
151:     for (auto i : instances_) {
152:       delete i;
153:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/ring_reducer_test.cc" line="323" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 322 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="&gt; void RingReducerTest::RunTest ( DataType dtype , const DeviceType &amp; device_type , int num_workers , int num_devices , int num_subdivs , int tensor_len , int fail_after )" content="313:         CHECK(inst);
314:         Tensor actual(dtype, TensorShape({tensor_len}));
315:         if (device_type_ == DEVICE_CPU) {
316:           CHECK(actual.CopyFrom(*inst, inst-&gt;shape()));
317:           VLOG(1) &lt;&lt; &quot;actual &quot; &lt;&lt; actual.SummarizeValue(100);
318:         } else if (device_type_ == DEVICE_GPU) {
319:           Notification note;
320:           Device* dev = instances_[di]-&gt;device_;
321:           auto* dev_info = dev-&gt;tensorflow_gpu_device_info();
322:           CHECK(dev_info);
323:           dev_info-&gt;default_context-&gt;CopyDeviceTensorToCPU(
324:               inst, &quot;&quot; /*tensor_name*/, dev, &amp;actual, [&amp;note](const Status&amp; s) {
325:                 CHECK(s.ok());
326:                 note.Notify();
327:               });
328:           note.WaitForNotification();
329:         }
330: 
331:         for (int i = 0; i &lt; tensor_len; ++i) {
332:           switch (dtype) {
333:             case DT_FLOAT:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/ring_reducer_test.cc" line="430" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dev_info] to null at line 428 implies that [dev_info ] might be null.Dereferencing null pointer [dev_info]." web_identify="{&quot;identify&quot;:&quot;dev_info&quot;}" func_info="void DeviceInstance::InitTensor ( DataType dtype , const TensorShape &amp; shape , const std :: function &lt; void ( Tensor * ) &gt; &amp; init_f )" content="420:       tensor_ =
421:           Tensor(device_-&gt;GetAllocator(AllocatorAttributes()), dtype, shape);
422:       if (device_type_ == DEVICE_CPU) {
423:         init_f(&amp;tensor_);
424:       } else if (device_type_ == DEVICE_GPU) {
425:         Tensor cpu_tensor(dtype, shape);
426:         init_f(&amp;cpu_tensor);
427:         auto* dev_info = device_-&gt;tensorflow_gpu_device_info();
428:         CHECK(dev_info);
429:         Notification note;
430:         dev_info-&gt;default_context-&gt;CopyCPUTensorToDevice(
431:             &amp;cpu_tensor, device_, &amp;tensor_, [&amp;note](const Status&amp; s) {
432:               CHECK(s.ok());
433:               note.Notify();
434:             });
435:         note.WaitForNotification();
436:       } else {
437:         LOG(FATAL) &lt;&lt; &quot;Unsupported device_type &quot; &lt;&lt; device_type_;
438:       }
439:     }
440: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/common_runtime/scoped_allocator.cc" line="53" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [tbuf_] suggests that it may be null, but it has already been dereferenced at line 43." web_identify="{&quot;identify&quot;:&quot;tbuf_&quot;}" func_info="ScopedAllocator::~ tensorflow::ScopedAllocator ( )" content="43:           &lt;&lt; static_cast&lt;void*&gt;(tbuf_-&gt;data());
44:   // In the absence of incomplete graph execution situations
45:   // (interruption by error status or control flow branch crossing
46:   // ScopedAllocation region) we expect expected_call_count_ == 0 at
47:   // exit.
48:   if (VLOG_IS_ON(1)) {
49:     if (expected_call_count_ &gt; 0)
50:       VLOG(1) &lt;&lt; &quot;expected_call_count_ = &quot; &lt;&lt; expected_call_count_
51:               &lt;&lt; &quot; at deallocation&quot;;
52:   }
53:   if (tbuf_) tbuf_-&gt;Unref();
54: }
55: 
56: void* ScopedAllocator::AllocateRaw(int32 field_index, size_t num_bytes) {
57:   VLOG(1) &lt;&lt; &quot;ScopedAllocator index &quot; &lt;&lt; id_ &lt;&lt; &quot; AllocateRaw &quot;
58:           &lt;&lt; &quot;field &quot; &lt;&lt; field_index &lt;&lt; &quot; num_bytes &quot; &lt;&lt; num_bytes;
59:   mutex_lock l(mu_);
60:   if (expected_call_count_ &lt;= 0) {
61:     LOG(ERROR) &lt;&lt; &quot;Scoped allocator &quot; &lt;&lt; name_
62:                &lt;&lt; &quot; could not satisfy request for &quot; &lt;&lt; num_bytes
63:                &lt;&lt; &quot; bytes, expected uses exhausted. &quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/debug/debug_io_utils.cc" line="444" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [callback] to null at line 443 implies that [callback ] might be null.Dereferencing null pointer [callback]." web_identify="{&quot;identify&quot;:&quot;callback&quot;}" func_info="Status DebugIO::PublishDebugTensor ( const DebugNodeKey &amp; debug_node_key , const Tensor &amp; tensor , const long wall_time_us , const gtl::ArraySlice &lt; string &gt; &amp; debug_urls , const bool gated_grpc )" content="434:         fail_statuses.push_back(s);
435:       }
436: #else
437:       GRPC_OSS_WINDOWS_UNIMPLEMENTED_ERROR;
438: #endif
439:     } else if (str_util::Lowercase(url).find(kMemoryURLScheme) == 0) {
440:       const string dump_root_dir = url.substr(strlen(kMemoryURLScheme));
441:       auto* callback_registry = DebugCallbackRegistry::singleton();
442:       auto* callback = callback_registry-&gt;GetCallback(dump_root_dir);
443:       CHECK(callback) &lt;&lt; &quot;No callback registered for: &quot; &lt;&lt; dump_root_dir;
444:       (*callback)(debug_node_key, tensor);
445:     } else {
446:       return Status(error::UNAVAILABLE,
447:                     strings::StrCat(&quot;Invalid debug target URL: &quot;, url));
448:     }
449:   }
450: 
451:   if (num_failed_urls == 0) {
452:     return Status::OK();
453:   } else {
454:     string error_message = strings::StrCat(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/collective_param_resolver_distributed_test.cc" line="235" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cp_res] to null at line 234 implies that [cp_res ] might be null.Dereferencing null pointer [cp_res]." web_identify="{&quot;identify&quot;:&quot;cp_res&quot;}" func_info="void DeviceResDistTest::IssueRequest ( int num_workers , int num_devices , int idx )" content="225:     int di = idx % num_devices;
226:     string task_name = strings::StrCat(&quot;/job:worker/replica:0/task:&quot;, wi);
227:     string device_name = strings::StrCat(task_name, &quot;/device:CPU:&quot;, di);
228:     while (idx &gt;= cp_.size()) {
229:       status_.resize(idx + 1);
230:       cp_.resize(idx + 1);
231:     }
232:     CollectiveParams* cp = &amp;cp_[idx];
233:     CollectiveParamResolverDistributed* cp_res = cp_resolvers_[task_name];
234:     CHECK(cp_res);
235:     cp_res-&gt;CompleteParamsAsync(device_name, cp, &amp;cm_,
236:                                 [this, idx, device_count](const Status&amp; s) {
237:                                   status_[idx] = s;
238:                                   {
239:                                     mutex_lock l(mu_);
240:                                     ++num_done_;
241:                                     if (num_done_ == device_count) {
242:                                       done_.notify_all();
243:                                     }
244:                                   }
245:                                 });
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/collective_rma_distributed_test.cc" line="113" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [h] suggests that it may be null, but it has already been dereferenced at line 108." web_identify="{&quot;identify&quot;:&quot;h&quot;}" func_info="void FakeWorker::RecvBufAsync ( CallOptions * opts , const RecvBufRequest * request , RecvBufResponse * response , std :: function &lt; void ( const Status &amp; ) &gt; done )" content="103:             // Since this is not really RDMA into pre-allocated memory send the
104:             // bytes in the response.
105:             RecvBufRespExtra extra;
106:             int64 num_bytes = h-&gt;prod_value-&gt;TotalBytes();
107:             extra.set_tensor_content(string(
108:                 reinterpret_cast&lt;const char*&gt;(DMAHelper::base(h-&gt;prod_value)),
109:                 num_bytes));
110:             response-&gt;mutable_transport_options()-&gt;PackFrom(extra);
111:           }
112:           done(s);
113:           if (h) BufRendezvous::DoneWithHook(h);
114:         });
115:   }
116: 
117:  private:
118:   string name_;
119:   DeviceMgr* device_mgr_;
120:   DeviceResolverDistributed* device_resolver_;
121:   BufRendezvous buf_rendezvous_;
122: };
123: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/device_resolver_distributed.cc" line="102" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [worker] to null at line 101 implies that [worker ] might be null.Dereferencing null pointer [worker]." web_identify="{&quot;identify&quot;:&quot;worker&quot;}" func_info="void DeviceResolverDistributed::RefreshRemoteAttributes ( const string &amp; device , const string &amp; task , const std::function &lt; void ( const Status &amp; ) &gt; &amp; done )" content="92:     done(Status::OK());
93:   }
94: }
95: 
96: void DeviceResolverDistributed::RefreshRemoteAttributes(
97:     const string&amp; device, const string&amp; task, const StatusCallback&amp; done) {
98:   GetStatusRequest* req = new GetStatusRequest;
99:   GetStatusResponse* resp = new GetStatusResponse;
100:   WorkerInterface* worker = worker_cache_-&gt;CreateWorker(task);
101:   CHECK(worker) &lt;&lt; &quot;Failed to get worker for &quot; &lt;&lt; task;
102:   worker-&gt;GetStatusAsync(
103:       req, resp, [this, device, task, req, resp, worker, done](Status s) {
104:         if (s.ok()) {
105:           mutex_lock l(mu_);
106:           for (const DeviceAttributes&amp; da : resp-&gt;device_attributes()) {
107:             attr_table_[da.name()] = da;
108:           }
109:         }
110:         done(s);
111:         delete req;
112:         delete resp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/master.cc" line="173" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [worker_cache] to null at line 156 implies that [worker_cache ] might be null.Dereferencing null pointer [worker_cache]." web_identify="{&quot;identify&quot;:&quot;worker_cache&quot;}" func_info="explicit DeviceFinder::DeviceFinder ( const protobuf :: RepeatedPtrField &lt; string &gt; &amp; device_filters , MasterEnv * env , WorkerCacheInterface * worker_cache ) : env_ ( env ) , worker_cache_ ( worker_cache )" content="163:       }
164:     };
165:     for (const string&amp; filter : device_filters) {
166:       process_filter(filter);
167:     }
168:     // Enumerates all known workers&apos; target. A target name is a
169:     // prefix of a device name. E.g., /job:mnist/replica:0/task:10.
170:     CHECK_GT(env_-&gt;local_devices.size(), 0) &lt;&lt; &quot;No local devices provided.&quot;;
171:     const string&amp; local_device_name = env_-&gt;local_devices[0]-&gt;name();
172:     std::vector&lt;string&gt; workers;
173:     worker_cache-&gt;ListWorkers(&amp;workers);
174:     if (filters_.empty()) {
175:       std::swap(workers, targets_);
176:     } else {
177:       for (const string&amp; name : workers) {
178:         if (MatchFilters(name) ||
179:             DeviceNameUtils::IsSameAddressSpace(name, local_device_name)) {
180:           targets_.push_back(name);
181:         }
182:       }
183:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/master_session.cc" line="1384" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [execution_state_] to null at line 1382 implies that [execution_state_ ] might be null.Dereferencing null pointer [execution_state_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;execution_state_&quot;}" func_info="Status MasterSession::Extend ( const ExtendSessionRequest * req , ExtendSessionResponse * resp )" content="1374:     }
1375: 
1376:     if (graph_version_ != req-&gt;current_graph_version()) {
1377:       return errors::Aborted(&quot;Current version is &quot;, graph_version_,
1378:                              &quot; but caller expected &quot;,
1379:                              req-&gt;current_graph_version(), &quot;.&quot;);
1380:     }
1381: 
1382:     CHECK(execution_state_);
1383:     TF_RETURN_IF_ERROR(
1384:         execution_state_-&gt;Extend(req-&gt;graph_def(), &amp;extended_execution_state));
1385: 
1386:     CHECK(extended_execution_state);
1387:     // The old execution state will be released outside the lock.
1388:     execution_state_.swap(extended_execution_state);
1389:     ++graph_version_;
1390:     resp-&gt;set_new_graph_version(graph_version_);
1391:   }
1392:   return Status::OK();
1393: }
1394: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/master_session.cc" line="2017" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;RunState::collective_graph_key,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;RunState::collective_graph_key,&quot;}" func_info="tensorflow" content="2007: void MasterSession::GarbageCollect() {
2008:   {
2009:     mutex_lock l(mu_);
2010:     closed_ = true;
2011:     garbage_collected_ = true;
2012:   }
2013:   cancellation_manager_.StartCancel();
2014:   Unref();
2015: }
2016: 
2017: MasterSession::RunState::RunState(const std::vector&lt;string&gt;&amp; input_names,
2018:                                   const std::vector&lt;string&gt;&amp; output_names,
2019:                                   ReffedClientGraph* rcg, const uint64 step_id,
2020:                                   const int64 count)
2021:     : rcg(rcg), step_id(step_id), count(count) {
2022:   // Initially all the feeds and fetches are pending.
2023:   for (auto&amp; name : input_names) {
2024:     pending_inputs[name] = false;
2025:   }
2026:   for (auto&amp; name : output_names) {
2027:     pending_outputs[name] = false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/master_test.cc" line="117" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here. The error is in macros." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="Status MasterTest::RunStep ( const string &amp; handle , const std :: vector &lt; std :: pair &lt; string , const Tensor * &gt; &gt; &amp; feed , const std :: map &lt; string , Tensor * &gt; &amp; fetch )" content="107:     for (const auto&amp; p : fetch) {
108:       const string&amp; fetch_name = p.first;
109:       req.add_fetch(fetch_name);
110:     }
111:     RunStepResponse resp;
112:     const Status s = FromGrpcStatus(master_-&gt;RunStep(&amp;ctx, req, &amp;resp));
113:     if (s.ok()) {
114:       for (const auto&amp; fetch_resp : resp.tensor()) {
115:         auto it = fetch.find(fetch_resp.name());
116:         CHECK(it != fetch.end());
117:         CHECK(it-&gt;second-&gt;FromProto(fetch_resp.tensor()));
118:       }
119:     }
120:     return s;
121:   }
122: 
123:   Status CloseSession(const string&amp; handle) {
124:     ::grpc::ClientContext ctx;
125:     CloseSessionRequest req;
126:     req.set_session_handle(handle);
127:     CloseSessionResponse resp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/rpc/grpc_channel.cc" line="181" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cache] to null at line 179 implies that [cache ] might be null.Dereferencing null pointer [cache]." web_identify="{&quot;identify&quot;:&quot;cache&quot;}" func_info="GRPC_CUSTOM_STRING MultiGrpcChannelCache::TranslateTask ( const string &amp; target )" content="171:         string r = c-&gt;TranslateTask(target);
172:         if (!r.empty()) {
173:           target_caches_.insert({target, c});
174:           cache = c;
175:           break;
176:         }
177:       }
178:     }
179:     CHECK(cache) &lt;&lt; &quot;Could not find GrpcChannelCache holding channel for &quot;
180:                  &lt;&lt; target;
181:     return cache-&gt;TranslateTask(target);
182:   }
183: 
184:  protected:
185:   SharedGrpcChannelPtr FindChannelOnce(const string&amp; target) override {
186:     for (GrpcChannelCache* cache : caches_) {
187:       SharedGrpcChannelPtr ch(cache-&gt;FindWorkerChannel(target));
188:       if (ch) {
189:         mutex_lock l(mu_);
190:         target_caches_.insert({target, cache});
191:         return ch;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/rpc/grpc_util.h" line="36" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GrpcByteSource::space_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GrpcByteSource::space_,&quot;}" func_info="tensorflow::GrpcByteSource" content="26: #include &quot;map/base/mlp/tf/tensorflow/core/lib/strings/stringprintf.h&quot;
27: #include &quot;map/base/mlp/tf/tensorflow/core/platform/mutex.h&quot;
28: #include &quot;map/base/mlp/tf/tensorflow/core/platform/protobuf.h&quot;
29: 
30: namespace tensorflow {
31: 
32: // Thin wrapper around ::grpc::ProtoBufferReader to give TensorResponse an
33: // efficient byte reader from which to decode a RecvTensorResponse.
34: class GrpcByteSource : public TensorResponse::Source {
35:  public:
36:   explicit GrpcByteSource(::grpc::ByteBuffer* buffer) : buffer_(buffer) {}
37:   ~GrpcByteSource() override { DeleteStream(); }
38: 
39:   typedef ::grpc::ProtoBufferReader Reader;
40: 
41:   protobuf::io::ZeroCopyInputStream* contents() override {
42:     DeleteStream();
43:     stream_ = new (&amp;space_) Reader(buffer_);
44:     return stream_;
45:   }
46: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc" line="191" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [callback_tag] to null at line 190 implies that [callback_tag ] might be null.Dereferencing null pointer [callback_tag]." web_identify="{&quot;identify&quot;:&quot;callback_tag&quot;}" func_info="void GrpcWorkerServiceThread::HandleRPCsLoop ( )" content="181:         ENQUEUE_REQUEST(GetStepSequence, true);
182:       }
183: 
184:       void* tag;
185:       bool ok;
186: 
187:       while (cq_-&gt;Next(&amp;tag, &amp;ok)) {
188:         UntypedCall&lt;GrpcWorkerServiceThread&gt;::Tag* callback_tag =
189:             static_cast&lt;UntypedCall&lt;GrpcWorkerServiceThread&gt;::Tag*&gt;(tag);
190:         CHECK(callback_tag);
191:         callback_tag-&gt;OnCompleted(this, ok);
192:       }
193:     }
194: 
195:    private:
196:     void Schedule(std::function&lt;void()&gt; f) {
197:       worker_-&gt;env()-&gt;compute_pool-&gt;Schedule(std::move(f));
198:     }
199: 
200:     // The following section contains one request handler method per
201:     // RPC. The `FooHandler` method is called (indirectly) by
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc" line="494" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [send_dev_context] to null at line 481 implies that [send_dev_context ] might be null.Dereferencing null pointer [send_dev_context]." web_identify="{&quot;identify&quot;:&quot;send_dev_context&quot;}" func_info="void GrpcWorker::GrpcRecvTensorAsync ( CallOptions * opts , const RecvTensorRequest * request ,::grpc::ByteBuffer * response , StatusCallback done )" content="484:               // &quot;val&quot; is on an accelerator device. Uses the device_context to
485:               // fill the copy on host.
486:               StatusCallback copy_ready = [response, done, copy,
487:                                            is_dead](const Status&amp; s) {
488:                 // The value is now ready to be returned on the wire.
489:                 grpc::EncodeTensorToByteBuffer(is_dead, *copy, response);
490:                 done(s);
491:                 delete copy;
492:               };
493: 
494:               send_dev_context-&gt;CopyDeviceTensorToCPU(
495:                   &amp;val, request-&gt;rendezvous_key(), src_dev, copy, copy_ready);
496:             } else {
497:               grpc::EncodeTensorToByteBuffer(is_dead, val, response);
498:               done(Status::OK());
499:             }
500:           }
501:         } else {
502:           //  !s.ok()
503:           done(status);
504:         }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/tensor_coding_test.cc" line="51" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;StringSource::space_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;StringSource::space_,&quot;}" func_info="tensorflow::StringSource" content="41:   Allocator* GetAllocator(AllocatorAttributes attr) override {
42:     return cpu_allocator();
43:   }
44: 
45:  private:
46:   DeviceAttributes attr_;
47: };
48: 
49: class StringSource : public TensorResponse::Source {
50:  public:
51:   explicit StringSource(const string* s, int block_size)
52:       : s_(s), stream_(nullptr), block_size_(block_size) {}
53:   ~StringSource() override { DeleteStream(); }
54: 
55:   protobuf::io::ZeroCopyInputStream* contents() override {
56:     DeleteStream();
57:     stream_ = new (&amp;space_)
58:         protobuf::io::ArrayInputStream(s_-&gt;data(), s_-&gt;size(), block_size_);
59:     return stream_;
60:   }
61: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/distributed_runtime/worker_cache_partial.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [rwi] to null at line 70 implies that [rwi ] might be null.Dereferencing null pointer [rwi]." web_identify="{&quot;identify&quot;:&quot;rwi&quot;}" func_info="Status WorkerCachePartial::RefreshDeviceStatus ( const string &amp; device_name )" content="67:   };
68:   std::unique_ptr&lt;WorkerInterface, decltype(deleter)&gt; rwi(CreateWorker(task),
69:                                                           deleter);
70:   if (s.ok() &amp;&amp; !rwi) {
71:     s = errors::Internal(&quot;RefreshDeviceStatus, unknown worker task: &quot;, task);
72:   }
73: 
74:   if (s.ok()) {
75:     GetStatusRequest req;
76:     GetStatusResponse resp;
77:     s = rwi-&gt;GetStatus(&amp;req, &amp;resp);
78:     if (s.ok()) {
79:       mutex_lock lock(mu_);
80:       for (auto&amp; dev_attr : resp.device_attributes()) {
81:         device_status_cache_[dev_attr.name()] = dev_attr;
82:       }
83:     }
84:   }
85:   return s;
86: }
87: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/graph/gradients.cc" line="277" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [iter] may be invalid here." web_identify="{&quot;identify&quot;:&quot;iter&quot;}" func_info="NodeOut SymbolicGradientBuilder::SumGradients ( const NodeOut &amp; src )" content="267:       }
268:     }
269:   }
270:   CHECK(!ready_.empty());
271: }
272: 
273: NodeOut SymbolicGradientBuilder::SumGradients(const NodeOut&amp; src) {
274:   const DataType dtype = src.dtype();
275:   auto iter = backprops_.find(src);
276:   CHECK(iter != backprops_.end());
277:   const auto&amp; grads = iter-&gt;second;
278:   if (grads.empty()) {
279:     // Nothing propagated back. The best we can come up is zeros.
280:     Node* zero_like = AddZerosLike(graph_, src);
281:     return {zero_like, 0};
282:   }
283:   if (grads.size() == 1) {
284:     // Just one backprop edge.
285:     return grads[0];
286:   }
287:   // Otherwise, adds backprop-ed gradients.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/graph/graph_constructor.cc" line="69" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Options::uniquify_names,uniquify_prefix,skip_mapped_nodes,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Options::uniquify_names,uniquify_prefix,skip_mapped_nodes,&quot;}" func_info="GraphConstructor::Options" content="59:       .One(allow_internal_ops ? Scanner::LETTER_DIGIT_DOT_UNDERSCORE
60:                               : Scanner::LETTER_DIGIT_DOT)
61:       .Any(Scanner::LETTER_DIGIT_DASH_DOT_SLASH_UNDERSCORE)
62:       .Eos()
63:       .GetResult();
64: }
65: 
66: class GraphConstructor {
67:  public:
68:   struct Options {
69:     Options(const GraphConstructorOptions&amp; in)  // NOLINT(runtime/explicit)
70:         : allow_internal_ops(in.allow_internal_ops),
71:           expect_device_spec(in.expect_device_spec),
72:           importing(false),
73:           validate_colocation_constraints(false) {}
74:     Options(const ImportGraphDefOptions&amp; in)  // NOLINT(runtime/explicit)
75:         : allow_internal_ops(false),
76:           expect_device_spec(false),
77:           prefix(in.prefix.empty() || str_util::EndsWith(in.prefix, &quot;/&quot;)
78:                      ? in.prefix
79:                      : in.prefix + &quot;/&quot;),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/graph/mkl_layout_pass.cc" line="4471" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options.partition_graphs] to null at line 4452 implies that [options.partition_graphs ] might be null.Dereferencing null pointer [options.partition_graphs]." web_identify="{&quot;identify&quot;:&quot;options.partition_graphs&quot;}" func_info="Status MklLayoutRewritePass::Run ( const GraphOptimizationPassOptions &amp; options )" content="4461:     g-&gt;reset(ng-&gt;release());
4462:   };
4463: 
4464:   if (kMklLayoutRewritePassGroup !=
4465:       OptimizationPassRegistry::POST_PARTITIONING) {
4466:     // For any pre-partitioning phase, a graph is stored in options.graph.
4467:     process_graph(options.graph);
4468:   } else {
4469:     // For post partitioning phase, graphs are stored in
4470:     // options.partition_graphs.
4471:     for (auto&amp; pg : *options.partition_graphs) {
4472:       process_graph(&amp;pg.second);
4473:     }
4474:   }
4475: 
4476:   return Status::OK();
4477: }
4478: #endif  // INTEL_MKL_ML
4479: }  // namespace tensorflow
4480: 
4481: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/graph/mkl_tfconversion_pass.cc" line="433" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options.partition_graphs] to null at line 415 implies that [options.partition_graphs ] might be null.Dereferencing null pointer [options.partition_graphs]." web_identify="{&quot;identify&quot;:&quot;options.partition_graphs&quot;}" func_info="Status MklToTfConversionPass::Run ( const GraphOptimizationPassOptions &amp; options )" content="423:     // Return the ownership of graph back
424:     g-&gt;reset(ng-&gt;release());
425:   };
426: 
427:   if (kMklTfConvPassGroup != OptimizationPassRegistry::POST_PARTITIONING) {
428:     // For any pre-partitioning phase, graph is stored in options.graph.
429:     process_graph(options.graph);
430:   } else {
431:     // For post partitioning phase, graphs are stored in
432:     // options.partition_graphs.
433:     for (auto&amp; pg : *options.partition_graphs) {
434:       process_graph(&amp;pg.second);
435:     }
436:   }
437: 
438:   return Status::OK();
439: }
440: 
441: }  // namespace tensorflow
442: 
443: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/costs/virtual_placer.cc" line="33" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cluster] to null at line 27 implies that [cluster ] might be null.Dereferencing null pointer [cluster]." web_identify="{&quot;identify&quot;:&quot;cluster&quot;}" func_info="VirtualPlacer::VirtualPlacer ( const Cluster * cluster )" content="23: namespace tensorflow {
24: namespace grappler {
25: 
26: VirtualPlacer::VirtualPlacer(const Cluster* cluster) {
27:   CHECK(cluster);
28: 
29:   // Default job name for canonical device name. Needs to be set before the
30:   // first call to to_lfqn_or_empty()
31:   default_job_name_lowercase_ = &quot;localhost&quot;;
32: 
33:   devices_ = cluster-&gt;GetDevices();
34:   lfqn_map_.reserve(devices_.size());
35:   for (const auto&amp; kv : devices_) {
36:     const auto lfqn = to_lfqn_or_empty(kv.first);
37:     if (lfqn.empty()) {
38:       LOG(ERROR) &lt;&lt; &quot;VirtualPlacer couldn&apos;t parse device name from cluster: &quot;
39:                  &lt;&lt; kv.first;
40:     } else {
41:       lfqn_map_[lfqn] = kv.first;
42:     }
43:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="119" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FirstReadyManager::node_state_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FirstReadyManager::node_state_,&quot;}" func_info="tensorflow::grappler" content="109: void LIFOManager::RemoveCurrNode() {
110:   // Make sure we have curr_pos_ ready to be removed.
111:   GetCurrNode();
112:   // Note curr_pos_ may not be pointing the last element if some nodes are
113:   // added.
114:   nodes_.erase(curr_pos_);
115: 
116:   curr_pos_ = nodes_.end();  // Reset curr_pos_.
117: }
118: 
119: FirstReadyManager::FirstReadyManager() : ReadyNodeManager() {
120:   std::make_heap(nodes_.begin(), nodes_.end());
121: }
122: 
123: void FirstReadyManager::Init(
124:     const std::unordered_map&lt;const NodeDef*, NodeState&gt;* node_state) {
125:   // Reset the node state since different instances of the scheduler can reuse
126:   // the same node_manager.
127:   node_state_ = node_state;
128:   nodes_.clear();
129:   waiting_queue_.clear();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="176" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CompositeNodeManager::node_state_,curr_node_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CompositeNodeManager::node_state_,curr_node_,&quot;}" func_info="tensorflow::grappler" content="166: void FirstReadyManager::DrainWaitingQueue() {
167:   for (const auto* node : waiting_queue_) {
168:     // push_heap in AddNode() and pop_heap in RemoveCurrNode() guarantees that
169:     // the first element is the node with minimum time_ready.
170:     nodes_.push_back(node);
171:     std::push_heap(nodes_.begin(), nodes_.end(), greater_);
172:   }
173:   waiting_queue_.clear();
174: }
175: 
176: CompositeNodeManager::CompositeNodeManager()
177:     : ReadyNodeManager(), send_manager_(), recv_manager_() {}
178: 
179: void CompositeNodeManager::Init(
180:     const std::unordered_map&lt;const NodeDef*, NodeState&gt;* node_state) {
181:   node_state_ = node_state;
182:   send_manager_.Init(node_state);
183:   recv_manager_.Init(node_state);
184:   curr_node_ = nullptr;
185: }
186: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/costs/virtual_scheduler.cc" line="393" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_node] to null at line 392 implies that [input_node ] might be null.Dereferencing null pointer [input_node]." web_identify="{&quot;identify&quot;:&quot;input_node&quot;}" func_info="Status VirtualScheduler::Init ( )" content="383:         inputs.push_back(input);
384:       }
385:     }
386:     for (const string&amp; input_node_name : inputs) {
387:       // Note that input_node_name may be in &lt;prefix&gt;&lt;node_name&gt;:&lt;port_num&gt;
388:       // format, where &lt;prefix&gt; (e.g., &quot;^&quot; for control dependency) and
389:       // &quot;:&lt;port_num&gt;&quot; may be omitted. NodeName() extracts only the node_name.
390:       const NodeDef* input_node = name_to_node[NodeName(input_node_name)];
391: 
392:       CHECK(input_node);
393:       const string in_device = DeviceName(input_node);
394:       const auto input_node_port_num = NodePosition(input_node_name);
395: 
396:       if (curr_node_device == in_device) {
397:         // Same device: connect input_node and curr_node directly.
398:         curr_node_state.inputs.push_back(
399:             std::make_pair(input_node, input_node_port_num));
400:         auto&amp; input_node_state = GetNodeStateOrCreateIt(input_node);
401:         input_node_state.outputs[input_node_port_num].push_back(curr_node);
402:       } else {
403:         RecvNodeDescriptor recv_node(input_node, input_node_port_num,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/grappler_item_builder.cc" line="496" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="std::unique_ptr &lt; GrapplerItem &gt; grappler::GrapplerItemFromMetaGraphDef ( const string &amp; id , const MetaGraphDef &amp; meta_graph , const ItemConfig &amp; cfg )" content="486:         if (signature_feed_nodes.count(node.name()) == 0) {
487:           new_item-&gt;feed.emplace_back(node.name(), fake_input);
488:         }
489:       } else if (cfg.feed_nodes.count(node.name()) &gt; 0) {
490:         // If specific feed nodes were given, only update their tensors.
491:         auto it = find_if(new_item-&gt;feed.begin(), new_item-&gt;feed.end(),
492:                           [&amp;node](std::pair&lt;string, Tensor&gt;&amp; f) {
493:                             return f.first == node.name();
494:                           });
495:         QCHECK(it != new_item-&gt;feed.end());
496:         it-&gt;second = fake_input;
497:       }
498: 
499:       // Set the shape of the node in the graph. This is needed for statically
500:       // inferring shapes and is a no-op when dynamically inferring shapes as
501:       // the Placeholder shape will match the shape passed from new_item-&gt;feed.
502:       *(node.mutable_attr()-&gt;at(&quot;shape&quot;).mutable_shape()) = shape_proto;
503:     } else if (IsConstant(node)) {
504:       auto it = asset_node_to_value.find(node.name());
505:       if (it != asset_node_to_value.end()) {
506:         auto iter = node.mutable_attr()-&gt;find(&quot;value&quot;);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/arithmetic_optimizer.cc" line="834" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [shapes_match] suggests that it may be null, but it has already been dereferenced at line 831." web_identify="{&quot;identify&quot;:&quot;shapes_match&quot;}" func_info="Status HoistCommonFactorOutOfAggregation::GetUniqueFactors ( const NodeDef * node , const string &amp; common_factor , const bool common_factor_is_denominator , bool * shapes_match , std :: vector &lt; string &gt; * unique_factors ) const" content="824:   // Unless the aggregation is Add, we have to make sure that all the y&apos;s
825:   // have the same shape since the other aggregation ops do not support
826:   // broadcasting.
827:   Status GetUniqueFactors(const NodeDef* node, const string&amp; common_factor,
828:                           const bool common_factor_is_denominator,
829:                           bool* shapes_match,
830:                           std::vector&lt;string&gt;* unique_factors) const {
831:     *shapes_match = true;
832:     unique_factors-&gt;reserve(node-&gt;input_size());
833: 
834:     for (int i = 0; i &lt; node-&gt;input_size() &amp;&amp; shapes_match; ++i) {
835:       const string&amp; input = node-&gt;input(i);
836:       if (IsControlInput(input)) {
837:         break;
838:       }
839:       NodeDef* inner_node;
840:       TF_RETURN_IF_ERROR(GetInputNode(input, &amp;inner_node));
841:       const int unique_factor_index =
842:           common_factor_is_denominator
843:               ? 0
844:               : (inner_node-&gt;input(0) == common_factor ? 1 : 0);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/auto_parallel.cc" line="179" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [dequeue_node] to null at line 162 implies that [dequeue_node ] might be null.Dereferencing null pointer [dequeue_node]." web_identify="{&quot;identify&quot;:&quot;dequeue_node&quot;}" func_info="Status AutoParallel::Initialize ( const GrapplerItem &amp; item )" content="169:   for (const auto&amp; variable : item.MainVariables()) {
170:     dont_replicate_nodes.insert(variable-&gt;name());
171:   }
172: 
173:   for (const auto&amp; init : item.init_ops) {
174:     dont_replicate_nodes.insert(NodeName(init));
175:   }
176: 
177:   // Don&apos;t replicate all input nodes, except the dequeue node.
178:   for (const auto&amp; input_node : input_nodes) {
179:     if (input_node-&gt;name() != dequeue_node-&gt;name()) {
180:       dont_replicate_nodes.insert(input_node-&gt;name());
181:     }
182:   }
183: 
184:   for (const auto&amp; node : train_nodes) {
185:     if (dont_replicate_nodes.find(node-&gt;name()) == dont_replicate_nodes.end()) {
186:       replica_nodes_.insert(node-&gt;name());
187:     }
188:   }
189:   LOG(INFO) &lt;&lt; &quot;Number of replica nodes: &quot; &lt;&lt; replica_nodes_.size();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/auto_parallel.h" line="29" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AutoParallel::item_,num_gpus_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AutoParallel::item_,num_gpus_,&quot;}" func_info="tensorflow::grappler::AutoParallel" content="19: #include &quot;map/base/mlp/tf/tensorflow/core/framework/variable.pb.h&quot;
20: #include &quot;map/base/mlp/tf/tensorflow/core/grappler/optimizers/graph_optimizer.h&quot;
21: #include &quot;map/base/mlp/tf/tensorflow/core/lib/core/status.h&quot;
22: 
23: namespace tensorflow {
24: namespace grappler {
25: 
26: // Automatically parallelize a graph by splitting in the batch dimension.
27: class AutoParallel : public GraphOptimizer {
28:  public:
29:   AutoParallel(int num_replicas) : num_replicas_(num_replicas) {
30:     CHECK(num_replicas_ &gt;= 2);
31:   }
32:   ~AutoParallel() override {}
33: 
34:   string name() const override { return &quot;autoparallel&quot;; };
35: 
36:   Status Optimize(Cluster* cluster, const GrapplerItem&amp; item,
37:                   GraphDef* output) override;
38: 
39:   void Feedback(Cluster* cluster, const GrapplerItem&amp; item,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/constant_folding.cc" line="178" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&quot;}" func_info="tensorflow::grappler" content="168:     }
169:   }
170:   if (update_node_map) {
171:     node_map-&gt;RemoveOutput(NodeName(old_input), node-&gt;name());
172:   }
173:   return removed_input;
174: }
175: 
176: }  // namespace
177: 
178: ConstantFolding::ConstantFolding(RewriterConfig::Toggle opt_level,
179:                                  DeviceBase* cpu_device)
180:     : opt_level_(opt_level), cpu_device_(cpu_device) {
181:   resource_mgr_.reset(new ResourceMgr());
182: }
183: 
184: ConstantFolding::ConstantFolding(DeviceBase* cpu_device)
185:     : ConstantFolding(RewriterConfig::ON, cpu_device) {}
186: 
187: // static
188: string ConstantFolding::AddControlDependency(const string&amp; input_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/constant_folding.cc" line="184" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ConstantFolding::graph_,has_fetch_,graph_modified_,graph_contains_assign_or_inplace_op_,&quot;}" func_info="tensorflow::grappler" content="174: }
175: 
176: }  // namespace
177: 
178: ConstantFolding::ConstantFolding(RewriterConfig::Toggle opt_level,
179:                                  DeviceBase* cpu_device)
180:     : opt_level_(opt_level), cpu_device_(cpu_device) {
181:   resource_mgr_.reset(new ResourceMgr());
182: }
183: 
184: ConstantFolding::ConstantFolding(DeviceBase* cpu_device)
185:     : ConstantFolding(RewriterConfig::ON, cpu_device) {}
186: 
187: // static
188: string ConstantFolding::AddControlDependency(const string&amp; input_name,
189:                                              GraphDef* graph,
190:                                              NodeMap* node_map) {
191:   if (IsControlInput(input_name)) {
192:     return input_name;
193:   }
194:   const NodeDef* node = node_map-&gt;GetNode(input_name);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/constant_folding.cc" line="2495" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [denom] to null at line 2494 implies that [denom ] might be null.Dereferencing null pointer [denom]." web_identify="{&quot;identify&quot;:&quot;denom&quot;}" func_info="bool ConstantFolding::ReduceDivToReciprocalMul ( GraphDef * optimized_graph , NodeDef * node )" content="2485: 
2486: bool ConstantFolding::ReduceDivToReciprocalMul(GraphDef* optimized_graph,
2487:                                                NodeDef* node) {
2488:   // Strength reduce floating point division by a constant Div(x, const) to
2489:   // multiplication by the reciprocal Mul(x, Reciprocal(const)). This in turn
2490:   // will be constant folded to Mul(x, 1.0/const).
2491:   if (node-&gt;input_size() &gt;= 2 &amp;&amp; (IsRealDiv(*node) || IsDiv(*node))) {
2492:     const string&amp; const_input = node-&gt;input(1);
2493:     const NodeDef* denom = node_map_-&gt;GetNode(const_input);
2494:     CHECK(denom != nullptr);
2495:     if (!IsReallyConstant(*denom)) {
2496:       return false;
2497:     }
2498:     if (node-&gt;attr().count(&quot;T&quot;) == 0) {
2499:       return false;
2500:     }
2501:     DataType type = node-&gt;attr().at(&quot;T&quot;).type();
2502:     if (IsDiv(*node) &amp;&amp;
2503:         !(DataTypeIsFloating(type) || DataTypeIsComplex(type))) {
2504:       return false;
2505:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/constant_folding.cc" line="2809" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input_node] to null at line 2808 implies that [input_node ] might be null.Dereferencing null pointer [input_node]." web_identify="{&quot;identify&quot;:&quot;input_node&quot;}" func_info="bool ConstantFolding::PartialAssocOpConstFolding ( GraphDef * optimized_graph , GraphProperties * properties , NodeDef * node )" content="2799:   const int num_non_control_inputs = NumNonControlInputs(*node);
2800:   if (IsAggregate(*node) &amp;&amp; IsCommutative(*node) &amp;&amp;
2801:       num_non_control_inputs &gt; 2) {
2802:     const int num_control_inputs = node-&gt;input_size() - num_non_control_inputs;
2803:     std::vector&lt;int&gt; const_inputs;
2804:     std::vector&lt;int&gt; nonconst_inputs;
2805:     for (int i = 0; i &lt; node-&gt;input_size(); ++i) {
2806:       const string&amp; input = node-&gt;input(i);
2807:       const NodeDef* input_node = node_map_-&gt;GetNode(NodeName(input));
2808:       CHECK(input_node != nullptr) &lt;&lt; input;
2809:       if (!IsControlInput(input) &amp;&amp; IsReallyConstant(*input_node)) {
2810:         const_inputs.push_back(i);
2811:       } else {
2812:         // Non-const and control inputs.
2813:         nonconst_inputs.push_back(i);
2814:       }
2815:     }
2816:     // Promote AccumulateNV2 with all constant inputs to AddN, since it is
2817:     // a fake node that cannot be constant folded by itself.
2818:     if (const_inputs.size() == num_non_control_inputs &amp;&amp;
2819:         node-&gt;op() == &quot;AccumulateNV2&quot;) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/dependency_optimizer.cc" line="85" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [input] to null at line 81 implies that [input ] might be null.Dereferencing null pointer [input]." web_identify="{&quot;identify&quot;:&quot;input&quot;}" func_info="bool DependencyOptimizer::SafeToRemoveIdentity ( const NodeDef &amp; node ) const" content="75:   }
76:   if (!fetch_nodes_known_) {
77:     // The output values of this node may be needed.
78:     return false;
79:   }
80:   const NodeDef* input = node_map_-&gt;GetNode(NodeName(node.input(0)));
81:   CHECK(input != nullptr) &lt;&lt; &quot;node = &quot; &lt;&lt; node.name()
82:                           &lt;&lt; &quot; input = &quot; &lt;&lt; node.input(0);
83:   // Don&apos;t remove Identity nodes corresponding to Variable reads or following
84:   // Recv.
85:   if (IsVariable(*input) || IsRecv(*input)) {
86:     return false;
87:   } else if (IsSwitch(*input)) {
88:     // Don&apos;t turn Identity nodes following Switch into NoOp or remove them
89:     // if it requires anchoring a control dependencies the Switch node, which
90:     // is not valid.
91:     if (str_util::StartsWith(node.name(), kConstantFoldingCtrl)) {
92:       // TODO(rmlarsen): Try to remove this artificial contraint.
93:       return false;
94:     }
95:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/dependency_optimizer.h" line="33" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DependencyOptimizer::fetch_nodes_known_,optimized_graph_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DependencyOptimizer::fetch_nodes_known_,optimized_graph_,&quot;}" func_info="tensorflow::grappler::DependencyOptimizer" content="23: 
24: namespace tensorflow {
25: namespace grappler {
26: 
27: // Optimize TF computations by removing control dependencies or re-arranging
28: // them to shorten the critical path for a model step or enable other
29: // optimizations, such as removing nodes that are effectively noops.
30: class DependencyOptimizer : public GraphOptimizer {
31:  public:
32:   DependencyOptimizer() {}
33:   explicit DependencyOptimizer(RewriterConfig::Toggle opt_level)
34:       : opt_level_(opt_level) {}
35:   ~DependencyOptimizer() override {}
36: 
37:   string name() const override { return &quot;dependency_optimizer&quot;; };
38: 
39:   Status Optimize(Cluster* cluster, const GrapplerItem&amp; item,
40:                   GraphDef* optimized_graph) override;
41: 
42:   void Feedback(Cluster* cluster, const GrapplerItem&amp; item,
43:                 const GraphDef&amp; optimized_graph, double result) override;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [node_to_copy] to null at line 73 implies that [node_to_copy ] might be null.Dereferencing null pointer [node_to_copy]." web_identify="{&quot;identify&quot;:&quot;node_to_copy&quot;}" func_info="NodeDef * grappler::AddCopyNode ( const GraphOptimizerContext &amp; ctx , const string &amp; name , const NodeDef * node_to_copy )" content="67:   properties-&gt;CopyFrom(output_properties[port]);
68:   return Status::OK();
69: }
70: 
71: NodeDef* AddCopyNode(const GraphOptimizerContext&amp; ctx, const string&amp; name,
72:                      const NodeDef* node_to_copy) {
73:   CHECK(node_to_copy != nullptr);
74:   CHECK(!ctx.node_map-&gt;NodeExists(name))
75:       &lt;&lt; &quot;Node &quot; &lt;&lt; name &lt;&lt; &quot; already exists in a graph&quot;;
76:   NodeDef* new_node = ctx.optimized_graph-&gt;add_node();
77:   *new_node = *node_to_copy;
78:   new_node-&gt;set_name(name);
79:   ctx.node_map-&gt;AddNode(name, new_node);
80:   return new_node;
81: }
82: 
83: NodeDef* AddEmptyNode(const GraphOptimizerContext&amp; ctx, const string&amp; name) {
84:   CHECK(!ctx.node_map-&gt;NodeExists(name))
85:       &lt;&lt; &quot;Node &quot; &lt;&lt; name &lt;&lt; &quot; already exists in a graph&quot;;
86:   NodeDef* new_node = ctx.optimized_graph-&gt;add_node();
87:   new_node-&gt;set_name(name);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/loop_optimizer.cc" line="50" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;LoopInvariantNodeMotionOptimizer::new_enter_id_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;LoopInvariantNodeMotionOptimizer::new_enter_id_,&quot;}" func_info="LoopInvariantNodeMotionOptimizer" content="40: #include &quot;tensorflow/core/util/saved_tensor_slice_util.h&quot;
41: 
42: using tensorflow::strings::StrCat;
43: 
44: namespace tensorflow {
45: namespace grappler {
46: namespace {
47: 
48: class LoopInvariantNodeMotionOptimizer {
49:  public:
50:   explicit LoopInvariantNodeMotionOptimizer(GraphDef* optimized_graph)
51:       : optimized_graph_(optimized_graph) {}
52:   virtual ~LoopInvariantNodeMotionOptimizer() = default;
53:   Status Optimize();
54: 
55:  private:
56:   Status FindInvariantNodes(NodeDef* node);
57:   Status RevertInvariantNodes();
58:   Status MoveInvariantNodes(const int frame_id);
59:   Status HandleInvariantNode(NodeDef* node, const int num_outputs,
60:                              const int frame_id);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/memory_optimizer.cc" line="256" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [child_component_iterator] may be invalid here." web_identify="{&quot;identify&quot;:&quot;child_component_iterator&quot;}" func_info="std::unordered_map &lt; const NodeDef * , int &gt; grappler::GetMaxDownstreamComponents ( const std :: unordered_set &lt; const NodeDef * &gt; &amp; recomputed_source_nodes , const std :: unordered_set &lt; NodeDef * &gt; &amp; target_nodes , const NodeMap &amp; node_map , const std :: unordered_map &lt; const NodeDef * , int &gt; &amp; components )" content="246:     } else {
247:       max_component = -1;
248:     }
249:     for (NodeDef* output :
250:          node_map.GetOutputs(original_recompute_node-&gt;name())) {
251:       if (recomputed_source_nodes.count(output) == 0) {
252:         continue;
253:       }
254:       auto child_component_iterator = recomputed_node_components.find(output);
255:       CHECK(child_component_iterator != recomputed_node_components.end());
256:       int child_component = child_component_iterator-&gt;second;
257:       if (child_component &gt; max_component) {
258:         max_component = child_component;
259:       }
260:     }
261:     CHECK_GE(max_component, 0);
262:     recomputed_node_components[original_recompute_node] = max_component;
263:   }
264:   return recomputed_node_components;
265: }
266: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc" line="142" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [inode] to null at line 141 implies that [inode ] might be null.Dereferencing null pointer [inode]." web_identify="{&quot;identify&quot;:&quot;inode&quot;}" func_info="Status GetInputs ( NodeMap * node_map , const std::vector &lt; NodeDef * &gt; &amp; ops , DataType dtype , std::vector &lt; InputDesc &gt; * inputs )" content="132:     VLOG(2) &lt;&lt; &quot;for node &quot; &lt;&lt; n-&gt;name();
133:     for (const auto&amp; input_name : n-&gt;input()) {
134:       if (!IsControlInput(input_name)) {
135:         if (inode) {
136:           return errors::Internal(&quot;Found more than one input for node &quot;,
137:                                   n-&gt;name());
138:         }
139:         ParseNodeName(input_name, &amp;position);
140:         inode = node_map-&gt;GetNode(input_name);
141:         CHECK(inode) &lt;&lt; input_name;
142:         VLOG(2) &lt;&lt; &quot;inode &quot; &lt;&lt; inode-&gt;DebugString();
143:       }
144:     }
145:     AttrSlice inode_attrs = AttrSlice(*inode);
146:     DataType inode_dtype;
147:     LOG_WARNING_AND_RETURN_IF_ERROR(
148:         GetNodeAttr(inode_attrs, &quot;T&quot;, &amp;inode_dtype));
149:     if (inode_dtype != dtype) {
150:       return errors::Internal(&quot;ScopedAllocatorOptimizer expected input type &quot;,
151:                               dtype, &quot; but found &quot;, inode_dtype);
152:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc" line="287" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph_properties_] to null at line 285 implies that [graph_properties_ ] might be null.Dereferencing null pointer [graph_properties_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;graph_properties_&quot;}" func_info="Status UnaryElementwiseRewriter::AnalyzeInputs ( ScopedAllocatorOptimizer * sa_opti , NodeMap * node_map , const std :: vector &lt; NodeDef * &gt; &amp; ops , const std :: set &lt; string &gt; &amp; op_instance_names , string * device_name , DataType * dtype , std :: vector &lt; TensorShape &gt; * input_shapes , std :: vector &lt; InputDesc &gt; * inputs , TensorShape * sa_shape )" content="277:   // and checking whether there are any considerations that prevent use
278:   // of a single ScopedAllocator for all of those inputs.
279:   Status AnalyzeInputs(ScopedAllocatorOptimizer* sa_opti, NodeMap* node_map,
280:                        const std::vector&lt;NodeDef*&gt;&amp; ops,
281:                        const std::set&lt;string&gt;&amp; op_instance_names,
282:                        string* device_name, DataType* dtype,
283:                        std::vector&lt;TensorShape&gt;* input_shapes,
284:                        std::vector&lt;InputDesc&gt;* inputs, TensorShape* sa_shape) {
285:     CHECK(graph_properties_);
286:     LOG_WARNING_AND_RETURN_IF_ERROR(
287:         CheckTypesAndGetShapes(*graph_properties_, ops, dtype, input_shapes));
288:     LOG_WARNING_AND_RETURN_IF_ERROR(
289:         GetInputs(sa_opti-&gt;node_map(), ops, *dtype, inputs));
290:     LOG_WARNING_AND_RETURN_IF_ERROR(CheckExistingScopedAllocator(*inputs));
291:     LOG_WARNING_AND_RETURN_IF_ERROR(
292:         CheckInternalDataDependency(op_instance_names, *inputs));
293:     ClearInternalControlInputs(op_instance_names, ops, node_map);
294:     *device_name = ops[0]-&gt;device();
295:     CHECK(!device_name-&gt;empty());
296:     CHECK(!input_shapes-&gt;empty());
297:     CHECK_EQ(0, Allocator::kAllocatorAlignment % DataTypeSize(*dtype))
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/grappler/utils.cc" line="57" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [graph] to null at line 56 implies that [graph ] might be null.Dereferencing null pointer [graph]." web_identify="{&quot;identify&quot;:&quot;graph&quot;}" func_info="NodeMap::NodeMap ( GraphDef * graph )" content="47: // TODO(ezhulenev): what about Identity passing tensor to Shape consumer?
48: bool IsShapeConsumer(const NodeDef&amp; node) {
49:   const string&amp; op = node.op();
50:   return op == &quot;Shape&quot; || op == &quot;ShapeN&quot; || op == &quot;Rank&quot; || op == &quot;Size&quot;;
51: }
52: 
53: }  // namespace
54: 
55: NodeMap::NodeMap(GraphDef* graph) {
56:   CHECK(graph != nullptr);
57:   for (int i = 0; i &lt; graph-&gt;node_size(); i++) {
58:     NodeDef* node = graph-&gt;mutable_node(i);
59:     const string&amp; node_name = node-&gt;name();
60:     auto rslt = nodes_.emplace(node_name, node);
61:     // Check that the graph doesn&apos;t contain multiple nodes with the same name.
62:     if (!rslt.second) {
63:       LOG(WARNING) &lt;&lt; &quot;Duplicated node in the graph: &quot; &lt;&lt; node_name;
64:     }
65:     for (const auto&amp; input : node-&gt;input()) {
66:       outputs_[NodeName(input)].insert(nodes_[node_name]);
67:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/candidate_sampler_ops.cc" line="56" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [sampler_] to null at line 52 implies that [sampler_ ] might be null.Dereferencing null pointer [sampler_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;sampler_&quot;}" func_info="void BaseCandidateSamplerOp::Compute ( OpKernelContext * context )" content="46:     const int32 batch_size = true_classes.dim_size(0);
47:     OP_REQUIRES(
48:         context, true_classes.dim_size(1) == num_true_,
49:         errors::InvalidArgument(&quot;true_classes must have &quot;
50:                                 &quot;num_true columns, expected: &quot;,
51:                                 true_classes.dim_size(1), &quot; was: &quot;, num_true_));
52:     CHECK(sampler_) &lt;&lt; &quot;CandidateSamplerOp did not set sampler_&quot;;
53: 
54:     if (unique_) {
55:       OP_REQUIRES(context, num_sampled_ &lt;= sampler_-&gt;range(),
56:                   errors::InvalidArgument(&quot;Sampler&apos;s range is too small.&quot;));
57:     }
58: 
59:     // Output candidates and expected_count.
60:     Tensor* out_sampled_candidates = nullptr;
61:     OP_REQUIRES_OK(context,
62:                    context-&gt;allocate_output(0, TensorShape({num_sampled_}),
63:                                             &amp;out_sampled_candidates));
64: 
65:     Tensor* out_true_expected_count = nullptr;
66:     OP_REQUIRES_OK(context, context-&gt;allocate_output(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/conv_ops_fused.cc" line="367" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;output_width1-stride_cols*&quot;}" func_info="void FusedResizeAndPadConvFunctor::operator() ( OpKernelContext * context , const Tensor &amp; input , int input_batches , int resized_height , int resized_width , int padded_height , int padded_width , int input_depth , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int stride_rows , int stride_cols , Padding padding , T3 * output_data , int output_height , int output_width , const ImageResizerState &amp; st , int top_padding , int bottom_padding , int left_padding , int right_padding , int pad_offset )" content="357:     // cache  |                    |
358:     // height |                    |
359:     //   v    +--------------------+
360:     // Each cache row contains a cache_line_width number of resized pixels,
361:     // each with input_depth channels. The cache height is typically less than
362:     // the full height the resized image would be, so it&apos;s filled up
363:     // incrementally as we progress downwards through the input creating im2col
364:     // patches.
365:     task_params.cache_start_x = -filter_left_offset;
366:     task_params.cache_end_x =
367:         (((output_width - 1) * stride_cols) - filter_left_offset) +
368:         filter_width;
369:     task_params.cache_line_width =
370:         task_params.cache_end_x - task_params.cache_start_x;
371:     task_params.cache_height =
372:         kResizeCacheSize / (task_params.cache_line_width * input_depth);
373:     const int needed_resize_cache_count =
374:         filter_height * task_params.cache_line_width * input_depth;
375:     OP_REQUIRES(context,
376:                 (needed_resize_cache_count * sizeof(T1)) &lt;= kResizeCacheSize,
377:                 errors::InvalidArgument(&quot;Input too large for resize cache&quot;));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/conv_ops_gpu_3.cu.cc" line="773" id="suspicious" subid="autovar" severity="Warning" msg="Reference to auto variable returned." web_identify="{&quot;identify&quot;:&quot;return&quot;}" func_info="&gt; const std::vector &lt; std::pair &lt; int , int &gt; &gt; &amp; functor::GetTileSizesFrontier ( )" content="763:     for (int long_side = 32; long_side &lt;= kMaxLongSideLen; long_side *= 2) {
764:       for (int short_side = 2; short_side &lt;= kMaxShortSideLen;
765:            short_side += 1) {
766:         if (TileSizeOnLongSideFrontier(long_side, short_side, SizeOfT)) {
767:           // The current combination lies on the frontier, thus we
768:           // add it to the frontier definition.
769:           frontier-&gt;push_back(std::make_pair(long_side, short_side));
770: 
771:           // The long side length is the largest one allowed iff its
772:           // corresponding short side length is 2.
773:           if (short_side == 2) return frontier;
774: 
775:           // We have exhausted all the possibilities in the frontier
776:           // with the given long side length.
777:           break;
778:         }
779:       }
780:     }
781:     LOG(FATAL)
782:         &lt;&lt; &quot;The corresponding short side length of the largest long side &quot;
783:            &quot;length has to be 2.&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/conv_ops_using_gemm.cc" line="325" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_batchesoutput_height*&quot;}" func_info="void Im2ColConvFunctor::operator() ( OpKernelContext * context , const T1 * input_data , int input_batches , int input_height , int input_width , int input_depth , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int stride_rows , int stride_cols , Padding padding , T3 * output_data , int output_height , int output_width )" content="315:                                 &quot;Conv2d&quot;, &quot;im2col_buffer&quot;,
316:                                 &amp;im2col_buffer_resource, creator));
317:     // This means that multiple ops can&apos;t be run simultaneously on different
318:     // threads, because we have a single shared resource. The platforms this is
319:     // aimed at have intra-op parallelism as their focus though, so it shouldn&apos;t
320:     // be an issue.
321:     mutex_lock lock_buffer(im2col_buffer_resource-&gt;mu);
322:     core::ScopedUnref unref_buffer(im2col_buffer_resource);
323:     T1* im2col_buffer = im2col_buffer_resource-&gt;data;
324: 
325:     const int64 patch_count = (input_batches * output_height * output_width);
326:     const int64 chunk_count =
327:         (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;
328:     for (int64 chunk_index = 0; chunk_index &lt; chunk_count; ++chunk_index) {
329:       const int64 patch_index_start = chunk_index * patches_per_chunk;
330:       const int64 patch_index_end =
331:           std::min(patch_index_start + patches_per_chunk, patch_count);
332:       for (int64 patch_index = patch_index_start; patch_index &lt; patch_index_end;
333:            ++patch_index) {
334:         const int64 batch = patch_index / (output_height * output_width);
335:         const int64 out_y = (patch_index / output_width) % output_height;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/cuda_solvers.h" line="403" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [success] to null at line 398 implies that [success ] might be null.Dereferencing null pointer [success]." web_identify="{&quot;identify&quot;:&quot;success&quot;}" func_info="HostLapackInfo DeviceLapackInfo::CopyToHost ( bool * success ) const" content="393: 
394:   // Allocates a new scratch space on the host and launches a copy of the
395:   // contents of *this to the new scratch space. Sets success to true if
396:   // the copy kernel was launched successfully.
397:   HostLapackInfo CopyToHost(bool* success) const {
398:     CHECK(success != nullptr);
399:     HostLapackInfo copy(context(), size(), debug_info());
400:     auto stream = context()-&gt;op_device_context()-&gt;stream();
401:     se::DeviceMemoryBase wrapped_src(
402:         static_cast&lt;void*&gt;(const_cast&lt;int*&gt;(this-&gt;data())));
403:     *success =
404:         stream-&gt;ThenMemcpy(copy.mutable_data(), wrapped_src, this-&gt;bytes())
405:             .ok();
406:     return copy;
407:   }
408: };
409: 
410: template &lt;typename Scalar&gt;
411: ScratchSpace&lt;Scalar&gt; CudaSolver::GetScratchSpace(const TensorShape&amp; shape,
412:                                                  const string&amp; debug_info,
413:                                                  bool on_host) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/data/group_by_window_dataset_op.cc" line="202" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Iterator::current_key_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Iterator::current_key_,&quot;}" func_info="GroupByWindowDatasetOp::Dataset::Iterator" content="192:             reduce_func_other_arguments_types_attr},
193:            {&quot;Twindow_size_func_other_arguments&quot;,
194:             window_size_func_other_arguments_types_attr}},
195:           output));
196:       return Status::OK();
197:     }
198: 
199:    private:
200:     class Iterator : public DatasetIterator&lt;Dataset&gt; {
201:      public:
202:       explicit Iterator(const Params&amp; params)
203:           : DatasetIterator&lt;Dataset&gt;(params) {}
204: 
205:       Status Initialize(IteratorContext* ctx) override {
206:         return dataset()-&gt;input_-&gt;MakeIterator(ctx, prefix(), &amp;input_impl_);
207:       }
208: 
209:       Status GetNextInternal(IteratorContext* ctx,
210:                              std::vector&lt;Tensor&gt;* out_tensors,
211:                              bool* end_of_sequence) override {
212:         mutex_lock l(mu_);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/data/optimize_dataset_op.cc" line="64" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Dataset::optimized_input_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Dataset::optimized_input_,&quot;}" func_info="OptimizeDatasetOp::Dataset" content="54:         ctx, ParseVectorArgument&lt;string&gt;(ctx, &quot;optimizations&quot;, &amp;optimizations));
55:     Dataset* dataset =
56:         new Dataset(ctx, input, optimizations, output_types_, output_shapes_);
57:     OP_REQUIRES_OK(ctx, dataset-&gt;Optimize(ctx));
58:     *output = dataset;
59:   }
60: 
61:  private:
62:   class Dataset : public GraphDatasetBase {
63:    public:
64:     Dataset(OpKernelContext* ctx, const DatasetBase* input,
65:             const std::vector&lt;string&gt;&amp; optimizations,
66:             const DataTypeVector&amp; output_types,
67:             const std::vector&lt;PartialTensorShape&gt;&amp; output_shapes)
68:         : GraphDatasetBase(ctx),
69:           input_(input),
70:           optimizations_(optimizations),
71:           output_types_(output_types),
72:           output_shapes_(output_shapes) {
73:       input_-&gt;Ref();
74:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/data/tensor_queue_dataset_op.cc" line="469" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [queue_] to null at line 468 implies that [queue_ ] might be null.Dereferencing null pointer [queue_]." web_identify="{&quot;identify&quot;:&quot;queue_&quot;}" func_info="Status TensorQueueInserter::Insert ( const std :: vector &lt; Tensor &gt; &amp; tensors ) const" content="459:         if (queue_) {
460:           mutex_lock lock(*queue_-&gt;mu());
461:           queue_-&gt;Unref();
462:           queue_-&gt;NotifyLocked();
463:           queue_ = nullptr;
464:         }
465:       }
466: 
467:       Status Insert(const std::vector&lt;Tensor&gt;&amp; tensors) const {
468:         CHECK(queue_);
469:         return queue_-&gt;Insert(tensors);
470:       }
471: 
472:      private:
473:       mutable TensorQueue* queue_;
474:     };
475: 
476:    private:
477:     TensorQueue* queue_;
478:   };
479: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/decode_image_op.cc" line="231" id="nullpointer" subid="explicitNullDereference" severity="Critical" msg="Dereferencing null pointer [output], [output] is assigned with null at line 211. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="void DecodeImageOp::DecodeJpeg ( OpKernelContext * context , StringPiece input )" content="221:                       : TensorShape({height, width, channels}),
222:                   &amp;output));
223:               if (!status.ok()) {
224:                 VLOG(1) &lt;&lt; status;
225:                 context-&gt;SetStatus(status);
226:                 return nullptr;
227:               }
228:               return output-&gt;flat&lt;uint8&gt;().data();
229:             }),
230:         errors::InvalidArgument(&quot;Invalid JPEG data or crop window, data size &quot;,
231:                                 input.size()));
232:   }
233: 
234:   void DecodePng(OpKernelContext* context, StringPiece input) {
235:     // Start decoding png to get shape details
236:     png::DecodeContext decode;
237:     OP_REQUIRES(context,
238:                 png::CommonInitDecode(input, channels_, channel_bits_, &amp;decode),
239:                 errors::InvalidArgument(&quot;Invalid PNG header, data size &quot;,
240:                                         input.size()));
241: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/decode_image_op.cc" line="327" id="nullpointer" subid="explicitNullDereference" severity="Critical" msg="Dereferencing null pointer [output], [output] is assigned with null at line 296. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="void DecodeImageOp::DecodeGif ( OpKernelContext * context , StringPiece input )" content="317:                       }
318:                       if (!status.ok()) {
319:                         VLOG(1) &lt;&lt; status;
320:                         context-&gt;SetStatus(status);
321:                         return nullptr;
322:                       }
323:                       return output-&gt;flat&lt;uint8&gt;().data();
324:                     },
325:                     &amp;error_string),
326:         errors::InvalidArgument(&quot;Invalid GIF data (size &quot;, input.size(), &quot;), &quot;,
327:                                 error_string));
328:   }
329: 
330:  private:
331:   FileFormat format_;
332:   int channels_;
333:   int channel_bits_ = 8;
334:   jpeg::UncompressFlags flags_;
335: };
336: 
337: REGISTER_KERNEL_BUILDER(Name(&quot;DecodeJpeg&quot;).Device(DEVICE_CPU), DecodeImageOp);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/deep_conv2d.cc" line="52" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_tile_rowsinput_tile_cols*&quot;}" func_info="static long tensorflow::GetDeepConvCost ( int input_tile_rows , int input_tile_cols , int out_tile_rows , int out_tile_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="42: //
43: // The transform matrices and input, filter and output tile sizes are all
44: // specified by the DeepConv2DTransform implementation selected at the
45: // start of the DeepConv2D call, based on convolution parameters.
46: 
47: // Approximate cost models for direct and deep convolutions.
48: static int64 GetDeepConvCost(int input_tile_rows, int input_tile_cols,
49:                              int out_tile_rows, int out_tile_cols, int in_depth,
50:                              int out_depth, int out_rows, int out_cols) {
51:   // Input transform cost.
52:   const int64 input_tile_spatial_size = input_tile_rows * input_tile_cols;
53:   const int64 input_transform_cost =
54:       input_tile_spatial_size * input_tile_spatial_size * in_depth;
55: 
56:   // Element-wise products (each product is a MatMul across depth).
57:   const int64 product_cost = input_tile_spatial_size * in_depth * out_depth;
58: 
59:   // Output transform cost.
60:   const int64 output_tile_spatial_size = out_tile_rows * out_tile_cols;
61:   const int64 output_transform_cost =
62:       output_tile_spatial_size * input_tile_spatial_size * out_depth;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/deep_conv2d.cc" line="60" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;out_tile_rowsout_tile_cols*&quot;}" func_info="static long tensorflow::GetDeepConvCost ( int input_tile_rows , int input_tile_cols , int out_tile_rows , int out_tile_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="50:                              int out_depth, int out_rows, int out_cols) {
51:   // Input transform cost.
52:   const int64 input_tile_spatial_size = input_tile_rows * input_tile_cols;
53:   const int64 input_transform_cost =
54:       input_tile_spatial_size * input_tile_spatial_size * in_depth;
55: 
56:   // Element-wise products (each product is a MatMul across depth).
57:   const int64 product_cost = input_tile_spatial_size * in_depth * out_depth;
58: 
59:   // Output transform cost.
60:   const int64 output_tile_spatial_size = out_tile_rows * out_tile_cols;
61:   const int64 output_transform_cost =
62:       output_tile_spatial_size * input_tile_spatial_size * out_depth;
63: 
64:   // Calculate number of input tiles to process.
65:   const int64 row_tiles = (out_rows + out_tile_rows - 1) / out_tile_rows;
66:   const int64 col_tiles = (out_cols + out_tile_cols - 1) / out_tile_cols;
67:   const int64 num_tiles = row_tiles * col_tiles;
68: 
69:   // Return total cost.
70:   return num_tiles *
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/deep_conv2d.cc" line="76" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;filter_rowsfilter_cols*&quot;}" func_info="static long tensorflow::GetDirectConvCost ( int filter_rows , int filter_cols , int in_depth , int out_depth , int out_rows , int out_cols )" content="66:   const int64 col_tiles = (out_cols + out_tile_cols - 1) / out_tile_cols;
67:   const int64 num_tiles = row_tiles * col_tiles;
68: 
69:   // Return total cost.
70:   return num_tiles *
71:          (input_transform_cost + product_cost + output_transform_cost);
72: }
73: 
74: static int64 GetDirectConvCost(int filter_rows, int filter_cols, int in_depth,
75:                                int out_depth, int out_rows, int out_cols) {
76:   return filter_rows * filter_cols * in_depth * out_depth * out_rows * out_cols;
77: }
78: 
79: // Reads environment variable &apos;env_var_name&apos;.
80: // Returns &apos;true&apos; if environment variable is enabled, false otherwise.
81: static bool ReadBoolFromEnvVar(const char* env_var_name, bool default_val) {
82:   const char* tf_env_var_val = getenv(env_var_name);
83:   if (tf_env_var_val != nullptr) {
84:     StringPiece tf_env_var_val_str(tf_env_var_val);
85:     if (tf_env_var_val_str == &quot;0&quot;) {
86:       return false;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="115" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed64Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="105:     data_size += WireFormatLite::Int32Size(
106:         input_t(static_cast&lt;int64&gt;(message_index), i));
107:   }
108:   return data_size;
109: }
110: 
111: template &lt;&gt;
112: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64, int64&gt;(const Tensor&amp; input,
113:                                                             int message_index,
114:                                                             int size) {
115:   return size * WireFormatLite::kFixed64Size;
116: }
117: 
118: template &lt;&gt;
119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="122" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="112: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED64, int64&gt;(const Tensor&amp; input,
113:                                                             int message_index,
114:                                                             int size) {
115:   return size * WireFormatLite::kFixed64Size;
116: }
117: 
118: template &lt;&gt;
119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="129" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32,int&gt; ( const Tensor &amp; input , int message_index , int size )" content="119: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int64&gt;(const Tensor&amp; input,
120:                                                             int message_index,
121:                                                             int size) {
122:   return size * WireFormatLite::kFixed32Size;
123: }
124: 
125: template &lt;&gt;
126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
133: size_t TotalPackedSize&lt;WireFormatLite::TYPE_BOOL, bool&gt;(const Tensor&amp; input,
134:                                                         int message_index,
135:                                                         int size) {
136:   return size * WireFormatLite::kBoolSize;
137: }
138: 
139: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="136" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekBoolSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_BOOL,bool&gt; ( const Tensor &amp; input , int message_index , int size )" content="126: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FIXED32, int32&gt;(const Tensor&amp; input,
127:                                                             int message_index,
128:                                                             int size) {
129:   return size * WireFormatLite::kFixed32Size;
130: }
131: 
132: template &lt;&gt;
133: size_t TotalPackedSize&lt;WireFormatLite::TYPE_BOOL, bool&gt;(const Tensor&amp; input,
134:                                                         int message_index,
135:                                                         int size) {
136:   return size * WireFormatLite::kBoolSize;
137: }
138: 
139: template &lt;&gt;
140: size_t TotalPackedSize&lt;WireFormatLite::TYPE_UINT32, int64&gt;(const Tensor&amp; input,
141:                                                            int message_index,
142:                                                            int size) {
143:   size_t data_size = 0;
144:   auto input_t = input.flat_inner_dims&lt;int64&gt;();
145:   for (int64 i = 0; i &lt; size; i++) {
146:     data_size += WireFormatLite::UInt32Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="181" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekSFixed32Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32,int&gt; ( const Tensor &amp; input , int message_index , int size )" content="171:   for (int64 i = 0; i &lt; size; i++) {
172:     data_size +=
173:         WireFormatLite::EnumSize(input_t(static_cast&lt;int64&gt;(message_index), i));
174:   }
175:   return data_size;
176: }
177: 
178: template &lt;&gt;
179: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32, int32&gt;(
180:     const Tensor&amp; input, int message_index, int size) {
181:   return size * WireFormatLite::kSFixed32Size;
182: }
183: 
184: template &lt;&gt;
185: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64, int64&gt;(
186:     const Tensor&amp; input, int message_index, int size) {
187:   return size * WireFormatLite::kSFixed64Size;
188: }
189: 
190: template &lt;&gt;
191: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SINT32, int32&gt;(const Tensor&amp; input,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="187" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekSFixed64Size::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64,long&gt; ( const Tensor &amp; input , int message_index , int size )" content="177: 
178: template &lt;&gt;
179: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED32, int32&gt;(
180:     const Tensor&amp; input, int message_index, int size) {
181:   return size * WireFormatLite::kSFixed32Size;
182: }
183: 
184: template &lt;&gt;
185: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SFIXED64, int64&gt;(
186:     const Tensor&amp; input, int message_index, int size) {
187:   return size * WireFormatLite::kSFixed64Size;
188: }
189: 
190: template &lt;&gt;
191: size_t TotalPackedSize&lt;WireFormatLite::TYPE_SINT32, int32&gt;(const Tensor&amp; input,
192:                                                            int message_index,
193:                                                            int size) {
194:   size_t data_size = 0;
195:   auto input_t = input.flat_inner_dims&lt;int32&gt;();
196:   for (int64 i = 0; i &lt; size; i++) {
197:     data_size += WireFormatLite::SInt32Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="55" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekDoubleSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE,double&gt; ( const Tensor &amp; input , int message_index , int size )" content="45: // Computes the total serialized size for a packed repeated field.
46: // For fixed-size types this can just multiply, but for variable-sized
47: // types it has to iterate through the values in the tensor.
48: template &lt;WireFormatLite::FieldType FieldType, typename TensorT&gt;
49: size_t TotalPackedSize(const Tensor&amp; input, int message_index, int size);
50: 
51: template &lt;&gt;
52: size_t TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE, double&gt;(const Tensor&amp; input,
53:                                                             int message_index,
54:                                                             int size) {
55:   return size * WireFormatLite::kDoubleSize;
56: }
57: 
58: template &lt;&gt;
59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="62" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFloatSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT,double&gt; ( const Tensor &amp; input , int message_index , int size )" content="52: size_t TotalPackedSize&lt;WireFormatLite::TYPE_DOUBLE, double&gt;(const Tensor&amp; input,
53:                                                             int message_index,
54:                                                             int size) {
55:   return size * WireFormatLite::kDoubleSize;
56: }
57: 
58: template &lt;&gt;
59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
66: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, float&gt;(const Tensor&amp; input,
67:                                                           int message_index,
68:                                                           int size) {
69:   return size * WireFormatLite::kFloatSize;
70: }
71: 
72: template &lt;&gt;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/encode_proto_op.cc" line="69" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;sizeWireFormatLitekFloatSize::*&quot;}" func_info="long TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT,float&gt; ( const Tensor &amp; input , int message_index , int size )" content="59: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, double&gt;(const Tensor&amp; input,
60:                                                            int message_index,
61:                                                            int size) {
62:   return size * WireFormatLite::kFloatSize;
63: }
64: 
65: template &lt;&gt;
66: size_t TotalPackedSize&lt;WireFormatLite::TYPE_FLOAT, float&gt;(const Tensor&amp; input,
67:                                                           int message_index,
68:                                                           int size) {
69:   return size * WireFormatLite::kFloatSize;
70: }
71: 
72: template &lt;&gt;
73: size_t TotalPackedSize&lt;WireFormatLite::TYPE_INT64, int64&gt;(const Tensor&amp; input,
74:                                                           int message_index,
75:                                                           int size) {
76:   size_t data_size = 0;
77:   auto input_t = input.flat_inner_dims&lt;int64&gt;();
78:   for (int64 i = 0; i &lt; size; i++) {
79:     data_size += WireFormatLite::Int64Size(
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/functional_ops.cc" line="413" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;State::limit_,delta_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;State::limit_,delta_,&quot;}" func_info="ForOp::State" content="403: 
404:   void ComputeAsync(OpKernelContext* ctx, DoneCallback done) override {
405:     (new State(this, ctx, done))-&gt;Start();
406:   }
407: 
408:  private:
409:   FHandle body_handle_;
410: 
411:   class State {
412:    public:
413:     State(ForOp* kernel, OpKernelContext* ctx, DoneCallback done)
414:         : kernel_(kernel),
415:           ctx_(ctx),
416:           done_(std::move(done)),
417:           lib_(CHECK_NOTNULL(ctx_-&gt;function_library())),
418:           args_(1 + ctx_-&gt;num_inputs() - 3) {
419:       args_[0] = Tensor(DT_INT32, {});
420:       iter_ = &amp;args_[0].scalar&lt;int32&gt;()();
421: 
422:       const int32 num_loop_inputs = ctx_-&gt;num_inputs() - 3;
423:       rets_.reserve(num_loop_inputs);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/hexagon/graph_transfer_utils.cc" line="39" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [data] to null at line 35 implies that [data ] might be null.Dereferencing null pointer [data]." web_identify="{&quot;identify&quot;:&quot;data&quot;}" func_info="&gt; GraphTransferUtils::GetTopNFloatResults ( const float * data , const string * labels , const int element_count )" content="29:     &amp;RemoteFusedGraphExecuteUtils::AddOutputTensorShapeTypeByTensorShapeMap;
30: 
31: /* static */ std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt;
32: GraphTransferUtils::GetTopNFloatResults(const float* const data,
33:                                         const string* const labels,
34:                                         const int element_count) {
35:   CHECK(data != nullptr);
36:   CHECK(labels != nullptr);
37:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue;
38:   for (int i = 0; i &lt; element_count; ++i) {
39:     queue.emplace(data[i], i, labels[i]);
40:   }
41:   return queue;
42: }
43: 
44: /* static */ void GraphTransferUtils::DumpTopNFloatResults(
45:     const float* const data, const string* const labels,
46:     const int element_count, const int top_n) {
47:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
48:       GetTopNFloatResults(data, labels, element_count);
49:   LOG(INFO) &lt;&lt; &quot;=== Dump ranking ===&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/hexagon/graph_transfer_utils.cc" line="39" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [labels] to null at line 36 implies that [labels ] might be null.Dereferencing null pointer [labels]." web_identify="{&quot;identify&quot;:&quot;labels&quot;}" func_info="&gt; GraphTransferUtils::GetTopNFloatResults ( const float * data , const string * labels , const int element_count )" content="29:     &amp;RemoteFusedGraphExecuteUtils::AddOutputTensorShapeTypeByTensorShapeMap;
30: 
31: /* static */ std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt;
32: GraphTransferUtils::GetTopNFloatResults(const float* const data,
33:                                         const string* const labels,
34:                                         const int element_count) {
35:   CHECK(data != nullptr);
36:   CHECK(labels != nullptr);
37:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue;
38:   for (int i = 0; i &lt; element_count; ++i) {
39:     queue.emplace(data[i], i, labels[i]);
40:   }
41:   return queue;
42: }
43: 
44: /* static */ void GraphTransferUtils::DumpTopNFloatResults(
45:     const float* const data, const string* const labels,
46:     const int element_count, const int top_n) {
47:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
48:       GetTopNFloatResults(data, labels, element_count);
49:   LOG(INFO) &lt;&lt; &quot;=== Dump ranking ===&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/hexagon/hexagon_control_wrapper.cc" line="392" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [outputs] to null at line 382 implies that [outputs ] might be null.Dereferencing null pointer [outputs]." web_identify="{&quot;identify&quot;:&quot;outputs&quot;}" func_info="bool HexagonControlWrapper::ReadOutputNode ( const string &amp; node_name , std::vector &lt; ByteArray &gt; * outputs )" content="382:   CHECK(outputs != nullptr);
383:   ByteArray output;
384:   const string tensor_name = AddPort(node_name);
385:   CHECK(output_port_map_.count(tensor_name) &gt; 0);
386:   const int port = output_port_map_.at(tensor_name);
387:   soc_interface_ReadOutputNodeWithPort(
388:       port, &amp;std::get&lt;0&gt;(output),
389:       reinterpret_cast&lt;uint64_t*&gt;(&amp;std::get&lt;1&gt;(output)));
390:   // TODO: Accept all results
391:   // std::get&lt;2&gt;(output) = DT_FLOAT;
392:   outputs-&gt;emplace_back(output);
393:   return true;
394: }
395: 
396: Status HexagonControlWrapper::FuseRemoteGraph(
397:     const GraphDef&amp; original_graph_def, const std::vector&lt;string&gt;&amp; inputs,
398:     const std::vector&lt;string&gt;&amp; outputs, GraphDef* fused_graph_def) {
399:   const std::unordered_set&lt;string&gt; fused_node_names =
400:       RemoteFusedGraphExecuteUtils::BuildNodeMapFromOpsDefinitions(
401:           original_graph_def, HexagonOpsDefinitions::getInstance());
402:   // TODO(satok): We may want to place shape and type inside this function
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc" line="126" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [img_floats_ptr] to null at line 125 implies that [img_floats_ptr ] might be null.Dereferencing null pointer [img_floats_ptr]." web_identify="{&quot;identify&quot;:&quot;img_floats_ptr&quot;}" func_info="static void tensorflow::LoadImage ( std :: vector &lt; float &gt; * img_floats_ptr )" content="116:   std::vector&lt;string&gt; labels(element_count);
117:   std::priority_queue&lt;std::tuple&lt;float, int, string&gt;&gt; queue =
118:       GraphTransferUtils::GetTopNFloatResults(float_array, labels.data(),
119:                                               element_count);
120:   const std::tuple&lt;float, int, string&gt;&amp; entry = queue.top();
121:   EXPECT_EQ(expected_first_id, std::get&lt;1&gt;(entry));
122: }
123: 
124: static void LoadImage(std::vector&lt;float&gt;* img_floats_ptr) {
125:   CHECK(img_floats_ptr != nullptr);
126:   std::vector&lt;float&gt;&amp; img_floats = *img_floats_ptr;
127:   // Read the data from the bitmap file into memory
128:   string bmp;
129:   TF_CHECK_OK(ReadFileToString(Env::Default(), IMAGE_FILENAME, &amp;bmp));
130:   const int fsize = bmp.size();
131:   LOG(INFO) &lt;&lt; &quot;Read &quot; &lt;&lt; IMAGE_FILENAME &lt;&lt; &quot;, size = &quot; &lt;&lt; fsize &lt;&lt; &quot;bytes&quot;;
132:   const int64 pixel_count = WIDTH * HEIGHT * DEPTH;
133:   CHECK(fsize &gt;= 22 /* pos of height */ + sizeof(int));
134:   CHECK(bmp.data() != nullptr);
135:   uint8* const img_bytes = bit_cast&lt;uint8*&gt;(bmp.data());
136:   const int header_size = *(reinterpret_cast&lt;int*&gt;(img_bytes + 10));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/image_resizer_state.h" line="133" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ImageResizerGradientState::batch_size,channels,resized_height,resized_width,original_height,original_width,height_scale,width_scale,output,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ImageResizerGradientState::batch_size,channels,resized_height,resized_width,original_height,original_width,height_scale,width_scale,output,&quot;}" func_info="tensorflow::ImageResizerGradientState" content="123:   int64 channels;
124:   float height_scale;
125:   float width_scale;
126:   Tensor* output = nullptr;
127: 
128:  private:
129:   bool align_corners_;
130: };
131: 
132: struct ImageResizerGradientState {
133:   explicit ImageResizerGradientState(bool align_corners)
134:       : align_corners_(align_corners) {}
135: 
136:   void ValidateAndCreateOutput(OpKernelContext* context, const Tensor&amp; input,
137:                                const Tensor&amp; original_image) {
138:     OP_REQUIRES(context, input.dims() == 4,
139:                 errors::InvalidArgument(&quot;input_grad must be 4-dimensional&quot;,
140:                                         input.shape().DebugString()));
141:     // Resizers always produce float images, so input gradient must
142:     // always be a float.
143:     OP_REQUIRES(context, input.dtype() == DT_FLOAT,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/image_resizer_state.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;ImageResizerState::batch_size,out_height,out_width,in_height,in_width,channels,height_scale,width_scale,output,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;ImageResizerState::batch_size,out_height,out_width,in_height,in_width,channels,height_scale,width_scale,output,&quot;}" func_info="tensorflow::ImageResizerState" content="39: 
40: // CalculateResizeScale determines the float scaling factor.
41: inline float CalculateResizeScale(int64 in_size, int64 out_size,
42:                                   bool align_corners) {
43:   return (align_corners &amp;&amp; out_size &gt; 1)
44:              ? (in_size - 1) / static_cast&lt;float&gt;(out_size - 1)
45:              : in_size / static_cast&lt;float&gt;(out_size);
46: }
47: 
48: struct ImageResizerState {
49:   explicit ImageResizerState(bool align_corners)
50:       : align_corners_(align_corners) {}
51: 
52:   // ValidateAndCalculateOutputSize checks the bounds on the input tensors
53:   // and requested size, sets up some of the resizing state such as the
54:   // height_scale and width_scale, and calculates the output size.
55:   // If any of these operations fails, it sets an error status in
56:   // the context, which the caller must check.
57:   void ValidateAndCalculateOutputSize(OpKernelContext* context,
58:                                       const Tensor&amp; input) {
59:     OP_REQUIRES(context, input.dims() == 4,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/lookup_util.cc" line="60" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TextFileLineIterator::key_index_,value_index_,env_,next_id_,delimiter_,ignore_split_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TextFileLineIterator::key_index_,value_index_,env_,next_id_,delimiter_,ignore_split_,&quot;}" func_info="TextFileLineIterator" content="50: 
51: // Iterator that reads a text file. Each iteration process one line, it parses
52: // the line and populates the keys and values tensors used for initialization
53: // with a single key and corresponding value.
54: //
55: // What information of the line to populate the key or values is specified by
56: // providing key_index and value_index.
57: class TextFileLineIterator
58:     : public InitializableLookupTable::InitTableIterator {
59:  public:
60:   TextFileLineIterator()
61:       : valid_(false),
62:         vocab_size_(-1),
63:         status_(errors::FailedPrecondition(&quot;Not initialized&quot;)) {}
64: 
65:   // Initialize iterator.
66:   //
67:   // Prepares the file &apos;filename&apos; and sets the data types to return the keys and
68:   // values tensors. It requires the indices of the tokens in the line given a
69:   // delimiter to specify where to pick the data from.
70:   //
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/mfcc_dct.cc" line="23" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccDct::coefficient_count_,input_length_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccDct::coefficient_count_,input_length_,&quot;}" func_info="tensorflow" content="13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/core/kernels/mfcc_dct.h&quot;
17: 
18: #include &lt;math.h&gt;
19: #include &quot;tensorflow/core/platform/logging.h&quot;
20: 
21: namespace tensorflow {
22: 
23: MfccDct::MfccDct() : initialized_(false) {}
24: 
25: bool MfccDct::Initialize(int input_length, int coefficient_count) {
26:   coefficient_count_ = coefficient_count;
27:   input_length_ = input_length;
28: 
29:   if (coefficient_count_ &lt; 1) {
30:     LOG(ERROR) &lt;&lt; &quot;Coefficient count must be positive.&quot;;
31:     return false;
32:   }
33: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/mfcc_mel_filterbank.cc" line="103" id="bufoverrun" subid="arrayIndexThenCheck" severity="Critical" msg="Array index &apos;channel&apos; is used before limits check." web_identify="{&quot;identify&quot;:&quot;channel&quot;}" func_info="bool MfccMelFilterbank::Initialize ( int input_length , double input_sample_rate , int output_channel_count , double lower_frequency_limit , double upper_frequency_limit )" content="93:   // each FFT bin, band_mapper tells us which channel this bin contributes to
94:   // on the right side of the triangle.  Thus this bin also contributes to the
95:   // left side of the next channel&apos;s triangle response.
96:   band_mapper_.resize(input_length_);
97:   int channel = 0;
98:   for (int i = 0; i &lt; input_length_; ++i) {
99:     double melf = FreqToMel(i * hz_per_sbin);
100:     if ((i &lt; start_index_) || (i &gt; end_index_)) {
101:       band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.
102:     } else {
103:       while ((center_frequencies_[channel] &lt; melf) &amp;&amp;
104:              (channel &lt; num_channels_)) {
105:         ++channel;
106:       }
107:       band_mapper_[i] = channel - 1;  // Can be == -1
108:     }
109:   }
110: 
111:   // Create the weighting functions to taper the band edges.  The contribution
112:   // of any one FFT bin is based on its distance along the continuum between two
113:   // mel-channel center frequencies.  This bin contributes weights_[i] to the
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/mfcc_mel_filterbank.cc" line="39" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;MfccMelFilterbank::num_channels_,sample_rate_,input_length_,start_index_,end_index_,&quot;}" func_info="tensorflow" content="29: // spectrum output will have some channels that are always zero.
30: 
31: #include &quot;tensorflow/core/kernels/mfcc_mel_filterbank.h&quot;
32: 
33: #include &lt;math.h&gt;
34: 
35: #include &quot;tensorflow/core/platform/logging.h&quot;
36: 
37: namespace tensorflow {
38: 
39: MfccMelFilterbank::MfccMelFilterbank() : initialized_(false) {}
40: 
41: bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,
42:                                    int output_channel_count,
43:                                    double lower_frequency_limit,
44:                                    double upper_frequency_limit) {
45:   num_channels_ = output_channel_count;
46:   sample_rate_ = input_sample_rate;
47:   input_length_ = input_length;
48: 
49:   if (num_channels_ &lt; 1) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/quantization_utils.h" line="922" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [task] to null at line 921 implies that [task ] might be null.Dereferencing null pointer [task]." web_identify="{&quot;identify&quot;:&quot;task&quot;}" func_info="void TensorflowGemmlowpWorkersPool::Execute ( const std :: vector &lt; gemmlowp :: Task * &gt; &amp; tasks )" content="912: 
913:   void Execute(const std::vector&lt;gemmlowp::Task*&gt;&amp; tasks) {
914:     assert(!tasks.empty());
915:     assert(workers_ != nullptr);
916:     counter_to_decrement_when_ready_.Reset(tasks.size());
917:     for (gemmlowp::Task* task : tasks) {
918:       workers_-&gt;Schedule([this, task]() {
919:         // TODO(cwhipkey): get a local_allocator from a thread local storage.
920:         gemmlowp::Allocator local_allocator;
921:         CHECK(task != nullptr);
922:         task-&gt;local_allocator = &amp;local_allocator;
923:         task-&gt;Run();
924:         counter_to_decrement_when_ready_.DecrementCount();
925:       });
926:     }
927:     counter_to_decrement_when_ready_.Wait();
928:     for (gemmlowp::Task* task : tasks) {
929:       delete task;
930:     }
931:   }
932: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/quantized_conv_ops.cc" line="292" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;input_batchesoutput_height*&quot;}" func_info="void Im2ColConvFunctor::operator() ( OpKernelContext * context , const T1 * input_data , int input_batches , int input_height , int input_width , int input_depth , int input_offset , const T2 * filter_data , int filter_height , int filter_width , int filter_count , int filter_offset , int stride , Padding padding , T3 * output_data , int output_height , int output_width , int output_shift , int output_offset , int output_mult )" content="282:                                 &quot;Conv2d&quot;, &quot;im2col_buffer&quot;,
283:                                 &amp;im2col_buffer_resource, creator));
284:     // This means that multiple ops can&apos;t be run simultaneously on different
285:     // threads, because we have a single shared resource. The platforms this is
286:     // aimed at have intra-op parallelism as their focus though, so it shouldn&apos;t
287:     // be an issue.
288:     mutex_lock lock_buffer(im2col_buffer_resource-&gt;mu);
289:     core::ScopedUnref unref_buffer(im2col_buffer_resource);
290:     T1* im2col_buffer = im2col_buffer_resource-&gt;data;
291: 
292:     const int64 patch_count = (input_batches * output_height * output_width);
293:     const int64 chunk_count =
294:         (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;
295: 
296:     for (int64 chunk_index = 0; chunk_index &lt; chunk_count; ++chunk_index) {
297:       const int64 patch_index_start = chunk_index * patches_per_chunk;
298:       const int64 patch_index_end =
299:           std::min(patch_index_start + patches_per_chunk, patch_count);
300:       for (int64 patch_index = patch_index_start; patch_index &lt; patch_index_end;
301:            ++patch_index) {
302:         const int64 batch = patch_index / (output_height * output_width);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/reference_gemm.h" line="75" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;ia_i_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="65: 
66:   const int32 highest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::highest());
67:   const int32 lowest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::lowest());
68:   const int32 rounding = (shift_c &lt; 1) ? 0 : (1 &lt;&lt; (shift_c - 1));
69: 
70:   int i, j, l;
71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/reference_gemm.h" line="77" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;jb_j_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="67:   const int32 lowest = static_cast&lt;int32&gt;(Eigen::NumTraits&lt;T3&gt;::lowest());
68:   const int32 rounding = (shift_c &lt; 1) ? 0 : (1 &lt;&lt; (shift_c - 1));
69: 
70:   int i, j, l;
71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
86:       if (output &lt; lowest) {
87:         output = lowest;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/reference_gemm.h" line="81" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;ic_i_stride*&quot;}" func_info="&gt; void tensorflow::ReferenceGemm ( bool transpose_a , bool transpose_b , bool transpose_c , long m , long n , long k , const T1 * a , int offset_a , long lda , const T2 * b , int offset_b , long ldb , T3 * c , int shift_c , int offset_c , int mult_c , long ldc )" content="71:   for (j = 0; j &lt; n; j++) {
72:     for (i = 0; i &lt; m; i++) {
73:       int32 total = 0;
74:       for (l = 0; l &lt; k; l++) {
75:         const size_t a_index = ((i * a_i_stride) + (l * a_l_stride));
76:         const int32 a_value = static_cast&lt;int32&gt;(a[a_index]) - offset_a;
77:         const size_t b_index = ((j * b_j_stride) + (l * b_l_stride));
78:         const int32 b_value = static_cast&lt;int32&gt;(b[b_index]) - offset_b;
79:         total += (a_value * b_value);
80:       }
81:       const size_t c_index = ((i * c_i_stride) + (j * c_j_stride));
82:       int32_t output = ((((total + offset_c) * mult_c) + rounding) &gt;&gt; shift_c);
83:       if (output &gt; highest) {
84:         output = highest;
85:       }
86:       if (output &lt; lowest) {
87:         output = lowest;
88:       }
89:       c[c_index] = static_cast&lt;T3&gt;(output);
90:     }
91:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/remote_fused_graph_execute_op.cc" line="52" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [remote_fused_graph_executor_] suggests that it may be null, but it has already been dereferenced at line 45." web_identify="{&quot;identify&quot;:&quot;remote_fused_graph_executor_&quot;}" func_info="explicit RemoteFusedGraphExecuteOp::RemoteFusedGraphExecuteOp ( OpKernelConstruction * ctx ) : OpKernel ( ctx ) , execute_info_ ( )" content="42:               execute_info_.executor_name());
43:       if (build_func != nullptr) {
44:         TF_CHECK_OK((*build_func)(&amp;remote_fused_graph_executor_));
45:         CHECK(remote_fused_graph_executor_-&gt;IsEnabled());
46:       } else {
47:         LOG(ERROR) &lt;&lt; &quot;Executor not found for &quot;
48:                    &lt;&lt; execute_info_.executor_name();
49:       }
50:     }
51: 
52:     if (remote_fused_graph_executor_) {
53:       // 1. Initialize remote processor
54:       remote_fused_graph_executor_-&gt;Init(execute_info_);
55:       // Explicitly clear serialized executor parameter after initialization
56:       // to release unnecessary memory.
57:       execute_info_.clear_serialized_executor_parameters();
58: 
59:       // 2. Setup graph in remote processor
60:       remote_fused_graph_executor_-&gt;SetupGraph();
61:     }
62:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/remote_fused_graph_execute_op.cc" line="76" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ctx] to null at line 75 implies that [ctx ] might be null.Dereferencing null pointer [ctx]." web_identify="{&quot;identify&quot;:&quot;ctx&quot;}" func_info="void RemoteFusedGraphExecuteOp::Compute ( OpKernelContext * ctx )" content="66:       // 6. Teardown graph in remote processor
67:       remote_fused_graph_executor_-&gt;TeardownGraph();
68: 
69:       // 7. Finalize remote processor
70:       remote_fused_graph_executor_-&gt;Finalize();
71:     }
72:   }
73: 
74:   void Compute(OpKernelContext* const ctx) final {
75:     CHECK(ctx != nullptr);
76:     const int input_count = ctx-&gt;num_inputs();
77:     const int graph_input_count = execute_info_.graph_input_node_name_size();
78:     CHECK(input_count == graph_input_count &amp;&amp;
79:           input_count == input_types_.size())
80:         &lt;&lt; &quot;input_count = &quot; &lt;&lt; input_count
81:         &lt;&lt; &quot;, gt input count = &quot; &lt;&lt; execute_info_.graph_input_node_name_size()
82:         &lt;&lt; &quot;, type count = &quot; &lt;&lt; input_types_.size();
83: 
84:     // 3. Send first data type inputs into remote processor
85:     for (int i = 0; i &lt; graph_input_count; ++i) {
86:       const Tensor&amp; input_tensor = ctx-&gt;input(i);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/remote_fused_graph_execute_op_test.cc" line="180" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [info_] to null at line 176 implies that [info_ ] might be null.Dereferencing null pointer [info_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;info_&quot;}" func_info="bool SampleRemoteFusedGraphExecutor::ExecuteGraph ( )" content="170:     }
171:     return true;
172:   }
173:   bool Finalize() final { return true; }
174:   bool SetupGraph() final { return true; }
175:   bool ExecuteGraph() final {
176:     CHECK(info_ != nullptr);
177:     // TODO(satok): Add utilities to implement this function more easily.
178:     // CAVEAT: This test only handles add op. You can implement here as you
179:     // like.
180:     CHECK_EQ(1, info_-&gt;graph_input_node_name_size());
181:     const string&amp; input_node_name = info_-&gt;graph_input_node_name(0);
182:     const Tensor&amp; input_tensor = input_tensor_cache_[input_node_name];
183:     const float input_val = *input_tensor.scalar&lt;float&gt;().data();
184:     // TODO(satok): Read NAME_B from node_a_plus_b
185:     const NodeDef&amp; node_b = *node_def_map_.at(NAME_B);
186:     const TensorProto* proto = nullptr;
187:     TF_CHECK_OK(GetNodeAttr(node_b, &quot;value&quot;, &amp;proto));
188:     Tensor const_tensor;
189:     TF_CHECK_OK(RemoteFusedGraphExecuteUtils::MakeTensorFromProto(
190:         *proto, &amp;const_tensor));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/remote_fused_graph_execute_utils.cc" line="312" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tensor_shape_map] to null at line 272 implies that [tensor_shape_map ] might be null.Dereferencing null pointer [tensor_shape_map]." web_identify="{&quot;identify&quot;:&quot;tensor_shape_map&quot;}" func_info="Status RemoteFusedGraphExecuteUtils::DryRunInferenceForAllNode ( const GraphDef &amp; graph_def , const std::vector &lt; std::pair &lt; string , Tensor &gt; &gt; &amp; input_node_info_list , const bool initialize_by_zero , RemoteFusedGraphExecuteUtils::TensorShapeMap * tensor_shape_map )" content="302:   // Append output tensor of input node in advance to create a map
303:   // to avoid memory reallocation inside vector
304:   for (const std::pair&lt;string, Tensor&gt;&amp; input_node_info :
305:        input_node_info_list) {
306:     output_tensors.push_back(input_node_info.second);
307:   }
308: 
309:   for (int i = 0; static_cast&lt;size_t&gt;(i) &lt; output_node_names.size(); ++i) {
310:     const string&amp; name = output_node_names.at(i);
311:     const Tensor&amp; tensor = output_tensors.at(i);
312:     EmplaceTensorShapeType(name, tensor, tensor_shape_map);
313:   }
314:   for (int i = 0; static_cast&lt;size_t&gt;(i) &lt; input_node_info_list.size(); ++i) {
315:     const string&amp; name = input_node_info_list.at(i).first;
316:     const Tensor&amp; tensor = output_tensors.at(output_node_names.size() + i);
317:     EmplaceTensorShapeType(name, tensor, tensor_shape_map);
318:   }
319:   CHECK_EQ(output_node_names.size() + input_node_info_list.size(),
320:            output_tensors.size());
321:   return status;
322: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/spectrogram.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 133 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; bool Spectrogram::ComputeSquaredMagnitudeSpectrogram ( const std::vector &lt; InputSample &gt; &amp; input , std::vector &lt; std::vector &lt; OutputSample &gt; &gt; * output )" content="124: template &lt;class InputSample, class OutputSample&gt;
125: bool Spectrogram::ComputeSquaredMagnitudeSpectrogram(
126:     const std::vector&lt;InputSample&gt;&amp; input,
127:     std::vector&lt;std::vector&lt;OutputSample&gt;&gt;* output) {
128:   if (!initialized_) {
129:     LOG(ERROR) &lt;&lt; &quot;ComputeSquaredMagnitudeSpectrogram() called before &quot;
130:                &lt;&lt; &quot;successful call to Initialize().&quot;;
131:     return false;
132:   }
133:   CHECK(output);
134:   output-&gt;clear();
135:   int input_start = 0;
136:   while (GetNextWindowOfSamples(input, &amp;input_start)) {
137:     DCHECK_EQ(input_queue_.size(), window_length_);
138:     ProcessCoreFFT();  // Processes input_queue_ to fft_input_output_.
139:     // Add a new slice vector onto the output, to save new result to.
140:     output-&gt;resize(output-&gt;size() + 1);
141:     // Get a reference to the newly added slice to fill in.
142:     auto&amp; spectrogram_slice = output-&gt;back();
143:     spectrogram_slice.resize(output_frequency_channels_);
144:     for (int i = 0; i &lt; output_frequency_channels_; ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/spectrogram.cc" line="93" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 92 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; bool Spectrogram::ComputeComplexSpectrogram ( const std::vector &lt; InputSample &gt; &amp; input , std::vector &lt; std::vector &lt; complex &lt; OutputSample &gt; &gt; &gt; * output )" content="83: template &lt;class InputSample, class OutputSample&gt;
84: bool Spectrogram::ComputeComplexSpectrogram(
85:     const std::vector&lt;InputSample&gt;&amp; input,
86:     std::vector&lt;std::vector&lt;complex&lt;OutputSample&gt;&gt;&gt;* output) {
87:   if (!initialized_) {
88:     LOG(ERROR) &lt;&lt; &quot;ComputeComplexSpectrogram() called before successful call &quot;
89:                &lt;&lt; &quot;to Initialize().&quot;;
90:     return false;
91:   }
92:   CHECK(output);
93:   output-&gt;clear();
94:   int input_start = 0;
95:   while (GetNextWindowOfSamples(input, &amp;input_start)) {
96:     DCHECK_EQ(input_queue_.size(), window_length_);
97:     ProcessCoreFFT();  // Processes input_queue_ to fft_input_output_.
98:     // Add a new slice vector onto the output, to save new result to.
99:     output-&gt;resize(output-&gt;size() + 1);
100:     // Get a reference to the newly added slice to fill in.
101:     auto&amp; spectrogram_slice = output-&gt;back();
102:     spectrogram_slice.resize(output_frequency_channels_);
103:     for (int i = 0; i &lt; output_frequency_channels_; ++i) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/kernels/spectrogram.h" line="46" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Spectrogram::fft_length_,output_frequency_channels_,window_length_,step_length_,samples_to_next_step_,&quot;}" func_info="tensorflow::Spectrogram" content="36: #include &lt;vector&gt;
37: 
38: #include &quot;third_party/fft2d/fft.h&quot;
39: #include &quot;map/base/mlp/tf/tensorflow/core/framework/op_kernel.h&quot;
40: #include &quot;map/base/mlp/tf/tensorflow/core/framework/tensor.h&quot;
41: 
42: namespace tensorflow {
43: 
44: class Spectrogram {
45:  public:
46:   Spectrogram() : initialized_(false) {}
47:   ~Spectrogram() {}
48: 
49:   // Initializes the class with a given window length and step length
50:   // (both in samples). Internally a Hann window is used as the window
51:   // function. Returns true on success, after which calls to Process()
52:   // are possible. window_length must be greater than 1 and step
53:   // length must be greater than 0.
54:   bool Initialize(int window_length, int step_length);
55: 
56:   // Initialize with an explicit window instead of a length.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/gif/gif_io.cc" line="77" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [gif_file] to null at line 65 implies that [gif_file ] might be null.Dereferencing null pointer [gif_file]." web_identify="{&quot;identify&quot;:&quot;gif_file&quot;}" func_info="char * gif::Decode ( const void * srcdata , int datasize , const std :: function &lt; char * ( int , int , int , int ) &gt; &amp; allocate_output , string * error_string )" content="67:                    &lt;&lt; GifErrorStringNonNull(error_code);
68:     }
69:   });
70:   if (error_code != D_GIF_SUCCEEDED) {
71:     *error_string = strings::StrCat(&quot;failed to open gif file: &quot;,
72:                                     GifErrorStringNonNull(error_code));
73:     return nullptr;
74:   }
75:   if (DGifSlurp(gif_file) != GIF_OK) {
76:     *error_string = strings::StrCat(&quot;failed to slurp gif file: &quot;,
77:                                     GifErrorStringNonNull(gif_file-&gt;Error));
78:     return nullptr;
79:   }
80:   if (gif_file-&gt;ImageCount &lt;= 0) {
81:     *error_string = strings::StrCat(&quot;gif file does not contain any image&quot;);
82:     return nullptr;
83:   }
84: 
85:   const int num_frames = gif_file-&gt;ImageCount;
86:   const int width = gif_file-&gt;SWidth;
87:   const int height = gif_file-&gt;SHeight;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/gtl/inlined_vector.h" line="296" id="compute" subid="SizeofForPointerSize" severity="Warning" msg="Use sizeof data of &apos;ptr&apos; instead of sizeof the pointer." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="T * InlinedVector::outofline_pointer ( ) const" content="286:     unsigned char data[kSize];
287:     // Force data to be aligned enough for a pointer.
288:     T* unused_aligner;
289:   } u_;
290: 
291:   inline void InitRep() { u_.data[kSize - 1] = 0; }
292:   inline bool is_inline() const { return u_.data[kSize - 1] != kSentinel; }
293: 
294:   inline T* outofline_pointer() const {
295:     T* ptr;
296:     memcpy(&amp;ptr, &amp;u_.data[0], sizeof(ptr));
297:     return ptr;
298:   }
299: 
300:   inline void set_outofline_pointer(T* p) {
301:     memcpy(&amp;u_.data[0], &amp;p, sizeof(p));
302:   }
303: 
304:   inline uint64_t outofline_word() const {
305:     uint64_t word;
306:     memcpy(&amp;word, &amp;u_.data[kSize - 8], sizeof(word));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/gtl/top_n.h" line="304" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 303 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; void TopN &lt; T , Cmp &gt;::ExtractNondestructive ( std::vector &lt; T &gt; * output ) const" content="294: template &lt;class T, class Cmp&gt;
295: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractNondestructive() const {
296:   auto out = new std::vector&lt;T&gt;;
297:   ExtractNondestructive(out);
298:   return out;
299: }
300: 
301: template &lt;class T, class Cmp&gt;
302: void TopN&lt;T, Cmp&gt;::ExtractNondestructive(std::vector&lt;T&gt; *output) const {
303:   CHECK(output);
304:   *output = elements_;
305:   if (state_ != HEAP_SORTED) {
306:     std::sort(output-&gt;begin(), output-&gt;end(), cmp_);
307:   } else {
308:     output-&gt;pop_back();
309:     std::sort_heap(output-&gt;begin(), output-&gt;end(), cmp_);
310:   }
311: }
312: 
313: template &lt;class T, class Cmp&gt;
314: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive() const {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/gtl/top_n.h" line="323" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output] to null at line 322 implies that [output ] might be null.Dereferencing null pointer [output]." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="&gt; void TopN &lt; T , Cmp &gt;::ExtractUnsortedNondestructive ( std::vector &lt; T &gt; * output ) const" content="313: template &lt;class T, class Cmp&gt;
314: std::vector&lt;T&gt; *TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive() const {
315:   auto elements = new std::vector&lt;T&gt;;
316:   ExtractUnsortedNondestructive(elements);
317:   return elements;
318: }
319: 
320: template &lt;class T, class Cmp&gt;
321: void TopN&lt;T, Cmp&gt;::ExtractUnsortedNondestructive(std::vector&lt;T&gt; *output) const {
322:   CHECK(output);
323:   *output = elements_;
324:   if (state_ == HEAP_SORTED) {
325:     // Remove the limit_+1&apos;th element.
326:     output-&gt;pop_back();
327:   }
328: }
329: 
330: template &lt;class T, class Cmp&gt;
331: void TopN&lt;T, Cmp&gt;::Reset() {
332:   elements_.clear();
333:   state_ = UNORDERED;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/io/snappy/snappy_inputbuffer.cc" line="20" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SnappyInputBuffer::next_out_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SnappyInputBuffer::next_out_,&quot;}" func_info="tensorflow::io" content="10: distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
11: WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12: See the License for the specific language governing permissions and
13: limitations under the License.
14: ==============================================================================*/
15: 
16: #include &quot;tensorflow/core/lib/io/snappy/snappy_inputbuffer.h&quot;
17: 
18: namespace tensorflow {
19: namespace io {
20: SnappyInputBuffer::SnappyInputBuffer(
21:     RandomAccessFile* file,
22:     size_t input_buffer_bytes,  // size of input_buffer_
23:     size_t output_buffer_bytes  // size of output_buffer_
24:     )
25:     : file_(file),
26:       input_buffer_capacity_(input_buffer_bytes),
27:       output_buffer_capacity_(output_buffer_bytes),
28:       input_buffer_(new char[input_buffer_capacity_]),
29:       output_buffer_(new char[output_buffer_capacity_]),
30:       next_in_(input_buffer_.get()) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/jpeg/jpeg_mem.cc" line="607" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [output] suggests that it may be null, but it has already been dereferenced at line 580. The error is in macros." web_identify="{&quot;identify&quot;:&quot;output&quot;}" func_info="bool CompressInternal ( const char * srcdata , int width , int height , const CompressFlags &amp; flags , string * output )" content="597:     in_stride = width * (static_cast&lt;int&gt;(flags.format) &amp; 0xff);
598:   } else if (in_stride &lt; width * components) {
599:     LOG(ERROR) &lt;&lt; &quot;Incompatible input stride&quot;;
600:     return false;
601:   }
602: 
603:   JOCTET* buffer = nullptr;
604: 
605:   // NOTE: for broader use xmp_metadata should be made a unicode string
606:   CHECK(srcdata != nullptr);
607:   CHECK(output != nullptr);
608:   // This struct contains the JPEG compression parameters and pointers to
609:   // working space
610:   struct jpeg_compress_struct cinfo;
611:   // This struct represents a JPEG error handler.
612:   struct jpeg_error_mgr jerr;
613:   jmp_buf jpeg_jmpbuf;  // recovery point in case of error
614: 
615:   // Step 1: allocate and initialize JPEG compression object
616:   // Use the usual jpeg error manager.
617:   cinfo.err = jpeg_std_error(&amp;jerr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/jpeg/jpeg_mem.cc" line="709" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [srcdata] to null at line 606 implies that [srcdata ] might be null.Dereferencing null pointer [srcdata]." web_identify="{&quot;identify&quot;:&quot;srcdata&quot;}" func_info="bool CompressInternal ( const char * srcdata , int width , int height , const CompressFlags &amp; flags , string * output )" content="699:     }
700:     jpeg_write_marker(&amp;cinfo, JPEG_APP0 + 1, joctet_packet.get(),
701:                       packet_length);
702:   }
703: 
704:   // JSAMPLEs per row in image_buffer
705:   std::unique_ptr&lt;JSAMPLE[]&gt; row_temp(
706:       new JSAMPLE[width * cinfo.input_components]);
707:   while (cinfo.next_scanline &lt; cinfo.image_height) {
708:     JSAMPROW row_pointer[1];  // pointer to JSAMPLE row[s]
709:     const uint8* r = &amp;srcdata[cinfo.next_scanline * in_stride];
710:     uint8* p = static_cast&lt;uint8*&gt;(row_temp.get());
711:     switch (flags.format) {
712:       case FORMAT_RGBA: {
713:         for (int i = 0; i &lt; width; ++i, p += 3, r += 4) {
714:           p[0] = r[0];
715:           p[1] = r[1];
716:           p[2] = r[2];
717:         }
718:         row_pointer[0] = row_temp.get();
719:         break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/png/png_io.h" line="57" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DecodeContext::data,data_left,num_passes,color_type,bit_depth,channels,need_to_synthesize_16,error_condition,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DecodeContext::data,data_left,num_passes,color_type,bit_depth,channels,need_to_synthesize_16,error_condition,&quot;}" func_info="tensorflow::png::DecodeContext" content="47:   int data_left;
48:   png_structp png_ptr;
49:   png_infop info_ptr;
50:   png_uint_32 width, height;
51:   int num_passes;
52:   int color_type;
53:   int bit_depth;
54:   int channels;
55:   bool need_to_synthesize_16;
56:   bool error_condition;
57:   DecodeContext() : png_ptr(NULL), info_ptr(NULL) {}
58: };
59: 
60: bool DecodeHeader(StringPiece png_string, int* width, int* height,
61:                   int* components, int* channel_bit_depth,
62:                   std::vector&lt;std::pair&lt;string, string&gt; &gt;* metadata);
63: 
64: // Sample usage for reading PNG:
65: //
66: // string png_string;  /* fill with input PNG format data */
67: // DecodeContext context;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/numbers.cc" line="105" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [endptr] suggests that it may be null, but it has already been dereferenced at line 71." web_identify="{&quot;identify&quot;:&quot;endptr&quot;}" func_info="&gt; T locale_independent_strtonum ( const char * str , const char * * endptr )" content="95:         result == std::numeric_limits&lt;T&gt;::infinity()) {
96:       result = std::numeric_limits&lt;T&gt;::infinity();
97:       s.clear(s.rdstate() &amp; ~std::ios::failbit);
98:     } else if (result == -std::numeric_limits&lt;T&gt;::max() ||
99:                result == -std::numeric_limits&lt;T&gt;::infinity()) {
100:       result = -std::numeric_limits&lt;T&gt;::infinity();
101:       s.clear(s.rdstate() &amp; ~std::ios::failbit);
102:     }
103:   }
104: 
105:   if (endptr) {
106:     *endptr =
107:         str +
108:         (s.fail() ? static_cast&lt;std::iostream::pos_type&gt;(0)
109:                   : (s.eof() ? static_cast&lt;std::iostream::pos_type&gt;(strlen(str))
110:                              : s.tellg()));
111:   }
112:   return result;
113: }
114: 
115: static inline const double_conversion::StringToDoubleConverter&amp;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="103" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="93:                                  : sizeof(v) == 4 ? static_cast&lt;uint32&gt;(v)
94:                                                   : static_cast&lt;uint64&gt;(v);
95:   }
96: };
97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="105" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="95:   }
96: };
97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="107" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="97: 
98: class AlphaNum {
99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="109" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="99:  public:
100:   // No bool ctor -- bools convert to an integral type.
101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="111" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="101:   // A bool ctor would also convert incoming pointers (bletch).
102: 
103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="113" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="103:   AlphaNum(int i32)  // NOLINT(runtime/explicit)
104:       : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}
105:   AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)
106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="116" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="106:       : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}
107:   AlphaNum(long x)  // NOLINT(runtime/explicit)
108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="118" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="108:       : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}
109:   AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)
110:       : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}
111:   AlphaNum(long long int i64)  // NOLINT(runtime/explicit)
112:       : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}
113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="123" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="113:   AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)
114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="124" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="114:       : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}
115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
134:   char digits_[kFastToBufferSize];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/lib/strings/strcat.h" line="125" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AlphaNum::digits_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AlphaNum::digits_,&quot;}" func_info="tensorflow::strings::AlphaNum" content="115: 
116:   AlphaNum(float f)  // NOLINT(runtime/explicit)
117:       : piece_(digits_, FloatToBuffer(f, digits_)) {}
118:   AlphaNum(double f)  // NOLINT(runtime/explicit)
119:       : piece_(digits_, DoubleToBuffer(f, digits_)) {}
120: 
121:   AlphaNum(Hex hex);               // NOLINT(runtime/explicit)
122: 
123:   AlphaNum(const char *c_str) : piece_(c_str) {}   // NOLINT(runtime/explicit)
124:   AlphaNum(const StringPiece &amp;pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
125:   AlphaNum(const tensorflow::string &amp;str)          // NOLINT(runtime/explicit)
126:       : piece_(str) {}
127: 
128:   StringPiece::size_type size() const { return piece_.size(); }
129:   const char *data() const { return piece_.data(); }
130:   StringPiece Piece() const { return piece_; }
131: 
132:  private:
133:   StringPiece piece_;
134:   char digits_[kFastToBufferSize];
135: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/ops/array_ops.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [perm] to null at line 122 implies that [perm ] might be null.Dereferencing null pointer [perm]." web_identify="{&quot;identify&quot;:&quot;perm&quot;}" func_info="Status TransposeShapeFn ( InferenceContext * c )" content="124:     return Status::OK();
125:   }
126: 
127:   // Find our value of the rank.
128:   int64 rank;
129:   if (c-&gt;RankKnown(input)) {
130:     rank = c-&gt;Rank(input);
131:   } else if (c-&gt;ValueKnown(perm_elems)) {
132:     rank = c-&gt;Value(perm_elems);
133:   } else {
134:     rank = perm-&gt;NumElements();
135:   }
136:   std::vector&lt;DimensionHandle&gt; dims;
137:   dims.resize(rank);
138:   TF_RETURN_IF_ERROR(c-&gt;WithRank(input, rank, &amp;input));
139:   // Ensure that perm is a vector and has rank elements.
140:   TF_RETURN_IF_ERROR(c-&gt;WithRank(perm_shape, 1, &amp;perm_shape));
141:   TF_RETURN_IF_ERROR(c-&gt;WithValue(perm_elems, rank, &amp;perm_elems));
142: 
143:   // If we know the rank of the input and the value of perm, we can return
144:   // all shape informantion, otherwise we can only return rank information,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request.cc" line="299" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [out_buffer] to null at line 297 implies that [out_buffer ] might be null.Dereferencing null pointer [out_buffer]." web_identify="{&quot;identify&quot;:&quot;out_buffer&quot;}" func_info="void CurlHttpRequest::SetResultBuffer ( std::vector &lt; char &gt; * out_buffer )" content="289:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_READDATA,
290:                                            reinterpret_cast&lt;void*&gt;(this)));
291:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_READFUNCTION,
292:                                            &amp;CurlHttpRequest::ReadCallback));
293: }
294: 
295: void CurlHttpRequest::SetResultBuffer(std::vector&lt;char&gt;* out_buffer) {
296:   CheckNotSent();
297:   CHECK(out_buffer != nullptr);
298: 
299:   out_buffer-&gt;clear();
300:   response_buffer_ = out_buffer;
301: 
302:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_WRITEDATA,
303:                                            reinterpret_cast&lt;void*&gt;(this)));
304:   CHECK_CURL_OK(libcurl_-&gt;curl_easy_setopt(curl_, CURLOPT_WRITEFUNCTION,
305:                                            &amp;CurlHttpRequest::WriteCallback));
306: }
307: 
308: void CurlHttpRequest::SetResultBufferDirect(char* buffer, size_t size) {
309:   CHECK(buffer != nullptr);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request.cc" line="336" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ptr] to null at line 325 implies that [ptr ] might be null.Dereferencing null pointer [ptr]." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="long CurlHttpRequest::WriteCallbackDirect ( const void * ptr , long size , long nmemb , void * userdata )" content="326:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(userdata);
327:   DirectResponseState* state = &amp;that-&gt;direct_response_;
328:   CHECK(state-&gt;buffer_ != nullptr);
329:   CHECK(state-&gt;bytes_transferred_ &lt;= state-&gt;buffer_size_);
330: 
331:   size_t curl_bytes_received = size * nmemb;
332:   size_t user_buffer_bytes_available =
333:       state-&gt;buffer_size_ - state-&gt;bytes_transferred_;
334:   size_t bytes_to_copy =
335:       std::min&lt;size_t&gt;(curl_bytes_received, user_buffer_bytes_available);
336:   memcpy(&amp;state-&gt;buffer_[state-&gt;bytes_transferred_], ptr, bytes_to_copy);
337:   state-&gt;bytes_transferred_ += bytes_to_copy;
338:   state-&gt;bytes_received_ += curl_bytes_received;
339:   // If we didn&apos;t have room to store the full response, returning less than
340:   // curl_bytes_received here will abort the transfer and curl_easy_perform()
341:   // will return CURLE_WRITE_ERROR. We will detect and handle this error there,
342:   // and can use state-&gt;bytes_received_ as stored above for logging purposes.
343:   return bytes_to_copy;
344: }
345: 
346: size_t CurlHttpRequest::GetResultBufferDirectBytesTransferred() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request.cc" line="336" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [state.buffer_] to null at line 328 implies that [state.buffer_ ] might be null.Dereferencing null pointer [state.buffer_]." web_identify="{&quot;identify&quot;:&quot;state.buffer_&quot;}" func_info="long CurlHttpRequest::WriteCallbackDirect ( const void * ptr , long size , long nmemb , void * userdata )" content="326:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(userdata);
327:   DirectResponseState* state = &amp;that-&gt;direct_response_;
328:   CHECK(state-&gt;buffer_ != nullptr);
329:   CHECK(state-&gt;bytes_transferred_ &lt;= state-&gt;buffer_size_);
330: 
331:   size_t curl_bytes_received = size * nmemb;
332:   size_t user_buffer_bytes_available =
333:       state-&gt;buffer_size_ - state-&gt;bytes_transferred_;
334:   size_t bytes_to_copy =
335:       std::min&lt;size_t&gt;(curl_bytes_received, user_buffer_bytes_available);
336:   memcpy(&amp;state-&gt;buffer_[state-&gt;bytes_transferred_], ptr, bytes_to_copy);
337:   state-&gt;bytes_transferred_ += bytes_to_copy;
338:   state-&gt;bytes_received_ += curl_bytes_received;
339:   // If we didn&apos;t have room to store the full response, returning less than
340:   // curl_bytes_received here will abort the transfer and curl_easy_perform()
341:   // will return CURLE_WRITE_ERROR. We will detect and handle this error there,
342:   // and can use state-&gt;bytes_received_ as stored above for logging purposes.
343:   return bytes_to_copy;
344: }
345: 
346: size_t CurlHttpRequest::GetResultBufferDirectBytesTransferred() {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request.cc" line="365" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [that.response_buffer_] to null at line 363 implies that [that.response_buffer_ ] might be null.Dereferencing null pointer [that.response_buffer_]." web_identify="{&quot;identify&quot;:&quot;that.response_buffer_&quot;}" func_info="long CurlHttpRequest::WriteCallback ( const void * ptr , long size , long nmemb , void * this_object )" content="355:   inactivity_timeout_secs_ = inactivity;
356:   request_timeout_secs_ = total;
357: }
358: 
359: size_t CurlHttpRequest::WriteCallback(const void* ptr, size_t size,
360:                                       size_t nmemb, void* this_object) {
361:   CHECK(ptr);
362:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
363:   CHECK(that-&gt;response_buffer_);
364:   const size_t bytes_to_copy = size * nmemb;
365:   that-&gt;response_buffer_-&gt;insert(
366:       that-&gt;response_buffer_-&gt;end(), reinterpret_cast&lt;const char*&gt;(ptr),
367:       reinterpret_cast&lt;const char*&gt;(ptr) + bytes_to_copy);
368: 
369:   return bytes_to_copy;
370: }
371: 
372: size_t CurlHttpRequest::ReadCallback(void* ptr, size_t size, size_t nmemb,
373:                                      FILE* this_object) {
374:   CHECK(ptr);
375:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request.cc" line="379" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ptr] to null at line 374 implies that [ptr ] might be null.Dereferencing null pointer [ptr]." web_identify="{&quot;identify&quot;:&quot;ptr&quot;}" func_info="long CurlHttpRequest::ReadCallback ( void * ptr , long size , long nmemb , FILE * this_object )" content="369:   return bytes_to_copy;
370: }
371: 
372: size_t CurlHttpRequest::ReadCallback(void* ptr, size_t size, size_t nmemb,
373:                                      FILE* this_object) {
374:   CHECK(ptr);
375:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
376:   CHECK(that-&gt;post_body_read_ &lt;= that-&gt;post_body_buffer_.size());
377:   const size_t bytes_to_copy = std::min(
378:       size * nmemb, that-&gt;post_body_buffer_.size() - that-&gt;post_body_read_);
379:   memcpy(ptr, that-&gt;post_body_buffer_.data() + that-&gt;post_body_read_,
380:          bytes_to_copy);
381:   that-&gt;post_body_read_ += bytes_to_copy;
382:   return bytes_to_copy;
383: }
384: 
385: size_t CurlHttpRequest::HeaderCallback(const void* ptr, size_t size,
386:                                        size_t nmemb, void* this_object) {
387:   CHECK(ptr);
388:   auto that = reinterpret_cast&lt;CurlHttpRequest*&gt;(this_object);
389:   StringPiece header(reinterpret_cast&lt;const char*&gt;(ptr), size * nmemb);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cloud/curl_http_request_test.cc" line="716" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;StatsTestFakeLibCurl::stats_had_recorded_request_,stats_had_recorded_response_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;StatsTestFakeLibCurl::stats_had_recorded_request_,stats_had_recorded_response_,&quot;}" func_info="StatsTestFakeLibCurl" content="706:   HttpRequest::RequestMethod record_response_method_ =
707:       HttpRequest::RequestMethod::kGet;
708:   Status record_response_result_;
709: 
710:   bool has_recorded_request_ = false;
711:   bool has_recorded_response_ = false;
712: };
713: 
714: class StatsTestFakeLibCurl : public FakeLibCurl {
715:  public:
716:   StatsTestFakeLibCurl(TestStats* stats, const string&amp; response_content,
717:                        uint64 response_code)
718:       : FakeLibCurl(response_content, response_code), stats_(stats) {}
719:   CURLcode curl_easy_perform(CURL* curl) override {
720:     CHECK(!performed_request_);
721:     performed_request_ = true;
722:     stats_had_recorded_request_ = stats_-&gt;has_recorded_request_;
723:     stats_had_recorded_response_ = stats_-&gt;has_recorded_response_;
724:     return FakeLibCurl::curl_easy_perform(curl);
725:   };
726: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/cpu_info.cc" line="72" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CPUIDInfo::family_,model_num_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CPUIDInfo::family_,model_num_,&quot;}" func_info="CPUIDInfo" content="62: int GetXCR0EAX() {
63:   int eax, edx;
64:   asm(&quot;XGETBV&quot; : &quot;=a&quot;(eax), &quot;=d&quot;(edx) : &quot;c&quot;(0));
65:   return eax;
66: }
67: #endif
68: 
69: // Structure for basic CPUID info
70: class CPUIDInfo {
71:  public:
72:   CPUIDInfo()
73:       : have_adx_(0),
74:         have_aes_(0),
75:         have_avx_(0),
76:         have_avx2_(0),
77:         have_avx512f_(0),
78:         have_avx512cd_(0),
79:         have_avx512er_(0),
80:         have_avx512pf_(0),
81:         have_avx512vl_(0),
82:         have_avx512bw_(0),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/env.cc" line="449" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FileStream::scratch_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FileStream::scratch_,&quot;}" func_info="FileStream" content="439:     TF_RETURN_IF_ERROR(target_file-&gt;Append(result));
440:     offset += result.size();
441:   }
442:   return target_file-&gt;Close();
443: }
444: 
445: // A ZeroCopyInputStream on a RandomAccessFile.
446: namespace {
447: class FileStream : public ::tensorflow::protobuf::io::ZeroCopyInputStream {
448:  public:
449:   explicit FileStream(RandomAccessFile* file) : file_(file), pos_(0) {}
450: 
451:   void BackUp(int count) override { pos_ -= count; }
452:   bool Skip(int count) override {
453:     pos_ += count;
454:     return true;
455:   }
456:   protobuf_int64 ByteCount() const override { return pos_; }
457:   Status status() const { return status_; }
458: 
459:   bool Next(const void** data, int* size) override {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/posix/subprocess.cc" line="255" id="memleak" subid="resourceLeak" severity="Warning" msg="Resource leak: devnull_fd" web_identify="{&quot;identify&quot;:&quot;devnull_fd&quot;}" func_info="" content="245:         close(child_pipe_[i]);
246:         child_pipe_[i] = -1;
247:         break;
248: 
249:       case ACTION_CLOSE:
250:       default:
251:         // Do not close stdin/out/err, instead redirect them to /dev/null so
252:         // their file descriptors remain unavailable for reuse by open(), etc.
253:         if (i &lt;= CHAN_STDERR) {
254:           if (devnull_fd &lt; 0) {
255:             while ((devnull_fd = open(&quot;/dev/null&quot;, O_RDWR, 0)) &lt; 0) {
256:               if (!retry(errno)) {
257:                 _exit(1);
258:               }
259:             }
260:           }
261:           while (dup2(devnull_fd, i) &lt; 0) {
262:             if (!retry(errno)) {
263:               _exit(1);
264:             }
265:           }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/vmodule_test.cc" line="80" id="memleak" subid="resourceLeak" severity="Warning" msg="Resource leak: f" web_identify="{&quot;identify&quot;:&quot;f&quot;}" func_info="" content="70:     return EXIT_FAILURE;
71:   }
72: 
73:   // Read data from the child&apos;s stdout.
74:   constexpr int kBufferSizeBytes = 4096;
75:   char buffer[kBufferSizeBytes];
76:   size_t result = fread(buffer, sizeof(buffer[0]), kBufferSizeBytes - 1, f);
77:   if (result == 0) {
78:     fprintf(stderr, &quot;Failed to read from child stdout: %zu %s\n&quot;, result,
79:             strerror(errno));
80:     return EXIT_FAILURE;
81:   }
82:   buffer[result] = &apos;\0&apos;;
83:   int status = pclose(f);
84:   if (status == -1) {
85:     fprintf(stderr, &quot;Failed to close popen child: %s\n&quot;, strerror(errno));
86:     return EXIT_FAILURE;
87:   }
88: 
89:   // Check output is as expected.
90:   const char kExpected[] =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/platform/windows/port.cc" line="160" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;data1e6*&quot;}" func_info="double port::NominalCPUFrequency ( )" content="150: string Demangle(const char* mangled) { return mangled; }
151: 
152: double NominalCPUFrequency() {
153:   DWORD data;
154:   DWORD data_size = sizeof(data);
155:   #pragma comment(lib, &quot;shlwapi.lib&quot;)  // For SHGetValue().
156:   if (SUCCEEDED(
157:           SHGetValueA(HKEY_LOCAL_MACHINE,
158:                       &quot;HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0&quot;,
159:                       &quot;~MHz&quot;, nullptr, &amp;data, &amp;data_size))) {
160:     return data * 1e6;  // Value is MHz.
161:   }
162:   return 1.0;
163: }
164: 
165: int64 AvailableRam() {
166:   MEMORYSTATUSEX statex;
167:   statex.dwLength = sizeof(statex);
168:   if (GlobalMemoryStatusEx(&amp;statex)) {
169:     return statex.ullAvailPhys;
170:   }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="113" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [filename] to null at line 112 implies that [filename ] might be null.Dereferencing null pointer [filename]." web_identify="{&quot;identify&quot;:&quot;filename&quot;}" func_info="void tfprof::ProfilerFromFile ( const string * filename )" content="103:     }
104:   }
105:   tf_stat = new TFStats(std::move(graph_ptr), nullptr, std::move(op_log_ptr),
106:                         nullptr);
107:   return true;
108: }
109: 
110: void ProfilerFromFile(const string* filename) {
111:   CHECK(!tf_stat) &lt;&lt; &quot;Currently only 1 living tfprof profiler is allowed&quot;;
112:   CHECK(filename) &lt;&lt; &quot;Missing profile filename to init profiler from file&quot;;
113:   tf_stat = new TFStats(*filename, nullptr);
114: }
115: 
116: void DeleteProfiler() {
117:   if (tf_stat) {
118:     delete tf_stat;
119:     tf_stat = nullptr;
120:   }
121: }
122: 
123: double AddStep(int64 step, const string* graph, const string* run_meta,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="134" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 125 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="double tfprof::AddStep ( long step , const string * graph , const string * run_meta , const string * op_log )" content="124:                const string* op_log) {
125:   CHECK(tf_stat);
126: 
127:   if (graph &amp;&amp; !graph-&gt;empty()) {
128:     std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
129:     if (!graph_ptr-&gt;ParseFromString(*graph)) {
130:       if (!protobuf::TextFormat::ParseFromString(*graph, graph_ptr.get())) {
131:         fprintf(stderr, &quot;Failed to parse graph\n&quot;);
132:       }
133:     }
134:     tf_stat-&gt;AddGraph(std::move(graph_ptr));
135:   }
136: 
137:   CHECK(run_meta &amp;&amp; !run_meta-&gt;empty());
138:   // TODO(xpan): Better error handling.
139:   std::unique_ptr&lt;RunMetadata&gt; run_meta_ptr(new RunMetadata());
140:   run_meta_ptr-&gt;ParseFromString(*run_meta);
141:   tf_stat-&gt;AddRunMeta(step, std::move(run_meta_ptr));
142: 
143:   if (op_log &amp;&amp; !op_log-&gt;empty()) {
144:     std::unique_ptr&lt;OpLogProto&gt; op_log_ptr;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="140" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [run_meta] to null at line 137 implies that [run_meta ] might be null.Dereferencing null pointer [run_meta]." web_identify="{&quot;identify&quot;:&quot;run_meta&quot;}" func_info="double tfprof::AddStep ( long step , const string * graph , const string * run_meta , const string * op_log )" content="130:       if (!protobuf::TextFormat::ParseFromString(*graph, graph_ptr.get())) {
131:         fprintf(stderr, &quot;Failed to parse graph\n&quot;);
132:       }
133:     }
134:     tf_stat-&gt;AddGraph(std::move(graph_ptr));
135:   }
136: 
137:   CHECK(run_meta &amp;&amp; !run_meta-&gt;empty());
138:   // TODO(xpan): Better error handling.
139:   std::unique_ptr&lt;RunMetadata&gt; run_meta_ptr(new RunMetadata());
140:   run_meta_ptr-&gt;ParseFromString(*run_meta);
141:   tf_stat-&gt;AddRunMeta(step, std::move(run_meta_ptr));
142: 
143:   if (op_log &amp;&amp; !op_log-&gt;empty()) {
144:     std::unique_ptr&lt;OpLogProto&gt; op_log_ptr;
145:     op_log_ptr.reset(new OpLogProto());
146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [command] to null at line 154 implies that [command ] might be null.Dereferencing null pointer [command]." web_identify="{&quot;identify&quot;:&quot;command&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options] to null at line 155 implies that [options ] might be null.Dereferencing null pointer [options]." web_identify="{&quot;identify&quot;:&quot;options&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="156" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 153 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="string tfprof::Profile ( const string * command , const string * options )" content="146:     op_log_ptr-&gt;ParseFromString(*op_log);
147:     tf_stat-&gt;AddOpLogProto(std::move(op_log_ptr));
148:   }
149:   return tf_stat-&gt;run_coverage();
150: }
151: 
152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="162" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 160 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="string tfprof::SerializeToString ( )" content="152: string Profile(const string* command, const string* options) {
153:   CHECK(tf_stat);
154:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
155:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
156:   return RunProfile(*command, *options, tf_stat);
157: }
158: 
159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="169" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [filename] to null at line 168 implies that [filename ] might be null.Dereferencing null pointer [filename]." web_identify="{&quot;identify&quot;:&quot;filename&quot;}" func_info="void tfprof::WriteProfile ( const string * filename )" content="159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
173:                           const string* op_log, const string* command,
174:                           const string* options) {
175:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
176:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
177:   std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
178:   if (graph &amp;&amp; !graph-&gt;empty()) {
179:     graph_ptr-&gt;ParseFromString(*graph);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="169" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tf_stat] to null at line 167 implies that [tf_stat ] might be null.Dereferencing null pointer [tf_stat]." web_identify="{&quot;identify&quot;:&quot;tf_stat&quot;}" func_info="void tfprof::WriteProfile ( const string * filename )" content="159: string SerializeToString() {
160:   CHECK(tf_stat);
161:   string content;
162:   tf_stat-&gt;SerializeToString(&amp;content);
163:   return content;
164: }
165: 
166: void WriteProfile(const string* filename) {
167:   CHECK(tf_stat);
168:   CHECK(filename) &lt;&lt; &quot;empty file name when asking to write profile.&quot;;
169:   tf_stat-&gt;WriteProfile(*filename);
170: }
171: 
172: string PrintModelAnalysis(const string* graph, const string* run_meta,
173:                           const string* op_log, const string* command,
174:                           const string* options) {
175:   CHECK(command) &lt;&lt; &quot;command mustn&apos;t be null&quot;;
176:   CHECK(options) &lt;&lt; &quot;options mustn&apos;t be null&quot;;
177:   std::unique_ptr&lt;GraphDef&gt; graph_ptr(new GraphDef());
178:   if (graph &amp;&amp; !graph-&gt;empty()) {
179:     graph_ptr-&gt;ParseFromString(*graph);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [command] to null at line 175 implies that [command ] might be null.Dereferencing null pointer [command]." web_identify="{&quot;identify&quot;:&quot;command&quot;}" func_info="string tfprof::PrintModelAnalysis ( const string * graph , const string * run_meta , const string * op_log , const string * command , const string * options )" content="190:     op_log_ptr.reset(new OpLogProto());
191:     op_log_ptr-&gt;ParseFromString(*op_log);
192:   }
193: 
194:   // TODO(xpan): Maybe need to init the checkpoint reader?
195:   std::unique_ptr&lt;checkpoint::CheckpointReader&gt; ckpt_reader;
196: 
197:   TFStats tf_stats(std::move(graph_ptr), std::move(run_meta_ptr),
198:                    std::move(op_log_ptr), std::move(ckpt_reader));
199: 
200:   return RunProfile(*command, *options, &amp;tf_stats);
201: }
202: 
203: }  // namespace tfprof
204: }  // namespace tensorflow
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/print_model_analysis.cc" line="200" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [options] to null at line 176 implies that [options ] might be null.Dereferencing null pointer [options]." web_identify="{&quot;identify&quot;:&quot;options&quot;}" func_info="string tfprof::PrintModelAnalysis ( const string * graph , const string * run_meta , const string * op_log , const string * command , const string * options )" content="190:     op_log_ptr.reset(new OpLogProto());
191:     op_log_ptr-&gt;ParseFromString(*op_log);
192:   }
193: 
194:   // TODO(xpan): Maybe need to init the checkpoint reader?
195:   std::unique_ptr&lt;checkpoint::CheckpointReader&gt; ckpt_reader;
196: 
197:   TFStats tf_stats(std::move(graph_ptr), std::move(run_meta_ptr),
198:                    std::move(op_log_ptr), std::move(ckpt_reader));
199: 
200:   return RunProfile(*command, *options, &amp;tf_stats);
201: }
202: 
203: }  // namespace tfprof
204: }  // namespace tensorflow
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/profiler/internal/tfprof_utils.cc" line="103" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [value] to null at line 100 implies that [value ] might be null.Dereferencing null pointer [value]." web_identify="{&quot;identify&quot;:&quot;value&quot;}" func_info="bool StringToBool ( StringPiece str , bool * value )" content="93: 
94: bool CaseEqual(StringPiece s1, StringPiece s2) {
95:   if (s1.size() != s2.size()) return false;
96:   return str_util::Lowercase(s1) == str_util::Lowercase(s2);
97: }
98: 
99: bool StringToBool(StringPiece str, bool* value) {
100:   CHECK(value != nullptr) &lt;&lt; &quot;NULL output boolean given.&quot;;
101:   if (CaseEqual(str, &quot;true&quot;) || CaseEqual(str, &quot;t&quot;) || CaseEqual(str, &quot;yes&quot;) ||
102:       CaseEqual(str, &quot;y&quot;) || CaseEqual(str, &quot;1&quot;)) {
103:     *value = true;
104:     return true;
105:   }
106:   if (CaseEqual(str, &quot;false&quot;) || CaseEqual(str, &quot;f&quot;) || CaseEqual(str, &quot;no&quot;) ||
107:       CaseEqual(str, &quot;n&quot;) || CaseEqual(str, &quot;0&quot;)) {
108:     *value = false;
109:     return true;
110:   }
111:   return false;
112: }
113: }  // namespace
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="158" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="148: Flag::Flag(const char* name, tensorflow::int64* dst, const string&amp; usage_text)
149:     : name_(name),
150:       type_(TYPE_INT64),
151:       int64_hook_([dst](int64 value) {
152:         *dst = value;
153:         return true;
154:       }),
155:       int64_default_for_display_(*dst),
156:       usage_text_(usage_text) {}
157: 
158: Flag::Flag(const char* name, float* dst, const string&amp; usage_text)
159:     : name_(name),
160:       type_(TYPE_FLOAT),
161:       float_hook_([dst](float value) {
162:         *dst = value;
163:         return true;
164:       }),
165:       float_default_for_display_(*dst),
166:       usage_text_(usage_text) {}
167: 
168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="168" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&quot;}" func_info="tensorflow" content="158: Flag::Flag(const char* name, float* dst, const string&amp; usage_text)
159:     : name_(name),
160:       type_(TYPE_FLOAT),
161:       float_hook_([dst](float value) {
162:         *dst = value;
163:         return true;
164:       }),
165:       float_default_for_display_(*dst),
166:       usage_text_(usage_text) {}
167: 
168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
169:     : name_(name),
170:       type_(TYPE_BOOL),
171:       bool_hook_([dst](bool value) {
172:         *dst = value;
173:         return true;
174:       }),
175:       bool_default_for_display_(*dst),
176:       usage_text_(usage_text) {}
177: 
178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="178" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="168: Flag::Flag(const char* name, bool* dst, const string&amp; usage_text)
169:     : name_(name),
170:       type_(TYPE_BOOL),
171:       bool_hook_([dst](bool value) {
172:         *dst = value;
173:         return true;
174:       }),
175:       bool_default_for_display_(*dst),
176:       usage_text_(usage_text) {}
177: 
178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
179:     : name_(name),
180:       type_(TYPE_STRING),
181:       string_hook_([dst](string value) {
182:         *dst = std::move(value);
183:         return true;
184:       }),
185:       string_default_for_display_(*dst),
186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="188" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="178: Flag::Flag(const char* name, string* dst, const string&amp; usage_text)
179:     : name_(name),
180:       type_(TYPE_STRING),
181:       string_hook_([dst](string value) {
182:         *dst = std::move(value);
183:         return true;
184:       }),
185:       string_default_for_display_(*dst),
186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
189:            int32 default_value_for_display, const string&amp; usage_text)
190:     : name_(name),
191:       type_(TYPE_INT32),
192:       int32_hook_(std::move(int32_hook)),
193:       int32_default_for_display_(default_value_for_display),
194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="196" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="186:       usage_text_(usage_text) {}
187: 
188: Flag::Flag(const char* name, std::function&lt;bool(int32)&gt; int32_hook,
189:            int32 default_value_for_display, const string&amp; usage_text)
190:     : name_(name),
191:       type_(TYPE_INT32),
192:       int32_hook_(std::move(int32_hook)),
193:       int32_default_for_display_(default_value_for_display),
194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
199:       type_(TYPE_INT64),
200:       int64_hook_(std::move(int64_hook)),
201:       int64_default_for_display_(default_value_for_display),
202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="204" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="194:       usage_text_(usage_text) {}
195: 
196: Flag::Flag(const char* name, std::function&lt;bool(int64)&gt; int64_hook,
197:            int64 default_value_for_display, const string&amp; usage_text)
198:     : name_(name),
199:       type_(TYPE_INT64),
200:       int64_hook_(std::move(int64_hook)),
201:       int64_default_for_display_(default_value_for_display),
202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
207:       type_(TYPE_FLOAT),
208:       float_hook_(std::move(float_hook)),
209:       float_default_for_display_(default_value_for_display),
210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="212" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,&quot;}" func_info="tensorflow" content="202:       usage_text_(usage_text) {}
203: 
204: Flag::Flag(const char* name, std::function&lt;bool(float)&gt; float_hook,
205:            float default_value_for_display, const string&amp; usage_text)
206:     : name_(name),
207:       type_(TYPE_FLOAT),
208:       float_hook_(std::move(float_hook)),
209:       float_default_for_display_(default_value_for_display),
210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
215:       type_(TYPE_BOOL),
216:       bool_hook_(std::move(bool_hook)),
217:       bool_default_for_display_(default_value_for_display),
218:       usage_text_(usage_text) {}
219: 
220: Flag::Flag(const char* name, std::function&lt;bool(string)&gt; string_hook,
221:            string default_value_for_display, const string&amp; usage_text)
222:     : name_(name),
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/command_line_flags.cc" line="220" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Flag::int32_default_for_display_,int64_default_for_display_,float_default_for_display_,bool_default_for_display_,&quot;}" func_info="tensorflow" content="210:       usage_text_(usage_text) {}
211: 
212: Flag::Flag(const char* name, std::function&lt;bool(bool)&gt; bool_hook,
213:            bool default_value_for_display, const string&amp; usage_text)
214:     : name_(name),
215:       type_(TYPE_BOOL),
216:       bool_hook_(std::move(bool_hook)),
217:       bool_default_for_display_(default_value_for_display),
218:       usage_text_(usage_text) {}
219: 
220: Flag::Flag(const char* name, std::function&lt;bool(string)&gt; string_hook,
221:            string default_value_for_display, const string&amp; usage_text)
222:     : name_(name),
223:       type_(TYPE_STRING),
224:       string_hook_(std::move(string_hook)),
225:       string_default_for_display_(std::move(default_value_for_display)),
226:       usage_text_(usage_text) {}
227: 
228: bool Flag::Parse(string arg, bool* value_parsing_ok) const {
229:   bool result = false;
230:   if (type_ == TYPE_INT32) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/events_writer.cc" line="109" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [recordio_writer_] to null at line 102 implies that [recordio_writer_ ] might be null.Dereferencing null pointer [recordio_writer_]." web_identify="{&quot;identify&quot;:&quot;recordio_writer_&quot;}" func_info="void EventsWriter::WriteSerializedEvent ( StringPiece event_str )" content="99: }
100: 
101: void EventsWriter::WriteSerializedEvent(StringPiece event_str) {
102:   if (recordio_writer_ == nullptr) {
103:     if (!InitIfNeeded().ok()) {
104:       LOG(ERROR) &lt;&lt; &quot;Write failed because file could not be opened.&quot;;
105:       return;
106:     }
107:   }
108:   num_outstanding_events_++;
109:   recordio_writer_-&gt;WriteRecord(event_str).IgnoreError();
110: }
111: 
112: // NOTE(touts); This is NOT the function called by the Python code.
113: // Python calls WriteSerializedEvent(), see events_writer.i.
114: void EventsWriter::WriteEvent(const Event&amp; event) {
115:   string record;
116:   event.AppendToString(&amp;record);
117:   WriteSerializedEvent(record);
118: }
119: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/events_writer.cc" line="129" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [recordio_file_] to null at line 122 implies that [recordio_file_ ] might be null.Dereferencing null pointer [recordio_file_]. The error is in macros." web_identify="{&quot;identify&quot;:&quot;recordio_file_&quot;}" func_info="Status EventsWriter::Flush ( )" content="119: 
120: Status EventsWriter::Flush() {
121:   if (num_outstanding_events_ == 0) return Status::OK();
122:   CHECK(recordio_file_ != nullptr) &lt;&lt; &quot;Unexpected NULL file&quot;;
123: 
124:   TF_RETURN_WITH_CONTEXT_IF_ERROR(recordio_writer_-&gt;Flush(), &quot;Failed to flush &quot;,
125:                                   num_outstanding_events_, &quot; events to &quot;,
126:                                   filename_);
127:   TF_RETURN_WITH_CONTEXT_IF_ERROR(recordio_file_-&gt;Sync(), &quot;Failed to sync &quot;,
128:                                   num_outstanding_events_, &quot; events to &quot;,
129:                                   filename_);
130: 
131:   // The FileStillExists() condition is necessary because
132:   // recordio_writer_-&gt;Sync() can return OK even if the underlying
133:   // file has been deleted.  EventWriter.FileDeletionBeforeWriting
134:   // demonstrates this and will fail if the FileHasDisappeared()
135:   // condition is removed.
136:   // Also, we deliberately attempt to Sync() before checking for a
137:   // disappearing file, in case for some file system File::Exists() is
138:   // false after File::Open() but before File::Sync().
139:   TF_RETURN_WITH_CONTEXT_IF_ERROR(FileStillExists(), &quot;Failed to flush &quot;,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/presized_cuckoo_map.h" line="195" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CuckooPathQueue::queue_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CuckooPathQueue::queue_,&quot;}" func_info="tensorflow::PresizedCuckooMap::CuckooPathQueue" content="185:     int parent;       // To index in the visited array.
186:     int parent_slot;  // Which slot in our parent did we come from?  -1 == root.
187:   };
188: 
189:   // CuckooPathQueue is a trivial circular queue for path entries.
190:   // The caller is responsible for not inserting more than kMaxQueueSize
191:   // entries.  Each PresizedCuckooMap has one (heap-allocated) CuckooPathQueue
192:   // that it reuses across inserts.
193:   class CuckooPathQueue {
194:    public:
195:     CuckooPathQueue() : head_(0), tail_(0) {}
196: 
197:     void push_back(CuckooPathEntry e) {
198:       queue_[tail_] = e;
199:       tail_ = (tail_ + 1) % kMaxQueueSize;
200:     }
201: 
202:     CuckooPathEntry pop_front() {
203:       CuckooPathEntry&amp; e = queue_[head_];
204:       head_ = (head_ + 1) % kMaxQueueSize;
205:       return e;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/sparse/dim_comparator.h" line="49" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DimComparator::ix_order_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DimComparator::ix_order_,&quot;}" func_info="tensorflow::sparse::DimComparator" content="39: //    IX(ai,2) &lt; IX(bi,2).
40: // If IX(ai,2) == IX(bi,2), it compares
41: //    IX(ai,1) &lt; IX(bi,1).
42: //
43: // This can be used to sort a vector of row indices into IX according to
44: // the values in IX in particular columns (dimensions) of interest.
45: class DimComparator {
46:  public:
47:   typedef typename gtl::ArraySlice&lt;int64&gt; VarDimArray;
48: 
49:   DimComparator(const TTypes&lt;int64&gt;::Matrix&amp; ix, const VarDimArray&amp; order,
50:                 const VarDimArray&amp; shape)
51:       : ix_(ix), order_(order), dims_(shape.size()) {
52:     DCHECK_GT(order.size(), size_t{0}) &lt;&lt; &quot;Must order using at least one index&quot;;
53:     DCHECK_LE(order.size(), shape.size()) &lt;&lt; &quot;Can only sort up to dims&quot;;
54:     for (size_t d = 0; d &lt; order.size(); ++d) {
55:       DCHECK_GE(order[d], 0);
56:       DCHECK_LT(order[d], shape.size());
57:     }
58:   }
59: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/sparse/sparse_tensor.h" line="609" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [status] to null at line 602 implies that [status ] might be null.Dereferencing null pointer [status]." web_identify="{&quot;identify&quot;:&quot;status&quot;}" func_info="&gt; std::vector &lt; SparseTensor &gt; SparseTensor::Split ( const SparseTensor &amp; input_tensor , const int split_dim , const int num_split , Status * status )" content="599:   const int split_dim_size = input_tensor.shape()[split_dim];
600:   const int split_size = split_dim_size / num_split;
601: 
602:   if (!(num_split &gt; 0 &amp;&amp; num_split &lt;= split_dim_size) &amp;&amp; status != nullptr) {
603:     *status = Status(error::INVALID_ARGUMENT,
604:                      strings::StrCat(&quot;num_split must be in the interval (0, &quot;,
605:                                      split_dim_size, &quot;]&quot;));
606:     return {};
607:   }
608:   if (!(split_dim &gt;= 0 &amp;&amp; split_dim &lt; num_dim)) {
609:     *status = Status(
610:         error::INVALID_ARGUMENT,
611:         strings::StrCat(&quot;num_dim must be in the interval [0, &quot;, num_dim, &quot;)&quot;));
612:     return {};
613:   }
614: 
615:   const int residual = split_dim_size % num_split;
616:   for (int i = 0; i &lt; input_tensor.indices().dim_size(0); ++i) {
617:     const int dim = input_tensor.indices().matrix&lt;int64&gt;()(i, split_dim);
618:     int slice_index = GetSliceIndex(dim, split_size, residual);
619:     num_values[slice_index]++;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/sparse/sparse_tensor.h" line="615" id="compute" subid="ZeroDivision" severity="Serious" msg="Either the condition &apos;num_split&gt;0&apos; is redundant or there is division by zero at line 615." web_identify="" func_info="&gt; std::vector &lt; SparseTensor &gt; SparseTensor::Split ( const SparseTensor &amp; input_tensor , const int split_dim , const int num_split , Status * status )" content="605:                                      split_dim_size, &quot;]&quot;));
606:     return {};
607:   }
608:   if (!(split_dim &gt;= 0 &amp;&amp; split_dim &lt; num_dim)) {
609:     *status = Status(
610:         error::INVALID_ARGUMENT,
611:         strings::StrCat(&quot;num_dim must be in the interval [0, &quot;, num_dim, &quot;)&quot;));
612:     return {};
613:   }
614: 
615:   const int residual = split_dim_size % num_split;
616:   for (int i = 0; i &lt; input_tensor.indices().dim_size(0); ++i) {
617:     const int dim = input_tensor.indices().matrix&lt;int64&gt;()(i, split_dim);
618:     int slice_index = GetSliceIndex(dim, split_size, residual);
619:     num_values[slice_index]++;
620:   }
621: 
622:   for (int i = 0; i &lt; num_split; ++i) {
623:     // TODO(ataei): Pass an allocator to avoid allocating large memory buffer.
624:     output_indices.emplace_back(DT_INT64,
625:                                 TensorShape({num_values[i], num_dim}));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="867" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 862 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::Lookup ( StringPiece key , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="857:   if (ret != val) delete ret;
858:   return Status::OK();
859: }
860: 
861: Status BundleReader::Lookup(StringPiece key, Tensor* val) {
862:   CHECK(val != nullptr);
863:   BundleEntryProto entry;
864:   TF_RETURN_IF_ERROR(GetBundleEntryProto(key, &amp;entry));
865: 
866:   if (entry.slices().empty()) {
867:     return GetValue(entry, val);
868:   } else {
869:     return GetSliceValue(
870:         key, entry,
871:         /* a full slice */ TensorSlice(TensorShape(entry.shape()).dims()), val);
872:   }
873: }
874: 
875: Status BundleReader::ReadCurrent(Tensor* val) {
876:   CHECK(val != nullptr);
877:   BundleEntryProto entry;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="885" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 876 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::ReadCurrent ( Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="875: Status BundleReader::ReadCurrent(Tensor* val) {
876:   CHECK(val != nullptr);
877:   BundleEntryProto entry;
878:   TF_RETURN_IF_ERROR(ParseEntryProto(iter_-&gt;key(), iter_-&gt;value(), &amp;entry));
879:   if (!TensorShape::IsValid(entry.shape())) {
880:     return errors::DataLoss(&quot;Invaid tensor shape: &quot;, iter_-&gt;key(), &quot; &quot;,
881:                             ProtoShortDebugString(entry.shape()));
882:   }
883: 
884:   if (entry.slices().empty()) {
885:     return GetValue(entry, val);
886:   } else {
887:     return GetSliceValue(
888:         iter_-&gt;key(), entry,
889:         /* a full slice */ TensorSlice(TensorShape(entry.shape()).dims()), val);
890:   }
891: }
892: 
893: Status BundleReader::LookupTensorSlices(StringPiece key,
894:                                         std::vector&lt;TensorSlice&gt;* slices) {
895:   slices-&gt;clear();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/core/util/tensor_bundle/tensor_bundle.cc" line="910" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [val] to null at line 907 implies that [val ] might be null.Dereferencing null pointer [val]." web_identify="{&quot;identify&quot;:&quot;val&quot;}" func_info="Status BundleReader::LookupSlice ( StringPiece full_tensor_key , const TensorSlice &amp; slice_spec , Eigen::TensorMap &lt; Eigen::Tensor &lt; T , NDIMS , Eigen::RowMajor , IndexType &gt; , Eigen::Aligned &gt; * val )" content="900:     slices-&gt;emplace_back(slice);
901:   }
902:   return Status::OK();
903: }
904: 
905: Status BundleReader::LookupSlice(StringPiece full_tensor_key,
906:                                  const TensorSlice&amp; slice_spec, Tensor* val) {
907:   CHECK(val != nullptr);
908:   BundleEntryProto entry;
909:   TF_RETURN_IF_ERROR(GetBundleEntryProto(full_tensor_key, &amp;entry));
910:   return GetSliceValue(full_tensor_key, entry, slice_spec, val);
911: }
912: 
913: Status BundleReader::GetSliceValue(StringPiece full_tensor_key,
914:                                    const BundleEntryProto&amp; full_tensor_entry,
915:                                    const TensorSlice&amp; slice_spec, Tensor* val) {
916:   using checkpoint::RegisterTensorSlice;
917:   using checkpoint::TensorSliceSet;
918:   DCHECK_GE(full_tensor_entry.slices_size(), 0);
919: 
920:   const TensorShape full_shape(TensorShape(full_tensor_entry.shape()));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/examples/android/jni/object_tracking/frame_pair.h" line="27" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FramePair::optical_flow_found_keypoint_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FramePair::optical_flow_found_keypoint_,&quot;}" func_info="tf_tracking::FramePair" content="17: #define TENSORFLOW_EXAMPLES_ANDROID_JNI_OBJECT_TRACKING_FRAME_PAIR_H_
18: 
19: #include &quot;map/base/mlp/tf/tensorflow/examples/android/jni/object_tracking/keypoint.h&quot;
20: 
21: namespace tf_tracking {
22: 
23: // A class that records keypoint correspondences from pairs of
24: // consecutive frames.
25: class FramePair {
26:  public:
27:   FramePair()
28:       : start_time_(0),
29:         end_time_(0),
30:         number_of_keypoints_(0) {}
31: 
32:   // Cleans up the FramePair so that they can be reused.
33:   void Init(const int64_t start_time, const int64_t end_time);
34: 
35:   void AdjustBox(const BoundingBox box,
36:                  float* const translation_x,
37:                  float* const translation_y,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/examples/android/jni/object_tracking/object_tracker.cc" line="670" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [detector_] suggests that it may be null, but it has already been dereferenced at line 652." web_identify="{&quot;identify&quot;:&quot;detector_&quot;}" func_info="void ObjectTracker::TrackObjects ( )" content="660:         object-&gt;GetPosition(), frame_pairs_[GetNthIndexFromEnd(0)]);
661:     object-&gt;UpdatePosition(tracked_position, curr_time_, *frame2_, false);
662: 
663:     if (automatic_removal_allowed &amp;&amp;
664:         object-&gt;GetNumConsecutiveFramesBelowThreshold() &gt;
665:         kMaxNumDetectionFailures * 5) {
666:       dead_objects.push_back(iter-&gt;first);
667:     }
668:   }
669: 
670:   if (detector_ != NULL &amp;&amp; automatic_removal_allowed) {
671:     for (std::vector&lt;std::string&gt;::iterator iter = dead_objects.begin();
672:          iter != dead_objects.end(); iter++) {
673:       LOGE(&quot;Removing object! %s&quot;, iter-&gt;c_str());
674:       ForgetTarget(*iter);
675:     }
676:   }
677:   TimeLog(&quot;Tracked all objects.&quot;);
678: 
679:   LOGV(&quot;%zu objects tracked!&quot;, objects_.size());
680: }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/examples/speech_commands/test_streaming_accuracy.cc" line="233" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;clip_duration_mssample_rate*&quot;}" func_info="int main ( int argc , char * argv [ ] )" content="223:   if (!decode_wav_status.ok()) {
224:     LOG(ERROR) &lt;&lt; decode_wav_status;
225:     return -1;
226:   }
227:   if (channel_count != 1) {
228:     LOG(ERROR) &lt;&lt; &quot;Only mono .wav files can be used, but input has &quot;
229:                &lt;&lt; channel_count &lt;&lt; &quot; channels.&quot;;
230:     return -1;
231:   }
232: 
233:   const int64 clip_duration_samples = (clip_duration_ms * sample_rate) / 1000;
234:   const int64 clip_stride_samples = (clip_stride_ms * sample_rate) / 1000;
235:   Tensor audio_data_tensor(tensorflow::DT_FLOAT,
236:                            tensorflow::TensorShape({clip_duration_samples, 1}));
237: 
238:   Tensor sample_rate_tensor(tensorflow::DT_INT32, tensorflow::TensorShape({}));
239:   sample_rate_tensor.scalar&lt;int32&gt;()() = sample_rate;
240: 
241:   tensorflow::RecognizeCommands recognize_commands(
242:       labels_list, average_window_ms, detection_threshold, suppression_ms);
243: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/examples/speech_commands/test_streaming_accuracy.cc" line="234" id="logic" subid="UnintentionalOverflow" severity="Warning" msg="Potentially overflowing expression around operator [ * ], which is evaluated using 4 byte arithmetic, and then used in a context that expects an expression of 8 bytes type." web_identify="{&quot;identify&quot;:&quot;clip_stride_mssample_rate*&quot;}" func_info="int main ( int argc , char * argv [ ] )" content="224:     LOG(ERROR) &lt;&lt; decode_wav_status;
225:     return -1;
226:   }
227:   if (channel_count != 1) {
228:     LOG(ERROR) &lt;&lt; &quot;Only mono .wav files can be used, but input has &quot;
229:                &lt;&lt; channel_count &lt;&lt; &quot; channels.&quot;;
230:     return -1;
231:   }
232: 
233:   const int64 clip_duration_samples = (clip_duration_ms * sample_rate) / 1000;
234:   const int64 clip_stride_samples = (clip_stride_ms * sample_rate) / 1000;
235:   Tensor audio_data_tensor(tensorflow::DT_FLOAT,
236:                            tensorflow::TensorShape({clip_duration_samples, 1}));
237: 
238:   Tensor sample_rate_tensor(tensorflow::DT_INT32, tensorflow::TensorShape({}));
239:   sample_rate_tensor.scalar&lt;int32&gt;()() = sample_rate;
240: 
241:   tensorflow::RecognizeCommands recognize_commands(
242:       labels_list, average_window_ms, detection_threshold, suppression_ms);
243: 
244:   std::vector&lt;std::pair&lt;string, int64&gt;&gt; all_found_words;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/python/eager/pywrap_tfe_src.cc" line="1355" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;PyVSpace::num_elements_,aggregate_fn_,zeros_,ones_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;PyVSpace::num_elements_,aggregate_fn_,zeros_,ones_,&quot;}" func_info="PyVSpace" content="1345: 
1346: void TFE_Py_TapeSetDeleteTrace(tensorflow::int64 tensor_id) {
1347:   for (TFE_Py_Tape* tape : SafeTapeSet()) {
1348:     tape-&gt;tape-&gt;DeleteTrace(tensor_id);
1349:   }
1350: }
1351: 
1352: class PyVSpace
1353:     : public tensorflow::eager::VSpace&lt;PyObject, PyBackwardFunction&gt; {
1354:  public:
1355:   explicit PyVSpace(PyObject* py_vspace) : py_vspace_(py_vspace) {}
1356: 
1357:   tensorflow::Status Initialize() {
1358:     num_elements_ = PyObject_GetAttrString(py_vspace_, &quot;num_elements_fn&quot;);
1359:     if (num_elements_ == nullptr) {
1360:       return tensorflow::errors::InvalidArgument(&quot;invalid vspace&quot;);
1361:     }
1362:     aggregate_fn_ = PyObject_GetAttrString(py_vspace_, &quot;aggregate_fn&quot;);
1363:     if (aggregate_fn_ == nullptr) {
1364:       return tensorflow::errors::InvalidArgument(&quot;invalid vspace&quot;);
1365:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/python/eager/pywrap_tfe_src.cc" line="1697" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="PyObject * MaybeGetDTypeForAttr ( const string &amp; attr , FastPathOpExecInfo * op_exec_info )" content="1687:   if (cached_it != op_exec_info-&gt;cached_dtypes.end()) {
1688:     return GetPythonObjectFromInt(cached_it-&gt;second);
1689:   }
1690: 
1691:   auto it = op_exec_info-&gt;attr_to_inputs_map-&gt;find(attr);
1692:   if (it == op_exec_info-&gt;attr_to_inputs_map-&gt;end()) {
1693:     // No other inputs - this should never happen.
1694:     Py_RETURN_NONE;
1695:   }
1696: 
1697:   for (const auto&amp; input_info : it-&gt;second) {
1698:     PyObject* item = PyTuple_GET_ITEM(
1699:         op_exec_info-&gt;args, kFastPathExecuteInputStartIndex + input_info.i);
1700:     if (input_info.is_list) {
1701:       for (int i = 0; i &lt; PySequence_Fast_GET_SIZE(item); i++) {
1702:         auto* dtype = MaybeGetDType(PySequence_Fast_GET_ITEM(item, i));
1703:         if (dtype != nullptr) return dtype;
1704:       }
1705:     } else {
1706:       auto* dtype = MaybeGetDType(item);
1707:       if (dtype != nullptr) return dtype;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/python/grappler/cost_analyzer.cc" line="26" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;CostAnalyzer::total_time_measured_,total_time_analytical_,total_time_measured_serialized_,total_time_analytical_upper_,total_time_analytical_lower_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;CostAnalyzer::total_time_measured_,total_time_analytical_,total_time_measured_serialized_,total_time_analytical_upper_,total_time_analytical_lower_,&quot;}" func_info="tensorflow::grappler" content="16: #include &quot;tensorflow/python/grappler/cost_analyzer.h&quot;
17: 
18: #include &lt;iomanip&gt;
19: #include &quot;tensorflow/core/grappler/costs/utils.h&quot;
20: #include &quot;tensorflow/core/grappler/grappler_item.h&quot;
21: #include &quot;tensorflow/core/lib/core/status.h&quot;
22: 
23: namespace tensorflow {
24: namespace grappler {
25: 
26: CostAnalyzer::CostAnalyzer(const GrapplerItem&amp; item, Cluster* cluster,
27:                            const string&amp; suffix)
28:     : item_(&amp;item),
29:       measure_estimator_(cluster, 10, 0),
30:       analytical_estimator_(cluster, false),
31:       suffix_(suffix) {}
32: 
33: Status CostAnalyzer::GenerateReport(std::ostream&amp; os, bool per_node_report,
34:                                     bool verbose) {
35:   GatherCosts();
36:   PreprocessCosts();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2090" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2073 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemvWithProfilingImpl ( Stream * stream , blas::Transpose trans , long m , long n , const T &amp; alpha , const DeviceMemory &lt; T &gt; &amp; a , int lda , const DeviceMemory &lt; T &gt; &amp; x , int incx , const T &amp; beta , DeviceMemory &lt; T &gt; * y , int incy , blas::ProfileResult * output_profile_result )" content="2080:   // Call blasGemm
2081:   bool result =
2082:       DoBlasGemv(stream, trans, m, n, alpha, a, lda, x, incx, beta, y, incy);
2083: 
2084:   if (timer != nullptr &amp;&amp; result) {
2085:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2086:     // state.
2087:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2088:       return false;
2089:     }
2090:     output_profile_result-&gt;set_is_valid(true);
2091:     output_profile_result-&gt;set_algorithm(blas::kDefaultBlasGemv);
2092:     output_profile_result-&gt;set_elapsed_time_in_ms(
2093:         timer-&gt;GetElapsedMilliseconds());
2094:   }
2095:   return result;
2096: }
2097: 
2098: template &lt;typename T, typename ParamType&gt;
2099: bool CUDABlas::DoBlasGemmWithProfilingImpl(
2100:     Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64 m,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2122" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2105 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemmWithProfilingImpl ( Stream * stream , blas::Transpose transa , blas::Transpose transb , long m , long n , long k , const ParamType &amp; alpha , const DeviceMemory &lt; T &gt; &amp; a , int lda , const DeviceMemory &lt; T &gt; &amp; b , int ldb , const ParamType &amp; beta , DeviceMemory &lt; T &gt; * c , int ldc , blas::ProfileResult * output_profile_result )" content="2112:   // Call blasGemm
2113:   bool result = DoBlasGemm(stream, transa, transb, m, n, k, alpha, a, lda, b,
2114:                            ldb, beta, c, ldc);
2115: 
2116:   if (timer != nullptr &amp;&amp; result) {
2117:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2118:     // state.
2119:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2120:       return false;
2121:     }
2122:     output_profile_result-&gt;set_is_valid(true);
2123:     output_profile_result-&gt;set_algorithm(blas::kDefaultBlasGemm);
2124:     output_profile_result-&gt;set_elapsed_time_in_ms(
2125:         timer-&gt;GetElapsedMilliseconds());
2126:   }
2127:   return result;
2128: }
2129: 
2130: static bool UsesTensorOps(blas::AlgorithmType algo) {
2131: #if CUDA_VERSION &gt;= 9000
2132:   cublasGemmAlgo_t cublas_algo = static_cast&lt;cublasGemmAlgo_t&gt;(algo);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_blas.cc" line="2216" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [output_profile_result] to null at line 2177 implies that [output_profile_result ] might be null.Dereferencing null pointer [output_profile_result]." web_identify="{&quot;identify&quot;:&quot;output_profile_result&quot;}" func_info="&gt; bool CUDABlas::DoBlasGemmWithAlgorithmImpl ( Stream * stream , blas::Transpose transa , blas::Transpose transb , long m , long n , long k , const HostOrDeviceScalar &lt; CompT &gt; &amp; alpha , const DeviceMemory &lt; InT &gt; &amp; a , int lda , const DeviceMemory &lt; InT &gt; &amp; b , int ldb , const HostOrDeviceScalar &lt; CompT &gt; &amp; beta , DeviceMemory &lt; OutT &gt; * c , int ldc , blas::ComputationType computation_type , blas::AlgorithmType algorithm , blas::ProfileResult * output_profile_result )" content="2206:       CUDAMemoryMutable(c), CUDADataType&lt;OutT&gt;::type, ldc,
2207:       CUDAComputationType(computation_type),
2208:       static_cast&lt;cublasGemmAlgo_t&gt;(algorithm));
2209: 
2210:   if (timer != nullptr &amp;&amp; result) {
2211:     // CUDATimer will CHECK-fail if we Stop() it while the stream is in an error
2212:     // state.
2213:     if (!timer-&gt;Stop(AsCUDAStream(stream))) {
2214:       return false;
2215:     }
2216:     output_profile_result-&gt;set_is_valid(true);
2217:     output_profile_result-&gt;set_algorithm(algorithm);
2218:     output_profile_result-&gt;set_elapsed_time_in_ms(
2219:         timer-&gt;GetElapsedMilliseconds());
2220:   }
2221:   return result;
2222: }
2223: 
2224: bool CUDABlas::GetBlasGemmAlgorithms(
2225:     std::vector&lt;blas::AlgorithmType&gt; *out_algorithms) {
2226: // cublasGemmAlgo_t (and the function that accepts this type, cublasGemmEx)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_driver.cc" line="809" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [kernel_name] to null at line 806 implies that [kernel_name ] might be null.Dereferencing null pointer [kernel_name]." web_identify="{&quot;identify&quot;:&quot;kernel_name&quot;}" func_info="bool CUDADriver::GetModuleFunction ( CudaContext * context , CUmodule module , const char * kernel_name , CUfunction * function )" content="799: }
800: 
801: /* static */ bool CUDADriver::GetModuleFunction(CudaContext *context,
802:                                                 CUmodule module,
803:                                                 const char *kernel_name,
804:                                                 CUfunction *function) {
805:   ScopedActivateContext activated{context};
806:   CHECK(module != nullptr &amp;&amp; kernel_name != nullptr);
807:   CUresult res = cuModuleGetFunction(function, module, kernel_name);
808:   if (res != CUDA_SUCCESS) {
809:     LOG(ERROR) &lt;&lt; &quot;failed to get PTX kernel \&quot;&quot; &lt;&lt; kernel_name
810:                &lt;&lt; &quot;\&quot; from module: &quot; &lt;&lt; ToString(res);
811:     return false;
812:   }
813: 
814:   return true;
815: }
816: 
817: /* static */ bool CUDADriver::GetModuleSymbol(CudaContext* context,
818:                                               CUmodule module,
819:                                               const char *symbol_name,
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_driver.cc" line="829" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [symbol_name] to null at line 824 implies that [symbol_name ] might be null.Dereferencing null pointer [symbol_name]." web_identify="{&quot;identify&quot;:&quot;symbol_name&quot;}" func_info="bool CUDADriver::GetModuleSymbol ( CudaContext * context , CUmodule module , const char * symbol_name , CUdeviceptr * dptr , long * bytes )" content="819:                                               const char *symbol_name,
820:                                               CUdeviceptr *dptr,
821:                                               size_t *bytes) {
822:   ScopedActivateContext activated{context};
823:   CHECK(module != nullptr &amp;&amp; symbol_name != nullptr &amp;&amp;
824:         (dptr != nullptr || bytes != nullptr));
825:   CUresult res = cuModuleGetGlobal(dptr, bytes, module, symbol_name);
826:   if (res != CUDA_SUCCESS) {
827:     // symbol may not be found in the current module, but it may reside in
828:     // another module.
829:     VLOG(2) &lt;&lt; &quot;failed to get symbol \&quot;&quot; &lt;&lt; symbol_name
830:             &lt;&lt; &quot;\&quot; from module: &quot; &lt;&lt; ToString(res);
831:     return false;
832:   }
833: 
834:   return true;
835: }
836: 
837: /* static */ void CUDADriver::UnloadModule(CudaContext *context,
838:                                            CUmodule module) {
839:   ScopedActivateContext activated{context};
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc" line="112" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [cuda_exec] to null at line 111 implies that [cuda_exec ] might be null.Dereferencing null pointer [cuda_exec]." web_identify="{&quot;identify&quot;:&quot;cuda_exec&quot;}" func_info="CudaContext * cuda::ExtractCudaContext ( CUDAExecutor * cuda_exec )" content="102:   return reinterpret_cast&lt;CUdeviceptr&gt;(gpu_mem.opaque());
103: }
104: 
105: // See description on const version above.
106: static CUdeviceptr AsCudaDevicePtr(DeviceMemoryBase *gpu_mem) {
107:   return AsCudaDevicePtr(*gpu_mem);
108: }
109: 
110: CudaContext* ExtractCudaContext(CUDAExecutor *cuda_exec) {
111:   CHECK(cuda_exec != nullptr);
112:   return cuda_exec-&gt;cuda_context();
113: }
114: 
115: CUDAExecutor *ExtractCudaExecutor(StreamExecutor *stream_exec) {
116:   return static_cast&lt;CUDAExecutor *&gt;(stream_exec-&gt;implementation());
117: }
118: 
119: CUDAExecutor::~CUDAExecutor() {
120:   CHECK(kernel_to_gpu_binary_.empty()) &lt;&lt; &quot;CUDAExecutor has live kernels.&quot;;
121:   CHECK(gpu_binary_to_module_.empty()) &lt;&lt; &quot;CUDAExecutor has loaded modules.&quot;;
122:   if (context_ != nullptr) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/kernel.h" line="103" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;KernelMetadata::registers_per_thread_,shared_memory_bytes_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;KernelMetadata::registers_per_thread_,shared_memory_bytes_,&quot;}" func_info="stream_executor::KernelMetadata" content="93: class KernelInterface;
94: }  // namespace internal
95: 
96: // KernelMetadata holds runtime-queryable attributes of a loaded kernel, such as
97: // registers allocated, shared memory used, etc.
98: // Not all platforms support reporting of all information, so each accessor
99: // returns false if the associated field is not populated in the underlying
100: // platform.
101: class KernelMetadata {
102:  public:
103:   KernelMetadata()
104:       : has_registers_per_thread_(false), has_shared_memory_bytes_(false) {}
105: 
106:   // Returns the number of registers used per thread executing this kernel.
107:   bool registers_per_thread(int *registers_per_thread) const;
108: 
109:   // Sets the number of registers used per thread executing this kernel.
110:   void set_registers_per_thread(int registers_per_thread);
111: 
112:   // Returns the amount of [static] shared memory used per block executing this
113:   // kernel. Note that dynamic shared memory allocations are not (and can not)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/multi_platform_manager.cc" line="54" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [platform] to null at line 53 implies that [platform ] might be null.Dereferencing null pointer [platform]." web_identify="{&quot;identify&quot;:&quot;platform&quot;}" func_info="port::Status MultiPlatformManager::RegisterPlatform ( std::unique_ptr &lt; Platform &gt; platform )" content="44:     return port::Status(
45:         port::error::NOT_FOUND,
46:         port::Printf(&quot;could not find registered platform with id: 0x%p&quot;, id));
47:   }
48:   return it-&gt;second;
49: }
50: 
51: /* static */ port::Status MultiPlatformManager::RegisterPlatform(
52:     std::unique_ptr&lt;Platform&gt; platform) {
53:   CHECK(platform != nullptr);
54:   string key = port::Lowercase(platform-&gt;Name());
55:   mutex_lock lock(platforms_mutex_);
56:   if (GetPlatformMap()-&gt;find(key) != GetPlatformMap()-&gt;end()) {
57:     return port::Status(port::error::INTERNAL,
58:                         &quot;platform is already registered with name: \&quot;&quot; +
59:                             platform-&gt;Name() + &quot;\&quot;&quot;);
60:   }
61:   GetPlatformByIdMap()-&gt;insert(std::make_pair(platform-&gt;id(), platform.get()));
62:   // Release ownership/uniqueness to prevent destruction on program exit.
63:   // This avoids Platforms &quot;cleaning up&quot; on program exit, because otherwise,
64:   // there are _very_ tricky races between StreamExecutor and underlying
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/mlp/tf/tensorflow/stream_executor/temporary_memory_manager.h" line="58" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;TemporaryMemoryManager::generation_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;TemporaryMemoryManager::generation_,&quot;}" func_info="stream_executor::internal::TemporaryMemoryManager" content="48:   // synchronization time.
49:   bool finalized;
50: };
51: 
52: // Manages temporary memories associated with a stream -- keeps records of
53: // outstanding temporaries and their state, and can deallocate them
54: // appropriately at points in the Stream lifecycle (e.g. BlockHostUntilDone,
55: // destruction).
56: class TemporaryMemoryManager {
57:  public:
58:   explicit TemporaryMemoryManager(Stream* stream) : stream_(stream) {}
59: 
60:   // Allocates a temporary array that is then managed by this object.
61:   template &lt;typename T&gt;
62:   port::StatusOr&lt;std::unique_ptr&lt;TemporaryDeviceMemory&lt;T&gt;&gt;&gt; AllocateArray(
63:       uint64 element_count);
64: 
65:   // Forces deallocation of all managed temporary memory regions.
66:   //
67:   // Called, for example, when the Stream owning this temporary memory manager
68:   // is destroyed.
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="11633" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_parser::_scratch,_error_handler,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_parser::_scratch,_error_handler,&quot;}" func_info="xpath_parser" content="11623: 		//					| AdditiveExpr &apos;-&apos; MultiplicativeExpr
11624: 		// MultiplicativeExpr ::= UnaryExpr
11625: 		//						  | MultiplicativeExpr &apos;*&apos; UnaryExpr
11626: 		//						  | MultiplicativeExpr &apos;div&apos; UnaryExpr
11627: 		//						  | MultiplicativeExpr &apos;mod&apos; UnaryExpr
11628: 		xpath_ast_node* parse_expression()
11629: 		{
11630: 			return parse_expression_rec(parse_path_or_unary_expression(), 0);
11631: 		}
11632: 
11633: 		xpath_parser(const char_t* query, xpath_variable_set* variables, xpath_allocator* alloc, xpath_parse_result* result): _alloc(alloc), _lexer(query), _query(query), _variables(variables), _result(result)
11634: 		{
11635: 		}
11636: 
11637: 		xpath_ast_node* parse()
11638: 		{
11639: 			xpath_ast_node* result = parse_expression();
11640: 
11641: 			if (_lexer.current() != lex_eof)
11642: 			{
11643: 				// there are still unparsed tokens left, error
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="11750" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_node::_attribute,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_node::_attribute,&quot;}" func_info="pugi" content="11740: 	PUGI__FN const xpath_parse_result&amp; xpath_exception::result() const
11741: 	{
11742: 		return _result;
11743: 	}
11744: #endif
11745: 
11746: 	PUGI__FN xpath_node::xpath_node()
11747: 	{
11748: 	}
11749: 
11750: 	PUGI__FN xpath_node::xpath_node(const xml_node&amp; node_): _node(node_)
11751: 	{
11752: 	}
11753: 
11754: 	PUGI__FN xpath_node::xpath_node(const xml_attribute&amp; attribute_, const xml_node&amp; parent_): _node(attribute_ ? parent_ : xml_node()), _attribute(attribute_)
11755: 	{
11756: 	}
11757: 
11758: 	PUGI__FN xml_node xpath_node::node() const
11759: 	{
11760: 		return _attribute ? xml_node() : _node;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="391" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [_items] suggests that it may be null, but it has already been dereferenced at line 388." web_identify="{&quot;identify&quot;:&quot;_items&quot;}" func_info="bool compact_hash_table::rehash ( )" content="381: 
382: 		if (!rt._items)
383: 			return false;
384: 
385: 		memset(rt._items, 0, sizeof(item_t) * rt._capacity);
386: 
387: 		for (size_t i = 0; i &lt; _capacity; ++i)
388: 			if (_items[i].key)
389: 				*rt.insert(_items[i].key) = _items[i].value;
390: 
391: 		if (_items)
392: 			xml_memory::deallocate(_items);
393: 
394: 		_capacity = rt._capacity;
395: 		_items = rt._items;
396: 
397: 		assert(_count == rt._count);
398: 
399: 		return true;
400: 	}
401: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="7501" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_stack_data::error_handler,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_stack_data::error_handler,&quot;}" func_info="xpath_stack_data" content="7491: 	{
7492: 		xpath_memory_block blocks[2];
7493: 		xpath_allocator result;
7494: 		xpath_allocator temp;
7495: 		xpath_stack stack;
7496: 
7497: 	#ifdef PUGIXML_NO_EXCEPTIONS
7498: 		jmp_buf error_handler;
7499: 	#endif
7500: 
7501: 		xpath_stack_data(): result(blocks + 0), temp(blocks + 1)
7502: 		{
7503: 			blocks[0].next = blocks[1].next = 0;
7504: 			blocks[0].capacity = blocks[1].capacity = sizeof(blocks[0].data);
7505: 
7506: 			stack.result = &amp;result;
7507: 			stack.temp = &amp;temp;
7508: 
7509: 		#ifdef PUGIXML_NO_EXCEPTIONS
7510: 			result.error_handler = temp.error_handler = &amp;error_handler;
7511: 		#endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="8378" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_variable_boolean::name,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_variable_boolean::name,&quot;}" func_info="xpath_variable_boolean" content="8368: 		return write;
8369: 	}
8370: 
8371: 	inline bool is_xpath_attribute(const char_t* name)
8372: 	{
8373: 		return !(starts_with(name, PUGIXML_TEXT(&quot;xmlns&quot;)) &amp;&amp; (name[5] == 0 || name[5] == &apos;:&apos;));
8374: 	}
8375: 
8376: 	struct xpath_variable_boolean: xpath_variable
8377: 	{
8378: 		xpath_variable_boolean(): xpath_variable(xpath_type_boolean), value(false)
8379: 		{
8380: 		}
8381: 
8382: 		bool value;
8383: 		char_t name[1];
8384: 	};
8385: 
8386: 	struct xpath_variable_number: xpath_variable
8387: 	{
8388: 		xpath_variable_number(): xpath_variable(xpath_type_number), value(0)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="8388" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_variable_number::name,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_variable_number::name,&quot;}" func_info="xpath_variable_number" content="8378: 		xpath_variable_boolean(): xpath_variable(xpath_type_boolean), value(false)
8379: 		{
8380: 		}
8381: 
8382: 		bool value;
8383: 		char_t name[1];
8384: 	};
8385: 
8386: 	struct xpath_variable_number: xpath_variable
8387: 	{
8388: 		xpath_variable_number(): xpath_variable(xpath_type_number), value(0)
8389: 		{
8390: 		}
8391: 
8392: 		double value;
8393: 		char_t name[1];
8394: 	};
8395: 
8396: 	struct xpath_variable_string: xpath_variable
8397: 	{
8398: 		xpath_variable_string(): xpath_variable(xpath_type_string), value(0)
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/deps/pugixml/src/pugixml.cpp" line="8398" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;xpath_variable_string::name,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;xpath_variable_string::name,&quot;}" func_info="xpath_variable_string" content="8388: 		xpath_variable_number(): xpath_variable(xpath_type_number), value(0)
8389: 		{
8390: 		}
8391: 
8392: 		double value;
8393: 		char_t name[1];
8394: 	};
8395: 
8396: 	struct xpath_variable_string: xpath_variable
8397: 	{
8398: 		xpath_variable_string(): xpath_variable(xpath_type_string), value(0)
8399: 		{
8400: 		}
8401: 
8402: 		~xpath_variable_string()
8403: 		{
8404: 			if (value) xml_memory::deallocate(value);
8405: 		}
8406: 
8407: 		char_t* value;
8408: 		char_t name[1];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/include/utils/maxheap.h" line="61" id="memleak" subid="memleakOnRealloc" severity="Warning" msg="Common realloc mistake: &apos;arr&apos; nulled but not freed upon failure" web_identify="{&quot;identify&quot;:&quot;arr&quot;}" func_info="" content="51:   size_t get_size() const {
52:     return arrsize;
53:   }
54:   /** \brief push a new element in the heap and resize the data structure if it is full
55:    * @param key ordering key of the new element
56:    * @param val value of the new element
57:    */
58:   void push(const double &amp;key, const val_t &amp;val) {
59:     if (++arrsize == maxsize) {
60:       maxsize = 2 * maxsize + 1;
61:       arr = (item *) realloc(arr, sizeof(item) * maxsize);
62:     }
63:     size_t p = arrsize;
64:     while (key &gt; arr[p &gt;&gt; 1].key) {
65:       arr[p] = arr[p &gt;&gt; 1];
66:       p &gt;&gt;= 1;
67:     }
68:     arr[p] = item(key, val);
69:   }
70:   /** \brief remove the element on the top of the heap, i.e. the element with max key value
71:    */
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/src/driver/driver.cc" line="266" id="nullpointer" subid="dereferenceBeforeCheck" severity="Serious" msg="Null - checking [opt_algorithm] suggests that it may be null, but it has already been dereferenced at line 264." web_identify="{&quot;identify&quot;:&quot;opt_algorithm&quot;}" func_info="void Driver::optimization_phase ( std::shared_ptr &lt; quickrank::optimization::Optimization &gt; opt_algorithm , std::shared_ptr &lt; learning::LTR_Algorithm &gt; ranking_algo , std::shared_ptr &lt; quickrank::metric::ir::Metric &gt; train_metric , std::shared_ptr &lt; quickrank::data::Dataset &gt; training_dataset , std::shared_ptr &lt; quickrank::data::Dataset &gt; validation_dataset , std::string training_partial_filename , std::string validation_partial_filename , const std::string output_filename , const std::string opt_algo_model_filename , const long npartialsave )" content="256:     const std::string output_filename,
257:     const std::string opt_algo_model_filename,
258:     const size_t npartialsave) {
259: 
260:   std::shared_ptr&lt;quickrank::data::Dataset&gt; training_partial_dataset;
261:   std::shared_ptr&lt;quickrank::data::Dataset&gt; validation_partial_dataset;
262: 
263:   // Variable meaning the algo needs partial scores
264:   bool need_ps = opt_algorithm-&gt;need_partial_score_dataset();
265: 
266:   if (opt_algorithm &amp;&amp; need_ps) {
267: 
268:     if (!training_partial_filename.empty() &amp;&amp;
269:         file_exist(training_partial_filename))
270:       training_partial_dataset = load_dataset(training_partial_filename,
271:                                               &quot;training (partial)&quot;);
272: 
273:     if (!validation_partial_filename.empty() &amp;&amp;
274:         file_exist(validation_partial_filename))
275:       validation_partial_dataset = load_dataset(validation_partial_filename,
276:                                                 &quot;validation (partial)&quot;);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/src/learning/forests/rankboost.cc" line="581" id="logic" subid="selfAssignment" severity="Warning" msg="Redundant assignment of &apos;weights[i]&apos; to itself." web_identify="{&quot;identify&quot;:&quot;weights[i]&quot;}" func_info="std::vector &lt; double &gt; Rankboost::get_weights ( ) const" content="571: 
572:   for (unsigned int t = 0; t &lt; best_T; t++)
573:     alphas[t] = weights[t];
574: 
575:   return true;
576: }
577: 
578: std::vector&lt;double&gt; Rankboost::get_weights() const {
579:   std::vector&lt;double&gt; weights(best_T);
580:   for (unsigned int i = 0; i &lt; best_T; ++i)
581:     weights[i] = weights[i];
582:   return weights;
583: }
584: 
585: } // namespace forests
586: } // namespace learning
587: } // namespace quickrank
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/quickrank/src/learning/tree/rt.cc" line="222" id="memleak" subid="deallocDealloc" severity="Warning" msg="Deallocating a deallocated pointer: featuresamples" web_identify="{&quot;identify&quot;:&quot;featuresamples&quot;}" func_info="" content="212:     double best_score = thread_best_score[0];
213:     size_t best_featureidx = thread_best_featureidx[0];
214:     size_t best_thresholdid = thread_best_thresholdid[0];
215:     for (int i = 1; i &lt; nth; ++i)
216:       if (thread_best_score[i] &gt; best_score)
217:         best_score = thread_best_score[i], best_featureidx =
218:             thread_best_featureidx[i], best_thresholdid =
219:             thread_best_thresholdid[i];
220:     // free some memory
221:     delete[] thread_best_score;
222:     delete[] featuresamples;
223:     delete[] thread_best_featureidx;
224:     delete[] thread_best_thresholdid;
225:     //if minvar is the same of initvalue then the node is unsplitable
226:     if (best_score == initvar)
227:       return false;
228: 
229:     //set some result values related to minvar
230:     const size_t last_thresholdidx = h-&gt;thresholds_size[best_featureidx]
231:         - 1;
232:     const float best_threshold =
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/util/digital_text_conversion/digital_text_conversion.cpp" line="156" id="logic" subid="selfAssignment" severity="Warning" msg="Redundant assignment of &apos;arab_digit&apos; to itself." web_identify="{&quot;identify&quot;:&quot;arab_digit&quot;}" func_info="std::wstring digital_text_conversion::CNDigitToArab ( const std :: wstring &amp; in_w )" content="146:             auto cn_digit_match = NextCNDigit(arab_digit, search_begin);
147:             if (cn_digit_match.first == std::wstring::npos) {
148:                 break;
149:             }
150:             auto arab_digit_tmp = CNDigitToArabInternal(arab_digit.substr(
151:                 cn_digit_match.first, cn_digit_match.second));
152:             arab_digit.replace(cn_digit_match.first, cn_digit_match.second,
153:                                arab_digit_tmp);
154:             search_begin = cn_digit_match.first + arab_digit_tmp.size() + 1;
155:         }
156:         arab_digit = arab_digit;
157:     } while (false);
158:     return arab_digit;
159: }
160: 
161: std::string CNDigitToArab(const std::string&amp; in) {
162:     std::wstring in_w;
163:     if (!UTF8ToWide(in.c_str(), in.size(), &amp;in_w)) {
164:         return in;
165:     }
166:     std::wstring arab_digit = CNDigitToArab(in_w);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/base/util/threadsafe_queue.hpp" line="198" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;(&quot;}" func_info="&gt; long ThreadsafeQueue::pop_bulk_util ( It insert_iter , long max , std :: chrono :: time_point &lt; Clock , Duration &gt; const &amp; abs_time )" content="188:     }
189: 
190:     template &lt;typename It, typename Clock, typename Duration&gt;
191:     ssize_t pop_bulk_util(
192:         It insert_iter, size_t max,
193:         std::chrono::time_point&lt;Clock, Duration&gt; const&amp; abs_time) {
194:         size_t insert_size = 0;
195:         while (true) {
196:             std::unique_lock&lt;std::mutex&gt; lock(queue_mutex_);
197:             if (!new_item_or_closed_event_.wait_until(lock, abs_time, [&amp;]() {
198:                     return (is_closed_ || !queue_.empty());
199:                 })) {
200:                 return insert_size;
201:             }
202:             if (is_closed_) {
203:                 return -1;
204:             }
205:             while (!queue_.empty() &amp;&amp; max &gt; insert_size) {
206:                 *insert_iter = std::move(queue_.front());
207:                 queue_.pop();
208:                 ++insert_size;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geocoding/addr_analy/normalize/township_segs.cc" line="73" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [tlist] to null at line 68 implies that [tlist ] might be null.Dereferencing null pointer [tlist]." web_identify="{&quot;identify&quot;:&quot;tlist&quot;}" func_info="void ProvinceCorpusGenerate ( const std::vector &lt; std::string &gt; &amp; all_corpus_lines , const std::string &amp; provinceid , const std::string &amp; province , const mtmap::GeoTextParser &amp; parser )" content="63:     std::vector&lt;std::string&gt; linesegs;
64:     SplitString(lines[i], &apos;\t&apos;, &amp;linesegs);
65:     //std::cout &lt;&lt; linesegs[0] &lt;&lt; &quot;:&quot; &lt;&lt; linesegs[1] &lt;&lt; std::endl;
66:     mtmap::MTokenList *tlist = parser.process(linesegs[0], &quot;analyzer_search&quot;);
67:     
68:     if (!tlist) {
69:       std::cout &lt;&lt; &quot;geotext precess failed! query:&quot; &lt;&lt; linesegs[0] &lt;&lt; &quot;\n&quot;;
70:     }
71:     
72:     std::string linestr;
73:     for(mtmap::MToken* token = tlist-&gt;head(); token != NULL; token = token-&gt;next()) {
74:       linestr += token-&gt;getTokenStr();
75:       if (token-&gt;next()) {
76:         linestr += &quot; &quot;;
77:       }
78:     }
79:     if (tlist) {
80:       delete tlist;
81:     }
82: 
83:     linestr += &quot;\t__label__&quot;;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geocoding/basecode/esclient/address_converter.h" line="31" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;Ctx::valueBuffer,parseBuffer,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;Ctx::valueBuffer,parseBuffer,&quot;}" func_info="esclient::AddrConverter::Ctx" content="21: class AddrConverter {
22:    public:
23:     typedef bool (AddrConverter::*AddrDataConverter)(
24:         const rapidjson::Value&amp;, mtmap::geocoding::AddrResult*);
25:     explicit AddrConverter();
26:     ~AddrConverter();
27: 
28:    public:
29:     class Ctx {
30:        public:
31:         Ctx()
32:             : valueAllocator(valueBuffer, sizeof(valueBuffer)),
33:               parseAllocator(parseBuffer, sizeof(parseBuffer)),
34:               speed_up_d(&amp;valueAllocator, sizeof(parseBuffer),
35:                          &amp;parseAllocator) {}
36: 
37:         // 解析tokenlist object时复用栈内存，提升性能
38:        private:
39:         char valueBuffer[4096];
40:         char parseBuffer[1024];
41:         rapidjson::MemoryPoolAllocator&lt;&gt; valueAllocator;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geocoding/geotext/src/admincoder.cpp" line="27" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;AdminInfo::alias,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;AdminInfo::alias,&quot;}" func_info="mtmap" content="17: 
18: #include &quot;third_party/octo/rapidjson/document.h&quot;
19: #include &quot;third_party/octo/rapidjson/istreamwrapper.h&quot;
20: 
21: #include &quot;string_utility.h&quot;
22: #include &quot;pinyin.h&quot;
23: #include &quot;admincoder.h&quot;
24: 
25: namespace mtmap {
26: 
27: AdminCoder::AdminInfo::AdminInfo(const AdminCoder::AdminInfo&amp; rh) :
28:                                 province_id(rh.province_id),
29:                                 province(rh.province),
30:                                 city_id(rh.city_id),
31:                                 city(rh.city),
32:                                 district_id(rh.district_id),
33:                                 district(rh.district),
34:                                 location(rh.location),
35:                                 admin_id_mt(rh.admin_id_mt),
36:                                 admin_id_dp(rh.admin_id_dp)
37: {
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geocoding/geotext/src/spelling_correction.cpp" line="129" id="bufoverrun" subid="arrayIndexThenCheck" severity="Critical" msg="Array index &apos;i&apos; is used before limits check." web_identify="{&quot;identify&quot;:&quot;i&quot;}" func_info="double SpellingCorrection::correction ( std::string &amp; result , const std::string &amp; text )" content="119: 
120:     /*
121:     std::cout &lt;&lt; &quot;beam_prob=&quot; &lt;&lt; prob
122:               &lt;&lt; &quot; confidence=&quot; &lt;&lt; confidence &lt;&lt; std::endl;
123:     printProb(words);
124:     printProb(res);
125:     */
126: 
127:     for (size_t i = 1; i &lt; res.size(); i++) {
128:         if ((res[i] == kAlpha || res[i] == kDigit || res[i] == kPunc
129:                     ) &amp;&amp; i &lt; original_words.size()) {
130:             res[i] = original_words[i];
131:         }
132:         result.append(res[i]);
133:     }
134: 
135:     if (result == text) confidence = 0.990000;
136: 
137:     return confidence;
138: }
139: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geodbus/src/handler.cpp" line="844" id="nullpointer" subid="invalidDereferenceIterator" severity="Serious" msg="Iterator [it] may be invalid here." web_identify="{&quot;identify&quot;:&quot;it&quot;}" func_info="bool GeoDbusServletHandler::fillEsData ( EsData &amp; ed , const std::map &lt; std::string , std::string &gt; &amp; metaJsonData , const std::string &amp; dataMapJson )" content="834:     case 1:  // way
835:         flag = mysqlToEsWay(ed, dataMapJson);
836:         break;
837:     case 2:  // area
838:         flag = mysqlToEsArea(ed, dataMapJson);
839:         break;
840:     case 3:  // Admin
841:         flag = mysqlToEsAdmin(ed, dataMapJson);
842:         break;
843:     default :
844:         GEO_LOG_WARN &lt;&lt; &quot;tableName:&quot; &lt;&lt; it-&gt;second &lt;&lt; &quot; no exist ignore!\n&quot;;
845:         return false;
846:     }
847: 
848: #if 0
849:     Json::FastWriter writer;
850:     std::string lstr = writer.write(ed.body);
851:     std::cout &lt;&lt; __func__ &lt;&lt; &quot; index:&quot; &lt;&lt; ed.index
852:               &lt;&lt; &quot; type:&quot; &lt;&lt; ed.type
853:               &lt;&lt; &quot; body:&quot; &lt;&lt; lstr &lt;&lt; &quot;\n&quot;;
854: #endif
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geodbus/src/server.cpp" line="52" id="suspicious" subid="autovar" severity="Warning" msg="Returning the address of a stack variable [server]." web_identify="{&quot;identify&quot;:&quot;server&quot;}" func_info="bool initServer ( const Config * conf )" content="42:     try {
43:         // 更多参数设置
44:         CthriftSvr server(conf-&gt;appkey, processor,
45:                           static_cast&lt;uint16_t&gt;(conf-&gt;server_port),
46:                           conf-&gt;server_single,  // 业务逻辑是否只能单线程运行
47:                           conf-&gt;server_timeout,    // 毫秒, 服务端超时时间, 只用作日志告警输出
48:                           100000,  // 服务最大链接数
49:                           static_cast&lt;int16_t&gt;(conf-&gt;server_worker_threads),
50:                           &quot;mtmap.geodbus.GeoDbusServlet&quot;);
51: 
52:         g_var-&gt;server = &amp;server;
53:         
54:         // 60*24*2 min
55:         //server.SetConnGCInterval(2880.0);
56:         server.serve();
57:     } catch(const cthrift::TException &amp;tx) {
58:         LOG_ERROR &lt;&lt; tx.what();
59:         return false;
60:     }
61:     
62:     return true;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geodbus/src/sql2es.cpp" line="580" id="memleak" subid="resourceLeak" severity="Warning" msg="Resource leak: pDir" web_identify="{&quot;identify&quot;:&quot;pDir&quot;}" func_info="" content="570:                 sprintf(childpath, &quot;%s/%s&quot;, path, ent-&gt;d_name);
571:                 listDir(childpath,files);
572:             }
573:         } else {
574:             sprintf(absolutepath, &quot;%s/%s&quot;, path, ent-&gt;d_name);
575:             files.push_back(absolutepath);
576:         }
577:     }
578: 
579:     //sort(files.begin(),files.end());//排序
580: }
581: 
582: 
583: 
584: int
585: main(int argc, char **argv) {
586:     // init gorvar
587:     Gorvar gvar;
588:     g_var = &amp;gvar;
589: 
590:     // init conf
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/base_builder/base_builder_input.cpp" line="33" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BaseBuilderInput::is_short_query_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BaseBuilderInput::is_short_query_,&quot;}" func_info="mtmap::geoinfo::base_builder" content="23: using mtmap::geoinfo::util::admin_util::GetCityByLocation;
24: using mtmap::geoinfo::util::admin_util::GetAdminInfoFromQuery;
25: using mtmap::geotext::adapter::Token;
26: using mtmap::geotext::adapter::TokenList;
27: using mtmap::geotext::adapter::TokenTag;
28: using osmium::geom::Coordinates;
29: 
30: namespace mtmap {
31: namespace geoinfo {
32: namespace base_builder {
33: BaseBuilderInput::BaseBuilderInput()
34:     : admin_info_ptr_(nullptr),
35:       location_admin_info_(nullptr),
36:       query_admin_info_(nullptr),
37:       merge_children_(false),
38:       is_cross_recall_(false),
39:       is_general_script_(true),
40:       is_cross_city_(false),
41:       token_list_cache_map_(new std::map&lt;std::string, TokenList&gt;),
42:       time_tracer_(nullptr) {}
43: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/base_builder/base_builder_output.cpp" line="12" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;BaseBuilderOutput::code,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;BaseBuilderOutput::code,&quot;}" func_info="mtmap::geoinfo::base_builder" content="2:  * Copyright (c) 2018 Meituan Inc. All rights reserved.
3:  */
4: /**
5:  * Author            : Ma Xiaowei &lt;maxiaowei05@meituan.com&gt;
6:  * Date              : 2018-09-05 10:39:23
7:  */
8: #include &quot;map/geoinfo/base_builder/base_builder_output.h&quot;
9: namespace mtmap {
10: namespace geoinfo {
11: namespace base_builder {
12: BaseBuilderOutput::BaseBuilderOutput() {
13:     cross_city = false;
14:     short_query = false;
15: }
16: }  // namespace base_builder
17: }  // namespace geoinfo
18: }  // namespace mtmap
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/base_builder/common_builder.cpp" line="242" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [usr_loc] to null at line 238 implies that [usr_loc ] might be null.Dereferencing null pointer [usr_loc]." web_identify="{&quot;identify&quot;:&quot;usr_loc&quot;}" func_info="void CommonBuilder::BuilderTypeFilter ( const BaseBuilderRequest &amp; req , const search_config &amp; conf , bool cross_city , bool local_request , int type , recall::RecallBasePtr recall )" content="232:             type == SHORT_BUILDER) {
233:             break;
234:         }
235:         if (!local_request) {
236:             break;
237:         }
238:         if (usr_loc != nullptr) {
239:             break;
240:         }
241:         NearbyBoundary near_by;
242:         near_by.centre_point = *usr_loc;
243:         near_by.__set_radius(20000);
244:         if (type == CHINESE_BUILDER &amp;&amp;
245:             conf.filter_conf().has_normal_freq_filter()) {
246:             recall-&gt;AddDocFreqFilter(conf.filter_conf().normal_freq_filter(),
247:                                      req.token_list, near_by);
248:         }
249:         if (type == RETRY_BUILDER &amp;&amp;
250:             conf.filter_conf().has_retry_freq_filter()) {
251:             recall-&gt;AddDocFreqFilter(conf.filter_conf().retry_freq_filter(),
252:                                      req.token_list, near_by);
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/doc_corr_score/doc_corr_score.cpp" line="42" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;DocCorrScore::bm_para_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;DocCorrScore::bm_para_,&quot;}" func_info="mtmap::geoinfo::doc_corr_score" content="32: using esclient::builder::termvectors::termvectors_builders::
33:     CreateMultiTermVectosBuilder;
34: using mtmap::geotext::adapter::Token;
35: using mtmap::geotext::adapter::TokenList;
36: using esclient::builder::query::QueryBuilders;
37: using esclient::request::SearchRequest;
38: 
39: namespace mtmap {
40: namespace geoinfo {
41: namespace doc_corr_score {
42: DocCorrScore::DocCorrScore() : es_executor_(nullptr) {}
43: 
44: DocCorrScore::~DocCorrScore() { StopBmParaRefreshTimer(); }
45: 
46: bool DocCorrScore::Init(const std::string&amp; index) {
47:     index_ = index;
48:     es_executor_ = ElasticSearchExecutor::GetInstance();
49:     if (!RefreshBmPara()) {
50:         CLOG_STR_ERROR(&quot;init bm_para_ faild&quot;);
51:         return false;
52:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/pipeline/osm2sql/src/category.h" line="181" id="logic" subid="STLFindError" severity="Warning" msg="Using int as return type of string::find is dangerous, it should use size_t instead." web_identify="{&quot;identify&quot;:&quot;.&quot;}" func_info="bool CategoryMap::analyseLine ( const std :: string &amp; line )" content="171: //        if (index-last&gt;0) {
172: //            ret-&gt;push_back(s.substr(last,index-last));
173: //        }
174: //    }
175: 
176: 
177:     bool analyseLine(const std::string &amp; line) {
178:         if (line.empty())
179:             return false;
180:         int start_pos = 0, end_pos = line.size() - 1, pos;
181:         if ((pos = line.find(COMMENT_CHAR)) != -1) {
182:             if (0 == pos) {  // 行的第一个字符就是注释字符
183:                 return false;
184:             }
185:             end_pos = pos - 1;
186:         }
187:         std::string new_line = line.substr(start_pos, start_pos + 1 - end_pos);  // 预处理，删除注释部分
188: 
189:         std::vector&lt;std::string&gt; res;
190: //        split(new_line, std::string(&quot;\t&quot;), &amp;res);
191:         split(res, new_line, boost::is_any_of(&quot;\t&quot;));
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/pipeline/osm2sql/src/sqlkv.h" line="17" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;wvalue::is_has,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;wvalue::is_has,&quot;}" func_info="wvalue" content="7: #ifndef MAP_GEOINFO_PIPELINE_OSM2SQL_SRC_SQLKV_H_
8: #define MAP_GEOINFO_PIPELINE_OSM2SQL_SRC_SQLKV_H_
9: 
10: #include&lt;string&gt;
11: #include&lt;map&gt;
12: #include &quot;third_party/osmium/osmium/builder/osm_object_builder.hpp&quot;
13: #include &quot;third_party/jsoncpp/include/json.h&quot;
14: 
15: class wvalue {
16:   public:
17:     wvalue(): is_str(true){};
18:     wvalue(std::string s, bool b): v(s), is_str(b) {};
19:     wvalue(std::string s, bool ih, bool is): v(s), is_has(ih), is_str(is) {};
20:     std::string v;
21:     bool is_has;
22:     bool is_str;
23: };
24: 
25: 
26: class SqlKv {
27:   private:
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/pipeline/osm2sql/src/sqlkv.h" line="18" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;wvalue::is_has,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;wvalue::is_has,&quot;}" func_info="wvalue" content="8: #define MAP_GEOINFO_PIPELINE_OSM2SQL_SRC_SQLKV_H_
9: 
10: #include&lt;string&gt;
11: #include&lt;map&gt;
12: #include &quot;third_party/osmium/osmium/builder/osm_object_builder.hpp&quot;
13: #include &quot;third_party/jsoncpp/include/json.h&quot;
14: 
15: class wvalue {
16:   public:
17:     wvalue(): is_str(true){};
18:     wvalue(std::string s, bool b): v(s), is_str(b) {};
19:     wvalue(std::string s, bool ih, bool is): v(s), is_has(ih), is_str(is) {};
20:     std::string v;
21:     bool is_has;
22:     bool is_str;
23: };
24: 
25: 
26: class SqlKv {
27:   private:
28:     // in
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/pipeline/osm2sql/src/sqlkv.h" line="53" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SqlKv::m_id,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SqlKv::m_id,&quot;}" func_info="SqlKv" content="43:     bool FmtWay();
44:     bool FmtArea();
45:     bool FmtAdmin();
46:     bool FmtPchild();
47:     bool ToGeodbus();
48:     bool FmtStatus();
49:   public:
50:     std::map&lt;std::string, wvalue&gt; m_map;
51:     std::string m_mysql;    // use mysql
52:     std::string m_geodbus;  // use geodbus
53:     explicit SqlKv(int t) {
54:         SetType(t);
55:     }
56: 
57:     bool SetIsMerge(bool b);
58:     bool SetType(int t);
59:     int GetType();
60:     bool SetGeoDbusOp(int t);
61:     bool SetGeoDbusOp(std::string op);
62:     int GetGeoDbusOp();
63:     std::string GetTypeStr();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/qsug/candidate_items.cc" line="60" id="suspicious" subid="autovar" severity="Warning" msg="Reference to auto variable returned." web_identify="{&quot;identify&quot;:&quot;return&quot;}" func_info="KeyWordItem &amp; CandidateItems::GetItem ( const int &amp; idx )" content="50:   return idx;
51: }
52: 
53: int CandidateItems::ItemsCount() {
54:   return items_.size();
55: }
56: 
57: KeyWordItem&amp; CandidateItems::GetItem(const int&amp; idx) {
58:   if (0 == items_.size() || idx &gt; items_.size() - 1) {
59:     KeyWordItem kw_word;
60:     return kw_word;
61:   }
62:   return items_[idx];
63: }
64:   
65: bool CandidateItems::GetCandidateKWItems(
66:     std::vector&lt;KeyWordItem&gt;&amp; kwitems,
67:     const InvertedList&amp; inverted_list,
68:     const int32&amp; page,
69:     const int32&amp; per_page) {
70:   int32 startPos = page * per_page;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/recall/recall_queue/multi_queue_manager.cpp" line="103" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [resp] to null at line 96 implies that [resp ] might be null.Dereferencing null pointer [resp]." web_identify="{&quot;identify&quot;:&quot;resp&quot;}" func_info="void MultiQueueManager::RunSingleQueueResponse ( boost::shared_ptr &lt; RecallSourceInterface &gt; src , boost::shared_ptr &lt; RecallQueueInterface &gt; queue , boost::shared_ptr &lt; RecallQueueContext &gt; queue_ctx , boost::shared_ptr &lt; FilterQueueContext &gt; filter_ctx , geocoding::AddrSearchResponse * resp )" content="93:         boost::shared_ptr&lt;RecallQueueContext&gt; queue_ctx,
94:         boost::shared_ptr&lt;FilterQueueContext&gt; filter_ctx,
95:         geocoding::AddrSearchResponse* resp) {
96:     if (resp == nullptr) {
97:         CLOG_STR_ERROR(&quot;empty resp in single queue&quot;);
98:     }
99:     queue-&gt;TotalResponse(resp,
100:             queue_ctx,
101:             filter_ctx,
102:             src);
103:     CLOG_STR_DEBUG(&quot;queue: &quot; &lt;&lt; queue-&gt;GetName() &lt;&lt; &quot; recall count:&quot; &lt;&lt; resp-&gt;search_hits.size() &lt;&lt; &quot; pointer:&quot; &lt;&lt; resp);
104: 
105: }
106: 
107: void MultiQueueManager::RunSingleSourceResponse(RecallSrcPtr src,
108:         boost::shared_ptr&lt;RecallQueueContext&gt; queue_ctx,
109:         boost::shared_ptr&lt;FilterQueueContext&gt; filter_ctx,
110:         geocoding::AddrSearchResponse* resp) {
111:     if (resp == nullptr) {
112:         CLOG_STR_ERROR(&quot;empty resp in single source&quot;);
113:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/recall/recall_queue/recall_queue.cpp" line="62" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [queue_ctx] to null at line 49 implies that [queue_ctx ] might be null.Dereferencing null pointer [queue_ctx]." web_identify="{&quot;identify&quot;:&quot;queue_ctx&quot;}" func_info="bool RecallQueueInterface::TotalResponse ( AddrSearchResponse * resp , boost::shared_ptr &lt; RecallQueueContext &gt; queue_ctx , boost::shared_ptr &lt; FilterQueueContext &gt; filter_ctx , boost::shared_ptr &lt; RecallSourceInterface &gt; src_inter )" content="52:             SetExpectCount(expect_map.at(GetName()));
53:         }
54:     }
55:     if (expect_count_ == 0) {
56:         return true;
57:     }
58:     //  CLOG_STR_ERROR(&quot;expect total:&quot; &lt;&lt; expect_count_);
59:     std::vector&lt;AddrSearchResponse&gt; resp_list;
60:     auto left_size = expect_count_;
61:     const auto&amp; analysis_result =
62:         queue_ctx-&gt;base_input.base_builder_req.query_analysis_result;
63:     const auto&amp; syntax_tree = analysis_result.syntax_tree;
64:     const auto&amp; token_list = queue_ctx-&gt;base_input.base_builder_req.token_list;
65:     for (size_t index = 0; index &lt; Size(); index++) {
66:         // CLOG_STR_ERROR(&quot;current left size:&quot; &lt;&lt; left_size);
67:         auto&amp; req = *GetAt(index);
68:         AddrSearchResponse curr_resp;
69:         req.from = 0;
70:         req.size = left_size;
71:         src_inter-&gt;AddrSingleRequest(req, &amp;curr_resp);
72:         if (curr_resp.search_total &lt; 0) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/scenario_filter/scenario_filter.cpp" line="97" id="suspicious" subid="SuspiciousPriority" severity="Information" msg="The priority of the &apos;+&apos; operation is higher than that of the &apos;&lt;&lt;&apos; operation. It&apos;s possible that parentheses should be used in the expression." web_identify="" func_info="bool ScenarioFilterList::Init ( const string &amp; conf_dir )" content="87:         std::string scenario =
88:             scenario_filter_files.scenario_filter(index).scenario();
89:         std::string conf_file =
90:             scenario_filter_files.scenario_filter(index).conf_file_name();
91:         if (scenario.empty()) {
92:             continue;
93:         }
94:         ScenarioFilterConfig scenario_filters;
95:         if (!::util::proto_util::ParseFromFile(
96:                  conf_dir + &quot;/filter_conf/&quot; + conf_file, &amp;scenario_filters)) {
97:             CLOG_STR_ERROR(&quot;ParseFromFile &quot; &lt;&lt; conf_dir + &quot;/filter_conf/&quot; +
98:                                                    conf_file &lt;&lt; &quot; fail&quot;);
99:             return false;
100:         }
101:         scenario_filter_config_[scenario] = scenario_filters;
102:     }
103:     return true;
104: }
105: 
106: }  // namespace geoinfo
107: }  // namespace mtmap
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoinfo/src/handler.cpp" line="95" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GeoInfoServletHandler::default_sugg_size_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GeoInfoServletHandler::default_sugg_size_,&quot;}" func_info="mtmap::geoinfo" content="85: using std::vector;
86: 
87: namespace {
88: const std::string kDebugMagicNumStr =
89:     boost::lexical_cast&lt;std::string&gt;(kDebugMagicNum);
90: }
91: 
92: namespace mtmap {
93: namespace geoinfo {
94: 
95: GeoInfoServletHandler::GeoInfoServletHandler() {
96:     // Your initialization goes here
97:     suggest_builder_ = nullptr;
98: }
99: 
100: bool GeoInfoServletHandler::Init(const std::string&amp; conf_dir) {
101:     // init protobuf config
102:     std::string search_conf_path = conf_dir + &quot;/search_config.conf&quot;;
103:     root_config search_conf_root;
104:     if (!::util::proto_util::ParseFromFile(search_conf_path,
105:                                            &amp;search_conf_root)) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geometry-algorithms/within/within.hpp" line="40" id="suspicious" subid="SuspiciousPriority" severity="Information" msg="Priority of the &apos;&amp;&amp;&apos; operation is higher than that of the &apos;||&apos; operation.It&apos;s possible that parentheses should be used in the expression." web_identify="{&quot;identify&quot;:&quot;&amp;&amp;&quot;}" func_info="&gt; bool algorithm::within ( const mapbox :: geometry :: point &lt; T &gt; &amp; pt , const mapbox :: geometry :: linear_ring &lt; T &gt; &amp; ring )" content="30: }
31: 
32: //pt ring
33: template &lt;typename T&gt;
34: bool within(const mapbox::geometry::point&lt;T&gt;&amp; pt, const mapbox::geometry::linear_ring&lt;T&gt;&amp; ring)
35: {
36:    int i,j = ring.size() -1 ;
37:    bool oddNodes =false;
38: 
39:    for (i = 0; i&lt;ring.size(); i++) {
40:        if (ring[i].y &lt; pt.y &amp;&amp; ring[j].y &gt;= pt.y || ring[j].y &lt; pt.y &amp;&amp; ring[i].y &gt;= pt.y)
41:        {   
42:            if(ring[i].x + (pt.y - ring[i].y) / (ring[j].y - ring[i].y) * (ring[j].x - ring[i].x) &lt; pt.x)
43:            {   
44:                oddNodes=!oddNodes;
45:            }   
46:        }   
47:        j=i;
48:    }   
49:   return oddNodes;
50: }
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoquery/query_location_search/query_token_backfill.cpp" line="52" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;;&quot;}" func_info="void QueryTokenBackfill::TokenBackfill ( QueryAnalysisResult * result , const mtmap::geotext::adapter::TokenList &amp; tokenlist )" content="42: 
43: void QueryTokenBackfill::TokenBackfill(QueryAnalysisResult* result,
44:                     const mtmap::geotext::adapter::TokenList&amp; tokenlist)
45: {
46:     std::string location_name;
47:     for (const auto&amp; location : result-&gt;geo.locations) {
48:         StringUtility::join(location_name,
49:                 {location.admin.province, location.admin.city,
50:                 location.admin.district, location.name, location.address},
51:                 std::string(&quot;_&quot;));
52:         break;
53:     }
54:     location_name = StringUtility::lower(location_name);
55: 
56:     for (const auto&amp; token : tokenlist.tokens) {
57:         if (IsBackfillType(token) || IsTokenHit(token, location_name)) {
58:             AppendTokenTerm(result-&gt;geo.terms, token);
59:         } else {
60:             if (token.leaves.empty()) {
61:                 AppendTokenTerm(result-&gt;plain.terms, token);
62:             } else {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/geoquery/src/server.cpp" line="163" id="suspicious" subid="autovar" severity="Warning" msg="Returning the address of a stack variable [server]." web_identify="{&quot;identify&quot;:&quot;server&quot;}" func_info="bool initServer ( )" content="153:                 );
154:         */
155:         CthriftSvr server(server_appkey, server_port, processor);
156:         server.SetConnGCInterval(30*24*60);
157:         server.SetMaxConNum(20000);
158:         server.SetOverTime(1000);
159:         server.SetWorkerThreadNum(64);
160:         server.SetServiceName(&quot;mtmap.geoquery.GeoQueryServlet&quot;);
161:         server.Init();
162: 
163:         g_server = &amp;server;
164: 
165:         LOG_WARN &lt;&lt; &quot;env:&quot; &lt;&lt; g_server-&gt;GetEnvInfo();
166: 
167:         g_server-&gt;serve();
168:     } catch (const cthrift::TException&amp; tx) {
169:         LOG_ERROR &lt;&lt; tx.what();
170:         return false;
171:     }
172: 
173:     handler-&gt;Stop();
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/rerank/src/feature/feature_calc_ctx.cpp" line="24" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;FeatureCalcCtx::feature_calc_result,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;FeatureCalcCtx::feature_calc_result,&quot;}" func_info="mtmap::rerank::feature" content="14: #include &quot;map/rerank/src/feature/feature_calc_ctx.h&quot;
15: #include &quot;map/rerank/src/util/const_values.h&quot;
16: 
17: // using mtmap::geocoding::AddrResult;
18: using mtmap::geotext::adapter::TokenList;
19: using mtmap::rerank::util::const_values::kDebugMagicNum;
20: namespace StringUtility = mtmap::geotext::string_utility;
21: namespace mtmap {
22: namespace rerank {
23: namespace feature {
24: FeatureCalcCtx::FeatureCalcCtx()
25:     : feature_calc_request(nullptr),
26:       graph(task_group_context),
27:       start_node(graph) {}
28: 
29: bool FeatureCalcCtx::IsDebug() {
30:     return feature_calc_request-&gt;debug &amp;&amp;
31:            feature_calc_request-&gt;debug == kDebugMagicNum;
32: }
33: 
34: void FeatureCalcCtx::AddDebugStr(std::string s) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/rerank/src/feature/feature_calc_excutor.cpp" line="39" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [request.feature_info] to null at line 35 implies that [request.feature_info ] might be null.Dereferencing null pointer [request.feature_info]." web_identify="{&quot;identify&quot;:&quot;request.feature_info&quot;}" func_info="ReturnCode::type FeatureCalcExcutor::Fit ( const FeatureCalcRequestInner &amp; request , FeatureCalcResult * result )" content="29:             request.doc_info-&gt;size()) {
30:         CLOG_STR_ERROR(&quot;doc_info size not equal to speed_up_doc_info size&quot;);
31:         return ReturnCode::BAD_PARAMETER;
32:     }
33:     ctx_.feature_calc_request = &amp;request;
34:     ctx_.feature_calc_result = result;
35:     if (!request.feature_info ||
36:         feature_info_.Parse(request.feature_info-&gt;c_str()).HasParseError()) {
37:         CLOG_STR_ERROR(
38:             &quot;invalid feature_info &quot;
39:             &lt;&lt; *request.feature_info &lt;&lt; &quot;, offset &quot;
40:             &lt;&lt; feature_info_.GetErrorOffset() &lt;&lt; &quot;, &quot;
41:             &lt;&lt; rapidjson::GetParseError_En(feature_info_.GetParseError()));
42:         return ReturnCode::BAD_PARAMETER;
43:     }
44:     auto features_iter = feature_info_.FindMember(&quot;features&quot;);
45:     if (features_iter == feature_info_.MemberEnd()) {
46:         CLOG_STR_ERROR(&quot;no features&quot;);
47:         return ReturnCode::BAD_PARAMETER;
48:     }
49:     if (!features_iter-&gt;value.IsArray()) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/rerank/src/feature/text_common_util.cpp" line="334" id="nullpointer" subid="dereferenceAfterCheck" severity="Serious" msg="Comparing [ctx.raw_query_analysis_result] to null at line 317 implies that [ctx.raw_query_analysis_result ] might be null.Dereferencing null pointer [ctx.raw_query_analysis_result]." web_identify="{&quot;identify&quot;:&quot;ctx.raw_query_analysis_result&quot;}" func_info="FitResult TextCommonUtil::FitQueryTransform ( FitRequest * fit_request )" content="324:             // 示例case:
325:             // 搜索‘北京天安门’，返回第一位的是‘北京天安门国际旅行社’,而不是‘天安门&apos;
326:             RemoveAdminToken(ctx-&gt;query_token_list.get());
327:         }
328:         fit_result.code = ReturnCode::SUCCESSFUL;
329:         fit_result.output_sender = fit_request-&gt;input_sender;
330:         return fit_result;
331:     }
332:     auto transform_node = new ContinueNode(ctx-&gt;graph, [ctx](GraphMessage) {
333:         ctx-&gt;query_token_list = std::make_unique&lt;TokenList&gt;(
334:             ctx-&gt;raw_query_analysis_result-&gt;tokenlist);
335:         RemoveQueryStop(ctx-&gt;query_token_list.get());
336:         RemoveAdminToken(ctx-&gt;query_token_list.get());
337:     });
338:     ctx-&gt;AddNode(key, std::unique_ptr&lt;ContinueNode&gt;(transform_node));
339:     tbb::flow::make_edge(*fit_query_analysis.output_sender, *transform_node);
340:     fit_result.code = ReturnCode::SUCCESSFUL;
341:     fit_result.output_sender = transform_node;
342:     return fit_result;
343: }
344: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_geojson/include/rapidjson/pointer.h" line="256" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: buffer" web_identify="{&quot;identify&quot;:&quot;buffer&quot;}" func_info="GenericPointer GenericPointer::Append ( int index , Allocator * allocator = 0 ) const" content="246: #endif
247: 
248:     //! Append a index token, and return a new Pointer
249:     /*!
250:         \param index Index to be appended.
251:         \param allocator Allocator for the newly return Pointer.
252:         \return A new Pointer with appended token.
253:     */
254:     GenericPointer Append(SizeType index, Allocator* allocator = 0) const {
255:         char buffer[21];
256:         SizeType length = (sizeof(SizeType) == 4 ? internal::u32toa(index, buffer): internal::u64toa(index, buffer)) - buffer;
257:         buffer[length] = &apos;\0&apos;;
258: 
259:         if (sizeof(Ch) == 1) {
260:             Token token = { (Ch*)buffer, length, index };
261:             return Append(token, allocator);
262:         }
263:         else {
264:             Ch name[21];
265:             for (size_t i = 0; i &lt;= length; i++)
266:                 name[i] = buffer[i];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/geometry/geometry/coordinates.hpp" line="62" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GcjEncryptor::_iix_,_iiy_,_iox_,_ioy_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GcjEncryptor::_iix_,_iiy_,_iox_,_ioy_,&quot;}" func_info="mapbox::geometry::GcjEncryptor" content="52:     unsigned int wgtochina_lb(int wg_flag, unsigned int wg_lng,
53:             unsigned int wg_lat, int wg_heit, int wg_week, unsigned int wg_time,
54:             unsigned int *china_lng, unsigned int *china_lat);
55: 
56: private:
57:     unsigned int _iix_, _iiy_;
58:     unsigned int _iox_, _ioy_;
59:     static const int _COFF_ = 3686400;
60: 
61: public:
62:     GcjEncryptor() {
63:         casm_rr = 0;
64:         casm_t1 = 0;
65:         casm_t2 = 0;
66:         casm_x1 = 0;
67:         casm_y1 = 0;
68:         casm_x2 = 0;
69:         casm_y2 = 0;
70:         casm_f = 0;
71:     }
72:     ~GcjEncryptor() {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/geometry/geometry/spatial_computing.hpp" line="80" id="suspicious" subid="SuspiciousPriority" severity="Information" msg="Priority of the &apos;&amp;&amp;&apos; operation is higher than that of the &apos;||&apos; operation.It&apos;s possible that parentheses should be used in the expression." web_identify="{&quot;identify&quot;:&quot;&amp;&amp;&quot;}" func_info="&gt; bool geometry::test_inPolygon ( const mapbox :: geometry :: point &lt; T &gt; pt , const mapbox :: geometry :: linear_ring &lt; T &gt; &amp; ring )" content="70: 	   (multiply(lineA[0], lineB[1], lineB[0])* multiply(lineB[1], lineA[1], lineB[0])&gt;=0));
71: }
72: 
73: template &lt;typename T&gt;
74: bool test_inPolygon(const mapbox::geometry::point&lt;T&gt; pt, const mapbox::geometry::linear_ring&lt;T&gt;&amp; ring)
75: {
76:    int i,j = ring.size() -1 ;
77:    bool oddNodes =false;
78: 
79:    for (i = 0; i&lt;ring.size(); i++) {
80:        if (ring[i].y &lt; pt.y &amp;&amp; ring[j].y &gt;= pt.y || ring[j].y &lt; pt.y &amp;&amp; ring[i].y &gt;= pt.y)
81:        {   
82:            if(ring[i].x + (pt.y - ring[i].y) / (ring[j].y - ring[i].y) * (ring[j].x - ring[i].x) &lt; pt.x)
83:            {   
84:                oddNodes=!oddNodes;
85:            }   
86:        }   
87:                j=i;
88:    }   
89: 
90:   return oddNodes;
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/internal/regex.h" line="264" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: n" web_identify="{&quot;identify&quot;:&quot;n&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="254:                     break;
255: 
256:                 case &apos;+&apos;:
257:                     if (!Eval(operandStack, kOneOrMore))
258:                         return;
259:                     break;
260: 
261:                 case &apos;{&apos;:
262:                     {
263:                         unsigned n, m;
264:                         if (!ParseUnsigned(ds, &amp;n))
265:                             return;
266: 
267:                         if (ds.Peek() == &apos;,&apos;) {
268:                             ds.Take();
269:                             if (ds.Peek() == &apos;}&apos;)
270:                                 m = kInfinityQuantifier;
271:                             else if (!ParseUnsigned(ds, &amp;m) || m &lt; n)
272:                                 return;
273:                         }
274:                         else
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/internal/regex.h" line="271" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: m" web_identify="{&quot;identify&quot;:&quot;m&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="261:                 case &apos;{&apos;:
262:                     {
263:                         unsigned n, m;
264:                         if (!ParseUnsigned(ds, &amp;n))
265:                             return;
266: 
267:                         if (ds.Peek() == &apos;,&apos;) {
268:                             ds.Take();
269:                             if (ds.Peek() == &apos;}&apos;)
270:                                 m = kInfinityQuantifier;
271:                             else if (!ParseUnsigned(ds, &amp;m) || m &lt; n)
272:                                 return;
273:                         }
274:                         else
275:                             m = n;
276: 
277:                         if (!EvalQuantifier(operandStack, n, m) || ds.Peek() != &apos;}&apos;)
278:                             return;
279:                         ds.Take();
280:                     }
281:                     break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/internal/regex.h" line="291" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: range" web_identify="{&quot;identify&quot;:&quot;range&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="281:                     break;
282: 
283:                 case &apos;.&apos;:
284:                     PushOperand(operandStack, kAnyCharacterClass);
285:                     ImplicitConcatenation(atomCountStack, operatorStack);
286:                     break;
287: 
288:                 case &apos;[&apos;:
289:                     {
290:                         SizeType range;
291:                         if (!ParseRange(ds, &amp;range))
292:                             return;
293:                         SizeType s = NewState(kRegexInvalidState, kRegexInvalidState, kRangeCharacterClass);
294:                         GetState(s).rangeStart = range;
295:                         *operandStack.template Push&lt;Frag&gt;() = Frag(s, s, s);
296:                     }
297:                     ImplicitConcatenation(atomCountStack, operatorStack);
298:                     break;
299: 
300:                 case &apos;\\&apos;: // Escape character
301:                     if (!CharacterEscape(ds, &amp;codepoint))
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/internal/regex.h" line="595" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: codepoint" web_identify="{&quot;identify&quot;:&quot;codepoint&quot;}" func_info="&gt; bool GenericRegex::CharacterEscape ( DecodedStream &lt; InputStream &gt; &amp; ds , int * escapedCodepoint )" content="585:             case &apos;)&apos;:
586:             case &apos;?&apos;:
587:             case &apos;*&apos;:
588:             case &apos;+&apos;:
589:             case &apos;.&apos;:
590:             case &apos;[&apos;:
591:             case &apos;]&apos;:
592:             case &apos;{&apos;:
593:             case &apos;}&apos;:
594:             case &apos;\\&apos;:
595:                 *escapedCodepoint = codepoint; return true;
596:             case &apos;f&apos;: *escapedCodepoint = 0x000C; return true;
597:             case &apos;n&apos;: *escapedCodepoint = 0x000A; return true;
598:             case &apos;r&apos;: *escapedCodepoint = 0x000D; return true;
599:             case &apos;t&apos;: *escapedCodepoint = 0x0009; return true;
600:             case &apos;v&apos;: *escapedCodepoint = 0x000B; return true;
601:             default:
602:                 return false; // Unsupported escape character
603:         }
604:     }
605: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/pointer.h" line="504" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;0&quot;}" func_info="internal::MaybeAddConst &lt; Const , PlainType &gt;::Type * GenericPointer::Get ( internal :: MaybeAddConst &lt; Const , PlainType &gt; :: Type &amp; root , long * unresolvedTokenIndex = 0 ) const" content="494:                     break;
495:                 v = &amp;((*v)[t-&gt;index]);
496:                 continue;
497:             default:
498:                 break;
499:             }
500: 
501:             // Error: unresolved token
502:             if (unresolvedTokenIndex)
503:                 *unresolvedTokenIndex = static_cast&lt;size_t&gt;(t - tokens_);
504:             return 0;
505:         }
506:         return v;
507:     }
508: 
509:     //! Query a const value in a const subtree.
510:     /*!
511:         \param root Root value of a DOM sub-tree to be resolved. It can be any value other than document root.
512:         \return Pointer to the value if it can be resolved. Otherwise null.
513:     */
514:     const ValueType* Get(const ValueType&amp; root, size_t* unresolvedTokenIndex = 0) const { 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="1268" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: buffer" web_identify="{&quot;identify&quot;:&quot;buffer&quot;}" func_info="static void TokenHelper::AppendIndexToken ( Stack &amp; documentStack , int index )" content="1258:     SValue multipleOf_;
1259:     bool exclusiveMinimum_;
1260:     bool exclusiveMaximum_;
1261: };
1262: 
1263: template&lt;typename Stack, typename Ch&gt;
1264: struct TokenHelper {
1265:     RAPIDJSON_FORCEINLINE static void AppendIndexToken(Stack&amp; documentStack, SizeType index) {
1266:         *documentStack.template Push&lt;Ch&gt;() = &apos;/&apos;;
1267:         char buffer[21];
1268:         size_t length = static_cast&lt;size_t&gt;((sizeof(SizeType) == 4 ? u32toa(index, buffer) : u64toa(index, buffer)) - buffer);
1269:         for (size_t i = 0; i &lt; length; i++)
1270:             *documentStack.template Push&lt;Ch&gt;() = buffer[i];
1271:     }
1272: };
1273: 
1274: // Partial specialized version for char to prevent buffer copying.
1275: template &lt;typename Stack&gt;
1276: struct TokenHelper&lt;Stack, char&gt; {
1277:     RAPIDJSON_FORCEINLINE static void AppendIndexToken(Stack&amp; documentStack, SizeType index) {
1278:         if (sizeof(SizeType) == 4) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="465" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="455:                     properties_[i].name = allProperties[i];
456:                     properties_[i].schema = GetTypeless();
457:                 }
458:             }
459:         }
460: 
461:         if (properties &amp;&amp; properties-&gt;IsObject()) {
462:             PointerType q = p.Append(GetPropertiesString(), allocator_);
463:             for (ConstMemberIterator itr = properties-&gt;MemberBegin(); itr != properties-&gt;MemberEnd(); ++itr) {
464:                 SizeType index;
465:                 if (FindPropertyIndex(itr-&gt;name, &amp;index))
466:                     schemaDocument-&gt;CreateSchema(&amp;properties_[index].schema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
467:             }
468:         }
469: 
470:         if (const ValueType* v = GetMember(value, GetPatternPropertiesString())) {
471:             PointerType q = p.Append(GetPatternPropertiesString(), allocator_);
472:             patternProperties_ = static_cast&lt;PatternProperty*&gt;(allocator_-&gt;Malloc(sizeof(PatternProperty) * v-&gt;MemberCount()));
473:             patternPropertyCount_ = 0;
474: 
475:             for (ConstMemberIterator itr = v-&gt;MemberBegin(); itr != v-&gt;MemberEnd(); ++itr) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="487" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="477:                 patternProperties_[patternPropertyCount_].pattern = CreatePattern(itr-&gt;name);
478:                 schemaDocument-&gt;CreateSchema(&amp;patternProperties_[patternPropertyCount_].schema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
479:                 patternPropertyCount_++;
480:             }
481:         }
482: 
483:         if (required &amp;&amp; required-&gt;IsArray())
484:             for (ConstValueIterator itr = required-&gt;Begin(); itr != required-&gt;End(); ++itr)
485:                 if (itr-&gt;IsString()) {
486:                     SizeType index;
487:                     if (FindPropertyIndex(*itr, &amp;index)) {
488:                         properties_[index].required = true;
489:                         hasRequired_ = true;
490:                     }
491:                 }
492: 
493:         if (dependencies &amp;&amp; dependencies-&gt;IsObject()) {
494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="498" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: sourceIndex" web_identify="{&quot;identify&quot;:&quot;sourceIndex&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="488:                         properties_[index].required = true;
489:                         hasRequired_ = true;
490:                     }
491:                 }
492: 
493:         if (dependencies &amp;&amp; dependencies-&gt;IsObject()) {
494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
498:                 if (FindPropertyIndex(itr-&gt;name, &amp;sourceIndex)) {
499:                     if (itr-&gt;value.IsArray()) {
500:                         properties_[sourceIndex].dependencies = static_cast&lt;bool*&gt;(allocator_-&gt;Malloc(sizeof(bool) * propertyCount_));
501:                         std::memset(properties_[sourceIndex].dependencies, 0, sizeof(bool)* propertyCount_);
502:                         for (ConstValueIterator targetItr = itr-&gt;value.Begin(); targetItr != itr-&gt;value.End(); ++targetItr) {
503:                             SizeType targetIndex;
504:                             if (FindPropertyIndex(*targetItr, &amp;targetIndex))
505:                                 properties_[sourceIndex].dependencies[targetIndex] = true;
506:                         }
507:                     }
508:                     else if (itr-&gt;value.IsObject()) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="504" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: targetIndex" web_identify="{&quot;identify&quot;:&quot;targetIndex&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
498:                 if (FindPropertyIndex(itr-&gt;name, &amp;sourceIndex)) {
499:                     if (itr-&gt;value.IsArray()) {
500:                         properties_[sourceIndex].dependencies = static_cast&lt;bool*&gt;(allocator_-&gt;Malloc(sizeof(bool) * propertyCount_));
501:                         std::memset(properties_[sourceIndex].dependencies, 0, sizeof(bool)* propertyCount_);
502:                         for (ConstValueIterator targetItr = itr-&gt;value.Begin(); targetItr != itr-&gt;value.End(); ++targetItr) {
503:                             SizeType targetIndex;
504:                             if (FindPropertyIndex(*targetItr, &amp;targetIndex))
505:                                 properties_[sourceIndex].dependencies[targetIndex] = true;
506:                         }
507:                     }
508:                     else if (itr-&gt;value.IsObject()) {
509:                         hasSchemaDependencies_ = true;
510:                         schemaDocument-&gt;CreateSchema(&amp;properties_[sourceIndex].dependenciesSchema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
511:                         properties_[sourceIndex].dependenciesValidatorIndex = validatorCount_;
512:                         validatorCount_++;
513:                     }
514:                 }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="792" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="bool Schema::Key ( SchemaValidationContext &lt; SchemaDocumentType &gt; &amp; context , const typename EncodingType :: Ch * str , int len , bool ) const" content="782:     
783:     bool Key(Context&amp; context, const Ch* str, SizeType len, bool) const {
784:         if (patternProperties_) {
785:             context.patternPropertiesSchemaCount = 0;
786:             for (SizeType i = 0; i &lt; patternPropertyCount_; i++)
787:                 if (patternProperties_[i].pattern &amp;&amp; IsPatternMatch(patternProperties_[i].pattern, str, len))
788:                     context.patternPropertiesSchemas[context.patternPropertiesSchemaCount++] = patternProperties_[i].schema;
789:         }
790: 
791:         SizeType index;
792:         if (FindPropertyIndex(ValueType(str, len).Move(), &amp;index)) {
793:             if (context.patternPropertiesSchemaCount &gt; 0) {
794:                 context.patternPropertiesSchemas[context.patternPropertiesSchemaCount++] = properties_[index].schema;
795:                 context.valueSchema = GetTypeless();
796:                 context.valuePatternValidatorType = Context::kPatternValidatorWithProperty;
797:             }
798:             else
799:                 context.valueSchema = properties_[index].schema;
800: 
801:             if (context.propertyExist)
802:                 context.propertyExist[index] = true;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/admin_make_index/include/rapidjson/schema.h" line="945" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SchemaArray::begin,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SchemaArray::begin,&quot;}" func_info="rapidjson::internal::Schema::SchemaArray" content="935: 
936: #if RAPIDJSON_SCHEMA_USE_INTERNALREGEX
937:         typedef internal::GenericRegex&lt;EncodingType&gt; RegexType;
938: #elif RAPIDJSON_SCHEMA_USE_STDREGEX
939:         typedef std::basic_regex&lt;Ch&gt; RegexType;
940: #else
941:         typedef char RegexType;
942: #endif
943: 
944:     struct SchemaArray {
945:         SchemaArray() : schemas(), count() {}
946:         ~SchemaArray() { AllocatorType::Free(schemas); }
947:         const SchemaType** schemas;
948:         SizeType begin; // begin index of context.validators
949:         SizeType count;
950:     };
951: 
952:     static const SchemaType* GetTypeless() {
953:         static SchemaType typeless(0, PointerType(), ValueType(kObjectType).Move(), ValueType(kObjectType).Move(), 0);
954:         return &amp;typeless;
955:     }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_geojson/include/rapidjson/pointer.h" line="256" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: buffer" web_identify="{&quot;identify&quot;:&quot;buffer&quot;}" func_info="GenericPointer GenericPointer::Append ( int index , Allocator * allocator = 0 ) const" content="246: #endif
247: 
248:     //! Append a index token, and return a new Pointer
249:     /*!
250:         \param index Index to be appended.
251:         \param allocator Allocator for the newly return Pointer.
252:         \return A new Pointer with appended token.
253:     */
254:     GenericPointer Append(SizeType index, Allocator* allocator = 0) const {
255:         char buffer[21];
256:         SizeType length = (sizeof(SizeType) == 4 ? internal::u32toa(index, buffer): internal::u64toa(index, buffer)) - buffer;
257:         buffer[length] = &apos;\0&apos;;
258: 
259:         if (sizeof(Ch) == 1) {
260:             Token token = { (Ch*)buffer, length, index };
261:             return Append(token, allocator);
262:         }
263:         else {
264:             Ch name[21];
265:             for (size_t i = 0; i &lt;= length; i++)
266:                 name[i] = buffer[i];
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/geometry/geometry/coordinates.hpp" line="62" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;GcjEncryptor::_iix_,_iiy_,_iox_,_ioy_,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;GcjEncryptor::_iix_,_iiy_,_iox_,_ioy_,&quot;}" func_info="mapbox::geometry::GcjEncryptor" content="52:     unsigned int wgtochina_lb(int wg_flag, unsigned int wg_lng,
53:             unsigned int wg_lat, int wg_heit, int wg_week, unsigned int wg_time,
54:             unsigned int *china_lng, unsigned int *china_lat);
55: 
56: private:
57:     unsigned int _iix_, _iiy_;
58:     unsigned int _iox_, _ioy_;
59:     static const int _COFF_ = 3686400;
60: 
61: public:
62:     GcjEncryptor() {
63:         casm_rr = 0;
64:         casm_t1 = 0;
65:         casm_t2 = 0;
66:         casm_x1 = 0;
67:         casm_y1 = 0;
68:         casm_x2 = 0;
69:         casm_y2 = 0;
70:         casm_f = 0;
71:     }
72:     ~GcjEncryptor() {}
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/geometry/geometry/spatial_computing.hpp" line="80" id="suspicious" subid="SuspiciousPriority" severity="Information" msg="Priority of the &apos;&amp;&amp;&apos; operation is higher than that of the &apos;||&apos; operation.It&apos;s possible that parentheses should be used in the expression." web_identify="{&quot;identify&quot;:&quot;&amp;&amp;&quot;}" func_info="&gt; bool geometry::test_inPolygon ( const mapbox :: geometry :: point &lt; T &gt; pt , const mapbox :: geometry :: linear_ring &lt; T &gt; &amp; ring )" content="70: 	   (multiply(lineA[0], lineB[1], lineB[0])* multiply(lineB[1], lineA[1], lineB[0])&gt;=0));
71: }
72: 
73: template &lt;typename T&gt;
74: bool test_inPolygon(const mapbox::geometry::point&lt;T&gt; pt, const mapbox::geometry::linear_ring&lt;T&gt;&amp; ring)
75: {
76:    int i,j = ring.size() -1 ;
77:    bool oddNodes =false;
78: 
79:    for (i = 0; i&lt;ring.size(); i++) {
80:        if (ring[i].y &lt; pt.y &amp;&amp; ring[j].y &gt;= pt.y || ring[j].y &lt; pt.y &amp;&amp; ring[i].y &gt;= pt.y)
81:        {   
82:            if(ring[i].x + (pt.y - ring[i].y) / (ring[j].y - ring[i].y) * (ring[j].x - ring[i].x) &lt; pt.x)
83:            {   
84:                oddNodes=!oddNodes;
85:            }   
86:        }   
87:                j=i;
88:    }   
89: 
90:   return oddNodes;
" inconclusive="true"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/internal/regex.h" line="264" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: n" web_identify="{&quot;identify&quot;:&quot;n&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="254:                     break;
255: 
256:                 case &apos;+&apos;:
257:                     if (!Eval(operandStack, kOneOrMore))
258:                         return;
259:                     break;
260: 
261:                 case &apos;{&apos;:
262:                     {
263:                         unsigned n, m;
264:                         if (!ParseUnsigned(ds, &amp;n))
265:                             return;
266: 
267:                         if (ds.Peek() == &apos;,&apos;) {
268:                             ds.Take();
269:                             if (ds.Peek() == &apos;}&apos;)
270:                                 m = kInfinityQuantifier;
271:                             else if (!ParseUnsigned(ds, &amp;m) || m &lt; n)
272:                                 return;
273:                         }
274:                         else
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/internal/regex.h" line="271" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: m" web_identify="{&quot;identify&quot;:&quot;m&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="261:                 case &apos;{&apos;:
262:                     {
263:                         unsigned n, m;
264:                         if (!ParseUnsigned(ds, &amp;n))
265:                             return;
266: 
267:                         if (ds.Peek() == &apos;,&apos;) {
268:                             ds.Take();
269:                             if (ds.Peek() == &apos;}&apos;)
270:                                 m = kInfinityQuantifier;
271:                             else if (!ParseUnsigned(ds, &amp;m) || m &lt; n)
272:                                 return;
273:                         }
274:                         else
275:                             m = n;
276: 
277:                         if (!EvalQuantifier(operandStack, n, m) || ds.Peek() != &apos;}&apos;)
278:                             return;
279:                         ds.Take();
280:                     }
281:                     break;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/internal/regex.h" line="291" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: range" web_identify="{&quot;identify&quot;:&quot;range&quot;}" func_info="&gt; void GenericRegex::Parse ( DecodedStream &lt; InputStream &gt; &amp; ds )" content="281:                     break;
282: 
283:                 case &apos;.&apos;:
284:                     PushOperand(operandStack, kAnyCharacterClass);
285:                     ImplicitConcatenation(atomCountStack, operatorStack);
286:                     break;
287: 
288:                 case &apos;[&apos;:
289:                     {
290:                         SizeType range;
291:                         if (!ParseRange(ds, &amp;range))
292:                             return;
293:                         SizeType s = NewState(kRegexInvalidState, kRegexInvalidState, kRangeCharacterClass);
294:                         GetState(s).rangeStart = range;
295:                         *operandStack.template Push&lt;Frag&gt;() = Frag(s, s, s);
296:                     }
297:                     ImplicitConcatenation(atomCountStack, operatorStack);
298:                     break;
299: 
300:                 case &apos;\\&apos;: // Escape character
301:                     if (!CharacterEscape(ds, &amp;codepoint))
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/internal/regex.h" line="595" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: codepoint" web_identify="{&quot;identify&quot;:&quot;codepoint&quot;}" func_info="&gt; bool GenericRegex::CharacterEscape ( DecodedStream &lt; InputStream &gt; &amp; ds , int * escapedCodepoint )" content="585:             case &apos;)&apos;:
586:             case &apos;?&apos;:
587:             case &apos;*&apos;:
588:             case &apos;+&apos;:
589:             case &apos;.&apos;:
590:             case &apos;[&apos;:
591:             case &apos;]&apos;:
592:             case &apos;{&apos;:
593:             case &apos;}&apos;:
594:             case &apos;\\&apos;:
595:                 *escapedCodepoint = codepoint; return true;
596:             case &apos;f&apos;: *escapedCodepoint = 0x000C; return true;
597:             case &apos;n&apos;: *escapedCodepoint = 0x000A; return true;
598:             case &apos;r&apos;: *escapedCodepoint = 0x000D; return true;
599:             case &apos;t&apos;: *escapedCodepoint = 0x0009; return true;
600:             case &apos;v&apos;: *escapedCodepoint = 0x000B; return true;
601:             default:
602:                 return false; // Unsupported escape character
603:         }
604:     }
605: 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/pointer.h" line="504" id="suspicious" subid="unConditionalBreakinLoop" severity="Warning" msg="An unconditional &apos;break/return/goto&apos; within a loop.It may be a mistake." web_identify="{&quot;identify&quot;:&quot;0&quot;}" func_info="internal::MaybeAddConst &lt; Const , PlainType &gt;::Type * GenericPointer::Get ( internal :: MaybeAddConst &lt; Const , PlainType &gt; :: Type &amp; root , long * unresolvedTokenIndex = 0 ) const" content="494:                     break;
495:                 v = &amp;((*v)[t-&gt;index]);
496:                 continue;
497:             default:
498:                 break;
499:             }
500: 
501:             // Error: unresolved token
502:             if (unresolvedTokenIndex)
503:                 *unresolvedTokenIndex = static_cast&lt;size_t&gt;(t - tokens_);
504:             return 0;
505:         }
506:         return v;
507:     }
508: 
509:     //! Query a const value in a const subtree.
510:     /*!
511:         \param root Root value of a DOM sub-tree to be resolved. It can be any value other than document root.
512:         \return Pointer to the value if it can be resolved. Otherwise null.
513:     */
514:     const ValueType* Get(const ValueType&amp; root, size_t* unresolvedTokenIndex = 0) const { 
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="1268" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: buffer" web_identify="{&quot;identify&quot;:&quot;buffer&quot;}" func_info="static void TokenHelper::AppendIndexToken ( Stack &amp; documentStack , int index )" content="1258:     SValue multipleOf_;
1259:     bool exclusiveMinimum_;
1260:     bool exclusiveMaximum_;
1261: };
1262: 
1263: template&lt;typename Stack, typename Ch&gt;
1264: struct TokenHelper {
1265:     RAPIDJSON_FORCEINLINE static void AppendIndexToken(Stack&amp; documentStack, SizeType index) {
1266:         *documentStack.template Push&lt;Ch&gt;() = &apos;/&apos;;
1267:         char buffer[21];
1268:         size_t length = static_cast&lt;size_t&gt;((sizeof(SizeType) == 4 ? u32toa(index, buffer) : u64toa(index, buffer)) - buffer);
1269:         for (size_t i = 0; i &lt; length; i++)
1270:             *documentStack.template Push&lt;Ch&gt;() = buffer[i];
1271:     }
1272: };
1273: 
1274: // Partial specialized version for char to prevent buffer copying.
1275: template &lt;typename Stack&gt;
1276: struct TokenHelper&lt;Stack, char&gt; {
1277:     RAPIDJSON_FORCEINLINE static void AppendIndexToken(Stack&amp; documentStack, SizeType index) {
1278:         if (sizeof(SizeType) == 4) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="465" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="455:                     properties_[i].name = allProperties[i];
456:                     properties_[i].schema = GetTypeless();
457:                 }
458:             }
459:         }
460: 
461:         if (properties &amp;&amp; properties-&gt;IsObject()) {
462:             PointerType q = p.Append(GetPropertiesString(), allocator_);
463:             for (ConstMemberIterator itr = properties-&gt;MemberBegin(); itr != properties-&gt;MemberEnd(); ++itr) {
464:                 SizeType index;
465:                 if (FindPropertyIndex(itr-&gt;name, &amp;index))
466:                     schemaDocument-&gt;CreateSchema(&amp;properties_[index].schema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
467:             }
468:         }
469: 
470:         if (const ValueType* v = GetMember(value, GetPatternPropertiesString())) {
471:             PointerType q = p.Append(GetPatternPropertiesString(), allocator_);
472:             patternProperties_ = static_cast&lt;PatternProperty*&gt;(allocator_-&gt;Malloc(sizeof(PatternProperty) * v-&gt;MemberCount()));
473:             patternPropertyCount_ = 0;
474: 
475:             for (ConstMemberIterator itr = v-&gt;MemberBegin(); itr != v-&gt;MemberEnd(); ++itr) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="487" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="477:                 patternProperties_[patternPropertyCount_].pattern = CreatePattern(itr-&gt;name);
478:                 schemaDocument-&gt;CreateSchema(&amp;patternProperties_[patternPropertyCount_].schema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
479:                 patternPropertyCount_++;
480:             }
481:         }
482: 
483:         if (required &amp;&amp; required-&gt;IsArray())
484:             for (ConstValueIterator itr = required-&gt;Begin(); itr != required-&gt;End(); ++itr)
485:                 if (itr-&gt;IsString()) {
486:                     SizeType index;
487:                     if (FindPropertyIndex(*itr, &amp;index)) {
488:                         properties_[index].required = true;
489:                         hasRequired_ = true;
490:                     }
491:                 }
492: 
493:         if (dependencies &amp;&amp; dependencies-&gt;IsObject()) {
494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="498" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: sourceIndex" web_identify="{&quot;identify&quot;:&quot;sourceIndex&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="488:                         properties_[index].required = true;
489:                         hasRequired_ = true;
490:                     }
491:                 }
492: 
493:         if (dependencies &amp;&amp; dependencies-&gt;IsObject()) {
494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
498:                 if (FindPropertyIndex(itr-&gt;name, &amp;sourceIndex)) {
499:                     if (itr-&gt;value.IsArray()) {
500:                         properties_[sourceIndex].dependencies = static_cast&lt;bool*&gt;(allocator_-&gt;Malloc(sizeof(bool) * propertyCount_));
501:                         std::memset(properties_[sourceIndex].dependencies, 0, sizeof(bool)* propertyCount_);
502:                         for (ConstValueIterator targetItr = itr-&gt;value.Begin(); targetItr != itr-&gt;value.End(); ++targetItr) {
503:                             SizeType targetIndex;
504:                             if (FindPropertyIndex(*targetItr, &amp;targetIndex))
505:                                 properties_[sourceIndex].dependencies[targetIndex] = true;
506:                         }
507:                     }
508:                     else if (itr-&gt;value.IsObject()) {
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="504" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: targetIndex" web_identify="{&quot;identify&quot;:&quot;targetIndex&quot;}" func_info="Schema::Schema ( SchemaDocumentType * schemaDocument , const typename SchemaDocumentType :: PointerType &amp; p , const typename SchemaDocumentType :: ValueType &amp; 1 , const typename SchemaDocumentType :: ValueType &amp; document , typename SchemaDocumentType :: AllocatorType * allocator ) : allocator_ ( allocator ) , enum_ ( ) , enumCount_ ( ) , not_ ( ) , type_ ( ( 1 &lt;&lt; kTotalSchemaType ) - 1 ) , validatorCount_ ( ) , properties_ ( ) , additionalPropertiesSchema_ ( ) , patternProperties_ ( ) , patternPropertyCount_ ( ) , propertyCount_ ( ) , minProperties_ ( ) , maxProperties_ ( int ( ~ 0 ) ) , additionalProperties_ ( true ) , hasDependencies_ ( ) , hasRequired_ ( ) , hasSchemaDependencies_ ( ) , additionalItemsSchema_ ( ) , itemsList_ ( ) , itemsTuple_ ( ) , itemsTupleCount_ ( ) , minItems_ ( ) , maxItems_ ( int ( ~ 0 ) ) , additionalItems_ ( true ) , uniqueItems_ ( false ) , pattern_ ( ) , minLength_ ( 0 ) , maxLength_ ( ~ int ( 0 ) ) , exclusiveMinimum_ ( false ) , exclusiveMaximum_ ( false )" content="494:             PointerType q = p.Append(GetDependenciesString(), allocator_);
495:             hasDependencies_ = true;
496:             for (ConstMemberIterator itr = dependencies-&gt;MemberBegin(); itr != dependencies-&gt;MemberEnd(); ++itr) {
497:                 SizeType sourceIndex;
498:                 if (FindPropertyIndex(itr-&gt;name, &amp;sourceIndex)) {
499:                     if (itr-&gt;value.IsArray()) {
500:                         properties_[sourceIndex].dependencies = static_cast&lt;bool*&gt;(allocator_-&gt;Malloc(sizeof(bool) * propertyCount_));
501:                         std::memset(properties_[sourceIndex].dependencies, 0, sizeof(bool)* propertyCount_);
502:                         for (ConstValueIterator targetItr = itr-&gt;value.Begin(); targetItr != itr-&gt;value.End(); ++targetItr) {
503:                             SizeType targetIndex;
504:                             if (FindPropertyIndex(*targetItr, &amp;targetIndex))
505:                                 properties_[sourceIndex].dependencies[targetIndex] = true;
506:                         }
507:                     }
508:                     else if (itr-&gt;value.IsObject()) {
509:                         hasSchemaDependencies_ = true;
510:                         schemaDocument-&gt;CreateSchema(&amp;properties_[sourceIndex].dependenciesSchema, q.Append(itr-&gt;name, allocator_), itr-&gt;value, document);
511:                         properties_[sourceIndex].dependenciesValidatorIndex = validatorCount_;
512:                         validatorCount_++;
513:                     }
514:                 }
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="792" id="uninit" subid="uninitvar" severity="Serious" msg="Uninitialized variable: index" web_identify="{&quot;identify&quot;:&quot;index&quot;}" func_info="bool Schema::Key ( SchemaValidationContext &lt; SchemaDocumentType &gt; &amp; context , const typename EncodingType :: Ch * str , int len , bool ) const" content="782:     
783:     bool Key(Context&amp; context, const Ch* str, SizeType len, bool) const {
784:         if (patternProperties_) {
785:             context.patternPropertiesSchemaCount = 0;
786:             for (SizeType i = 0; i &lt; patternPropertyCount_; i++)
787:                 if (patternProperties_[i].pattern &amp;&amp; IsPatternMatch(patternProperties_[i].pattern, str, len))
788:                     context.patternPropertiesSchemas[context.patternPropertiesSchemaCount++] = patternProperties_[i].schema;
789:         }
790: 
791:         SizeType index;
792:         if (FindPropertyIndex(ValueType(str, len).Move(), &amp;index)) {
793:             if (context.patternPropertiesSchemaCount &gt; 0) {
794:                 context.patternPropertiesSchemas[context.patternPropertiesSchemaCount++] = properties_[index].schema;
795:                 context.valueSchema = GetTypeless();
796:                 context.valuePatternValidatorType = Context::kPatternValidatorWithProperty;
797:             }
798:             else
799:                 context.valueSchema = properties_[index].schema;
800: 
801:             if (context.propertyExist)
802:                 context.propertyExist[index] = true;
"/>
    <error file="/Users/yangbo7/Code/MT/cmap/map/revgeo/make_index/rgc_make_index/include/rapidjson/schema.h" line="945" id="uninit" subid="uninitMemberVar" severity="Warning" msg="Member variable &apos;SchemaArray::begin,&apos; is not initialized in the constructor." web_identify="{&quot;identify&quot;:&quot;SchemaArray::begin,&quot;}" func_info="rapidjson::internal::Schema::SchemaArray" content="935: 
936: #if RAPIDJSON_SCHEMA_USE_INTERNALREGEX
937:         typedef internal::GenericRegex&lt;EncodingType&gt; RegexType;
938: #elif RAPIDJSON_SCHEMA_USE_STDREGEX
939:         typedef std::basic_regex&lt;Ch&gt; RegexType;
940: #else
941:         typedef char RegexType;
942: #endif
943: 
944:     struct SchemaArray {
945:         SchemaArray() : schemas(), count() {}
946:         ~SchemaArray() { AllocatorType::Free(schemas); }
947:         const SchemaType** schemas;
948:         SizeType begin; // begin index of context.validators
949:         SizeType count;
950:     };
951: 
952:     static const SchemaType* GetTypeless() {
953:         static SchemaType typeless(0, PointerType(), ValueType(kObjectType).Move(), ValueType(kObjectType).Move(), 0);
954:         return &amp;typeless;
955:     }
"/>

</results>
